{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import skimage as ski\n",
    "import skimage.io\n",
    "\n",
    "from im2col_cython import col2im_cython, im2col_cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ZADATAK\n",
    "\n",
    "Dovr≈°ite implementacije potpuno povezanog sloja, sloja nelinearnosti te funkcije gubitka u razredima FC, ReLU i SoftmaxCrossEntropyWithLogits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_init = np.zeros\n",
    "\n",
    "def variance_scaling_initializer(shape, fan_in, factor=2.0, seed=None):\n",
    "    sigma = np.sqrt(factor / fan_in)\n",
    "    return stats.truncnorm(-2, 2, loc=0, scale=sigma).rvs(shape)\n",
    "\n",
    "\n",
    "# -- ABSTRACT CLASS DEFINITION --\n",
    "class Layer(metaclass = ABCMeta):\n",
    "    \"Interface for layers\"\n",
    "    # See documentation of abstract base classes (ABC): https://docs.python.org/3/library/abc.html\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          inputs: ndarray tensor.\n",
    "        Returns:\n",
    "          ndarray tensor, result of the forward pass.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def backward_inputs(self, grads):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          grads: gradient of the loss with respect to the output of the layer.\n",
    "        Returns:\n",
    "          Gradient of the loss with respect to the input of the layer.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def backward_params(self, grads):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          grads: gradient of the loss with respect to the output of the layer.\n",
    "        Returns:\n",
    "          Gradient of the loss with respect to all the parameters of the layer as a list\n",
    "          [[w0, g0], ..., [wk, gk], self.name] where w are parameter weights and g their gradient.\n",
    "          Note that wk and gk must have the same shape.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "# -- CONVOLUTION LAYER --\n",
    "class Convolution(Layer):\n",
    "    \"N-dimensional convolution layer\"\n",
    "\n",
    "    def __init__(self, input_layer, num_filters, kernel_size, name, padding='SAME',\n",
    "               weights_initializer_fn=variance_scaling_initializer,\n",
    "               bias_initializer_fn=zero_init):\n",
    "        self.input_shape = input_layer.shape\n",
    "        N, C, H, W = input_layer.shape\n",
    "        self.C = C\n",
    "        self.N = N\n",
    "        self.num_filters = num_filters\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        assert kernel_size % 2 == 1\n",
    "\n",
    "        self.padding = padding\n",
    "\n",
    "        if padding == 'SAME':\n",
    "            # with zero padding\n",
    "            self.shape = (N, num_filters, H, W)\n",
    "            self.pad = (kernel_size - 1) // 2\n",
    "        else:\n",
    "            # without padding\n",
    "            self.shape = (N, num_filters, H - kernel_size + 1, W - kernel_size + 1)\n",
    "            self.pad = 0\n",
    "\n",
    "        fan_in = C * kernel_size**2\n",
    "        self.weights = weights_initializer_fn([num_filters, kernel_size**2 * C], fan_in)\n",
    "        self.bias = bias_initializer_fn([num_filters])\n",
    "        # this implementation doesn't support strided convolutions\n",
    "        self.stride = 1\n",
    "        self.name = name\n",
    "        self.has_params = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        k = self.kernel_size\n",
    "        self.x_cols = im2col_cython(x, k, k, self.pad, self.stride)\n",
    "        res = self.weights.dot(self.x_cols) + self.bias.reshape(-1, 1)\n",
    "        N, C, H, W = x.shape\n",
    "        out = res.reshape(self.num_filters, self.shape[2], self.shape[3], N)\n",
    "        return out.transpose(3, 0, 1, 2)\n",
    "\n",
    "    def backward_inputs(self, grad_out):\n",
    "        # nice trick from CS231n, backward pass can be done with just matrix mul and col2im\n",
    "        grad_out = grad_out.transpose(1, 2, 3, 0).reshape(self.num_filters, -1)\n",
    "        grad_x_cols = self.weights.T.dot(grad_out)\n",
    "        N, C, H, W = self.input_shape\n",
    "        k = self.kernel_size\n",
    "        grad_x = col2im_cython(grad_x_cols, N, C, H, W, k, k, self.pad, self.stride)\n",
    "        return grad_x\n",
    "\n",
    "    def backward_params(self, grad_out):\n",
    "        grad_bias = np.sum(grad_out, axis=(0, 2, 3))\n",
    "        grad_out = grad_out.transpose(1, 2, 3, 0).reshape(self.num_filters, -1)\n",
    "        grad_weights = grad_out.dot(self.x_cols.T).reshape(self.weights.shape)\n",
    "        return [[self.weights, grad_weights], [self.bias, grad_bias], self.name]\n",
    "\n",
    "\n",
    "class MaxPooling(Layer):\n",
    "    def __init__(self, input_layer, name, pool_size=2, stride=2):\n",
    "        self.name = name\n",
    "        self.input_shape = input_layer.shape\n",
    "        N, C, H, W = self.input_shape\n",
    "        self.stride = stride\n",
    "        self.shape = (N, C, H // stride, W // stride)\n",
    "        self.pool_size = pool_size\n",
    "        assert pool_size == stride, 'Invalid pooling params'\n",
    "        assert H % pool_size == 0\n",
    "        assert W % pool_size == 0\n",
    "        self.has_params = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        self.input_shape = x.shape\n",
    "        # with this clever reshaping we can implement pooling where pool_size == stride\n",
    "        self.x = x.reshape(N, C, H // self.pool_size, self.pool_size,\n",
    "                           W // self.pool_size, self.pool_size)\n",
    "        self.out = self.x.max(axis=3).max(axis=4)\n",
    "        # if you are returning class member be sure to return a copy\n",
    "        return self.out.copy()\n",
    "\n",
    "    def backward_inputs(self, grad_out):\n",
    "        grad_x = np.zeros_like(self.x)\n",
    "        out_newaxis = self.out[:, :, :, np.newaxis, :, np.newaxis]\n",
    "        mask = (self.x == out_newaxis)\n",
    "        dout_newaxis = grad_out[:, :, :, np.newaxis, :, np.newaxis]\n",
    "        dout_broadcast, _ = np.broadcast_arrays(dout_newaxis, grad_x)\n",
    "        # this is almost the same as the real backward pass\n",
    "        grad_x[mask] = dout_broadcast[mask]\n",
    "        # in the very rare case that more then one input have the same max value\n",
    "        # we can aprox the real gradient routing by evenly distributing across multiple inputs\n",
    "        # but in almost all cases this sum will be 1\n",
    "        grad_x /= np.sum(mask, axis=(3, 5), keepdims=True)\n",
    "        grad_x = grad_x.reshape(self.input_shape)\n",
    "        return grad_x\n",
    "\n",
    "\n",
    "class Flatten(Layer):\n",
    "    def __init__(self, input_layer, name):\n",
    "        self.input_shape = input_layer.shape\n",
    "        self.N = self.input_shape[0]\n",
    "        self.num_outputs = 1\n",
    "        for i in range(1, len(self.input_shape)):\n",
    "            self.num_outputs *= self.input_shape[i]\n",
    "        self.shape = (self.N, self.num_outputs)\n",
    "        self.has_params = False\n",
    "        self.name = name\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.input_shape = inputs.shape\n",
    "        inputs_flat = inputs.reshape(self.input_shape[0], -1)\n",
    "        self.shape = inputs_flat.shape\n",
    "        return inputs_flat\n",
    "\n",
    "    def backward_inputs(self, grads):\n",
    "        return grads.reshape(self.input_shape)\n",
    "\n",
    "\n",
    "class FC(Layer):\n",
    "    def __init__(self, input_layer, num_outputs, name,\n",
    "               weights_initializer_fn=variance_scaling_initializer,\n",
    "               bias_initializer_fn=zero_init):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          input_layer: layer below\n",
    "          num_outputs: number of neurons in this layer\n",
    "          weights_initializer_fn: initializer function for weights,\n",
    "          bias_initializer_fn: initializer function for biases\n",
    "        \"\"\"\n",
    "\n",
    "        self.input_shape = input_layer.shape\n",
    "        self.N = self.input_shape[0]\n",
    "        self.shape = (self.N, num_outputs)\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "        self.num_inputs = 1\n",
    "        for i in range(1, len(self.input_shape)):\n",
    "            self.num_inputs *= self.input_shape[i]\n",
    "\n",
    "        self.weights = weights_initializer_fn([num_outputs, self.num_inputs], fan_in=self.num_inputs)\n",
    "        self.bias = bias_initializer_fn([num_outputs])\n",
    "        self.name = name\n",
    "        self.has_params = True\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          inputs: ndarray of shape (N, num_inputs)\n",
    "        Returns:\n",
    "          An ndarray of shape (N, num_outputs)\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        return inputs.dot(self.weights.T) + self.bias\n",
    "\n",
    "    def backward_inputs(self, grads):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          grads: ndarray of shape (N, num_outputs)\n",
    "        Returns:\n",
    "          An ndarray of shape (N, num_inputs)\n",
    "        \"\"\"\n",
    "        return grads.dot(self.weights)\n",
    "\n",
    "    def backward_params(self, grads):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          grads: ndarray of shape (N, num_outputs)\n",
    "        Returns:\n",
    "          List of params and gradient pairs.\n",
    "        \"\"\"\n",
    "        grad_weights = grads.T.dot(self.inputs)\n",
    "        grad_bias = grads.sum(axis = 0)\n",
    "        return [[self.weights, grad_weights], [self.bias, grad_bias], self.name]\n",
    "\n",
    "\n",
    "\n",
    "class ReLU(Layer):\n",
    "    def __init__(self, input_layer, name):\n",
    "        self.shape = input_layer.shape\n",
    "        self.name = name\n",
    "        self.has_params = False\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          inputs: ndarray of shape (N, C, H, W).\n",
    "        Returns:\n",
    "          ndarray of shape (N, C, H, W).\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        return np.maximum(0, inputs)\n",
    "\n",
    "    def backward_inputs(self, grads):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          grads: ndarray of shape (N, C, H, W).\n",
    "        Returns:\n",
    "          ndarray of shape (N, C, H, W).\n",
    "        \"\"\"\n",
    "        grads[self.inputs < 0] = 0\n",
    "        return grads\n",
    "\n",
    "def softmax(x):\n",
    "    x -= np.max(x)\n",
    "    logits_exp = np.exp(x)\n",
    "    return logits_exp / np.sum(logits_exp, axis=1, keepdims=True)\n",
    "\n",
    "class SoftmaxCrossEntropyWithLogits():\n",
    "    def __init__(self):\n",
    "        self.has_params = False\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x: ndarray of shape (N, num_classes).\n",
    "          y: ndarray of shape (N, num_classes).\n",
    "        Returns:\n",
    "          Scalar, average loss over N examples.\n",
    "          It is better to compute average loss here instead of just sum\n",
    "          because then learning rate and weight decay won't depend on batch size.\n",
    "\n",
    "        \"\"\"\n",
    "        return (y * -np.log(softmax(x))).sum(axis=1).mean()\n",
    "\n",
    "    def backward_inputs(self, x, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x: ndarray of shape (N, num_classes).\n",
    "          y: ndarray of shape (N, num_classes).\n",
    "        Returns:\n",
    "          Gradient with respect to the x, ndarray of shape (N, num_classes).\n",
    "        \"\"\"\n",
    "        # Hint: don't forget that we took the average in the forward pass\n",
    "        N = len(x)\n",
    "        return (softmax(x) - y) / N\n",
    "\n",
    "\n",
    "class L2Regularizer():\n",
    "    def __init__(self, weights, weight_decay, name):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          weights: parameters which will be regularizerized\n",
    "          weight_decay: lambda, regularization strength\n",
    "          name: layer name\n",
    "        \"\"\"\n",
    "        # this is still a reference to original tensor so don't change self.weights\n",
    "        self.weights = weights\n",
    "        self.weight_decay = weight_decay\n",
    "        self.name = name\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "         Returns:\n",
    "          Scalar, loss due to the L2 regularization.\n",
    "        \"\"\"\n",
    "        return self.weight_decay * 0.5 * np.sum(self.weights * self.weights)\n",
    "\n",
    "    def backward_params(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "          Gradient of the L2 loss with respect to the regularized weights.\n",
    "        \"\"\"\n",
    "        grad_weights = self.weight_decay * self.weights\n",
    "        return [[self.weights, grad_weights], self.name]\n",
    "\n",
    "\n",
    "class RegularizedLoss():\n",
    "    def __init__(self, data_loss, regularizer_losses):\n",
    "        self.data_loss = data_loss\n",
    "        self.regularizer_losses = regularizer_losses\n",
    "        self.has_params = True\n",
    "        self.name = 'RegularizedLoss'\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        loss_val = self.data_loss.forward(x, y)\n",
    "        for loss in self.regularizer_losses:\n",
    "            loss_val += loss.forward()\n",
    "        return loss_val\n",
    "\n",
    "    def backward_inputs(self, x, y):\n",
    "        return self.data_loss.backward_inputs(x, y)\n",
    "\n",
    "    def backward_params(self):\n",
    "        grads = []\n",
    "        for loss in self.regularizer_losses:\n",
    "            grads += [loss.backward_params()]\n",
    "        return grads\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution\n",
      "Check grad wrt input\n",
      "Relative error =  7.1781396328e-09\n",
      "Error norm =  4.08426369364e-10\n",
      "Check grad wrt params\n",
      "Check weights:\n",
      "Relative error =  3.79737411839e-10\n",
      "Error norm =  3.9800787816e-10\n",
      "Check biases:\n",
      "Relative error =  1.3861585688e-12\n",
      "Error norm =  4.00344010748e-11\n",
      "\n",
      "MaxPooling\n",
      "Check grad wrt input\n",
      "Relative error =  3.27563595128e-12\n",
      "Error norm =  9.20217924051e-11\n",
      "\n",
      "ReLU\n",
      "Check grad wrt input\n",
      "Relative error =  3.27562605199e-12\n",
      "Error norm =  4.55006932058e-11\n",
      "\n",
      "FC\n",
      "Check grad wrt input\n",
      "Relative error =  7.54229391412e-08\n",
      "Error norm =  7.10190512924e-10\n",
      "Check grad wrt params\n",
      "Check weights:\n",
      "Relative error =  2.82027039502e-09\n",
      "Error norm =  7.4205428145e-10\n",
      "Check biases:\n",
      "Relative error =  3.50880153745e-11\n",
      "Error norm =  1.01330545962e-10\n",
      "\n",
      "SoftmaxCrossEntropyWithLogits\n",
      "Relative error =  4.27615033983e-07\n",
      "Error norm =  5.07774274724e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"\\nL2Regularizer\")\\nx = np.random.randn(5, 4, 8, 8)\\ngrad_out = np.random.randn(5, 4, 4, 4)\\nl2reg = L2Regularizer(x, 1e-2, \\'L2reg\\')\\nprint(\"Check grad wrt params\")\\nfunc = lambda params: l2reg.forward()\\ngrad_num = eval_numerical_gradient(func, l2reg.weights, 1)\\ngrads = l2reg.backward_params()\\ngrad = grads[0][1]\\nprint(\"Relative error = \", rel_error(grad_num, grad))\\nprint(\"Error norm = \", np.linalg.norm(grad_num - grad))\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "def eval_numerical_gradient(f, x, df, h=1e-5):\n",
    "    \"\"\"\n",
    "    Evaluate a numeric gradient for a function that accepts a numpy\n",
    "    array and returns a numpy array.\n",
    "    - f should be a function that takes a single argument\n",
    "    - x is the point (numpy array) to evaluate the gradient at\n",
    "    \"\"\"\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h\n",
    "        # evaluate f(x + h)\n",
    "        pos = f(x.copy()).copy()\n",
    "        x[ix] = oldval - h\n",
    "        # evaluate f(x - h)\n",
    "        neg = f(x.copy()).copy()\n",
    "        x[ix] = oldval\n",
    "\n",
    "        # compute the partial derivative with centered formula\n",
    "        grad[ix] = np.sum((pos - neg) * df) / (2 * h)\n",
    "        # step to next dimension\n",
    "        it.iternext()\n",
    "    return grad\n",
    "\n",
    "def check_grad_inputs(layer, x, grad_out):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    layer: Layer object\n",
    "    x: ndarray tensor input data\n",
    "    grad_out: ndarray tensor gradient from the next layer\n",
    "    \"\"\"\n",
    "    grad_x_num = eval_numerical_gradient(layer.forward, x, grad_out)\n",
    "    grad_x = layer.backward_inputs(grad_out)\n",
    "    print(\"Relative error = \", rel_error(grad_x_num, grad_x))\n",
    "    print(\"Error norm = \", np.linalg.norm(grad_x_num - grad_x))\n",
    "\n",
    "def check_grad_params(layer, x, w, b, grad_out):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    layer: Layer object\n",
    "    x: ndarray tensor input data\n",
    "    w: ndarray tensor layer weights\n",
    "    b: ndarray tensor layer biases\n",
    "    grad_out: ndarray tensor gradient from the next layer\n",
    "    \"\"\"\n",
    "    func = lambda params: layer.forward(x)\n",
    "    grad_w_num = eval_numerical_gradient(func, w, grad_out)\n",
    "    grad_b_num = eval_numerical_gradient(func, b, grad_out)\n",
    "    grads = layer.backward_params(grad_out)\n",
    "    grad_w = grads[0][1]\n",
    "    grad_b = grads[1][1]\n",
    "    print(\"Check weights:\")\n",
    "    print(\"Relative error = \", rel_error(grad_w_num, grad_w))\n",
    "    print(\"Error norm = \", np.linalg.norm(grad_w_num - grad_w))\n",
    "    print(\"Check biases:\")\n",
    "    print(\"Relative error = \", rel_error(grad_b_num, grad_b))\n",
    "    print(\"Error norm = \", np.linalg.norm(grad_b_num - grad_b))\n",
    "\n",
    "print(\"Convolution\")\n",
    "x = np.random.randn(4, 3, 5, 5)\n",
    "grad_out = np.random.randn(4, 2, 5, 5)\n",
    "conv = Convolution(x, 2, 3, \"conv1\")\n",
    "print(\"Check grad wrt input\")\n",
    "check_grad_inputs(conv, x, grad_out)\n",
    "print(\"Check grad wrt params\")\n",
    "check_grad_params(conv, x, conv.weights, conv.bias, grad_out)\n",
    "\n",
    "print(\"\\nMaxPooling\")\n",
    "x = np.random.randn(5, 4, 8, 8)\n",
    "grad_out = np.random.randn(5, 4, 4, 4)\n",
    "pool = MaxPooling(x, \"pool\", 2, 2)\n",
    "print(\"Check grad wrt input\")\n",
    "check_grad_inputs(pool, x, grad_out)\n",
    "\n",
    "print(\"\\nReLU\")\n",
    "x = np.random.randn(4, 3, 5, 5)\n",
    "grad_out = np.random.randn(4, 3, 5, 5)\n",
    "relu = ReLU(x, \"relu\")\n",
    "print(\"Check grad wrt input\")\n",
    "check_grad_inputs(relu, x, grad_out)\n",
    "\n",
    "print(\"\\nFC\")\n",
    "x = np.random.randn(20, 40)\n",
    "grad_out = np.random.randn(20, 30)\n",
    "fc = FC(x, 30, \"fc\")\n",
    "print(\"Check grad wrt input\")\n",
    "check_grad_inputs(fc, x, grad_out)\n",
    "print(\"Check grad wrt params\")\n",
    "check_grad_params(fc, x, fc.weights, fc.bias, grad_out)\n",
    "\n",
    "print(\"\\nSoftmaxCrossEntropyWithLogits\")\n",
    "x = np.random.randn(50, 20)\n",
    "y = np.zeros([50, 20])\n",
    "y[:,0] = 1\n",
    "loss = SoftmaxCrossEntropyWithLogits()\n",
    "grad_x_num = eval_numerical_gradient(lambda x: loss.forward(x, y), x, 1)\n",
    "out = loss.forward(x, y)\n",
    "grad_x = loss.backward_inputs(x, y)\n",
    "print(\"Relative error = \", rel_error(grad_x_num, grad_x))\n",
    "print(\"Error norm = \", np.linalg.norm(grad_x_num - grad_x))\n",
    "\n",
    "\"\"\"\n",
    "print(\"\\nL2Regularizer\")\n",
    "x = np.random.randn(5, 4, 8, 8)\n",
    "grad_out = np.random.randn(5, 4, 4, 4)\n",
    "l2reg = L2Regularizer(x, 1e-2, 'L2reg')\n",
    "print(\"Check grad wrt params\")\n",
    "func = lambda params: l2reg.forward()\n",
    "grad_num = eval_numerical_gradient(func, l2reg.weights, 1)\n",
    "grads = l2reg.backward_params()\n",
    "grad = grads[0][1]\n",
    "print(\"Relative error = \", rel_error(grad_num, grad))\n",
    "print(\"Error norm = \", np.linalg.norm(grad_num - grad))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_pass(net, inputs):\n",
    "    output = inputs\n",
    "    for layer in net:\n",
    "        output = layer.forward(output)\n",
    "    return output\n",
    "\n",
    "\n",
    "def backward_pass(net, loss, x, y):\n",
    "    grads = []\n",
    "    grad_out = loss.backward_inputs(x, y)\n",
    "    if loss.has_params:\n",
    "        grads += loss.backward_params()\n",
    "    for layer in reversed(net):\n",
    "        grad_inputs = layer.backward_inputs(grad_out)\n",
    "        if layer.has_params:\n",
    "            grads += [layer.backward_params(grad_out)]\n",
    "        grad_out = grad_inputs\n",
    "    return grads\n",
    "\n",
    "def sgd_update_params(grads, config):\n",
    "    lr = config['lr']\n",
    "    for layer_grads in grads:\n",
    "        for i in range(len(layer_grads) - 1):\n",
    "            params = layer_grads[i][0]\n",
    "            grads = layer_grads[i][1]\n",
    "            #print(layer_grads[-1], \" -> \", grads.sum())\n",
    "            params -= lr * grads\n",
    "\n",
    "\n",
    "def draw_conv_filters(epoch, step, layer, save_dir):\n",
    "    C = layer.C\n",
    "    w = layer.weights.copy()\n",
    "    num_filters = w.shape[0]\n",
    "    k = int(np.sqrt(w.shape[1] / C))\n",
    "    w = w.reshape(num_filters, C, k, k)\n",
    "    w -= w.min()\n",
    "    w /= w.max()\n",
    "    border = 1\n",
    "    cols = 8\n",
    "    rows = math.ceil(num_filters / cols)\n",
    "    width = cols * k + (cols-1) * border\n",
    "    height = rows * k + (rows-1) * border\n",
    "    #for i in range(C):\n",
    "    for i in range(1):\n",
    "        img = np.zeros([height, width])\n",
    "        \n",
    "        for j in range(num_filters):\n",
    "            r = int(j / cols) * (k + border)\n",
    "            c = int(j % cols) * (k + border)\n",
    "            img[r:r+k,c:c+k] = w[j,i]\n",
    "            \n",
    "        filename = '%s_epoch_%02d_step_%06d_input_%03d.png' % (layer.name, epoch, step, i)\n",
    "        ski.io.imsave(os.path.join(save_dir, filename), img)\n",
    "\n",
    "\n",
    "def train(train_x, train_y, valid_x, valid_y, net, loss, config):\n",
    "    lr_policy = config['lr_policy']\n",
    "    batch_size = config['batch_size']\n",
    "    max_epochs = config['max_epochs']\n",
    "    save_dir = config['save_dir']\n",
    "    num_examples = train_x.shape[0]\n",
    "    assert num_examples % batch_size == 0\n",
    "    num_batches = num_examples // batch_size\n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        if epoch in lr_policy:\n",
    "            solver_config = lr_policy[epoch]\n",
    "            \n",
    "        cnt_correct = 0\n",
    "        #for i in range(num_batches):\n",
    "        # shuffle the data at the beggining of each epoch\n",
    "        permutation_idx = np.random.permutation(num_examples)\n",
    "        train_x = train_x[permutation_idx]\n",
    "        train_y = train_y[permutation_idx]\n",
    "        #for i in range(100):\n",
    "        for i in range(num_batches):\n",
    "            # store mini-batch to ndarray\n",
    "            batch_x = train_x[i*batch_size:(i+1)*batch_size, :]\n",
    "            batch_y = train_y[i*batch_size:(i+1)*batch_size, :]\n",
    "            logits = forward_pass(net, batch_x)\n",
    "            loss_val = loss.forward(logits, batch_y)\n",
    "            # compute classification accuracy\n",
    "            yp = np.argmax(logits, 1)\n",
    "            yt = np.argmax(batch_y, 1)\n",
    "            cnt_correct += (yp == yt).sum()\n",
    "            grads = backward_pass(net, loss, logits, batch_y)\n",
    "            sgd_update_params(grads, solver_config)\n",
    "            \n",
    "            if i % 5 == 0:\n",
    "                print(\"epoch %d, step %d/%d, batch loss = %.2f\" % (epoch, i*batch_size, num_examples, loss_val))\n",
    "                \n",
    "            if i % 100 == 0:\n",
    "                draw_conv_filters(epoch, i*batch_size, net[0], save_dir)\n",
    "                #draw_conv_filters(epoch, i*batch_size, net[3])\n",
    "            if i > 0 and i % 50 == 0:\n",
    "                print(\"Train accuracy = %.2f\" % (cnt_correct / ((i+1)*batch_size) * 100))\n",
    "        print(\"Train accuracy = %.2f\" % (cnt_correct / num_examples * 100))\n",
    "        evaluate(\"Validation\", valid_x, valid_y, net, loss, config)\n",
    "    return net\n",
    "\n",
    "\n",
    "def evaluate(name, x, y, net, loss, config):\n",
    "    print(\"\\nRunning evaluation: \", name)\n",
    "    batch_size = config['batch_size']\n",
    "    num_examples = x.shape[0]\n",
    "    assert num_examples % batch_size == 0\n",
    "    num_batches = num_examples // batch_size\n",
    "    cnt_correct = 0\n",
    "    loss_avg = 0\n",
    "    for i in range(num_batches):\n",
    "        batch_x = x[i*batch_size:(i+1)*batch_size, :]\n",
    "        batch_y = y[i*batch_size:(i+1)*batch_size, :]\n",
    "        logits = forward_pass(net, batch_x)\n",
    "        yp = np.argmax(logits, 1)\n",
    "        yt = np.argmax(batch_y, 1)\n",
    "        cnt_correct += (yp == yt).sum()\n",
    "        loss_val = loss.forward(logits, batch_y)\n",
    "        loss_avg += loss_val\n",
    "        #print(\"step %d / %d, loss = %.2f\" % (i*batch_size, num_examples, loss_val / batch_size))\n",
    "    valid_acc = cnt_correct / num_examples * 100\n",
    "    loss_avg /= num_batches\n",
    "    print(name + \" accuracy = %.2f\" % valid_acc)\n",
    "    print(name + \" avg loss = %.2f\\n\" % loss_avg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Training without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "tf.app.flags.DEFINE_string('data_dir', \n",
    "  '/tmp/data/', 'Directory for storing data')\n",
    "mnist = input_data.read_data_sets(\n",
    "  tf.app.flags.FLAGS.data_dir, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 0/55000, batch loss = 2.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Anaconda/anaconda/lib/python3.5/site-packages/skimage/util/dtype.py:110: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 250/55000, batch loss = 1.96\n",
      "epoch 1, step 500/55000, batch loss = 1.45\n",
      "epoch 1, step 750/55000, batch loss = 0.94\n",
      "epoch 1, step 1000/55000, batch loss = 0.58\n",
      "epoch 1, step 1250/55000, batch loss = 0.64\n",
      "epoch 1, step 1500/55000, batch loss = 0.47\n",
      "epoch 1, step 1750/55000, batch loss = 0.71\n",
      "epoch 1, step 2000/55000, batch loss = 0.29\n",
      "epoch 1, step 2250/55000, batch loss = 0.44\n",
      "epoch 1, step 2500/55000, batch loss = 0.40\n",
      "Train accuracy = 70.39\n",
      "epoch 1, step 2750/55000, batch loss = 0.18\n",
      "epoch 1, step 3000/55000, batch loss = 0.33\n",
      "epoch 1, step 3250/55000, batch loss = 0.31\n",
      "epoch 1, step 3500/55000, batch loss = 0.38\n",
      "epoch 1, step 3750/55000, batch loss = 0.43\n",
      "epoch 1, step 4000/55000, batch loss = 0.15\n",
      "epoch 1, step 4250/55000, batch loss = 0.50\n",
      "epoch 1, step 4500/55000, batch loss = 0.42\n",
      "epoch 1, step 4750/55000, batch loss = 0.16\n",
      "epoch 1, step 5000/55000, batch loss = 0.30\n",
      "Train accuracy = 80.83\n",
      "epoch 1, step 5250/55000, batch loss = 0.18\n",
      "epoch 1, step 5500/55000, batch loss = 0.13\n",
      "epoch 1, step 5750/55000, batch loss = 0.15\n",
      "epoch 1, step 6000/55000, batch loss = 0.24\n",
      "epoch 1, step 6250/55000, batch loss = 0.13\n",
      "epoch 1, step 6500/55000, batch loss = 0.14\n",
      "epoch 1, step 6750/55000, batch loss = 0.10\n",
      "epoch 1, step 7000/55000, batch loss = 0.11\n",
      "epoch 1, step 7250/55000, batch loss = 0.25\n",
      "epoch 1, step 7500/55000, batch loss = 0.16\n",
      "Train accuracy = 85.36\n",
      "epoch 1, step 7750/55000, batch loss = 0.14\n",
      "epoch 1, step 8000/55000, batch loss = 0.15\n",
      "epoch 1, step 8250/55000, batch loss = 0.08\n",
      "epoch 1, step 8500/55000, batch loss = 0.24\n",
      "epoch 1, step 8750/55000, batch loss = 0.21\n",
      "epoch 1, step 9000/55000, batch loss = 0.18\n",
      "epoch 1, step 9250/55000, batch loss = 0.05\n",
      "epoch 1, step 9500/55000, batch loss = 0.15\n",
      "epoch 1, step 9750/55000, batch loss = 0.25\n",
      "epoch 1, step 10000/55000, batch loss = 0.07\n",
      "Train accuracy = 87.90\n",
      "epoch 1, step 10250/55000, batch loss = 0.24\n",
      "epoch 1, step 10500/55000, batch loss = 0.21\n",
      "epoch 1, step 10750/55000, batch loss = 0.14\n",
      "epoch 1, step 11000/55000, batch loss = 0.11\n",
      "epoch 1, step 11250/55000, batch loss = 0.22\n",
      "epoch 1, step 11500/55000, batch loss = 0.05\n",
      "epoch 1, step 11750/55000, batch loss = 0.15\n",
      "epoch 1, step 12000/55000, batch loss = 0.06\n",
      "epoch 1, step 12250/55000, batch loss = 0.45\n",
      "epoch 1, step 12500/55000, batch loss = 0.06\n",
      "Train accuracy = 89.63\n",
      "epoch 1, step 12750/55000, batch loss = 0.08\n",
      "epoch 1, step 13000/55000, batch loss = 0.18\n",
      "epoch 1, step 13250/55000, batch loss = 0.09\n",
      "epoch 1, step 13500/55000, batch loss = 0.19\n",
      "epoch 1, step 13750/55000, batch loss = 0.17\n",
      "epoch 1, step 14000/55000, batch loss = 0.29\n",
      "epoch 1, step 14250/55000, batch loss = 0.05\n",
      "epoch 1, step 14500/55000, batch loss = 0.11\n",
      "epoch 1, step 14750/55000, batch loss = 0.01\n",
      "epoch 1, step 15000/55000, batch loss = 0.16\n",
      "Train accuracy = 90.78\n",
      "epoch 1, step 15250/55000, batch loss = 0.06\n",
      "epoch 1, step 15500/55000, batch loss = 0.18\n",
      "epoch 1, step 15750/55000, batch loss = 0.08\n",
      "epoch 1, step 16000/55000, batch loss = 0.03\n",
      "epoch 1, step 16250/55000, batch loss = 0.20\n",
      "epoch 1, step 16500/55000, batch loss = 0.08\n",
      "epoch 1, step 16750/55000, batch loss = 0.24\n",
      "epoch 1, step 17000/55000, batch loss = 0.03\n",
      "epoch 1, step 17250/55000, batch loss = 0.16\n",
      "epoch 1, step 17500/55000, batch loss = 0.21\n",
      "Train accuracy = 91.69\n",
      "epoch 1, step 17750/55000, batch loss = 0.09\n",
      "epoch 1, step 18000/55000, batch loss = 0.16\n",
      "epoch 1, step 18250/55000, batch loss = 0.04\n",
      "epoch 1, step 18500/55000, batch loss = 0.12\n",
      "epoch 1, step 18750/55000, batch loss = 0.08\n",
      "epoch 1, step 19000/55000, batch loss = 0.09\n",
      "epoch 1, step 19250/55000, batch loss = 0.21\n",
      "epoch 1, step 19500/55000, batch loss = 0.15\n",
      "epoch 1, step 19750/55000, batch loss = 0.03\n",
      "epoch 1, step 20000/55000, batch loss = 0.04\n",
      "Train accuracy = 92.34\n",
      "epoch 1, step 20250/55000, batch loss = 0.05\n",
      "epoch 1, step 20500/55000, batch loss = 0.08\n",
      "epoch 1, step 20750/55000, batch loss = 0.07\n",
      "epoch 1, step 21000/55000, batch loss = 0.12\n",
      "epoch 1, step 21250/55000, batch loss = 0.05\n",
      "epoch 1, step 21500/55000, batch loss = 0.22\n",
      "epoch 1, step 21750/55000, batch loss = 0.03\n",
      "epoch 1, step 22000/55000, batch loss = 0.08\n",
      "epoch 1, step 22250/55000, batch loss = 0.13\n",
      "epoch 1, step 22500/55000, batch loss = 0.07\n",
      "Train accuracy = 92.87\n",
      "epoch 1, step 22750/55000, batch loss = 0.08\n",
      "epoch 1, step 23000/55000, batch loss = 0.11\n",
      "epoch 1, step 23250/55000, batch loss = 0.05\n",
      "epoch 1, step 23500/55000, batch loss = 0.12\n",
      "epoch 1, step 23750/55000, batch loss = 0.22\n",
      "epoch 1, step 24000/55000, batch loss = 0.14\n",
      "epoch 1, step 24250/55000, batch loss = 0.15\n",
      "epoch 1, step 24500/55000, batch loss = 0.09\n",
      "epoch 1, step 24750/55000, batch loss = 0.19\n",
      "epoch 1, step 25000/55000, batch loss = 0.12\n",
      "Train accuracy = 93.26\n",
      "epoch 1, step 25250/55000, batch loss = 0.10\n",
      "epoch 1, step 25500/55000, batch loss = 0.11\n",
      "epoch 1, step 25750/55000, batch loss = 0.02\n",
      "epoch 1, step 26000/55000, batch loss = 0.26\n",
      "epoch 1, step 26250/55000, batch loss = 0.01\n",
      "epoch 1, step 26500/55000, batch loss = 0.03\n",
      "epoch 1, step 26750/55000, batch loss = 0.03\n",
      "epoch 1, step 27000/55000, batch loss = 0.01\n",
      "epoch 1, step 27250/55000, batch loss = 0.09\n",
      "epoch 1, step 27500/55000, batch loss = 0.11\n",
      "Train accuracy = 93.67\n",
      "epoch 1, step 27750/55000, batch loss = 0.06\n",
      "epoch 1, step 28000/55000, batch loss = 0.16\n",
      "epoch 1, step 28250/55000, batch loss = 0.30\n",
      "epoch 1, step 28500/55000, batch loss = 0.18\n",
      "epoch 1, step 28750/55000, batch loss = 0.01\n",
      "epoch 1, step 29000/55000, batch loss = 0.08\n",
      "epoch 1, step 29250/55000, batch loss = 0.04\n",
      "epoch 1, step 29500/55000, batch loss = 0.02\n",
      "epoch 1, step 29750/55000, batch loss = 0.16\n",
      "epoch 1, step 30000/55000, batch loss = 0.09\n",
      "Train accuracy = 93.96\n",
      "epoch 1, step 30250/55000, batch loss = 0.03\n",
      "epoch 1, step 30500/55000, batch loss = 0.08\n",
      "epoch 1, step 30750/55000, batch loss = 0.01\n",
      "epoch 1, step 31000/55000, batch loss = 0.09\n",
      "epoch 1, step 31250/55000, batch loss = 0.09\n",
      "epoch 1, step 31500/55000, batch loss = 0.16\n",
      "epoch 1, step 31750/55000, batch loss = 0.07\n",
      "epoch 1, step 32000/55000, batch loss = 0.02\n",
      "epoch 1, step 32250/55000, batch loss = 0.03\n",
      "epoch 1, step 32500/55000, batch loss = 0.08\n",
      "Train accuracy = 94.23\n",
      "epoch 1, step 32750/55000, batch loss = 0.13\n",
      "epoch 1, step 33000/55000, batch loss = 0.06\n",
      "epoch 1, step 33250/55000, batch loss = 0.03\n",
      "epoch 1, step 33500/55000, batch loss = 0.05\n",
      "epoch 1, step 33750/55000, batch loss = 0.08\n",
      "epoch 1, step 34000/55000, batch loss = 0.23\n",
      "epoch 1, step 34250/55000, batch loss = 0.02\n",
      "epoch 1, step 34500/55000, batch loss = 0.07\n",
      "epoch 1, step 34750/55000, batch loss = 0.06\n",
      "epoch 1, step 35000/55000, batch loss = 0.21\n",
      "Train accuracy = 94.47\n",
      "epoch 1, step 35250/55000, batch loss = 0.02\n",
      "epoch 1, step 35500/55000, batch loss = 0.18\n",
      "epoch 1, step 35750/55000, batch loss = 0.04\n",
      "epoch 1, step 36000/55000, batch loss = 0.01\n",
      "epoch 1, step 36250/55000, batch loss = 0.04\n",
      "epoch 1, step 36500/55000, batch loss = 0.02\n",
      "epoch 1, step 36750/55000, batch loss = 0.05\n",
      "epoch 1, step 37000/55000, batch loss = 0.08\n",
      "epoch 1, step 37250/55000, batch loss = 0.01\n",
      "epoch 1, step 37500/55000, batch loss = 0.04\n",
      "Train accuracy = 94.67\n",
      "epoch 1, step 37750/55000, batch loss = 0.19\n",
      "epoch 1, step 38000/55000, batch loss = 0.08\n",
      "epoch 1, step 38250/55000, batch loss = 0.06\n",
      "epoch 1, step 38500/55000, batch loss = 0.03\n",
      "epoch 1, step 38750/55000, batch loss = 0.13\n",
      "epoch 1, step 39000/55000, batch loss = 0.02\n",
      "epoch 1, step 39250/55000, batch loss = 0.03\n",
      "epoch 1, step 39500/55000, batch loss = 0.09\n",
      "epoch 1, step 39750/55000, batch loss = 0.07\n",
      "epoch 1, step 40000/55000, batch loss = 0.05\n",
      "Train accuracy = 94.93\n",
      "epoch 1, step 40250/55000, batch loss = 0.15\n",
      "epoch 1, step 40500/55000, batch loss = 0.10\n",
      "epoch 1, step 40750/55000, batch loss = 0.09\n",
      "epoch 1, step 41000/55000, batch loss = 0.05\n",
      "epoch 1, step 41250/55000, batch loss = 0.08\n",
      "epoch 1, step 41500/55000, batch loss = 0.20\n",
      "epoch 1, step 41750/55000, batch loss = 0.06\n",
      "epoch 1, step 42000/55000, batch loss = 0.19\n",
      "epoch 1, step 42250/55000, batch loss = 0.06\n",
      "epoch 1, step 42500/55000, batch loss = 0.15\n",
      "Train accuracy = 95.11\n",
      "epoch 1, step 42750/55000, batch loss = 0.00\n",
      "epoch 1, step 43000/55000, batch loss = 0.03\n",
      "epoch 1, step 43250/55000, batch loss = 0.07\n",
      "epoch 1, step 43500/55000, batch loss = 0.02\n",
      "epoch 1, step 43750/55000, batch loss = 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 44000/55000, batch loss = 0.02\n",
      "epoch 1, step 44250/55000, batch loss = 0.01\n",
      "epoch 1, step 44500/55000, batch loss = 0.02\n",
      "epoch 1, step 44750/55000, batch loss = 0.02\n",
      "epoch 1, step 45000/55000, batch loss = 0.00\n",
      "Train accuracy = 95.28\n",
      "epoch 1, step 45250/55000, batch loss = 0.02\n",
      "epoch 1, step 45500/55000, batch loss = 0.04\n",
      "epoch 1, step 45750/55000, batch loss = 0.02\n",
      "epoch 1, step 46000/55000, batch loss = 0.03\n",
      "epoch 1, step 46250/55000, batch loss = 0.04\n",
      "epoch 1, step 46500/55000, batch loss = 0.07\n",
      "epoch 1, step 46750/55000, batch loss = 0.02\n",
      "epoch 1, step 47000/55000, batch loss = 0.02\n",
      "epoch 1, step 47250/55000, batch loss = 0.10\n",
      "epoch 1, step 47500/55000, batch loss = 0.01\n",
      "Train accuracy = 95.40\n",
      "epoch 1, step 47750/55000, batch loss = 0.08\n",
      "epoch 1, step 48000/55000, batch loss = 0.08\n",
      "epoch 1, step 48250/55000, batch loss = 0.05\n",
      "epoch 1, step 48500/55000, batch loss = 0.02\n",
      "epoch 1, step 48750/55000, batch loss = 0.07\n",
      "epoch 1, step 49000/55000, batch loss = 0.24\n",
      "epoch 1, step 49250/55000, batch loss = 0.03\n",
      "epoch 1, step 49500/55000, batch loss = 0.05\n",
      "epoch 1, step 49750/55000, batch loss = 0.10\n",
      "epoch 1, step 50000/55000, batch loss = 0.04\n",
      "Train accuracy = 95.49\n",
      "epoch 1, step 50250/55000, batch loss = 0.11\n",
      "epoch 1, step 50500/55000, batch loss = 0.08\n",
      "epoch 1, step 50750/55000, batch loss = 0.04\n",
      "epoch 1, step 51000/55000, batch loss = 0.09\n",
      "epoch 1, step 51250/55000, batch loss = 0.04\n",
      "epoch 1, step 51500/55000, batch loss = 0.16\n",
      "epoch 1, step 51750/55000, batch loss = 0.05\n",
      "epoch 1, step 52000/55000, batch loss = 0.14\n",
      "epoch 1, step 52250/55000, batch loss = 0.07\n",
      "epoch 1, step 52500/55000, batch loss = 0.11\n",
      "Train accuracy = 95.60\n",
      "epoch 1, step 52750/55000, batch loss = 0.03\n",
      "epoch 1, step 53000/55000, batch loss = 0.02\n",
      "epoch 1, step 53250/55000, batch loss = 0.10\n",
      "epoch 1, step 53500/55000, batch loss = 0.07\n",
      "epoch 1, step 53750/55000, batch loss = 0.11\n",
      "epoch 1, step 54000/55000, batch loss = 0.00\n",
      "epoch 1, step 54250/55000, batch loss = 0.10\n",
      "epoch 1, step 54500/55000, batch loss = 0.05\n",
      "epoch 1, step 54750/55000, batch loss = 0.03\n",
      "Train accuracy = 95.72\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 98.10\n",
      "Validation avg loss = 0.06\n",
      "\n",
      "epoch 2, step 0/55000, batch loss = 0.02\n",
      "epoch 2, step 250/55000, batch loss = 0.01\n",
      "epoch 2, step 500/55000, batch loss = 0.07\n",
      "epoch 2, step 750/55000, batch loss = 0.18\n",
      "epoch 2, step 1000/55000, batch loss = 0.08\n",
      "epoch 2, step 1250/55000, batch loss = 0.01\n",
      "epoch 2, step 1500/55000, batch loss = 0.07\n",
      "epoch 2, step 1750/55000, batch loss = 0.09\n",
      "epoch 2, step 2000/55000, batch loss = 0.08\n",
      "epoch 2, step 2250/55000, batch loss = 0.06\n",
      "epoch 2, step 2500/55000, batch loss = 0.01\n",
      "Train accuracy = 98.59\n",
      "epoch 2, step 2750/55000, batch loss = 0.02\n",
      "epoch 2, step 3000/55000, batch loss = 0.00\n",
      "epoch 2, step 3250/55000, batch loss = 0.01\n",
      "epoch 2, step 3500/55000, batch loss = 0.13\n",
      "epoch 2, step 3750/55000, batch loss = 0.05\n",
      "epoch 2, step 4000/55000, batch loss = 0.01\n",
      "epoch 2, step 4250/55000, batch loss = 0.02\n",
      "epoch 2, step 4500/55000, batch loss = 0.03\n",
      "epoch 2, step 4750/55000, batch loss = 0.04\n",
      "epoch 2, step 5000/55000, batch loss = 0.02\n",
      "Train accuracy = 98.53\n",
      "epoch 2, step 5250/55000, batch loss = 0.06\n",
      "epoch 2, step 5500/55000, batch loss = 0.02\n",
      "epoch 2, step 5750/55000, batch loss = 0.00\n",
      "epoch 2, step 6000/55000, batch loss = 0.04\n",
      "epoch 2, step 6250/55000, batch loss = 0.03\n",
      "epoch 2, step 6500/55000, batch loss = 0.05\n",
      "epoch 2, step 6750/55000, batch loss = 0.04\n",
      "epoch 2, step 7000/55000, batch loss = 0.01\n",
      "epoch 2, step 7250/55000, batch loss = 0.03\n",
      "epoch 2, step 7500/55000, batch loss = 0.08\n",
      "Train accuracy = 98.60\n",
      "epoch 2, step 7750/55000, batch loss = 0.05\n",
      "epoch 2, step 8000/55000, batch loss = 0.09\n",
      "epoch 2, step 8250/55000, batch loss = 0.01\n",
      "epoch 2, step 8500/55000, batch loss = 0.03\n",
      "epoch 2, step 8750/55000, batch loss = 0.01\n",
      "epoch 2, step 9000/55000, batch loss = 0.00\n",
      "epoch 2, step 9250/55000, batch loss = 0.03\n",
      "epoch 2, step 9500/55000, batch loss = 0.02\n",
      "epoch 2, step 9750/55000, batch loss = 0.01\n",
      "epoch 2, step 10000/55000, batch loss = 0.02\n",
      "Train accuracy = 98.64\n",
      "epoch 2, step 10250/55000, batch loss = 0.17\n",
      "epoch 2, step 10500/55000, batch loss = 0.01\n",
      "epoch 2, step 10750/55000, batch loss = 0.05\n",
      "epoch 2, step 11000/55000, batch loss = 0.02\n",
      "epoch 2, step 11250/55000, batch loss = 0.07\n",
      "epoch 2, step 11500/55000, batch loss = 0.01\n",
      "epoch 2, step 11750/55000, batch loss = 0.02\n",
      "epoch 2, step 12000/55000, batch loss = 0.01\n",
      "epoch 2, step 12250/55000, batch loss = 0.01\n",
      "epoch 2, step 12500/55000, batch loss = 0.02\n",
      "Train accuracy = 98.68\n",
      "epoch 2, step 12750/55000, batch loss = 0.04\n",
      "epoch 2, step 13000/55000, batch loss = 0.01\n",
      "epoch 2, step 13250/55000, batch loss = 0.12\n",
      "epoch 2, step 13500/55000, batch loss = 0.00\n",
      "epoch 2, step 13750/55000, batch loss = 0.00\n",
      "epoch 2, step 14000/55000, batch loss = 0.09\n",
      "epoch 2, step 14250/55000, batch loss = 0.05\n",
      "epoch 2, step 14500/55000, batch loss = 0.01\n",
      "epoch 2, step 14750/55000, batch loss = 0.01\n",
      "epoch 2, step 15000/55000, batch loss = 0.05\n",
      "Train accuracy = 98.64\n",
      "epoch 2, step 15250/55000, batch loss = 0.00\n",
      "epoch 2, step 15500/55000, batch loss = 0.04\n",
      "epoch 2, step 15750/55000, batch loss = 0.12\n",
      "epoch 2, step 16000/55000, batch loss = 0.07\n",
      "epoch 2, step 16250/55000, batch loss = 0.01\n",
      "epoch 2, step 16500/55000, batch loss = 0.01\n",
      "epoch 2, step 16750/55000, batch loss = 0.03\n",
      "epoch 2, step 17000/55000, batch loss = 0.03\n",
      "epoch 2, step 17250/55000, batch loss = 0.06\n",
      "epoch 2, step 17500/55000, batch loss = 0.01\n",
      "Train accuracy = 98.64\n",
      "epoch 2, step 17750/55000, batch loss = 0.00\n",
      "epoch 2, step 18000/55000, batch loss = 0.04\n",
      "epoch 2, step 18250/55000, batch loss = 0.03\n",
      "epoch 2, step 18500/55000, batch loss = 0.06\n",
      "epoch 2, step 18750/55000, batch loss = 0.01\n",
      "epoch 2, step 19000/55000, batch loss = 0.00\n",
      "epoch 2, step 19250/55000, batch loss = 0.05\n",
      "epoch 2, step 19500/55000, batch loss = 0.01\n",
      "epoch 2, step 19750/55000, batch loss = 0.05\n",
      "epoch 2, step 20000/55000, batch loss = 0.14\n",
      "Train accuracy = 98.62\n",
      "epoch 2, step 20250/55000, batch loss = 0.08\n",
      "epoch 2, step 20500/55000, batch loss = 0.07\n",
      "epoch 2, step 20750/55000, batch loss = 0.06\n",
      "epoch 2, step 21000/55000, batch loss = 0.10\n",
      "epoch 2, step 21250/55000, batch loss = 0.04\n",
      "epoch 2, step 21500/55000, batch loss = 0.01\n",
      "epoch 2, step 21750/55000, batch loss = 0.07\n",
      "epoch 2, step 22000/55000, batch loss = 0.12\n",
      "epoch 2, step 22250/55000, batch loss = 0.00\n",
      "epoch 2, step 22500/55000, batch loss = 0.02\n",
      "Train accuracy = 98.59\n",
      "epoch 2, step 22750/55000, batch loss = 0.07\n",
      "epoch 2, step 23000/55000, batch loss = 0.05\n",
      "epoch 2, step 23250/55000, batch loss = 0.00\n",
      "epoch 2, step 23500/55000, batch loss = 0.05\n",
      "epoch 2, step 23750/55000, batch loss = 0.03\n",
      "epoch 2, step 24000/55000, batch loss = 0.07\n",
      "epoch 2, step 24250/55000, batch loss = 0.05\n",
      "epoch 2, step 24500/55000, batch loss = 0.01\n",
      "epoch 2, step 24750/55000, batch loss = 0.09\n",
      "epoch 2, step 25000/55000, batch loss = 0.09\n",
      "Train accuracy = 98.55\n",
      "epoch 2, step 25250/55000, batch loss = 0.01\n",
      "epoch 2, step 25500/55000, batch loss = 0.01\n",
      "epoch 2, step 25750/55000, batch loss = 0.01\n",
      "epoch 2, step 26000/55000, batch loss = 0.00\n",
      "epoch 2, step 26250/55000, batch loss = 0.07\n",
      "epoch 2, step 26500/55000, batch loss = 0.07\n",
      "epoch 2, step 26750/55000, batch loss = 0.06\n",
      "epoch 2, step 27000/55000, batch loss = 0.03\n",
      "epoch 2, step 27250/55000, batch loss = 0.06\n",
      "epoch 2, step 27500/55000, batch loss = 0.01\n",
      "Train accuracy = 98.58\n",
      "epoch 2, step 27750/55000, batch loss = 0.01\n",
      "epoch 2, step 28000/55000, batch loss = 0.03\n",
      "epoch 2, step 28250/55000, batch loss = 0.04\n",
      "epoch 2, step 28500/55000, batch loss = 0.06\n",
      "epoch 2, step 28750/55000, batch loss = 0.05\n",
      "epoch 2, step 29000/55000, batch loss = 0.01\n",
      "epoch 2, step 29250/55000, batch loss = 0.02\n",
      "epoch 2, step 29500/55000, batch loss = 0.04\n",
      "epoch 2, step 29750/55000, batch loss = 0.05\n",
      "epoch 2, step 30000/55000, batch loss = 0.03\n",
      "Train accuracy = 98.58\n",
      "epoch 2, step 30250/55000, batch loss = 0.00\n",
      "epoch 2, step 30500/55000, batch loss = 0.02\n",
      "epoch 2, step 30750/55000, batch loss = 0.00\n",
      "epoch 2, step 31000/55000, batch loss = 0.01\n",
      "epoch 2, step 31250/55000, batch loss = 0.07\n",
      "epoch 2, step 31500/55000, batch loss = 0.18\n",
      "epoch 2, step 31750/55000, batch loss = 0.01\n",
      "epoch 2, step 32000/55000, batch loss = 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, step 32250/55000, batch loss = 0.01\n",
      "epoch 2, step 32500/55000, batch loss = 0.00\n",
      "Train accuracy = 98.61\n",
      "epoch 2, step 32750/55000, batch loss = 0.02\n",
      "epoch 2, step 33000/55000, batch loss = 0.00\n",
      "epoch 2, step 33250/55000, batch loss = 0.08\n",
      "epoch 2, step 33500/55000, batch loss = 0.03\n",
      "epoch 2, step 33750/55000, batch loss = 0.02\n",
      "epoch 2, step 34000/55000, batch loss = 0.07\n",
      "epoch 2, step 34250/55000, batch loss = 0.06\n",
      "epoch 2, step 34500/55000, batch loss = 0.04\n",
      "epoch 2, step 34750/55000, batch loss = 0.03\n",
      "epoch 2, step 35000/55000, batch loss = 0.02\n",
      "Train accuracy = 98.63\n",
      "epoch 2, step 35250/55000, batch loss = 0.05\n",
      "epoch 2, step 35500/55000, batch loss = 0.04\n",
      "epoch 2, step 35750/55000, batch loss = 0.03\n",
      "epoch 2, step 36000/55000, batch loss = 0.04\n",
      "epoch 2, step 36250/55000, batch loss = 0.20\n",
      "epoch 2, step 36500/55000, batch loss = 0.06\n",
      "epoch 2, step 36750/55000, batch loss = 0.05\n",
      "epoch 2, step 37000/55000, batch loss = 0.03\n",
      "epoch 2, step 37250/55000, batch loss = 0.06\n",
      "epoch 2, step 37500/55000, batch loss = 0.02\n",
      "Train accuracy = 98.60\n",
      "epoch 2, step 37750/55000, batch loss = 0.02\n",
      "epoch 2, step 38000/55000, batch loss = 0.09\n",
      "epoch 2, step 38250/55000, batch loss = 0.07\n",
      "epoch 2, step 38500/55000, batch loss = 0.05\n",
      "epoch 2, step 38750/55000, batch loss = 0.00\n",
      "epoch 2, step 39000/55000, batch loss = 0.02\n",
      "epoch 2, step 39250/55000, batch loss = 0.00\n",
      "epoch 2, step 39500/55000, batch loss = 0.01\n",
      "epoch 2, step 39750/55000, batch loss = 0.00\n",
      "epoch 2, step 40000/55000, batch loss = 0.03\n",
      "Train accuracy = 98.61\n",
      "epoch 2, step 40250/55000, batch loss = 0.11\n",
      "epoch 2, step 40500/55000, batch loss = 0.06\n",
      "epoch 2, step 40750/55000, batch loss = 0.01\n",
      "epoch 2, step 41000/55000, batch loss = 0.07\n",
      "epoch 2, step 41250/55000, batch loss = 0.00\n",
      "epoch 2, step 41500/55000, batch loss = 0.02\n",
      "epoch 2, step 41750/55000, batch loss = 0.00\n",
      "epoch 2, step 42000/55000, batch loss = 0.10\n",
      "epoch 2, step 42250/55000, batch loss = 0.05\n",
      "epoch 2, step 42500/55000, batch loss = 0.05\n",
      "Train accuracy = 98.59\n",
      "epoch 2, step 42750/55000, batch loss = 0.10\n",
      "epoch 2, step 43000/55000, batch loss = 0.01\n",
      "epoch 2, step 43250/55000, batch loss = 0.05\n",
      "epoch 2, step 43500/55000, batch loss = 0.00\n",
      "epoch 2, step 43750/55000, batch loss = 0.09\n",
      "epoch 2, step 44000/55000, batch loss = 0.03\n",
      "epoch 2, step 44250/55000, batch loss = 0.01\n",
      "epoch 2, step 44500/55000, batch loss = 0.01\n",
      "epoch 2, step 44750/55000, batch loss = 0.04\n",
      "epoch 2, step 45000/55000, batch loss = 0.01\n",
      "Train accuracy = 98.59\n",
      "epoch 2, step 45250/55000, batch loss = 0.00\n",
      "epoch 2, step 45500/55000, batch loss = 0.06\n",
      "epoch 2, step 45750/55000, batch loss = 0.01\n",
      "epoch 2, step 46000/55000, batch loss = 0.01\n",
      "epoch 2, step 46250/55000, batch loss = 0.08\n",
      "epoch 2, step 46500/55000, batch loss = 0.06\n",
      "epoch 2, step 46750/55000, batch loss = 0.06\n",
      "epoch 2, step 47000/55000, batch loss = 0.01\n",
      "epoch 2, step 47250/55000, batch loss = 0.05\n",
      "epoch 2, step 47500/55000, batch loss = 0.11\n",
      "Train accuracy = 98.59\n",
      "epoch 2, step 47750/55000, batch loss = 0.09\n",
      "epoch 2, step 48000/55000, batch loss = 0.02\n",
      "epoch 2, step 48250/55000, batch loss = 0.01\n",
      "epoch 2, step 48500/55000, batch loss = 0.06\n",
      "epoch 2, step 48750/55000, batch loss = 0.03\n",
      "epoch 2, step 49000/55000, batch loss = 0.01\n",
      "epoch 2, step 49250/55000, batch loss = 0.01\n",
      "epoch 2, step 49500/55000, batch loss = 0.05\n",
      "epoch 2, step 49750/55000, batch loss = 0.03\n",
      "epoch 2, step 50000/55000, batch loss = 0.02\n",
      "Train accuracy = 98.59\n",
      "epoch 2, step 50250/55000, batch loss = 0.05\n",
      "epoch 2, step 50500/55000, batch loss = 0.02\n",
      "epoch 2, step 50750/55000, batch loss = 0.01\n",
      "epoch 2, step 51000/55000, batch loss = 0.00\n",
      "epoch 2, step 51250/55000, batch loss = 0.01\n",
      "epoch 2, step 51500/55000, batch loss = 0.05\n",
      "epoch 2, step 51750/55000, batch loss = 0.05\n",
      "epoch 2, step 52000/55000, batch loss = 0.00\n",
      "epoch 2, step 52250/55000, batch loss = 0.02\n",
      "epoch 2, step 52500/55000, batch loss = 0.01\n",
      "Train accuracy = 98.60\n",
      "epoch 2, step 52750/55000, batch loss = 0.01\n",
      "epoch 2, step 53000/55000, batch loss = 0.02\n",
      "epoch 2, step 53250/55000, batch loss = 0.01\n",
      "epoch 2, step 53500/55000, batch loss = 0.03\n",
      "epoch 2, step 53750/55000, batch loss = 0.05\n",
      "epoch 2, step 54000/55000, batch loss = 0.08\n",
      "epoch 2, step 54250/55000, batch loss = 0.01\n",
      "epoch 2, step 54500/55000, batch loss = 0.02\n",
      "epoch 2, step 54750/55000, batch loss = 0.00\n",
      "Train accuracy = 98.61\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 98.74\n",
      "Validation avg loss = 0.04\n",
      "\n",
      "epoch 3, step 0/55000, batch loss = 0.01\n",
      "epoch 3, step 250/55000, batch loss = 0.03\n",
      "epoch 3, step 500/55000, batch loss = 0.02\n",
      "epoch 3, step 750/55000, batch loss = 0.02\n",
      "epoch 3, step 1000/55000, batch loss = 0.04\n",
      "epoch 3, step 1250/55000, batch loss = 0.04\n",
      "epoch 3, step 1500/55000, batch loss = 0.01\n",
      "epoch 3, step 1750/55000, batch loss = 0.00\n",
      "epoch 3, step 2000/55000, batch loss = 0.01\n",
      "epoch 3, step 2250/55000, batch loss = 0.00\n",
      "epoch 3, step 2500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.06\n",
      "epoch 3, step 2750/55000, batch loss = 0.03\n",
      "epoch 3, step 3000/55000, batch loss = 0.04\n",
      "epoch 3, step 3250/55000, batch loss = 0.02\n",
      "epoch 3, step 3500/55000, batch loss = 0.09\n",
      "epoch 3, step 3750/55000, batch loss = 0.01\n",
      "epoch 3, step 4000/55000, batch loss = 0.03\n",
      "epoch 3, step 4250/55000, batch loss = 0.05\n",
      "epoch 3, step 4500/55000, batch loss = 0.01\n",
      "epoch 3, step 4750/55000, batch loss = 0.01\n",
      "epoch 3, step 5000/55000, batch loss = 0.03\n",
      "Train accuracy = 99.05\n",
      "epoch 3, step 5250/55000, batch loss = 0.01\n",
      "epoch 3, step 5500/55000, batch loss = 0.07\n",
      "epoch 3, step 5750/55000, batch loss = 0.04\n",
      "epoch 3, step 6000/55000, batch loss = 0.01\n",
      "epoch 3, step 6250/55000, batch loss = 0.01\n",
      "epoch 3, step 6500/55000, batch loss = 0.02\n",
      "epoch 3, step 6750/55000, batch loss = 0.04\n",
      "epoch 3, step 7000/55000, batch loss = 0.00\n",
      "epoch 3, step 7250/55000, batch loss = 0.02\n",
      "epoch 3, step 7500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.23\n",
      "epoch 3, step 7750/55000, batch loss = 0.03\n",
      "epoch 3, step 8000/55000, batch loss = 0.01\n",
      "epoch 3, step 8250/55000, batch loss = 0.02\n",
      "epoch 3, step 8500/55000, batch loss = 0.01\n",
      "epoch 3, step 8750/55000, batch loss = 0.00\n",
      "epoch 3, step 9000/55000, batch loss = 0.01\n",
      "epoch 3, step 9250/55000, batch loss = 0.00\n",
      "epoch 3, step 9500/55000, batch loss = 0.13\n",
      "epoch 3, step 9750/55000, batch loss = 0.02\n",
      "epoch 3, step 10000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.34\n",
      "epoch 3, step 10250/55000, batch loss = 0.02\n",
      "epoch 3, step 10500/55000, batch loss = 0.01\n",
      "epoch 3, step 10750/55000, batch loss = 0.00\n",
      "epoch 3, step 11000/55000, batch loss = 0.00\n",
      "epoch 3, step 11250/55000, batch loss = 0.00\n",
      "epoch 3, step 11500/55000, batch loss = 0.05\n",
      "epoch 3, step 11750/55000, batch loss = 0.01\n",
      "epoch 3, step 12000/55000, batch loss = 0.01\n",
      "epoch 3, step 12250/55000, batch loss = 0.01\n",
      "epoch 3, step 12500/55000, batch loss = 0.02\n",
      "Train accuracy = 99.36\n",
      "epoch 3, step 12750/55000, batch loss = 0.01\n",
      "epoch 3, step 13000/55000, batch loss = 0.01\n",
      "epoch 3, step 13250/55000, batch loss = 0.02\n",
      "epoch 3, step 13500/55000, batch loss = 0.01\n",
      "epoch 3, step 13750/55000, batch loss = 0.01\n",
      "epoch 3, step 14000/55000, batch loss = 0.01\n",
      "epoch 3, step 14250/55000, batch loss = 0.09\n",
      "epoch 3, step 14500/55000, batch loss = 0.10\n",
      "epoch 3, step 14750/55000, batch loss = 0.03\n",
      "epoch 3, step 15000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.37\n",
      "epoch 3, step 15250/55000, batch loss = 0.09\n",
      "epoch 3, step 15500/55000, batch loss = 0.01\n",
      "epoch 3, step 15750/55000, batch loss = 0.04\n",
      "epoch 3, step 16000/55000, batch loss = 0.01\n",
      "epoch 3, step 16250/55000, batch loss = 0.02\n",
      "epoch 3, step 16500/55000, batch loss = 0.00\n",
      "epoch 3, step 16750/55000, batch loss = 0.01\n",
      "epoch 3, step 17000/55000, batch loss = 0.01\n",
      "epoch 3, step 17250/55000, batch loss = 0.01\n",
      "epoch 3, step 17500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.38\n",
      "epoch 3, step 17750/55000, batch loss = 0.03\n",
      "epoch 3, step 18000/55000, batch loss = 0.01\n",
      "epoch 3, step 18250/55000, batch loss = 0.01\n",
      "epoch 3, step 18500/55000, batch loss = 0.04\n",
      "epoch 3, step 18750/55000, batch loss = 0.01\n",
      "epoch 3, step 19000/55000, batch loss = 0.02\n",
      "epoch 3, step 19250/55000, batch loss = 0.00\n",
      "epoch 3, step 19500/55000, batch loss = 0.01\n",
      "epoch 3, step 19750/55000, batch loss = 0.01\n",
      "epoch 3, step 20000/55000, batch loss = 0.08\n",
      "Train accuracy = 99.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, step 20250/55000, batch loss = 0.02\n",
      "epoch 3, step 20500/55000, batch loss = 0.01\n",
      "epoch 3, step 20750/55000, batch loss = 0.03\n",
      "epoch 3, step 21000/55000, batch loss = 0.05\n",
      "epoch 3, step 21250/55000, batch loss = 0.02\n",
      "epoch 3, step 21500/55000, batch loss = 0.00\n",
      "epoch 3, step 21750/55000, batch loss = 0.11\n",
      "epoch 3, step 22000/55000, batch loss = 0.01\n",
      "epoch 3, step 22250/55000, batch loss = 0.01\n",
      "epoch 3, step 22500/55000, batch loss = 0.02\n",
      "Train accuracy = 99.37\n",
      "epoch 3, step 22750/55000, batch loss = 0.00\n",
      "epoch 3, step 23000/55000, batch loss = 0.02\n",
      "epoch 3, step 23250/55000, batch loss = 0.00\n",
      "epoch 3, step 23500/55000, batch loss = 0.01\n",
      "epoch 3, step 23750/55000, batch loss = 0.00\n",
      "epoch 3, step 24000/55000, batch loss = 0.02\n",
      "epoch 3, step 24250/55000, batch loss = 0.01\n",
      "epoch 3, step 24500/55000, batch loss = 0.02\n",
      "epoch 3, step 24750/55000, batch loss = 0.00\n",
      "epoch 3, step 25000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.40\n",
      "epoch 3, step 25250/55000, batch loss = 0.01\n",
      "epoch 3, step 25500/55000, batch loss = 0.01\n",
      "epoch 3, step 25750/55000, batch loss = 0.01\n",
      "epoch 3, step 26000/55000, batch loss = 0.01\n",
      "epoch 3, step 26250/55000, batch loss = 0.18\n",
      "epoch 3, step 26500/55000, batch loss = 0.01\n",
      "epoch 3, step 26750/55000, batch loss = 0.00\n",
      "epoch 3, step 27000/55000, batch loss = 0.05\n",
      "epoch 3, step 27250/55000, batch loss = 0.14\n",
      "epoch 3, step 27500/55000, batch loss = 0.02\n",
      "Train accuracy = 99.42\n",
      "epoch 3, step 27750/55000, batch loss = 0.00\n",
      "epoch 3, step 28000/55000, batch loss = 0.01\n",
      "epoch 3, step 28250/55000, batch loss = 0.01\n",
      "epoch 3, step 28500/55000, batch loss = 0.04\n",
      "epoch 3, step 28750/55000, batch loss = 0.04\n",
      "epoch 3, step 29000/55000, batch loss = 0.08\n",
      "epoch 3, step 29250/55000, batch loss = 0.02\n",
      "epoch 3, step 29500/55000, batch loss = 0.00\n",
      "epoch 3, step 29750/55000, batch loss = 0.07\n",
      "epoch 3, step 30000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.41\n",
      "epoch 3, step 30250/55000, batch loss = 0.02\n",
      "epoch 3, step 30500/55000, batch loss = 0.12\n",
      "epoch 3, step 30750/55000, batch loss = 0.02\n",
      "epoch 3, step 31000/55000, batch loss = 0.06\n",
      "epoch 3, step 31250/55000, batch loss = 0.02\n",
      "epoch 3, step 31500/55000, batch loss = 0.01\n",
      "epoch 3, step 31750/55000, batch loss = 0.07\n",
      "epoch 3, step 32000/55000, batch loss = 0.03\n",
      "epoch 3, step 32250/55000, batch loss = 0.00\n",
      "epoch 3, step 32500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.41\n",
      "epoch 3, step 32750/55000, batch loss = 0.01\n",
      "epoch 3, step 33000/55000, batch loss = 0.01\n",
      "epoch 3, step 33250/55000, batch loss = 0.04\n",
      "epoch 3, step 33500/55000, batch loss = 0.00\n",
      "epoch 3, step 33750/55000, batch loss = 0.03\n",
      "epoch 3, step 34000/55000, batch loss = 0.00\n",
      "epoch 3, step 34250/55000, batch loss = 0.00\n",
      "epoch 3, step 34500/55000, batch loss = 0.01\n",
      "epoch 3, step 34750/55000, batch loss = 0.07\n",
      "epoch 3, step 35000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.41\n",
      "epoch 3, step 35250/55000, batch loss = 0.00\n",
      "epoch 3, step 35500/55000, batch loss = 0.01\n",
      "epoch 3, step 35750/55000, batch loss = 0.01\n",
      "epoch 3, step 36000/55000, batch loss = 0.04\n",
      "epoch 3, step 36250/55000, batch loss = 0.01\n",
      "epoch 3, step 36500/55000, batch loss = 0.00\n",
      "epoch 3, step 36750/55000, batch loss = 0.00\n",
      "epoch 3, step 37000/55000, batch loss = 0.05\n",
      "epoch 3, step 37250/55000, batch loss = 0.01\n",
      "epoch 3, step 37500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.43\n",
      "epoch 3, step 37750/55000, batch loss = 0.04\n",
      "epoch 3, step 38000/55000, batch loss = 0.08\n",
      "epoch 3, step 38250/55000, batch loss = 0.00\n",
      "epoch 3, step 38500/55000, batch loss = 0.01\n",
      "epoch 3, step 38750/55000, batch loss = 0.02\n",
      "epoch 3, step 39000/55000, batch loss = 0.00\n",
      "epoch 3, step 39250/55000, batch loss = 0.00\n",
      "epoch 3, step 39500/55000, batch loss = 0.01\n",
      "epoch 3, step 39750/55000, batch loss = 0.06\n",
      "epoch 3, step 40000/55000, batch loss = 0.03\n",
      "Train accuracy = 99.43\n",
      "epoch 3, step 40250/55000, batch loss = 0.00\n",
      "epoch 3, step 40500/55000, batch loss = 0.01\n",
      "epoch 3, step 40750/55000, batch loss = 0.06\n",
      "epoch 3, step 41000/55000, batch loss = 0.01\n",
      "epoch 3, step 41250/55000, batch loss = 0.01\n",
      "epoch 3, step 41500/55000, batch loss = 0.03\n",
      "epoch 3, step 41750/55000, batch loss = 0.00\n",
      "epoch 3, step 42000/55000, batch loss = 0.00\n",
      "epoch 3, step 42250/55000, batch loss = 0.03\n",
      "epoch 3, step 42500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.42\n",
      "epoch 3, step 42750/55000, batch loss = 0.01\n",
      "epoch 3, step 43000/55000, batch loss = 0.02\n",
      "epoch 3, step 43250/55000, batch loss = 0.01\n",
      "epoch 3, step 43500/55000, batch loss = 0.00\n",
      "epoch 3, step 43750/55000, batch loss = 0.01\n",
      "epoch 3, step 44000/55000, batch loss = 0.00\n",
      "epoch 3, step 44250/55000, batch loss = 0.01\n",
      "epoch 3, step 44500/55000, batch loss = 0.01\n",
      "epoch 3, step 44750/55000, batch loss = 0.00\n",
      "epoch 3, step 45000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.43\n",
      "epoch 3, step 45250/55000, batch loss = 0.01\n",
      "epoch 3, step 45500/55000, batch loss = 0.01\n",
      "epoch 3, step 45750/55000, batch loss = 0.01\n",
      "epoch 3, step 46000/55000, batch loss = 0.00\n",
      "epoch 3, step 46250/55000, batch loss = 0.01\n",
      "epoch 3, step 46500/55000, batch loss = 0.01\n",
      "epoch 3, step 46750/55000, batch loss = 0.00\n",
      "epoch 3, step 47000/55000, batch loss = 0.04\n",
      "epoch 3, step 47250/55000, batch loss = 0.01\n",
      "epoch 3, step 47500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.43\n",
      "epoch 3, step 47750/55000, batch loss = 0.01\n",
      "epoch 3, step 48000/55000, batch loss = 0.00\n",
      "epoch 3, step 48250/55000, batch loss = 0.00\n",
      "epoch 3, step 48500/55000, batch loss = 0.05\n",
      "epoch 3, step 48750/55000, batch loss = 0.00\n",
      "epoch 3, step 49000/55000, batch loss = 0.00\n",
      "epoch 3, step 49250/55000, batch loss = 0.01\n",
      "epoch 3, step 49500/55000, batch loss = 0.03\n",
      "epoch 3, step 49750/55000, batch loss = 0.03\n",
      "epoch 3, step 50000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.43\n",
      "epoch 3, step 50250/55000, batch loss = 0.03\n",
      "epoch 3, step 50500/55000, batch loss = 0.01\n",
      "epoch 3, step 50750/55000, batch loss = 0.00\n",
      "epoch 3, step 51000/55000, batch loss = 0.02\n",
      "epoch 3, step 51250/55000, batch loss = 0.05\n",
      "epoch 3, step 51500/55000, batch loss = 0.00\n",
      "epoch 3, step 51750/55000, batch loss = 0.02\n",
      "epoch 3, step 52000/55000, batch loss = 0.03\n",
      "epoch 3, step 52250/55000, batch loss = 0.05\n",
      "epoch 3, step 52500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.44\n",
      "epoch 3, step 52750/55000, batch loss = 0.01\n",
      "epoch 3, step 53000/55000, batch loss = 0.12\n",
      "epoch 3, step 53250/55000, batch loss = 0.02\n",
      "epoch 3, step 53500/55000, batch loss = 0.00\n",
      "epoch 3, step 53750/55000, batch loss = 0.01\n",
      "epoch 3, step 54000/55000, batch loss = 0.01\n",
      "epoch 3, step 54250/55000, batch loss = 0.00\n",
      "epoch 3, step 54500/55000, batch loss = 0.02\n",
      "epoch 3, step 54750/55000, batch loss = 0.00\n",
      "Train accuracy = 99.44\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.16\n",
      "Validation avg loss = 0.03\n",
      "\n",
      "epoch 4, step 0/55000, batch loss = 0.00\n",
      "epoch 4, step 250/55000, batch loss = 0.01\n",
      "epoch 4, step 500/55000, batch loss = 0.02\n",
      "epoch 4, step 750/55000, batch loss = 0.00\n",
      "epoch 4, step 1000/55000, batch loss = 0.09\n",
      "epoch 4, step 1250/55000, batch loss = 0.00\n",
      "epoch 4, step 1500/55000, batch loss = 0.04\n",
      "epoch 4, step 1750/55000, batch loss = 0.01\n",
      "epoch 4, step 2000/55000, batch loss = 0.03\n",
      "epoch 4, step 2250/55000, batch loss = 0.01\n",
      "epoch 4, step 2500/55000, batch loss = 0.03\n",
      "Train accuracy = 99.37\n",
      "epoch 4, step 2750/55000, batch loss = 0.02\n",
      "epoch 4, step 3000/55000, batch loss = 0.01\n",
      "epoch 4, step 3250/55000, batch loss = 0.00\n",
      "epoch 4, step 3500/55000, batch loss = 0.00\n",
      "epoch 4, step 3750/55000, batch loss = 0.00\n",
      "epoch 4, step 4000/55000, batch loss = 0.02\n",
      "epoch 4, step 4250/55000, batch loss = 0.01\n",
      "epoch 4, step 4500/55000, batch loss = 0.01\n",
      "epoch 4, step 4750/55000, batch loss = 0.01\n",
      "epoch 4, step 5000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.49\n",
      "epoch 4, step 5250/55000, batch loss = 0.01\n",
      "epoch 4, step 5500/55000, batch loss = 0.00\n",
      "epoch 4, step 5750/55000, batch loss = 0.01\n",
      "epoch 4, step 6000/55000, batch loss = 0.01\n",
      "epoch 4, step 6250/55000, batch loss = 0.00\n",
      "epoch 4, step 6500/55000, batch loss = 0.00\n",
      "epoch 4, step 6750/55000, batch loss = 0.01\n",
      "epoch 4, step 7000/55000, batch loss = 0.00\n",
      "epoch 4, step 7250/55000, batch loss = 0.00\n",
      "epoch 4, step 7500/55000, batch loss = 0.02\n",
      "Train accuracy = 99.60\n",
      "epoch 4, step 7750/55000, batch loss = 0.00\n",
      "epoch 4, step 8000/55000, batch loss = 0.04\n",
      "epoch 4, step 8250/55000, batch loss = 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, step 8500/55000, batch loss = 0.00\n",
      "epoch 4, step 8750/55000, batch loss = 0.00\n",
      "epoch 4, step 9000/55000, batch loss = 0.03\n",
      "epoch 4, step 9250/55000, batch loss = 0.01\n",
      "epoch 4, step 9500/55000, batch loss = 0.00\n",
      "epoch 4, step 9750/55000, batch loss = 0.00\n",
      "epoch 4, step 10000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.53\n",
      "epoch 4, step 10250/55000, batch loss = 0.00\n",
      "epoch 4, step 10500/55000, batch loss = 0.01\n",
      "epoch 4, step 10750/55000, batch loss = 0.01\n",
      "epoch 4, step 11000/55000, batch loss = 0.00\n",
      "epoch 4, step 11250/55000, batch loss = 0.01\n",
      "epoch 4, step 11500/55000, batch loss = 0.01\n",
      "epoch 4, step 11750/55000, batch loss = 0.02\n",
      "epoch 4, step 12000/55000, batch loss = 0.00\n",
      "epoch 4, step 12250/55000, batch loss = 0.02\n",
      "epoch 4, step 12500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.52\n",
      "epoch 4, step 12750/55000, batch loss = 0.00\n",
      "epoch 4, step 13000/55000, batch loss = 0.03\n",
      "epoch 4, step 13250/55000, batch loss = 0.00\n",
      "epoch 4, step 13500/55000, batch loss = 0.01\n",
      "epoch 4, step 13750/55000, batch loss = 0.04\n",
      "epoch 4, step 14000/55000, batch loss = 0.02\n",
      "epoch 4, step 14250/55000, batch loss = 0.02\n",
      "epoch 4, step 14500/55000, batch loss = 0.04\n",
      "epoch 4, step 14750/55000, batch loss = 0.00\n",
      "epoch 4, step 15000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.50\n",
      "epoch 4, step 15250/55000, batch loss = 0.03\n",
      "epoch 4, step 15500/55000, batch loss = 0.00\n",
      "epoch 4, step 15750/55000, batch loss = 0.04\n",
      "epoch 4, step 16000/55000, batch loss = 0.02\n",
      "epoch 4, step 16250/55000, batch loss = 0.01\n",
      "epoch 4, step 16500/55000, batch loss = 0.00\n",
      "epoch 4, step 16750/55000, batch loss = 0.02\n",
      "epoch 4, step 17000/55000, batch loss = 0.04\n",
      "epoch 4, step 17250/55000, batch loss = 0.00\n",
      "epoch 4, step 17500/55000, batch loss = 0.02\n",
      "Train accuracy = 99.46\n",
      "epoch 4, step 17750/55000, batch loss = 0.06\n",
      "epoch 4, step 18000/55000, batch loss = 0.03\n",
      "epoch 4, step 18250/55000, batch loss = 0.03\n",
      "epoch 4, step 18500/55000, batch loss = 0.13\n",
      "epoch 4, step 18750/55000, batch loss = 0.02\n",
      "epoch 4, step 19000/55000, batch loss = 0.02\n",
      "epoch 4, step 19250/55000, batch loss = 0.00\n",
      "epoch 4, step 19500/55000, batch loss = 0.01\n",
      "epoch 4, step 19750/55000, batch loss = 0.02\n",
      "epoch 4, step 20000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.46\n",
      "epoch 4, step 20250/55000, batch loss = 0.02\n",
      "epoch 4, step 20500/55000, batch loss = 0.00\n",
      "epoch 4, step 20750/55000, batch loss = 0.03\n",
      "epoch 4, step 21000/55000, batch loss = 0.00\n",
      "epoch 4, step 21250/55000, batch loss = 0.02\n",
      "epoch 4, step 21500/55000, batch loss = 0.01\n",
      "epoch 4, step 21750/55000, batch loss = 0.02\n",
      "epoch 4, step 22000/55000, batch loss = 0.00\n",
      "epoch 4, step 22250/55000, batch loss = 0.00\n",
      "epoch 4, step 22500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.48\n",
      "epoch 4, step 22750/55000, batch loss = 0.00\n",
      "epoch 4, step 23000/55000, batch loss = 0.01\n",
      "epoch 4, step 23250/55000, batch loss = 0.01\n",
      "epoch 4, step 23500/55000, batch loss = 0.02\n",
      "epoch 4, step 23750/55000, batch loss = 0.05\n",
      "epoch 4, step 24000/55000, batch loss = 0.01\n",
      "epoch 4, step 24250/55000, batch loss = 0.01\n",
      "epoch 4, step 24500/55000, batch loss = 0.00\n",
      "epoch 4, step 24750/55000, batch loss = 0.04\n",
      "epoch 4, step 25000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.48\n",
      "epoch 4, step 25250/55000, batch loss = 0.01\n",
      "epoch 4, step 25500/55000, batch loss = 0.00\n",
      "epoch 4, step 25750/55000, batch loss = 0.01\n",
      "epoch 4, step 26000/55000, batch loss = 0.01\n",
      "epoch 4, step 26250/55000, batch loss = 0.01\n",
      "epoch 4, step 26500/55000, batch loss = 0.02\n",
      "epoch 4, step 26750/55000, batch loss = 0.01\n",
      "epoch 4, step 27000/55000, batch loss = 0.02\n",
      "epoch 4, step 27250/55000, batch loss = 0.02\n",
      "epoch 4, step 27500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.49\n",
      "epoch 4, step 27750/55000, batch loss = 0.03\n",
      "epoch 4, step 28000/55000, batch loss = 0.01\n",
      "epoch 4, step 28250/55000, batch loss = 0.01\n",
      "epoch 4, step 28500/55000, batch loss = 0.00\n",
      "epoch 4, step 28750/55000, batch loss = 0.02\n",
      "epoch 4, step 29000/55000, batch loss = 0.18\n",
      "epoch 4, step 29250/55000, batch loss = 0.00\n",
      "epoch 4, step 29500/55000, batch loss = 0.00\n",
      "epoch 4, step 29750/55000, batch loss = 0.01\n",
      "epoch 4, step 30000/55000, batch loss = 0.07\n",
      "Train accuracy = 99.48\n",
      "epoch 4, step 30250/55000, batch loss = 0.05\n",
      "epoch 4, step 30500/55000, batch loss = 0.01\n",
      "epoch 4, step 30750/55000, batch loss = 0.00\n",
      "epoch 4, step 31000/55000, batch loss = 0.03\n",
      "epoch 4, step 31250/55000, batch loss = 0.00\n",
      "epoch 4, step 31500/55000, batch loss = 0.00\n",
      "epoch 4, step 31750/55000, batch loss = 0.01\n",
      "epoch 4, step 32000/55000, batch loss = 0.00\n",
      "epoch 4, step 32250/55000, batch loss = 0.00\n",
      "epoch 4, step 32500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.49\n",
      "epoch 4, step 32750/55000, batch loss = 0.00\n",
      "epoch 4, step 33000/55000, batch loss = 0.01\n",
      "epoch 4, step 33250/55000, batch loss = 0.02\n",
      "epoch 4, step 33500/55000, batch loss = 0.01\n",
      "epoch 4, step 33750/55000, batch loss = 0.01\n",
      "epoch 4, step 34000/55000, batch loss = 0.00\n",
      "epoch 4, step 34250/55000, batch loss = 0.01\n",
      "epoch 4, step 34500/55000, batch loss = 0.01\n",
      "epoch 4, step 34750/55000, batch loss = 0.00\n",
      "epoch 4, step 35000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.50\n",
      "epoch 4, step 35250/55000, batch loss = 0.01\n",
      "epoch 4, step 35500/55000, batch loss = 0.00\n",
      "epoch 4, step 35750/55000, batch loss = 0.00\n",
      "epoch 4, step 36000/55000, batch loss = 0.01\n",
      "epoch 4, step 36250/55000, batch loss = 0.00\n",
      "epoch 4, step 36500/55000, batch loss = 0.01\n",
      "epoch 4, step 36750/55000, batch loss = 0.01\n",
      "epoch 4, step 37000/55000, batch loss = 0.00\n",
      "epoch 4, step 37250/55000, batch loss = 0.00\n",
      "epoch 4, step 37500/55000, batch loss = 0.08\n",
      "Train accuracy = 99.51\n",
      "epoch 4, step 37750/55000, batch loss = 0.02\n",
      "epoch 4, step 38000/55000, batch loss = 0.00\n",
      "epoch 4, step 38250/55000, batch loss = 0.01\n",
      "epoch 4, step 38500/55000, batch loss = 0.09\n",
      "epoch 4, step 38750/55000, batch loss = 0.00\n",
      "epoch 4, step 39000/55000, batch loss = 0.02\n",
      "epoch 4, step 39250/55000, batch loss = 0.00\n",
      "epoch 4, step 39500/55000, batch loss = 0.03\n",
      "epoch 4, step 39750/55000, batch loss = 0.00\n",
      "epoch 4, step 40000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.51\n",
      "epoch 4, step 40250/55000, batch loss = 0.01\n",
      "epoch 4, step 40500/55000, batch loss = 0.01\n",
      "epoch 4, step 40750/55000, batch loss = 0.06\n",
      "epoch 4, step 41000/55000, batch loss = 0.07\n",
      "epoch 4, step 41250/55000, batch loss = 0.00\n",
      "epoch 4, step 41500/55000, batch loss = 0.00\n",
      "epoch 4, step 41750/55000, batch loss = 0.01\n",
      "epoch 4, step 42000/55000, batch loss = 0.14\n",
      "epoch 4, step 42250/55000, batch loss = 0.01\n",
      "epoch 4, step 42500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.52\n",
      "epoch 4, step 42750/55000, batch loss = 0.03\n",
      "epoch 4, step 43000/55000, batch loss = 0.00\n",
      "epoch 4, step 43250/55000, batch loss = 0.00\n",
      "epoch 4, step 43500/55000, batch loss = 0.01\n",
      "epoch 4, step 43750/55000, batch loss = 0.03\n",
      "epoch 4, step 44000/55000, batch loss = 0.00\n",
      "epoch 4, step 44250/55000, batch loss = 0.00\n",
      "epoch 4, step 44500/55000, batch loss = 0.00\n",
      "epoch 4, step 44750/55000, batch loss = 0.05\n",
      "epoch 4, step 45000/55000, batch loss = 0.06\n",
      "Train accuracy = 99.51\n",
      "epoch 4, step 45250/55000, batch loss = 0.04\n",
      "epoch 4, step 45500/55000, batch loss = 0.01\n",
      "epoch 4, step 45750/55000, batch loss = 0.03\n",
      "epoch 4, step 46000/55000, batch loss = 0.01\n",
      "epoch 4, step 46250/55000, batch loss = 0.01\n",
      "epoch 4, step 46500/55000, batch loss = 0.01\n",
      "epoch 4, step 46750/55000, batch loss = 0.00\n",
      "epoch 4, step 47000/55000, batch loss = 0.00\n",
      "epoch 4, step 47250/55000, batch loss = 0.01\n",
      "epoch 4, step 47500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.53\n",
      "epoch 4, step 47750/55000, batch loss = 0.09\n",
      "epoch 4, step 48000/55000, batch loss = 0.00\n",
      "epoch 4, step 48250/55000, batch loss = 0.00\n",
      "epoch 4, step 48500/55000, batch loss = 0.02\n",
      "epoch 4, step 48750/55000, batch loss = 0.00\n",
      "epoch 4, step 49000/55000, batch loss = 0.02\n",
      "epoch 4, step 49250/55000, batch loss = 0.00\n",
      "epoch 4, step 49500/55000, batch loss = 0.00\n",
      "epoch 4, step 49750/55000, batch loss = 0.01\n",
      "epoch 4, step 50000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.52\n",
      "epoch 4, step 50250/55000, batch loss = 0.00\n",
      "epoch 4, step 50500/55000, batch loss = 0.03\n",
      "epoch 4, step 50750/55000, batch loss = 0.01\n",
      "epoch 4, step 51000/55000, batch loss = 0.04\n",
      "epoch 4, step 51250/55000, batch loss = 0.06\n",
      "epoch 4, step 51500/55000, batch loss = 0.01\n",
      "epoch 4, step 51750/55000, batch loss = 0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, step 52000/55000, batch loss = 0.08\n",
      "epoch 4, step 52250/55000, batch loss = 0.01\n",
      "epoch 4, step 52500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.52\n",
      "epoch 4, step 52750/55000, batch loss = 0.05\n",
      "epoch 4, step 53000/55000, batch loss = 0.01\n",
      "epoch 4, step 53250/55000, batch loss = 0.01\n",
      "epoch 4, step 53500/55000, batch loss = 0.05\n",
      "epoch 4, step 53750/55000, batch loss = 0.00\n",
      "epoch 4, step 54000/55000, batch loss = 0.00\n",
      "epoch 4, step 54250/55000, batch loss = 0.00\n",
      "epoch 4, step 54500/55000, batch loss = 0.00\n",
      "epoch 4, step 54750/55000, batch loss = 0.04\n",
      "Train accuracy = 99.51\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.18\n",
      "Validation avg loss = 0.03\n",
      "\n",
      "epoch 5, step 0/55000, batch loss = 0.00\n",
      "epoch 5, step 250/55000, batch loss = 0.00\n",
      "epoch 5, step 500/55000, batch loss = 0.02\n",
      "epoch 5, step 750/55000, batch loss = 0.00\n",
      "epoch 5, step 1000/55000, batch loss = 0.01\n",
      "epoch 5, step 1250/55000, batch loss = 0.00\n",
      "epoch 5, step 1500/55000, batch loss = 0.03\n",
      "epoch 5, step 1750/55000, batch loss = 0.01\n",
      "epoch 5, step 2000/55000, batch loss = 0.00\n",
      "epoch 5, step 2250/55000, batch loss = 0.00\n",
      "epoch 5, step 2500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.73\n",
      "epoch 5, step 2750/55000, batch loss = 0.01\n",
      "epoch 5, step 3000/55000, batch loss = 0.00\n",
      "epoch 5, step 3250/55000, batch loss = 0.01\n",
      "epoch 5, step 3500/55000, batch loss = 0.01\n",
      "epoch 5, step 3750/55000, batch loss = 0.00\n",
      "epoch 5, step 4000/55000, batch loss = 0.02\n",
      "epoch 5, step 4250/55000, batch loss = 0.00\n",
      "epoch 5, step 4500/55000, batch loss = 0.01\n",
      "epoch 5, step 4750/55000, batch loss = 0.02\n",
      "epoch 5, step 5000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.68\n",
      "epoch 5, step 5250/55000, batch loss = 0.00\n",
      "epoch 5, step 5500/55000, batch loss = 0.04\n",
      "epoch 5, step 5750/55000, batch loss = 0.03\n",
      "epoch 5, step 6000/55000, batch loss = 0.02\n",
      "epoch 5, step 6250/55000, batch loss = 0.01\n",
      "epoch 5, step 6500/55000, batch loss = 0.00\n",
      "epoch 5, step 6750/55000, batch loss = 0.01\n",
      "epoch 5, step 7000/55000, batch loss = 0.00\n",
      "epoch 5, step 7250/55000, batch loss = 0.01\n",
      "epoch 5, step 7500/55000, batch loss = 0.03\n",
      "Train accuracy = 99.64\n",
      "epoch 5, step 7750/55000, batch loss = 0.03\n",
      "epoch 5, step 8000/55000, batch loss = 0.03\n",
      "epoch 5, step 8250/55000, batch loss = 0.00\n",
      "epoch 5, step 8500/55000, batch loss = 0.00\n",
      "epoch 5, step 8750/55000, batch loss = 0.00\n",
      "epoch 5, step 9000/55000, batch loss = 0.01\n",
      "epoch 5, step 9250/55000, batch loss = 0.00\n",
      "epoch 5, step 9500/55000, batch loss = 0.01\n",
      "epoch 5, step 9750/55000, batch loss = 0.11\n",
      "epoch 5, step 10000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.66\n",
      "epoch 5, step 10250/55000, batch loss = 0.00\n",
      "epoch 5, step 10500/55000, batch loss = 0.01\n",
      "epoch 5, step 10750/55000, batch loss = 0.01\n",
      "epoch 5, step 11000/55000, batch loss = 0.00\n",
      "epoch 5, step 11250/55000, batch loss = 0.02\n",
      "epoch 5, step 11500/55000, batch loss = 0.01\n",
      "epoch 5, step 11750/55000, batch loss = 0.00\n",
      "epoch 5, step 12000/55000, batch loss = 0.02\n",
      "epoch 5, step 12250/55000, batch loss = 0.01\n",
      "epoch 5, step 12500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.70\n",
      "epoch 5, step 12750/55000, batch loss = 0.01\n",
      "epoch 5, step 13000/55000, batch loss = 0.00\n",
      "epoch 5, step 13250/55000, batch loss = 0.00\n",
      "epoch 5, step 13500/55000, batch loss = 0.00\n",
      "epoch 5, step 13750/55000, batch loss = 0.00\n",
      "epoch 5, step 14000/55000, batch loss = 0.00\n",
      "epoch 5, step 14250/55000, batch loss = 0.00\n",
      "epoch 5, step 14500/55000, batch loss = 0.00\n",
      "epoch 5, step 14750/55000, batch loss = 0.00\n",
      "epoch 5, step 15000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.67\n",
      "epoch 5, step 15250/55000, batch loss = 0.01\n",
      "epoch 5, step 15500/55000, batch loss = 0.01\n",
      "epoch 5, step 15750/55000, batch loss = 0.00\n",
      "epoch 5, step 16000/55000, batch loss = 0.01\n",
      "epoch 5, step 16250/55000, batch loss = 0.02\n",
      "epoch 5, step 16500/55000, batch loss = 0.02\n",
      "epoch 5, step 16750/55000, batch loss = 0.02\n",
      "epoch 5, step 17000/55000, batch loss = 0.00\n",
      "epoch 5, step 17250/55000, batch loss = 0.00\n",
      "epoch 5, step 17500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.66\n",
      "epoch 5, step 17750/55000, batch loss = 0.02\n",
      "epoch 5, step 18000/55000, batch loss = 0.00\n",
      "epoch 5, step 18250/55000, batch loss = 0.04\n",
      "epoch 5, step 18500/55000, batch loss = 0.03\n",
      "epoch 5, step 18750/55000, batch loss = 0.01\n",
      "epoch 5, step 19000/55000, batch loss = 0.02\n",
      "epoch 5, step 19250/55000, batch loss = 0.01\n",
      "epoch 5, step 19500/55000, batch loss = 0.00\n",
      "epoch 5, step 19750/55000, batch loss = 0.06\n",
      "epoch 5, step 20000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.63\n",
      "epoch 5, step 20250/55000, batch loss = 0.04\n",
      "epoch 5, step 20500/55000, batch loss = 0.00\n",
      "epoch 5, step 20750/55000, batch loss = 0.05\n",
      "epoch 5, step 21000/55000, batch loss = 0.01\n",
      "epoch 5, step 21250/55000, batch loss = 0.01\n",
      "epoch 5, step 21500/55000, batch loss = 0.03\n",
      "epoch 5, step 21750/55000, batch loss = 0.02\n",
      "epoch 5, step 22000/55000, batch loss = 0.00\n",
      "epoch 5, step 22250/55000, batch loss = 0.06\n",
      "epoch 5, step 22500/55000, batch loss = 0.03\n",
      "Train accuracy = 99.57\n",
      "epoch 5, step 22750/55000, batch loss = 0.00\n",
      "epoch 5, step 23000/55000, batch loss = 0.05\n",
      "epoch 5, step 23250/55000, batch loss = 0.01\n",
      "epoch 5, step 23500/55000, batch loss = 0.02\n",
      "epoch 5, step 23750/55000, batch loss = 0.00\n",
      "epoch 5, step 24000/55000, batch loss = 0.06\n",
      "epoch 5, step 24250/55000, batch loss = 0.00\n",
      "epoch 5, step 24500/55000, batch loss = 0.00\n",
      "epoch 5, step 24750/55000, batch loss = 0.00\n",
      "epoch 5, step 25000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.59\n",
      "epoch 5, step 25250/55000, batch loss = 0.00\n",
      "epoch 5, step 25500/55000, batch loss = 0.01\n",
      "epoch 5, step 25750/55000, batch loss = 0.00\n",
      "epoch 5, step 26000/55000, batch loss = 0.00\n",
      "epoch 5, step 26250/55000, batch loss = 0.00\n",
      "epoch 5, step 26500/55000, batch loss = 0.00\n",
      "epoch 5, step 26750/55000, batch loss = 0.00\n",
      "epoch 5, step 27000/55000, batch loss = 0.02\n",
      "epoch 5, step 27250/55000, batch loss = 0.01\n",
      "epoch 5, step 27500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.60\n",
      "epoch 5, step 27750/55000, batch loss = 0.01\n",
      "epoch 5, step 28000/55000, batch loss = 0.04\n",
      "epoch 5, step 28250/55000, batch loss = 0.00\n",
      "epoch 5, step 28500/55000, batch loss = 0.02\n",
      "epoch 5, step 28750/55000, batch loss = 0.01\n",
      "epoch 5, step 29000/55000, batch loss = 0.00\n",
      "epoch 5, step 29250/55000, batch loss = 0.00\n",
      "epoch 5, step 29500/55000, batch loss = 0.01\n",
      "epoch 5, step 29750/55000, batch loss = 0.00\n",
      "epoch 5, step 30000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.60\n",
      "epoch 5, step 30250/55000, batch loss = 0.00\n",
      "epoch 5, step 30500/55000, batch loss = 0.01\n",
      "epoch 5, step 30750/55000, batch loss = 0.01\n",
      "epoch 5, step 31000/55000, batch loss = 0.00\n",
      "epoch 5, step 31250/55000, batch loss = 0.04\n",
      "epoch 5, step 31500/55000, batch loss = 0.00\n",
      "epoch 5, step 31750/55000, batch loss = 0.03\n",
      "epoch 5, step 32000/55000, batch loss = 0.02\n",
      "epoch 5, step 32250/55000, batch loss = 0.12\n",
      "epoch 5, step 32500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.61\n",
      "epoch 5, step 32750/55000, batch loss = 0.01\n",
      "epoch 5, step 33000/55000, batch loss = 0.00\n",
      "epoch 5, step 33250/55000, batch loss = 0.01\n",
      "epoch 5, step 33500/55000, batch loss = 0.01\n",
      "epoch 5, step 33750/55000, batch loss = 0.01\n",
      "epoch 5, step 34000/55000, batch loss = 0.02\n",
      "epoch 5, step 34250/55000, batch loss = 0.00\n",
      "epoch 5, step 34500/55000, batch loss = 0.01\n",
      "epoch 5, step 34750/55000, batch loss = 0.00\n",
      "epoch 5, step 35000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.62\n",
      "epoch 5, step 35250/55000, batch loss = 0.01\n",
      "epoch 5, step 35500/55000, batch loss = 0.00\n",
      "epoch 5, step 35750/55000, batch loss = 0.00\n",
      "epoch 5, step 36000/55000, batch loss = 0.01\n",
      "epoch 5, step 36250/55000, batch loss = 0.00\n",
      "epoch 5, step 36500/55000, batch loss = 0.00\n",
      "epoch 5, step 36750/55000, batch loss = 0.00\n",
      "epoch 5, step 37000/55000, batch loss = 0.00\n",
      "epoch 5, step 37250/55000, batch loss = 0.02\n",
      "epoch 5, step 37500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.61\n",
      "epoch 5, step 37750/55000, batch loss = 0.00\n",
      "epoch 5, step 38000/55000, batch loss = 0.02\n",
      "epoch 5, step 38250/55000, batch loss = 0.00\n",
      "epoch 5, step 38500/55000, batch loss = 0.00\n",
      "epoch 5, step 38750/55000, batch loss = 0.00\n",
      "epoch 5, step 39000/55000, batch loss = 0.00\n",
      "epoch 5, step 39250/55000, batch loss = 0.05\n",
      "epoch 5, step 39500/55000, batch loss = 0.02\n",
      "epoch 5, step 39750/55000, batch loss = 0.02\n",
      "epoch 5, step 40000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, step 40250/55000, batch loss = 0.00\n",
      "epoch 5, step 40500/55000, batch loss = 0.02\n",
      "epoch 5, step 40750/55000, batch loss = 0.01\n",
      "epoch 5, step 41000/55000, batch loss = 0.01\n",
      "epoch 5, step 41250/55000, batch loss = 0.04\n",
      "epoch 5, step 41500/55000, batch loss = 0.01\n",
      "epoch 5, step 41750/55000, batch loss = 0.01\n",
      "epoch 5, step 42000/55000, batch loss = 0.00\n",
      "epoch 5, step 42250/55000, batch loss = 0.19\n",
      "epoch 5, step 42500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.61\n",
      "epoch 5, step 42750/55000, batch loss = 0.01\n",
      "epoch 5, step 43000/55000, batch loss = 0.01\n",
      "epoch 5, step 43250/55000, batch loss = 0.17\n",
      "epoch 5, step 43500/55000, batch loss = 0.11\n",
      "epoch 5, step 43750/55000, batch loss = 0.00\n",
      "epoch 5, step 44000/55000, batch loss = 0.05\n",
      "epoch 5, step 44250/55000, batch loss = 0.00\n",
      "epoch 5, step 44500/55000, batch loss = 0.02\n",
      "epoch 5, step 44750/55000, batch loss = 0.00\n",
      "epoch 5, step 45000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.60\n",
      "epoch 5, step 45250/55000, batch loss = 0.00\n",
      "epoch 5, step 45500/55000, batch loss = 0.03\n",
      "epoch 5, step 45750/55000, batch loss = 0.03\n",
      "epoch 5, step 46000/55000, batch loss = 0.00\n",
      "epoch 5, step 46250/55000, batch loss = 0.01\n",
      "epoch 5, step 46500/55000, batch loss = 0.11\n",
      "epoch 5, step 46750/55000, batch loss = 0.00\n",
      "epoch 5, step 47000/55000, batch loss = 0.00\n",
      "epoch 5, step 47250/55000, batch loss = 0.03\n",
      "epoch 5, step 47500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.60\n",
      "epoch 5, step 47750/55000, batch loss = 0.00\n",
      "epoch 5, step 48000/55000, batch loss = 0.01\n",
      "epoch 5, step 48250/55000, batch loss = 0.00\n",
      "epoch 5, step 48500/55000, batch loss = 0.00\n",
      "epoch 5, step 48750/55000, batch loss = 0.00\n",
      "epoch 5, step 49000/55000, batch loss = 0.00\n",
      "epoch 5, step 49250/55000, batch loss = 0.03\n",
      "epoch 5, step 49500/55000, batch loss = 0.07\n",
      "epoch 5, step 49750/55000, batch loss = 0.01\n",
      "epoch 5, step 50000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.60\n",
      "epoch 5, step 50250/55000, batch loss = 0.00\n",
      "epoch 5, step 50500/55000, batch loss = 0.03\n",
      "epoch 5, step 50750/55000, batch loss = 0.00\n",
      "epoch 5, step 51000/55000, batch loss = 0.01\n",
      "epoch 5, step 51250/55000, batch loss = 0.00\n",
      "epoch 5, step 51500/55000, batch loss = 0.10\n",
      "epoch 5, step 51750/55000, batch loss = 0.15\n",
      "epoch 5, step 52000/55000, batch loss = 0.02\n",
      "epoch 5, step 52250/55000, batch loss = 0.01\n",
      "epoch 5, step 52500/55000, batch loss = 0.03\n",
      "Train accuracy = 99.60\n",
      "epoch 5, step 52750/55000, batch loss = 0.00\n",
      "epoch 5, step 53000/55000, batch loss = 0.00\n",
      "epoch 5, step 53250/55000, batch loss = 0.04\n",
      "epoch 5, step 53500/55000, batch loss = 0.02\n",
      "epoch 5, step 53750/55000, batch loss = 0.07\n",
      "epoch 5, step 54000/55000, batch loss = 0.00\n",
      "epoch 5, step 54250/55000, batch loss = 0.00\n",
      "epoch 5, step 54500/55000, batch loss = 0.01\n",
      "epoch 5, step 54750/55000, batch loss = 0.07\n",
      "Train accuracy = 99.59\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.20\n",
      "Validation avg loss = 0.03\n",
      "\n",
      "epoch 6, step 0/55000, batch loss = 0.04\n",
      "epoch 6, step 250/55000, batch loss = 0.00\n",
      "epoch 6, step 500/55000, batch loss = 0.00\n",
      "epoch 6, step 750/55000, batch loss = 0.01\n",
      "epoch 6, step 1000/55000, batch loss = 0.00\n",
      "epoch 6, step 1250/55000, batch loss = 0.00\n",
      "epoch 6, step 1500/55000, batch loss = 0.00\n",
      "epoch 6, step 1750/55000, batch loss = 0.02\n",
      "epoch 6, step 2000/55000, batch loss = 0.01\n",
      "epoch 6, step 2250/55000, batch loss = 0.01\n",
      "epoch 6, step 2500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.37\n",
      "epoch 6, step 2750/55000, batch loss = 0.01\n",
      "epoch 6, step 3000/55000, batch loss = 0.00\n",
      "epoch 6, step 3250/55000, batch loss = 0.05\n",
      "epoch 6, step 3500/55000, batch loss = 0.00\n",
      "epoch 6, step 3750/55000, batch loss = 0.00\n",
      "epoch 6, step 4000/55000, batch loss = 0.04\n",
      "epoch 6, step 4250/55000, batch loss = 0.00\n",
      "epoch 6, step 4500/55000, batch loss = 0.00\n",
      "epoch 6, step 4750/55000, batch loss = 0.00\n",
      "epoch 6, step 5000/55000, batch loss = 0.03\n",
      "Train accuracy = 99.47\n",
      "epoch 6, step 5250/55000, batch loss = 0.00\n",
      "epoch 6, step 5500/55000, batch loss = 0.00\n",
      "epoch 6, step 5750/55000, batch loss = 0.00\n",
      "epoch 6, step 6000/55000, batch loss = 0.01\n",
      "epoch 6, step 6250/55000, batch loss = 0.00\n",
      "epoch 6, step 6500/55000, batch loss = 0.01\n",
      "epoch 6, step 6750/55000, batch loss = 0.05\n",
      "epoch 6, step 7000/55000, batch loss = 0.01\n",
      "epoch 6, step 7250/55000, batch loss = 0.01\n",
      "epoch 6, step 7500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.48\n",
      "epoch 6, step 7750/55000, batch loss = 0.00\n",
      "epoch 6, step 8000/55000, batch loss = 0.00\n",
      "epoch 6, step 8250/55000, batch loss = 0.01\n",
      "epoch 6, step 8500/55000, batch loss = 0.04\n",
      "epoch 6, step 8750/55000, batch loss = 0.01\n",
      "epoch 6, step 9000/55000, batch loss = 0.01\n",
      "epoch 6, step 9250/55000, batch loss = 0.00\n",
      "epoch 6, step 9500/55000, batch loss = 0.18\n",
      "epoch 6, step 9750/55000, batch loss = 0.00\n",
      "epoch 6, step 10000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.48\n",
      "epoch 6, step 10250/55000, batch loss = 0.00\n",
      "epoch 6, step 10500/55000, batch loss = 0.00\n",
      "epoch 6, step 10750/55000, batch loss = 0.00\n",
      "epoch 6, step 11000/55000, batch loss = 0.00\n",
      "epoch 6, step 11250/55000, batch loss = 0.01\n",
      "epoch 6, step 11500/55000, batch loss = 0.00\n",
      "epoch 6, step 11750/55000, batch loss = 0.00\n",
      "epoch 6, step 12000/55000, batch loss = 0.01\n",
      "epoch 6, step 12250/55000, batch loss = 0.08\n",
      "epoch 6, step 12500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.50\n",
      "epoch 6, step 12750/55000, batch loss = 0.04\n",
      "epoch 6, step 13000/55000, batch loss = 0.01\n",
      "epoch 6, step 13250/55000, batch loss = 0.02\n",
      "epoch 6, step 13500/55000, batch loss = 0.00\n",
      "epoch 6, step 13750/55000, batch loss = 0.01\n",
      "epoch 6, step 14000/55000, batch loss = 0.03\n",
      "epoch 6, step 14250/55000, batch loss = 0.03\n",
      "epoch 6, step 14500/55000, batch loss = 0.01\n",
      "epoch 6, step 14750/55000, batch loss = 0.01\n",
      "epoch 6, step 15000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.50\n",
      "epoch 6, step 15250/55000, batch loss = 0.01\n",
      "epoch 6, step 15500/55000, batch loss = 0.00\n",
      "epoch 6, step 15750/55000, batch loss = 0.02\n",
      "epoch 6, step 16000/55000, batch loss = 0.02\n",
      "epoch 6, step 16250/55000, batch loss = 0.01\n",
      "epoch 6, step 16500/55000, batch loss = 0.00\n",
      "epoch 6, step 16750/55000, batch loss = 0.05\n",
      "epoch 6, step 17000/55000, batch loss = 0.02\n",
      "epoch 6, step 17250/55000, batch loss = 0.01\n",
      "epoch 6, step 17500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.49\n",
      "epoch 6, step 17750/55000, batch loss = 0.01\n",
      "epoch 6, step 18000/55000, batch loss = 0.01\n",
      "epoch 6, step 18250/55000, batch loss = 0.00\n",
      "epoch 6, step 18500/55000, batch loss = 0.06\n",
      "epoch 6, step 18750/55000, batch loss = 0.00\n",
      "epoch 6, step 19000/55000, batch loss = 0.01\n",
      "epoch 6, step 19250/55000, batch loss = 0.01\n",
      "epoch 6, step 19500/55000, batch loss = 0.00\n",
      "epoch 6, step 19750/55000, batch loss = 0.01\n",
      "epoch 6, step 20000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.52\n",
      "epoch 6, step 20250/55000, batch loss = 0.01\n",
      "epoch 6, step 20500/55000, batch loss = 0.02\n",
      "epoch 6, step 20750/55000, batch loss = 0.01\n",
      "epoch 6, step 21000/55000, batch loss = 0.00\n",
      "epoch 6, step 21250/55000, batch loss = 0.07\n",
      "epoch 6, step 21500/55000, batch loss = 0.02\n",
      "epoch 6, step 21750/55000, batch loss = 0.00\n",
      "epoch 6, step 22000/55000, batch loss = 0.01\n",
      "epoch 6, step 22250/55000, batch loss = 0.01\n",
      "epoch 6, step 22500/55000, batch loss = 0.03\n",
      "Train accuracy = 99.51\n",
      "epoch 6, step 22750/55000, batch loss = 0.00\n",
      "epoch 6, step 23000/55000, batch loss = 0.00\n",
      "epoch 6, step 23250/55000, batch loss = 0.01\n",
      "epoch 6, step 23500/55000, batch loss = 0.00\n",
      "epoch 6, step 23750/55000, batch loss = 0.01\n",
      "epoch 6, step 24000/55000, batch loss = 0.07\n",
      "epoch 6, step 24250/55000, batch loss = 0.00\n",
      "epoch 6, step 24500/55000, batch loss = 0.01\n",
      "epoch 6, step 24750/55000, batch loss = 0.02\n",
      "epoch 6, step 25000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.52\n",
      "epoch 6, step 25250/55000, batch loss = 0.00\n",
      "epoch 6, step 25500/55000, batch loss = 0.01\n",
      "epoch 6, step 25750/55000, batch loss = 0.00\n",
      "epoch 6, step 26000/55000, batch loss = 0.04\n",
      "epoch 6, step 26250/55000, batch loss = 0.00\n",
      "epoch 6, step 26500/55000, batch loss = 0.00\n",
      "epoch 6, step 26750/55000, batch loss = 0.01\n",
      "epoch 6, step 27000/55000, batch loss = 0.00\n",
      "epoch 6, step 27250/55000, batch loss = 0.02\n",
      "epoch 6, step 27500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.52\n",
      "epoch 6, step 27750/55000, batch loss = 0.00\n",
      "epoch 6, step 28000/55000, batch loss = 0.01\n",
      "epoch 6, step 28250/55000, batch loss = 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, step 28500/55000, batch loss = 0.00\n",
      "epoch 6, step 28750/55000, batch loss = 0.03\n",
      "epoch 6, step 29000/55000, batch loss = 0.01\n",
      "epoch 6, step 29250/55000, batch loss = 0.00\n",
      "epoch 6, step 29500/55000, batch loss = 0.02\n",
      "epoch 6, step 29750/55000, batch loss = 0.00\n",
      "epoch 6, step 30000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.53\n",
      "epoch 6, step 30250/55000, batch loss = 0.01\n",
      "epoch 6, step 30500/55000, batch loss = 0.00\n",
      "epoch 6, step 30750/55000, batch loss = 0.02\n",
      "epoch 6, step 31000/55000, batch loss = 0.03\n",
      "epoch 6, step 31250/55000, batch loss = 0.01\n",
      "epoch 6, step 31500/55000, batch loss = 0.05\n",
      "epoch 6, step 31750/55000, batch loss = 0.00\n",
      "epoch 6, step 32000/55000, batch loss = 0.01\n",
      "epoch 6, step 32250/55000, batch loss = 0.00\n",
      "epoch 6, step 32500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.54\n",
      "epoch 6, step 32750/55000, batch loss = 0.01\n",
      "epoch 6, step 33000/55000, batch loss = 0.01\n",
      "epoch 6, step 33250/55000, batch loss = 0.00\n",
      "epoch 6, step 33500/55000, batch loss = 0.03\n",
      "epoch 6, step 33750/55000, batch loss = 0.00\n",
      "epoch 6, step 34000/55000, batch loss = 0.00\n",
      "epoch 6, step 34250/55000, batch loss = 0.01\n",
      "epoch 6, step 34500/55000, batch loss = 0.02\n",
      "epoch 6, step 34750/55000, batch loss = 0.00\n",
      "epoch 6, step 35000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.56\n",
      "epoch 6, step 35250/55000, batch loss = 0.01\n",
      "epoch 6, step 35500/55000, batch loss = 0.01\n",
      "epoch 6, step 35750/55000, batch loss = 0.01\n",
      "epoch 6, step 36000/55000, batch loss = 0.02\n",
      "epoch 6, step 36250/55000, batch loss = 0.03\n",
      "epoch 6, step 36500/55000, batch loss = 0.00\n",
      "epoch 6, step 36750/55000, batch loss = 0.01\n",
      "epoch 6, step 37000/55000, batch loss = 0.03\n",
      "epoch 6, step 37250/55000, batch loss = 0.00\n",
      "epoch 6, step 37500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.55\n",
      "epoch 6, step 37750/55000, batch loss = 0.02\n",
      "epoch 6, step 38000/55000, batch loss = 0.00\n",
      "epoch 6, step 38250/55000, batch loss = 0.00\n",
      "epoch 6, step 38500/55000, batch loss = 0.01\n",
      "epoch 6, step 38750/55000, batch loss = 0.00\n",
      "epoch 6, step 39000/55000, batch loss = 0.01\n",
      "epoch 6, step 39250/55000, batch loss = 0.07\n",
      "epoch 6, step 39500/55000, batch loss = 0.02\n",
      "epoch 6, step 39750/55000, batch loss = 0.01\n",
      "epoch 6, step 40000/55000, batch loss = 0.06\n",
      "Train accuracy = 99.56\n",
      "epoch 6, step 40250/55000, batch loss = 0.01\n",
      "epoch 6, step 40500/55000, batch loss = 0.03\n",
      "epoch 6, step 40750/55000, batch loss = 0.00\n",
      "epoch 6, step 41000/55000, batch loss = 0.01\n",
      "epoch 6, step 41250/55000, batch loss = 0.01\n",
      "epoch 6, step 41500/55000, batch loss = 0.00\n",
      "epoch 6, step 41750/55000, batch loss = 0.00\n",
      "epoch 6, step 42000/55000, batch loss = 0.01\n",
      "epoch 6, step 42250/55000, batch loss = 0.01\n",
      "epoch 6, step 42500/55000, batch loss = 0.03\n",
      "Train accuracy = 99.56\n",
      "epoch 6, step 42750/55000, batch loss = 0.02\n",
      "epoch 6, step 43000/55000, batch loss = 0.02\n",
      "epoch 6, step 43250/55000, batch loss = 0.01\n",
      "epoch 6, step 43500/55000, batch loss = 0.00\n",
      "epoch 6, step 43750/55000, batch loss = 0.00\n",
      "epoch 6, step 44000/55000, batch loss = 0.00\n",
      "epoch 6, step 44250/55000, batch loss = 0.00\n",
      "epoch 6, step 44500/55000, batch loss = 0.03\n",
      "epoch 6, step 44750/55000, batch loss = 0.06\n",
      "epoch 6, step 45000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.56\n",
      "epoch 6, step 45250/55000, batch loss = 0.01\n",
      "epoch 6, step 45500/55000, batch loss = 0.01\n",
      "epoch 6, step 45750/55000, batch loss = 0.01\n",
      "epoch 6, step 46000/55000, batch loss = 0.01\n",
      "epoch 6, step 46250/55000, batch loss = 0.00\n",
      "epoch 6, step 46500/55000, batch loss = 0.00\n",
      "epoch 6, step 46750/55000, batch loss = 0.00\n",
      "epoch 6, step 47000/55000, batch loss = 0.00\n",
      "epoch 6, step 47250/55000, batch loss = 0.00\n",
      "epoch 6, step 47500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.58\n",
      "epoch 6, step 47750/55000, batch loss = 0.01\n",
      "epoch 6, step 48000/55000, batch loss = 0.03\n",
      "epoch 6, step 48250/55000, batch loss = 0.00\n",
      "epoch 6, step 48500/55000, batch loss = 0.02\n",
      "epoch 6, step 48750/55000, batch loss = 0.01\n",
      "epoch 6, step 49000/55000, batch loss = 0.01\n",
      "epoch 6, step 49250/55000, batch loss = 0.01\n",
      "epoch 6, step 49500/55000, batch loss = 0.01\n",
      "epoch 6, step 49750/55000, batch loss = 0.00\n",
      "epoch 6, step 50000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.58\n",
      "epoch 6, step 50250/55000, batch loss = 0.01\n",
      "epoch 6, step 50500/55000, batch loss = 0.03\n",
      "epoch 6, step 50750/55000, batch loss = 0.01\n",
      "epoch 6, step 51000/55000, batch loss = 0.00\n",
      "epoch 6, step 51250/55000, batch loss = 0.01\n",
      "epoch 6, step 51500/55000, batch loss = 0.00\n",
      "epoch 6, step 51750/55000, batch loss = 0.00\n",
      "epoch 6, step 52000/55000, batch loss = 0.01\n",
      "epoch 6, step 52250/55000, batch loss = 0.00\n",
      "epoch 6, step 52500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.58\n",
      "epoch 6, step 52750/55000, batch loss = 0.00\n",
      "epoch 6, step 53000/55000, batch loss = 0.01\n",
      "epoch 6, step 53250/55000, batch loss = 0.01\n",
      "epoch 6, step 53500/55000, batch loss = 0.01\n",
      "epoch 6, step 53750/55000, batch loss = 0.00\n",
      "epoch 6, step 54000/55000, batch loss = 0.00\n",
      "epoch 6, step 54250/55000, batch loss = 0.02\n",
      "epoch 6, step 54500/55000, batch loss = 0.05\n",
      "epoch 6, step 54750/55000, batch loss = 0.03\n",
      "Train accuracy = 99.58\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.18\n",
      "Validation avg loss = 0.03\n",
      "\n",
      "epoch 7, step 0/55000, batch loss = 0.00\n",
      "epoch 7, step 250/55000, batch loss = 0.06\n",
      "epoch 7, step 500/55000, batch loss = 0.06\n",
      "epoch 7, step 750/55000, batch loss = 0.01\n",
      "epoch 7, step 1000/55000, batch loss = 0.01\n",
      "epoch 7, step 1250/55000, batch loss = 0.03\n",
      "epoch 7, step 1500/55000, batch loss = 0.00\n",
      "epoch 7, step 1750/55000, batch loss = 0.01\n",
      "epoch 7, step 2000/55000, batch loss = 0.01\n",
      "epoch 7, step 2250/55000, batch loss = 0.00\n",
      "epoch 7, step 2500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.53\n",
      "epoch 7, step 2750/55000, batch loss = 0.00\n",
      "epoch 7, step 3000/55000, batch loss = 0.00\n",
      "epoch 7, step 3250/55000, batch loss = 0.00\n",
      "epoch 7, step 3500/55000, batch loss = 0.00\n",
      "epoch 7, step 3750/55000, batch loss = 0.00\n",
      "epoch 7, step 4000/55000, batch loss = 0.01\n",
      "epoch 7, step 4250/55000, batch loss = 0.00\n",
      "epoch 7, step 4500/55000, batch loss = 0.01\n",
      "epoch 7, step 4750/55000, batch loss = 0.00\n",
      "epoch 7, step 5000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.54\n",
      "epoch 7, step 5250/55000, batch loss = 0.00\n",
      "epoch 7, step 5500/55000, batch loss = 0.03\n",
      "epoch 7, step 5750/55000, batch loss = 0.02\n",
      "epoch 7, step 6000/55000, batch loss = 0.01\n",
      "epoch 7, step 6250/55000, batch loss = 0.00\n",
      "epoch 7, step 6500/55000, batch loss = 0.00\n",
      "epoch 7, step 6750/55000, batch loss = 0.01\n",
      "epoch 7, step 7000/55000, batch loss = 0.03\n",
      "epoch 7, step 7250/55000, batch loss = 0.00\n",
      "epoch 7, step 7500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.58\n",
      "epoch 7, step 7750/55000, batch loss = 0.02\n",
      "epoch 7, step 8000/55000, batch loss = 0.00\n",
      "epoch 7, step 8250/55000, batch loss = 0.02\n",
      "epoch 7, step 8500/55000, batch loss = 0.00\n",
      "epoch 7, step 8750/55000, batch loss = 0.00\n",
      "epoch 7, step 9000/55000, batch loss = 0.02\n",
      "epoch 7, step 9250/55000, batch loss = 0.00\n",
      "epoch 7, step 9500/55000, batch loss = 0.05\n",
      "epoch 7, step 9750/55000, batch loss = 0.05\n",
      "epoch 7, step 10000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.55\n",
      "epoch 7, step 10250/55000, batch loss = 0.00\n",
      "epoch 7, step 10500/55000, batch loss = 0.02\n",
      "epoch 7, step 10750/55000, batch loss = 0.00\n",
      "epoch 7, step 11000/55000, batch loss = 0.02\n",
      "epoch 7, step 11250/55000, batch loss = 0.03\n",
      "epoch 7, step 11500/55000, batch loss = 0.00\n",
      "epoch 7, step 11750/55000, batch loss = 0.02\n",
      "epoch 7, step 12000/55000, batch loss = 0.03\n",
      "epoch 7, step 12250/55000, batch loss = 0.01\n",
      "epoch 7, step 12500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.59\n",
      "epoch 7, step 12750/55000, batch loss = 0.00\n",
      "epoch 7, step 13000/55000, batch loss = 0.00\n",
      "epoch 7, step 13250/55000, batch loss = 0.00\n",
      "epoch 7, step 13500/55000, batch loss = 0.09\n",
      "epoch 7, step 13750/55000, batch loss = 0.02\n",
      "epoch 7, step 14000/55000, batch loss = 0.01\n",
      "epoch 7, step 14250/55000, batch loss = 0.01\n",
      "epoch 7, step 14500/55000, batch loss = 0.03\n",
      "epoch 7, step 14750/55000, batch loss = 0.02\n",
      "epoch 7, step 15000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.59\n",
      "epoch 7, step 15250/55000, batch loss = 0.01\n",
      "epoch 7, step 15500/55000, batch loss = 0.00\n",
      "epoch 7, step 15750/55000, batch loss = 0.00\n",
      "epoch 7, step 16000/55000, batch loss = 0.00\n",
      "epoch 7, step 16250/55000, batch loss = 0.00\n",
      "epoch 7, step 16500/55000, batch loss = 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, step 16750/55000, batch loss = 0.00\n",
      "epoch 7, step 17000/55000, batch loss = 0.00\n",
      "epoch 7, step 17250/55000, batch loss = 0.00\n",
      "epoch 7, step 17500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.57\n",
      "epoch 7, step 17750/55000, batch loss = 0.01\n",
      "epoch 7, step 18000/55000, batch loss = 0.19\n",
      "epoch 7, step 18250/55000, batch loss = 0.00\n",
      "epoch 7, step 18500/55000, batch loss = 0.06\n",
      "epoch 7, step 18750/55000, batch loss = 0.00\n",
      "epoch 7, step 19000/55000, batch loss = 0.00\n",
      "epoch 7, step 19250/55000, batch loss = 0.01\n",
      "epoch 7, step 19500/55000, batch loss = 0.00\n",
      "epoch 7, step 19750/55000, batch loss = 0.00\n",
      "epoch 7, step 20000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.56\n",
      "epoch 7, step 20250/55000, batch loss = 0.00\n",
      "epoch 7, step 20500/55000, batch loss = 0.01\n",
      "epoch 7, step 20750/55000, batch loss = 0.00\n",
      "epoch 7, step 21000/55000, batch loss = 0.01\n",
      "epoch 7, step 21250/55000, batch loss = 0.01\n",
      "epoch 7, step 21500/55000, batch loss = 0.04\n",
      "epoch 7, step 21750/55000, batch loss = 0.00\n",
      "epoch 7, step 22000/55000, batch loss = 0.01\n",
      "epoch 7, step 22250/55000, batch loss = 0.00\n",
      "epoch 7, step 22500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.54\n",
      "epoch 7, step 22750/55000, batch loss = 0.01\n",
      "epoch 7, step 23000/55000, batch loss = 0.00\n",
      "epoch 7, step 23250/55000, batch loss = 0.00\n",
      "epoch 7, step 23500/55000, batch loss = 0.00\n",
      "epoch 7, step 23750/55000, batch loss = 0.01\n",
      "epoch 7, step 24000/55000, batch loss = 0.01\n",
      "epoch 7, step 24250/55000, batch loss = 0.00\n",
      "epoch 7, step 24500/55000, batch loss = 0.01\n",
      "epoch 7, step 24750/55000, batch loss = 0.01\n",
      "epoch 7, step 25000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.57\n",
      "epoch 7, step 25250/55000, batch loss = 0.00\n",
      "epoch 7, step 25500/55000, batch loss = 0.02\n",
      "epoch 7, step 25750/55000, batch loss = 0.00\n",
      "epoch 7, step 26000/55000, batch loss = 0.00\n",
      "epoch 7, step 26250/55000, batch loss = 0.01\n",
      "epoch 7, step 26500/55000, batch loss = 0.00\n",
      "epoch 7, step 26750/55000, batch loss = 0.00\n",
      "epoch 7, step 27000/55000, batch loss = 0.00\n",
      "epoch 7, step 27250/55000, batch loss = 0.02\n",
      "epoch 7, step 27500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.59\n",
      "epoch 7, step 27750/55000, batch loss = 0.04\n",
      "epoch 7, step 28000/55000, batch loss = 0.01\n",
      "epoch 7, step 28250/55000, batch loss = 0.01\n",
      "epoch 7, step 28500/55000, batch loss = 0.01\n",
      "epoch 7, step 28750/55000, batch loss = 0.00\n",
      "epoch 7, step 29000/55000, batch loss = 0.00\n",
      "epoch 7, step 29250/55000, batch loss = 0.00\n",
      "epoch 7, step 29500/55000, batch loss = 0.00\n",
      "epoch 7, step 29750/55000, batch loss = 0.01\n",
      "epoch 7, step 30000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.60\n",
      "epoch 7, step 30250/55000, batch loss = 0.03\n",
      "epoch 7, step 30500/55000, batch loss = 0.00\n",
      "epoch 7, step 30750/55000, batch loss = 0.02\n",
      "epoch 7, step 31000/55000, batch loss = 0.04\n",
      "epoch 7, step 31250/55000, batch loss = 0.04\n",
      "epoch 7, step 31500/55000, batch loss = 0.00\n",
      "epoch 7, step 31750/55000, batch loss = 0.00\n",
      "epoch 7, step 32000/55000, batch loss = 0.02\n",
      "epoch 7, step 32250/55000, batch loss = 0.00\n",
      "epoch 7, step 32500/55000, batch loss = 0.02\n",
      "Train accuracy = 99.60\n",
      "epoch 7, step 32750/55000, batch loss = 0.00\n",
      "epoch 7, step 33000/55000, batch loss = 0.02\n",
      "epoch 7, step 33250/55000, batch loss = 0.01\n",
      "epoch 7, step 33500/55000, batch loss = 0.00\n",
      "epoch 7, step 33750/55000, batch loss = 0.00\n",
      "epoch 7, step 34000/55000, batch loss = 0.00\n",
      "epoch 7, step 34250/55000, batch loss = 0.02\n",
      "epoch 7, step 34500/55000, batch loss = 0.00\n",
      "epoch 7, step 34750/55000, batch loss = 0.02\n",
      "epoch 7, step 35000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.58\n",
      "epoch 7, step 35250/55000, batch loss = 0.01\n",
      "epoch 7, step 35500/55000, batch loss = 0.00\n",
      "epoch 7, step 35750/55000, batch loss = 0.01\n",
      "epoch 7, step 36000/55000, batch loss = 0.01\n",
      "epoch 7, step 36250/55000, batch loss = 0.06\n",
      "epoch 7, step 36500/55000, batch loss = 0.00\n",
      "epoch 7, step 36750/55000, batch loss = 0.00\n",
      "epoch 7, step 37000/55000, batch loss = 0.02\n",
      "epoch 7, step 37250/55000, batch loss = 0.00\n",
      "epoch 7, step 37500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.59\n",
      "epoch 7, step 37750/55000, batch loss = 0.00\n",
      "epoch 7, step 38000/55000, batch loss = 0.00\n",
      "epoch 7, step 38250/55000, batch loss = 0.01\n",
      "epoch 7, step 38500/55000, batch loss = 0.02\n",
      "epoch 7, step 38750/55000, batch loss = 0.01\n",
      "epoch 7, step 39000/55000, batch loss = 0.03\n",
      "epoch 7, step 39250/55000, batch loss = 0.01\n",
      "epoch 7, step 39500/55000, batch loss = 0.01\n",
      "epoch 7, step 39750/55000, batch loss = 0.09\n",
      "epoch 7, step 40000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.60\n",
      "epoch 7, step 40250/55000, batch loss = 0.03\n",
      "epoch 7, step 40500/55000, batch loss = 0.02\n",
      "epoch 7, step 40750/55000, batch loss = 0.00\n",
      "epoch 7, step 41000/55000, batch loss = 0.00\n",
      "epoch 7, step 41250/55000, batch loss = 0.03\n",
      "epoch 7, step 41500/55000, batch loss = 0.01\n",
      "epoch 7, step 41750/55000, batch loss = 0.03\n",
      "epoch 7, step 42000/55000, batch loss = 0.01\n",
      "epoch 7, step 42250/55000, batch loss = 0.00\n",
      "epoch 7, step 42500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.59\n",
      "epoch 7, step 42750/55000, batch loss = 0.00\n",
      "epoch 7, step 43000/55000, batch loss = 0.02\n",
      "epoch 7, step 43250/55000, batch loss = 0.02\n",
      "epoch 7, step 43500/55000, batch loss = 0.00\n",
      "epoch 7, step 43750/55000, batch loss = 0.01\n",
      "epoch 7, step 44000/55000, batch loss = 0.01\n",
      "epoch 7, step 44250/55000, batch loss = 0.01\n",
      "epoch 7, step 44500/55000, batch loss = 0.00\n",
      "epoch 7, step 44750/55000, batch loss = 0.01\n",
      "epoch 7, step 45000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.60\n",
      "epoch 7, step 45250/55000, batch loss = 0.01\n",
      "epoch 7, step 45500/55000, batch loss = 0.01\n",
      "epoch 7, step 45750/55000, batch loss = 0.02\n",
      "epoch 7, step 46000/55000, batch loss = 0.00\n",
      "epoch 7, step 46250/55000, batch loss = 0.03\n",
      "epoch 7, step 46500/55000, batch loss = 0.02\n",
      "epoch 7, step 46750/55000, batch loss = 0.00\n",
      "epoch 7, step 47000/55000, batch loss = 0.01\n",
      "epoch 7, step 47250/55000, batch loss = 0.03\n",
      "epoch 7, step 47500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.60\n",
      "epoch 7, step 47750/55000, batch loss = 0.00\n",
      "epoch 7, step 48000/55000, batch loss = 0.02\n",
      "epoch 7, step 48250/55000, batch loss = 0.02\n",
      "epoch 7, step 48500/55000, batch loss = 0.00\n",
      "epoch 7, step 48750/55000, batch loss = 0.08\n",
      "epoch 7, step 49000/55000, batch loss = 0.02\n",
      "epoch 7, step 49250/55000, batch loss = 0.01\n",
      "epoch 7, step 49500/55000, batch loss = 0.01\n",
      "epoch 7, step 49750/55000, batch loss = 0.01\n",
      "epoch 7, step 50000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.60\n",
      "epoch 7, step 50250/55000, batch loss = 0.01\n",
      "epoch 7, step 50500/55000, batch loss = 0.04\n",
      "epoch 7, step 50750/55000, batch loss = 0.02\n",
      "epoch 7, step 51000/55000, batch loss = 0.05\n",
      "epoch 7, step 51250/55000, batch loss = 0.00\n",
      "epoch 7, step 51500/55000, batch loss = 0.01\n",
      "epoch 7, step 51750/55000, batch loss = 0.00\n",
      "epoch 7, step 52000/55000, batch loss = 0.00\n",
      "epoch 7, step 52250/55000, batch loss = 0.00\n",
      "epoch 7, step 52500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.60\n",
      "epoch 7, step 52750/55000, batch loss = 0.00\n",
      "epoch 7, step 53000/55000, batch loss = 0.01\n",
      "epoch 7, step 53250/55000, batch loss = 0.01\n",
      "epoch 7, step 53500/55000, batch loss = 0.06\n",
      "epoch 7, step 53750/55000, batch loss = 0.00\n",
      "epoch 7, step 54000/55000, batch loss = 0.01\n",
      "epoch 7, step 54250/55000, batch loss = 0.01\n",
      "epoch 7, step 54500/55000, batch loss = 0.00\n",
      "epoch 7, step 54750/55000, batch loss = 0.00\n",
      "Train accuracy = 99.60\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.18\n",
      "Validation avg loss = 0.03\n",
      "\n",
      "epoch 8, step 0/55000, batch loss = 0.01\n",
      "epoch 8, step 250/55000, batch loss = 0.02\n",
      "epoch 8, step 500/55000, batch loss = 0.03\n",
      "epoch 8, step 750/55000, batch loss = 0.01\n",
      "epoch 8, step 1000/55000, batch loss = 0.01\n",
      "epoch 8, step 1250/55000, batch loss = 0.00\n",
      "epoch 8, step 1500/55000, batch loss = 0.00\n",
      "epoch 8, step 1750/55000, batch loss = 0.02\n",
      "epoch 8, step 2000/55000, batch loss = 0.01\n",
      "epoch 8, step 2250/55000, batch loss = 0.01\n",
      "epoch 8, step 2500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.57\n",
      "epoch 8, step 2750/55000, batch loss = 0.01\n",
      "epoch 8, step 3000/55000, batch loss = 0.01\n",
      "epoch 8, step 3250/55000, batch loss = 0.00\n",
      "epoch 8, step 3500/55000, batch loss = 0.00\n",
      "epoch 8, step 3750/55000, batch loss = 0.01\n",
      "epoch 8, step 4000/55000, batch loss = 0.01\n",
      "epoch 8, step 4250/55000, batch loss = 0.00\n",
      "epoch 8, step 4500/55000, batch loss = 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, step 4750/55000, batch loss = 0.16\n",
      "epoch 8, step 5000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.66\n",
      "epoch 8, step 5250/55000, batch loss = 0.00\n",
      "epoch 8, step 5500/55000, batch loss = 0.03\n",
      "epoch 8, step 5750/55000, batch loss = 0.00\n",
      "epoch 8, step 6000/55000, batch loss = 0.00\n",
      "epoch 8, step 6250/55000, batch loss = 0.01\n",
      "epoch 8, step 6500/55000, batch loss = 0.01\n",
      "epoch 8, step 6750/55000, batch loss = 0.00\n",
      "epoch 8, step 7000/55000, batch loss = 0.04\n",
      "epoch 8, step 7250/55000, batch loss = 0.00\n",
      "epoch 8, step 7500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.66\n",
      "epoch 8, step 7750/55000, batch loss = 0.02\n",
      "epoch 8, step 8000/55000, batch loss = 0.00\n",
      "epoch 8, step 8250/55000, batch loss = 0.01\n",
      "epoch 8, step 8500/55000, batch loss = 0.00\n",
      "epoch 8, step 8750/55000, batch loss = 0.01\n",
      "epoch 8, step 9000/55000, batch loss = 0.01\n",
      "epoch 8, step 9250/55000, batch loss = 0.00\n",
      "epoch 8, step 9500/55000, batch loss = 0.01\n",
      "epoch 8, step 9750/55000, batch loss = 0.01\n",
      "epoch 8, step 10000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.66\n",
      "epoch 8, step 10250/55000, batch loss = 0.00\n",
      "epoch 8, step 10500/55000, batch loss = 0.00\n",
      "epoch 8, step 10750/55000, batch loss = 0.00\n",
      "epoch 8, step 11000/55000, batch loss = 0.02\n",
      "epoch 8, step 11250/55000, batch loss = 0.08\n",
      "epoch 8, step 11500/55000, batch loss = 0.06\n",
      "epoch 8, step 11750/55000, batch loss = 0.00\n",
      "epoch 8, step 12000/55000, batch loss = 0.00\n",
      "epoch 8, step 12250/55000, batch loss = 0.00\n",
      "epoch 8, step 12500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.63\n",
      "epoch 8, step 12750/55000, batch loss = 0.01\n",
      "epoch 8, step 13000/55000, batch loss = 0.05\n",
      "epoch 8, step 13250/55000, batch loss = 0.06\n",
      "epoch 8, step 13500/55000, batch loss = 0.01\n",
      "epoch 8, step 13750/55000, batch loss = 0.00\n",
      "epoch 8, step 14000/55000, batch loss = 0.00\n",
      "epoch 8, step 14250/55000, batch loss = 0.00\n",
      "epoch 8, step 14500/55000, batch loss = 0.02\n",
      "epoch 8, step 14750/55000, batch loss = 0.02\n",
      "epoch 8, step 15000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.63\n",
      "epoch 8, step 15250/55000, batch loss = 0.00\n",
      "epoch 8, step 15500/55000, batch loss = 0.01\n",
      "epoch 8, step 15750/55000, batch loss = 0.00\n",
      "epoch 8, step 16000/55000, batch loss = 0.06\n",
      "epoch 8, step 16250/55000, batch loss = 0.03\n",
      "epoch 8, step 16500/55000, batch loss = 0.00\n",
      "epoch 8, step 16750/55000, batch loss = 0.02\n",
      "epoch 8, step 17000/55000, batch loss = 0.10\n",
      "epoch 8, step 17250/55000, batch loss = 0.00\n",
      "epoch 8, step 17500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.58\n",
      "epoch 8, step 17750/55000, batch loss = 0.00\n",
      "epoch 8, step 18000/55000, batch loss = 0.00\n",
      "epoch 8, step 18250/55000, batch loss = 0.01\n",
      "epoch 8, step 18500/55000, batch loss = 0.01\n",
      "epoch 8, step 18750/55000, batch loss = 0.01\n",
      "epoch 8, step 19000/55000, batch loss = 0.00\n",
      "epoch 8, step 19250/55000, batch loss = 0.01\n",
      "epoch 8, step 19500/55000, batch loss = 0.01\n",
      "epoch 8, step 19750/55000, batch loss = 0.00\n",
      "epoch 8, step 20000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.60\n",
      "epoch 8, step 20250/55000, batch loss = 0.00\n",
      "epoch 8, step 20500/55000, batch loss = 0.08\n",
      "epoch 8, step 20750/55000, batch loss = 0.01\n",
      "epoch 8, step 21000/55000, batch loss = 0.00\n",
      "epoch 8, step 21250/55000, batch loss = 0.01\n",
      "epoch 8, step 21500/55000, batch loss = 0.00\n",
      "epoch 8, step 21750/55000, batch loss = 0.04\n",
      "epoch 8, step 22000/55000, batch loss = 0.04\n",
      "epoch 8, step 22250/55000, batch loss = 0.00\n",
      "epoch 8, step 22500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.61\n",
      "epoch 8, step 22750/55000, batch loss = 0.00\n",
      "epoch 8, step 23000/55000, batch loss = 0.12\n",
      "epoch 8, step 23250/55000, batch loss = 0.00\n",
      "epoch 8, step 23500/55000, batch loss = 0.02\n",
      "epoch 8, step 23750/55000, batch loss = 0.03\n",
      "epoch 8, step 24000/55000, batch loss = 0.01\n",
      "epoch 8, step 24250/55000, batch loss = 0.00\n",
      "epoch 8, step 24500/55000, batch loss = 0.01\n",
      "epoch 8, step 24750/55000, batch loss = 0.01\n",
      "epoch 8, step 25000/55000, batch loss = 0.03\n",
      "Train accuracy = 99.60\n",
      "epoch 8, step 25250/55000, batch loss = 0.00\n",
      "epoch 8, step 25500/55000, batch loss = 0.00\n",
      "epoch 8, step 25750/55000, batch loss = 0.04\n",
      "epoch 8, step 26000/55000, batch loss = 0.00\n",
      "epoch 8, step 26250/55000, batch loss = 0.01\n",
      "epoch 8, step 26500/55000, batch loss = 0.01\n",
      "epoch 8, step 26750/55000, batch loss = 0.00\n",
      "epoch 8, step 27000/55000, batch loss = 0.01\n",
      "epoch 8, step 27250/55000, batch loss = 0.00\n",
      "epoch 8, step 27500/55000, batch loss = 0.02\n",
      "Train accuracy = 99.59\n",
      "epoch 8, step 27750/55000, batch loss = 0.00\n",
      "epoch 8, step 28000/55000, batch loss = 0.03\n",
      "epoch 8, step 28250/55000, batch loss = 0.00\n",
      "epoch 8, step 28500/55000, batch loss = 0.01\n",
      "epoch 8, step 28750/55000, batch loss = 0.01\n",
      "epoch 8, step 29000/55000, batch loss = 0.01\n",
      "epoch 8, step 29250/55000, batch loss = 0.02\n",
      "epoch 8, step 29500/55000, batch loss = 0.00\n",
      "epoch 8, step 29750/55000, batch loss = 0.01\n",
      "epoch 8, step 30000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.60\n",
      "epoch 8, step 30250/55000, batch loss = 0.01\n",
      "epoch 8, step 30500/55000, batch loss = 0.03\n",
      "epoch 8, step 30750/55000, batch loss = 0.00\n",
      "epoch 8, step 31000/55000, batch loss = 0.01\n",
      "epoch 8, step 31250/55000, batch loss = 0.00\n",
      "epoch 8, step 31500/55000, batch loss = 0.02\n",
      "epoch 8, step 31750/55000, batch loss = 0.00\n",
      "epoch 8, step 32000/55000, batch loss = 0.01\n",
      "epoch 8, step 32250/55000, batch loss = 0.00\n",
      "epoch 8, step 32500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.61\n",
      "epoch 8, step 32750/55000, batch loss = 0.01\n",
      "epoch 8, step 33000/55000, batch loss = 0.01\n",
      "epoch 8, step 33250/55000, batch loss = 0.00\n",
      "epoch 8, step 33500/55000, batch loss = 0.01\n",
      "epoch 8, step 33750/55000, batch loss = 0.02\n",
      "epoch 8, step 34000/55000, batch loss = 0.02\n",
      "epoch 8, step 34250/55000, batch loss = 0.00\n",
      "epoch 8, step 34500/55000, batch loss = 0.00\n",
      "epoch 8, step 34750/55000, batch loss = 0.02\n",
      "epoch 8, step 35000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.61\n",
      "epoch 8, step 35250/55000, batch loss = 0.00\n",
      "epoch 8, step 35500/55000, batch loss = 0.01\n",
      "epoch 8, step 35750/55000, batch loss = 0.01\n",
      "epoch 8, step 36000/55000, batch loss = 0.00\n",
      "epoch 8, step 36250/55000, batch loss = 0.00\n",
      "epoch 8, step 36500/55000, batch loss = 0.00\n",
      "epoch 8, step 36750/55000, batch loss = 0.01\n",
      "epoch 8, step 37000/55000, batch loss = 0.01\n",
      "epoch 8, step 37250/55000, batch loss = 0.02\n",
      "epoch 8, step 37500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.61\n",
      "epoch 8, step 37750/55000, batch loss = 0.01\n",
      "epoch 8, step 38000/55000, batch loss = 0.04\n",
      "epoch 8, step 38250/55000, batch loss = 0.05\n",
      "epoch 8, step 38500/55000, batch loss = 0.03\n",
      "epoch 8, step 38750/55000, batch loss = 0.00\n",
      "epoch 8, step 39000/55000, batch loss = 0.01\n",
      "epoch 8, step 39250/55000, batch loss = 0.01\n",
      "epoch 8, step 39500/55000, batch loss = 0.00\n",
      "epoch 8, step 39750/55000, batch loss = 0.15\n",
      "epoch 8, step 40000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.59\n",
      "epoch 8, step 40250/55000, batch loss = 0.01\n",
      "epoch 8, step 40500/55000, batch loss = 0.01\n",
      "epoch 8, step 40750/55000, batch loss = 0.02\n",
      "epoch 8, step 41000/55000, batch loss = 0.01\n",
      "epoch 8, step 41250/55000, batch loss = 0.00\n",
      "epoch 8, step 41500/55000, batch loss = 0.01\n",
      "epoch 8, step 41750/55000, batch loss = 0.01\n",
      "epoch 8, step 42000/55000, batch loss = 0.02\n",
      "epoch 8, step 42250/55000, batch loss = 0.02\n",
      "epoch 8, step 42500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.59\n",
      "epoch 8, step 42750/55000, batch loss = 0.02\n",
      "epoch 8, step 43000/55000, batch loss = 0.00\n",
      "epoch 8, step 43250/55000, batch loss = 0.03\n",
      "epoch 8, step 43500/55000, batch loss = 0.09\n",
      "epoch 8, step 43750/55000, batch loss = 0.00\n",
      "epoch 8, step 44000/55000, batch loss = 0.00\n",
      "epoch 8, step 44250/55000, batch loss = 0.02\n",
      "epoch 8, step 44500/55000, batch loss = 0.01\n",
      "epoch 8, step 44750/55000, batch loss = 0.02\n",
      "epoch 8, step 45000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.59\n",
      "epoch 8, step 45250/55000, batch loss = 0.00\n",
      "epoch 8, step 45500/55000, batch loss = 0.00\n",
      "epoch 8, step 45750/55000, batch loss = 0.01\n",
      "epoch 8, step 46000/55000, batch loss = 0.00\n",
      "epoch 8, step 46250/55000, batch loss = 0.00\n",
      "epoch 8, step 46500/55000, batch loss = 0.00\n",
      "epoch 8, step 46750/55000, batch loss = 0.00\n",
      "epoch 8, step 47000/55000, batch loss = 0.03\n",
      "epoch 8, step 47250/55000, batch loss = 0.01\n",
      "epoch 8, step 47500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.59\n",
      "epoch 8, step 47750/55000, batch loss = 0.01\n",
      "epoch 8, step 48000/55000, batch loss = 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, step 48250/55000, batch loss = 0.00\n",
      "epoch 8, step 48500/55000, batch loss = 0.00\n",
      "epoch 8, step 48750/55000, batch loss = 0.01\n",
      "epoch 8, step 49000/55000, batch loss = 0.00\n",
      "epoch 8, step 49250/55000, batch loss = 0.04\n",
      "epoch 8, step 49500/55000, batch loss = 0.03\n",
      "epoch 8, step 49750/55000, batch loss = 0.00\n",
      "epoch 8, step 50000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.59\n",
      "epoch 8, step 50250/55000, batch loss = 0.02\n",
      "epoch 8, step 50500/55000, batch loss = 0.01\n",
      "epoch 8, step 50750/55000, batch loss = 0.04\n",
      "epoch 8, step 51000/55000, batch loss = 0.01\n",
      "epoch 8, step 51250/55000, batch loss = 0.01\n",
      "epoch 8, step 51500/55000, batch loss = 0.00\n",
      "epoch 8, step 51750/55000, batch loss = 0.00\n",
      "epoch 8, step 52000/55000, batch loss = 0.01\n",
      "epoch 8, step 52250/55000, batch loss = 0.00\n",
      "epoch 8, step 52500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.60\n",
      "epoch 8, step 52750/55000, batch loss = 0.00\n",
      "epoch 8, step 53000/55000, batch loss = 0.04\n",
      "epoch 8, step 53250/55000, batch loss = 0.00\n",
      "epoch 8, step 53500/55000, batch loss = 0.01\n",
      "epoch 8, step 53750/55000, batch loss = 0.01\n",
      "epoch 8, step 54000/55000, batch loss = 0.01\n",
      "epoch 8, step 54250/55000, batch loss = 0.02\n",
      "epoch 8, step 54500/55000, batch loss = 0.00\n",
      "epoch 8, step 54750/55000, batch loss = 0.01\n",
      "Train accuracy = 99.60\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.18\n",
      "Validation avg loss = 0.03\n",
      "\n",
      "\n",
      "Running evaluation:  Test\n",
      "Test accuracy = 99.12\n",
      "Test avg loss = 0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = \"/Users/goran/Documents/III_Semestar/DU/labosi/2_lab/zad1_images/\"\n",
    "\n",
    "config = {}\n",
    "config['max_epochs'] = 8\n",
    "config['batch_size'] = 50\n",
    "config['save_dir'] = SAVE_DIR\n",
    "config['lr_policy'] = {1:{'lr':1e-1}, 3:{'lr':1e-2}, 5:{'lr':1e-3}, 7:{'lr':1e-4}}\n",
    "\n",
    "#np.random.seed(100) \n",
    "np.random.seed(int(time.time() * 1e6) % 2**31)\n",
    "train_x = mnist.train.images\n",
    "train_x = train_x.reshape([-1, 1, 28, 28])\n",
    "train_y = mnist.train.labels\n",
    "valid_x = mnist.validation.images\n",
    "valid_x = valid_x.reshape([-1, 1, 28, 28])\n",
    "valid_y = mnist.validation.labels\n",
    "test_x = mnist.test.images\n",
    "test_x = test_x.reshape([-1, 1, 28, 28])\n",
    "test_y = mnist.test.labels\n",
    "train_mean = train_x.mean()\n",
    "train_x -= train_mean\n",
    "valid_x -= train_mean\n",
    "test_x -= train_mean\n",
    "\n",
    "\n",
    "net = []\n",
    "inputs = np.random.randn(config['batch_size'], 1, 28, 28)\n",
    "net += [Convolution(inputs, 16, 5, \"conv1\")]\n",
    "net += [MaxPooling(net[-1], \"pool1\")]\n",
    "net += [ReLU(net[-1], \"relu1\")]\n",
    "net += [Convolution(net[-1], 32, 5, \"conv2\")]\n",
    "net += [MaxPooling(net[-1], \"pool2\")]\n",
    "net += [ReLU(net[-1], \"relu2\")]\n",
    "# out = 7x7\n",
    "net += [Flatten(net[-1], \"flatten3\")]\n",
    "net += [FC(net[-1], 512, \"fc3\")]\n",
    "net += [ReLU(net[-1], \"relu3\")]\n",
    "net += [FC(net[-1], 10, \"logits\")]\n",
    "\n",
    "loss = SoftmaxCrossEntropyWithLogits()\n",
    "\n",
    "train(train_x, train_y, valid_x, valid_y, net, loss, config)\n",
    "evaluate(\"Test\", test_x, test_y, net, loss, config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ZADATAK\n",
    "U ovom zadatku trebate dodati podr≈°ku za L2 regularizaciju parametara. Dovr≈°ite implementaciju L2Regularizer sloja te nauƒçite regularizirani model iz prethodnog zadatka koji se nalazi u train_l2reg.py. Igrajte se s regularizacijskim parametrom tako da nauƒçite tri razliƒçite mre≈æe Œª=1e‚àí3, Œª=1e‚àí2, Œª=1e‚àí1 te usporedite nauƒçene filtre u prvom sloju i dobivenu toƒçnost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN training with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAMBDA: 0.1 \n",
      "\n",
      "epoch 1, step 0/55000, batch loss = 45.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Anaconda/anaconda/lib/python3.5/site-packages/skimage/util/dtype.py:110: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 250/55000, batch loss = 41.19\n",
      "epoch 1, step 500/55000, batch loss = 37.59\n",
      "epoch 1, step 750/55000, batch loss = 33.67\n",
      "epoch 1, step 1000/55000, batch loss = 30.02\n",
      "epoch 1, step 1250/55000, batch loss = 28.21\n",
      "epoch 1, step 1500/55000, batch loss = 24.67\n",
      "epoch 1, step 1750/55000, batch loss = 22.70\n",
      "epoch 1, step 2000/55000, batch loss = 20.17\n",
      "epoch 1, step 2250/55000, batch loss = 18.52\n",
      "epoch 1, step 2500/55000, batch loss = 16.81\n",
      "Train accuracy = 64.12\n",
      "epoch 1, step 2750/55000, batch loss = 15.04\n",
      "epoch 1, step 3000/55000, batch loss = 13.74\n",
      "epoch 1, step 3250/55000, batch loss = 12.79\n",
      "epoch 1, step 3500/55000, batch loss = 11.47\n",
      "epoch 1, step 3750/55000, batch loss = 10.38\n",
      "epoch 1, step 4000/55000, batch loss = 9.51\n",
      "epoch 1, step 4250/55000, batch loss = 8.62\n",
      "epoch 1, step 4500/55000, batch loss = 7.99\n",
      "epoch 1, step 4750/55000, batch loss = 7.21\n",
      "epoch 1, step 5000/55000, batch loss = 7.04\n",
      "Train accuracy = 75.05\n",
      "epoch 1, step 5250/55000, batch loss = 5.94\n",
      "epoch 1, step 5500/55000, batch loss = 5.57\n",
      "epoch 1, step 5750/55000, batch loss = 5.32\n",
      "epoch 1, step 6000/55000, batch loss = 4.76\n",
      "epoch 1, step 6250/55000, batch loss = 4.32\n",
      "epoch 1, step 6500/55000, batch loss = 3.88\n",
      "epoch 1, step 6750/55000, batch loss = 3.61\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-cf515697e832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegularizedLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-ae82f462c543>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_x, train_y, valid_x, valid_y, net, loss, config)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;31m# compute classification accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-ae82f462c543>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(net, inputs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-4e3a4a3eb842>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    121\u001b[0m         self.x = x.reshape(N, C, H // self.pool_size, self.pool_size,\n\u001b[1;32m    122\u001b[0m                            W // self.pool_size, self.pool_size)\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;31m# if you are returning class member be sure to return a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/Anaconda/anaconda/lib/python3.5/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SAVE_DIR = \"/Users/goran/Documents/III_Semestar/DU/labosi/2_lab/zad2_images/\"\n",
    "\n",
    "\n",
    "config = {}\n",
    "config['max_epochs'] = 5\n",
    "config['batch_size'] = 50\n",
    "config['save_dir'] = SAVE_DIR\n",
    "config['lr_policy'] = {1:{'lr':1e-1}, 3:{'lr':1e-2}, 5:{'lr':1e-3}, 7:{'lr':1e-4}}\n",
    "\n",
    "#np.random.seed(100) \n",
    "for lmbd in [1e-1, 1e-2, 1e-3]:\n",
    "    print(\"LAMBDA:\", lmbd, \"\\n\")\n",
    "    np.random.seed(int(time.time() * 1e6) % 2**31)\n",
    "\n",
    "    train_x = mnist.train.images\n",
    "    train_x = train_x.reshape([-1, 1, 28, 28])\n",
    "    train_y = mnist.train.labels\n",
    "\n",
    "    valid_x = mnist.validation.images\n",
    "    valid_x = valid_x.reshape([-1, 1, 28, 28])\n",
    "    valid_y = mnist.validation.labels\n",
    "\n",
    "    test_x = mnist.test.images\n",
    "    test_x = test_x.reshape([-1, 1, 28, 28])\n",
    "    test_y = mnist.test.labels\n",
    "\n",
    "    train_mean = train_x.mean()\n",
    "    train_x -= train_mean\n",
    "    valid_x -= train_mean\n",
    "    test_x -= train_mean\n",
    "\n",
    "    weight_decay = lmbd\n",
    "    net = []\n",
    "\n",
    "    regularizers = []\n",
    "    inputs = np.random.randn(config['batch_size'], 1, 28, 28)\n",
    "    net += [Convolution(inputs, 16, 5, \"conv1\")]\n",
    "    regularizers += [L2Regularizer(net[-1].weights, weight_decay, 'conv1_l2reg')]\n",
    "    net += [MaxPooling(net[-1], \"pool1\")]\n",
    "    net += [ReLU(net[-1], \"relu1\")]\n",
    "    net += [Convolution(net[-1], 32, 5, \"conv2\")]\n",
    "    regularizers += [L2Regularizer(net[-1].weights, weight_decay, 'conv2_l2reg')]\n",
    "    net += [MaxPooling(net[-1], \"pool2\")]\n",
    "    net += [ReLU(net[-1], \"relu2\")]\n",
    "    ## 7x7\n",
    "    net += [Flatten(net[-1], \"flatten3\")]\n",
    "    net += [FC(net[-1], 512, \"fc3\")]\n",
    "    regularizers += [L2Regularizer(net[-1].weights, weight_decay, 'fc3_l2reg')]\n",
    "    net += [ReLU(net[-1], \"relu3\")]\n",
    "    net += [FC(net[-1], 10, \"logits\")]\n",
    "\n",
    "    data_loss = SoftmaxCrossEntropyWithLogits()\n",
    "    loss = RegularizedLoss(data_loss, regularizers)\n",
    "\n",
    "    train(train_x, train_y, valid_x, valid_y, net, loss, config)\n",
    "    evaluate(\"Test\", test_x, test_y, net, loss, config)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
