{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import skimage as ski\n",
    "import skimage.io\n",
    "\n",
    "from im2col_cython import col2im_cython, im2col_cython\n",
    "\n",
    "import _pickle as pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ZADATAK\n",
    "\n",
    "Dovr≈°ite implementacije potpuno povezanog sloja, sloja nelinearnosti te funkcije gubitka u razredima FC, ReLU i SoftmaxCrossEntropyWithLogits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_init = np.zeros\n",
    "\n",
    "def variance_scaling_initializer(shape, fan_in, factor=2.0, seed=None):\n",
    "    sigma = np.sqrt(factor / fan_in)\n",
    "    return stats.truncnorm(-2, 2, loc=0, scale=sigma).rvs(shape)\n",
    "\n",
    "\n",
    "# -- ABSTRACT CLASS DEFINITION --\n",
    "class Layer(metaclass = ABCMeta):\n",
    "    \"Interface for layers\"\n",
    "    # See documentation of abstract base classes (ABC): https://docs.python.org/3/library/abc.html\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          inputs: ndarray tensor.\n",
    "        Returns:\n",
    "          ndarray tensor, result of the forward pass.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def backward_inputs(self, grads):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          grads: gradient of the loss with respect to the output of the layer.\n",
    "        Returns:\n",
    "          Gradient of the loss with respect to the input of the layer.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def backward_params(self, grads):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          grads: gradient of the loss with respect to the output of the layer.\n",
    "        Returns:\n",
    "          Gradient of the loss with respect to all the parameters of the layer as a list\n",
    "          [[w0, g0], ..., [wk, gk], self.name] where w are parameter weights and g their gradient.\n",
    "          Note that wk and gk must have the same shape.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "# -- CONVOLUTION LAYER --\n",
    "class Convolution(Layer):\n",
    "    \"N-dimensional convolution layer\"\n",
    "\n",
    "    def __init__(self, input_layer, num_filters, kernel_size, name, padding='SAME',\n",
    "               weights_initializer_fn=variance_scaling_initializer,\n",
    "               bias_initializer_fn=zero_init):\n",
    "        self.input_shape = input_layer.shape\n",
    "        N, C, H, W = input_layer.shape\n",
    "        self.C = C\n",
    "        self.N = N\n",
    "        self.num_filters = num_filters\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        assert kernel_size % 2 == 1\n",
    "\n",
    "        self.padding = padding\n",
    "\n",
    "        if padding == 'SAME':\n",
    "            # with zero padding\n",
    "            self.shape = (N, num_filters, H, W)\n",
    "            self.pad = (kernel_size - 1) // 2\n",
    "        else:\n",
    "            # without padding\n",
    "            self.shape = (N, num_filters, H - kernel_size + 1, W - kernel_size + 1)\n",
    "            self.pad = 0\n",
    "\n",
    "        fan_in = C * kernel_size**2\n",
    "        self.weights = weights_initializer_fn([num_filters, kernel_size**2 * C], fan_in)\n",
    "        self.bias = bias_initializer_fn([num_filters])\n",
    "        # this implementation doesn't support strided convolutions\n",
    "        self.stride = 1\n",
    "        self.name = name\n",
    "        self.has_params = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        k = self.kernel_size\n",
    "        self.x_cols = im2col_cython(x, k, k, self.pad, self.stride)\n",
    "        res = self.weights.dot(self.x_cols) + self.bias.reshape(-1, 1)\n",
    "        N, C, H, W = x.shape\n",
    "        out = res.reshape(self.num_filters, self.shape[2], self.shape[3], N)\n",
    "        return out.transpose(3, 0, 1, 2)\n",
    "\n",
    "    def backward_inputs(self, grad_out):\n",
    "        # nice trick from CS231n, backward pass can be done with just matrix mul and col2im\n",
    "        grad_out = grad_out.transpose(1, 2, 3, 0).reshape(self.num_filters, -1)\n",
    "        grad_x_cols = self.weights.T.dot(grad_out)\n",
    "        N, C, H, W = self.input_shape\n",
    "        k = self.kernel_size\n",
    "        grad_x = col2im_cython(grad_x_cols, N, C, H, W, k, k, self.pad, self.stride)\n",
    "        return grad_x\n",
    "\n",
    "    def backward_params(self, grad_out):\n",
    "        grad_bias = np.sum(grad_out, axis=(0, 2, 3))\n",
    "        grad_out = grad_out.transpose(1, 2, 3, 0).reshape(self.num_filters, -1)\n",
    "        grad_weights = grad_out.dot(self.x_cols.T).reshape(self.weights.shape)\n",
    "        return [[self.weights, grad_weights], [self.bias, grad_bias], self.name]\n",
    "\n",
    "\n",
    "class MaxPooling(Layer):\n",
    "    def __init__(self, input_layer, name, pool_size=2, stride=2):\n",
    "        self.name = name\n",
    "        self.input_shape = input_layer.shape\n",
    "        N, C, H, W = self.input_shape\n",
    "        self.stride = stride\n",
    "        self.shape = (N, C, H // stride, W // stride)\n",
    "        self.pool_size = pool_size\n",
    "        assert pool_size == stride, 'Invalid pooling params'\n",
    "        assert H % pool_size == 0\n",
    "        assert W % pool_size == 0\n",
    "        self.has_params = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        self.input_shape = x.shape\n",
    "        # with this clever reshaping we can implement pooling where pool_size == stride\n",
    "        self.x = x.reshape(N, C, H // self.pool_size, self.pool_size,\n",
    "                           W // self.pool_size, self.pool_size)\n",
    "        self.out = self.x.max(axis=3).max(axis=4)\n",
    "        # if you are returning class member be sure to return a copy\n",
    "        return self.out.copy()\n",
    "\n",
    "    def backward_inputs(self, grad_out):\n",
    "        grad_x = np.zeros_like(self.x)\n",
    "        out_newaxis = self.out[:, :, :, np.newaxis, :, np.newaxis]\n",
    "        mask = (self.x == out_newaxis)\n",
    "        dout_newaxis = grad_out[:, :, :, np.newaxis, :, np.newaxis]\n",
    "        dout_broadcast, _ = np.broadcast_arrays(dout_newaxis, grad_x)\n",
    "        # this is almost the same as the real backward pass\n",
    "        grad_x[mask] = dout_broadcast[mask]\n",
    "        # in the very rare case that more then one input have the same max value\n",
    "        # we can aprox the real gradient routing by evenly distributing across multiple inputs\n",
    "        # but in almost all cases this sum will be 1\n",
    "        grad_x /= np.sum(mask, axis=(3, 5), keepdims=True)\n",
    "        grad_x = grad_x.reshape(self.input_shape)\n",
    "        return grad_x\n",
    "\n",
    "\n",
    "class Flatten(Layer):\n",
    "    def __init__(self, input_layer, name):\n",
    "        self.input_shape = input_layer.shape\n",
    "        self.N = self.input_shape[0]\n",
    "        self.num_outputs = 1\n",
    "        for i in range(1, len(self.input_shape)):\n",
    "            self.num_outputs *= self.input_shape[i]\n",
    "        self.shape = (self.N, self.num_outputs)\n",
    "        self.has_params = False\n",
    "        self.name = name\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.input_shape = inputs.shape\n",
    "        inputs_flat = inputs.reshape(self.input_shape[0], -1)\n",
    "        self.shape = inputs_flat.shape\n",
    "        return inputs_flat\n",
    "\n",
    "    def backward_inputs(self, grads):\n",
    "        return grads.reshape(self.input_shape)\n",
    "\n",
    "\n",
    "class FC(Layer):\n",
    "    def __init__(self, input_layer, num_outputs, name,\n",
    "               weights_initializer_fn=variance_scaling_initializer,\n",
    "               bias_initializer_fn=zero_init):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          input_layer: layer below\n",
    "          num_outputs: number of neurons in this layer\n",
    "          weights_initializer_fn: initializer function for weights,\n",
    "          bias_initializer_fn: initializer function for biases\n",
    "        \"\"\"\n",
    "\n",
    "        self.input_shape = input_layer.shape\n",
    "        self.N = self.input_shape[0]\n",
    "        self.shape = (self.N, num_outputs)\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "        self.num_inputs = 1\n",
    "        for i in range(1, len(self.input_shape)):\n",
    "            self.num_inputs *= self.input_shape[i]\n",
    "\n",
    "        self.weights = weights_initializer_fn([num_outputs, self.num_inputs], fan_in=self.num_inputs)\n",
    "        self.bias = bias_initializer_fn([num_outputs])\n",
    "        self.name = name\n",
    "        self.has_params = True\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          inputs: ndarray of shape (N, num_inputs)\n",
    "        Returns:\n",
    "          An ndarray of shape (N, num_outputs)\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        return inputs.dot(self.weights.T) + self.bias\n",
    "\n",
    "    def backward_inputs(self, grads):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          grads: ndarray of shape (N, num_outputs)\n",
    "        Returns:\n",
    "          An ndarray of shape (N, num_inputs)\n",
    "        \"\"\"\n",
    "        return grads.dot(self.weights)\n",
    "\n",
    "    def backward_params(self, grads):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          grads: ndarray of shape (N, num_outputs)\n",
    "        Returns:\n",
    "          List of params and gradient pairs.\n",
    "        \"\"\"\n",
    "        grad_weights = grads.T.dot(self.inputs)\n",
    "        grad_bias = grads.sum(axis = 0)\n",
    "        return [[self.weights, grad_weights], [self.bias, grad_bias], self.name]\n",
    "\n",
    "\n",
    "\n",
    "class ReLU(Layer):\n",
    "    def __init__(self, input_layer, name):\n",
    "        self.shape = input_layer.shape\n",
    "        self.name = name\n",
    "        self.has_params = False\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          inputs: ndarray of shape (N, C, H, W).\n",
    "        Returns:\n",
    "          ndarray of shape (N, C, H, W).\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        return np.maximum(0, inputs)\n",
    "\n",
    "    def backward_inputs(self, grads):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          grads: ndarray of shape (N, C, H, W).\n",
    "        Returns:\n",
    "          ndarray of shape (N, C, H, W).\n",
    "        \"\"\"\n",
    "        grads[self.inputs < 0] = 0\n",
    "        return grads\n",
    "\n",
    "def softmax(x):\n",
    "    x -= np.max(x)\n",
    "    logits_exp = np.exp(x)\n",
    "    return logits_exp / np.sum(logits_exp, axis=1, keepdims=True)\n",
    "\n",
    "class SoftmaxCrossEntropyWithLogits():\n",
    "    def __init__(self):\n",
    "        self.has_params = False\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x: ndarray of shape (N, num_classes).\n",
    "          y: ndarray of shape (N, num_classes).\n",
    "        Returns:\n",
    "          Scalar, average loss over N examples.\n",
    "          It is better to compute average loss here instead of just sum\n",
    "          because then learning rate and weight decay won't depend on batch size.\n",
    "\n",
    "        \"\"\"\n",
    "        return (-np.log(softmax(x)) * y).sum(axis=1).mean()\n",
    "\n",
    "    def backward_inputs(self, x, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x: ndarray of shape (N, num_classes).\n",
    "          y: ndarray of shape (N, num_classes).\n",
    "        Returns:\n",
    "          Gradient with respect to the x, ndarray of shape (N, num_classes).\n",
    "        \"\"\"\n",
    "        # Hint: don't forget that we took the average in the forward pass\n",
    "        N = len(x)\n",
    "        return (softmax(x) - y) / N\n",
    "\n",
    "\n",
    "class L2Regularizer():\n",
    "    def __init__(self, weights, weight_decay, name):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          weights: parameters which will be regularizerized\n",
    "          weight_decay: lambda, regularization strength\n",
    "          name: layer name\n",
    "        \"\"\"\n",
    "        # this is still a reference to original tensor so don't change self.weights\n",
    "        self.weights = weights\n",
    "        self.weight_decay = weight_decay\n",
    "        self.name = name\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "         Returns:\n",
    "          Scalar, loss due to the L2 regularization.\n",
    "        \"\"\"\n",
    "        return self.weight_decay * 0.5 * np.sum(self.weights * self.weights)\n",
    "\n",
    "    def backward_params(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "          Gradient of the L2 loss with respect to the regularized weights.\n",
    "        \"\"\"\n",
    "        grad_weights = self.weight_decay * self.weights\n",
    "        return [[self.weights, grad_weights], self.name]\n",
    "\n",
    "\n",
    "class RegularizedLoss():\n",
    "    def __init__(self, data_loss, regularizer_losses):\n",
    "        self.data_loss = data_loss\n",
    "        self.regularizer_losses = regularizer_losses\n",
    "        self.has_params = True\n",
    "        self.name = 'RegularizedLoss'\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        loss_val = self.data_loss.forward(x, y)\n",
    "        for loss in self.regularizer_losses:\n",
    "            loss_val += loss.forward()\n",
    "        return loss_val\n",
    "\n",
    "    def backward_inputs(self, x, y):\n",
    "        return self.data_loss.backward_inputs(x, y)\n",
    "\n",
    "    def backward_params(self):\n",
    "        grads = []\n",
    "        for loss in self.regularizer_losses:\n",
    "            grads += [loss.backward_params()]\n",
    "        return grads\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution\n",
      "Check grad wrt input\n",
      "Relative error =  7.1781396328e-09\n",
      "Error norm =  4.08426369364e-10\n",
      "Check grad wrt params\n",
      "Check weights:\n",
      "Relative error =  3.79737411839e-10\n",
      "Error norm =  3.9800787816e-10\n",
      "Check biases:\n",
      "Relative error =  1.3861585688e-12\n",
      "Error norm =  4.00344010748e-11\n",
      "\n",
      "MaxPooling\n",
      "Check grad wrt input\n",
      "Relative error =  3.27563595128e-12\n",
      "Error norm =  9.20217924051e-11\n",
      "\n",
      "ReLU\n",
      "Check grad wrt input\n",
      "Relative error =  3.27562605199e-12\n",
      "Error norm =  4.55006932058e-11\n",
      "\n",
      "FC\n",
      "Check grad wrt input\n",
      "Relative error =  7.54229391412e-08\n",
      "Error norm =  7.10190512924e-10\n",
      "Check grad wrt params\n",
      "Check weights:\n",
      "Relative error =  2.82027039502e-09\n",
      "Error norm =  7.4205428145e-10\n",
      "Check biases:\n",
      "Relative error =  3.50880153745e-11\n",
      "Error norm =  1.01330545962e-10\n",
      "\n",
      "SoftmaxCrossEntropyWithLogits\n",
      "Relative error =  4.27615033983e-07\n",
      "Error norm =  5.07774274724e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"\\nL2Regularizer\")\\nx = np.random.randn(5, 4, 8, 8)\\ngrad_out = np.random.randn(5, 4, 4, 4)\\nl2reg = L2Regularizer(x, 1e-2, \\'L2reg\\')\\nprint(\"Check grad wrt params\")\\nfunc = lambda params: l2reg.forward()\\ngrad_num = eval_numerical_gradient(func, l2reg.weights, 1)\\ngrads = l2reg.backward_params()\\ngrad = grads[0][1]\\nprint(\"Relative error = \", rel_error(grad_num, grad))\\nprint(\"Error norm = \", np.linalg.norm(grad_num - grad))\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "def eval_numerical_gradient(f, x, df, h=1e-5):\n",
    "    \"\"\"\n",
    "    Evaluate a numeric gradient for a function that accepts a numpy\n",
    "    array and returns a numpy array.\n",
    "    - f should be a function that takes a single argument\n",
    "    - x is the point (numpy array) to evaluate the gradient at\n",
    "    \"\"\"\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h\n",
    "        # evaluate f(x + h)\n",
    "        pos = f(x.copy()).copy()\n",
    "        x[ix] = oldval - h\n",
    "        # evaluate f(x - h)\n",
    "        neg = f(x.copy()).copy()\n",
    "        x[ix] = oldval\n",
    "\n",
    "        # compute the partial derivative with centered formula\n",
    "        grad[ix] = np.sum((pos - neg) * df) / (2 * h)\n",
    "        # step to next dimension\n",
    "        it.iternext()\n",
    "    return grad\n",
    "\n",
    "def check_grad_inputs(layer, x, grad_out):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    layer: Layer object\n",
    "    x: ndarray tensor input data\n",
    "    grad_out: ndarray tensor gradient from the next layer\n",
    "    \"\"\"\n",
    "    grad_x_num = eval_numerical_gradient(layer.forward, x, grad_out)\n",
    "    grad_x = layer.backward_inputs(grad_out)\n",
    "    print(\"Relative error = \", rel_error(grad_x_num, grad_x))\n",
    "    print(\"Error norm = \", np.linalg.norm(grad_x_num - grad_x))\n",
    "\n",
    "def check_grad_params(layer, x, w, b, grad_out):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    layer: Layer object\n",
    "    x: ndarray tensor input data\n",
    "    w: ndarray tensor layer weights\n",
    "    b: ndarray tensor layer biases\n",
    "    grad_out: ndarray tensor gradient from the next layer\n",
    "    \"\"\"\n",
    "    func = lambda params: layer.forward(x)\n",
    "    grad_w_num = eval_numerical_gradient(func, w, grad_out)\n",
    "    grad_b_num = eval_numerical_gradient(func, b, grad_out)\n",
    "    grads = layer.backward_params(grad_out)\n",
    "    grad_w = grads[0][1]\n",
    "    grad_b = grads[1][1]\n",
    "    print(\"Check weights:\")\n",
    "    print(\"Relative error = \", rel_error(grad_w_num, grad_w))\n",
    "    print(\"Error norm = \", np.linalg.norm(grad_w_num - grad_w))\n",
    "    print(\"Check biases:\")\n",
    "    print(\"Relative error = \", rel_error(grad_b_num, grad_b))\n",
    "    print(\"Error norm = \", np.linalg.norm(grad_b_num - grad_b))\n",
    "\n",
    "print(\"Convolution\")\n",
    "x = np.random.randn(4, 3, 5, 5)\n",
    "grad_out = np.random.randn(4, 2, 5, 5)\n",
    "conv = Convolution(x, 2, 3, \"conv1\")\n",
    "print(\"Check grad wrt input\")\n",
    "check_grad_inputs(conv, x, grad_out)\n",
    "print(\"Check grad wrt params\")\n",
    "check_grad_params(conv, x, conv.weights, conv.bias, grad_out)\n",
    "\n",
    "print(\"\\nMaxPooling\")\n",
    "x = np.random.randn(5, 4, 8, 8)\n",
    "grad_out = np.random.randn(5, 4, 4, 4)\n",
    "pool = MaxPooling(x, \"pool\", 2, 2)\n",
    "print(\"Check grad wrt input\")\n",
    "check_grad_inputs(pool, x, grad_out)\n",
    "\n",
    "print(\"\\nReLU\")\n",
    "x = np.random.randn(4, 3, 5, 5)\n",
    "grad_out = np.random.randn(4, 3, 5, 5)\n",
    "relu = ReLU(x, \"relu\")\n",
    "print(\"Check grad wrt input\")\n",
    "check_grad_inputs(relu, x, grad_out)\n",
    "\n",
    "print(\"\\nFC\")\n",
    "x = np.random.randn(20, 40)\n",
    "grad_out = np.random.randn(20, 30)\n",
    "fc = FC(x, 30, \"fc\")\n",
    "print(\"Check grad wrt input\")\n",
    "check_grad_inputs(fc, x, grad_out)\n",
    "print(\"Check grad wrt params\")\n",
    "check_grad_params(fc, x, fc.weights, fc.bias, grad_out)\n",
    "\n",
    "print(\"\\nSoftmaxCrossEntropyWithLogits\")\n",
    "x = np.random.randn(50, 20)\n",
    "y = np.zeros([50, 20])\n",
    "y[:,0] = 1\n",
    "loss = SoftmaxCrossEntropyWithLogits()\n",
    "grad_x_num = eval_numerical_gradient(lambda x: loss.forward(x, y), x, 1)\n",
    "out = loss.forward(x, y)\n",
    "grad_x = loss.backward_inputs(x, y)\n",
    "print(\"Relative error = \", rel_error(grad_x_num, grad_x))\n",
    "print(\"Error norm = \", np.linalg.norm(grad_x_num - grad_x))\n",
    "\n",
    "\"\"\"\n",
    "print(\"\\nL2Regularizer\")\n",
    "x = np.random.randn(5, 4, 8, 8)\n",
    "grad_out = np.random.randn(5, 4, 4, 4)\n",
    "l2reg = L2Regularizer(x, 1e-2, 'L2reg')\n",
    "print(\"Check grad wrt params\")\n",
    "func = lambda params: l2reg.forward()\n",
    "grad_num = eval_numerical_gradient(func, l2reg.weights, 1)\n",
    "grads = l2reg.backward_params()\n",
    "grad = grads[0][1]\n",
    "print(\"Relative error = \", rel_error(grad_num, grad))\n",
    "print(\"Error norm = \", np.linalg.norm(grad_num - grad))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_pass(net, inputs):\n",
    "    output = inputs\n",
    "    for layer in net:\n",
    "        output = layer.forward(output)\n",
    "    return output\n",
    "\n",
    "\n",
    "def backward_pass(net, loss, x, y):\n",
    "    grads = []\n",
    "    grad_out = loss.backward_inputs(x, y)\n",
    "    if loss.has_params:\n",
    "        grads += loss.backward_params()\n",
    "    for layer in reversed(net):\n",
    "        grad_inputs = layer.backward_inputs(grad_out)\n",
    "        if layer.has_params:\n",
    "            grads += [layer.backward_params(grad_out)]\n",
    "        grad_out = grad_inputs\n",
    "    return grads\n",
    "\n",
    "def sgd_update_params(grads, config):\n",
    "    lr = config['lr']\n",
    "    for layer_grads in grads:\n",
    "        for i in range(len(layer_grads) - 1):\n",
    "            params = layer_grads[i][0]\n",
    "            grads = layer_grads[i][1]\n",
    "            #print(layer_grads[-1], \" -> \", grads.sum())\n",
    "            params -= lr * grads\n",
    "\n",
    "\n",
    "def draw_conv_filters(epoch, step, layer, save_dir):\n",
    "    C = layer.C\n",
    "    w = layer.weights.copy()\n",
    "    num_filters = w.shape[0]\n",
    "    k = int(np.sqrt(w.shape[1] / C))\n",
    "    w = w.reshape(num_filters, C, k, k)\n",
    "    w -= w.min()\n",
    "    w /= w.max()\n",
    "    border = 1\n",
    "    cols = 8\n",
    "    rows = math.ceil(num_filters / cols)\n",
    "    width = cols * k + (cols-1) * border\n",
    "    height = rows * k + (rows-1) * border\n",
    "    #for i in range(C):\n",
    "    for i in range(1):\n",
    "        img = np.zeros([height, width])\n",
    "        \n",
    "        for j in range(num_filters):\n",
    "            r = int(j / cols) * (k + border)\n",
    "            c = int(j % cols) * (k + border)\n",
    "            img[r:r+k,c:c+k] = w[j,i]\n",
    "            \n",
    "        filename = '%s_epoch_%02d_step_%06d_input_%03d.png' % (layer.name, epoch, step, i)\n",
    "        ski.io.imsave(os.path.join(save_dir, filename), img)\n",
    "\n",
    "\n",
    "def train(train_x, train_y, valid_x, valid_y, net, loss, config):\n",
    "    lr_policy = config['lr_policy']\n",
    "    batch_size = config['batch_size']\n",
    "    max_epochs = config['max_epochs']\n",
    "    save_dir = config['save_dir']\n",
    "    num_examples = train_x.shape[0]\n",
    "    assert num_examples % batch_size == 0\n",
    "    num_batches = num_examples // batch_size\n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        if epoch in lr_policy:\n",
    "            solver_config = lr_policy[epoch]\n",
    "            \n",
    "        cnt_correct = 0\n",
    "        #for i in range(num_batches):\n",
    "        # shuffle the data at the beggining of each epoch\n",
    "        permutation_idx = np.random.permutation(num_examples)\n",
    "        train_x = train_x[permutation_idx]\n",
    "        train_y = train_y[permutation_idx]\n",
    "        #for i in range(100):\n",
    "        for i in range(num_batches):\n",
    "            # store mini-batch to ndarray\n",
    "            batch_x = train_x[i*batch_size:(i+1)*batch_size, :]\n",
    "            batch_y = train_y[i*batch_size:(i+1)*batch_size, :]\n",
    "            logits = forward_pass(net, batch_x)\n",
    "            loss_val = loss.forward(logits, batch_y)\n",
    "            # compute classification accuracy\n",
    "            yp = np.argmax(logits, 1)\n",
    "            yt = np.argmax(batch_y, 1)\n",
    "            cnt_correct += (yp == yt).sum()\n",
    "            grads = backward_pass(net, loss, logits, batch_y)\n",
    "            sgd_update_params(grads, solver_config)\n",
    "            \n",
    "            if i % 5 == 0:\n",
    "                print(\"epoch %d, step %d/%d, batch loss = %.2f\" % (epoch, i*batch_size, num_examples, loss_val))\n",
    "                \n",
    "            if i % 100 == 0:\n",
    "                draw_conv_filters(epoch, i*batch_size, net[0], save_dir)\n",
    "                #draw_conv_filters(epoch, i*batch_size, net[3])\n",
    "            if i > 0 and i % 50 == 0:\n",
    "                print(\"Train accuracy = %.2f\" % (cnt_correct / ((i+1)*batch_size) * 100))\n",
    "        print(\"Train accuracy = %.2f\" % (cnt_correct / num_examples * 100))\n",
    "        evaluate(\"Validation\", valid_x, valid_y, net, loss, config)\n",
    "    return net\n",
    "\n",
    "\n",
    "def evaluate(name, x, y, net, loss, config):\n",
    "    print(\"\\nRunning evaluation: \", name)\n",
    "    batch_size = config['batch_size']\n",
    "    num_examples = x.shape[0]\n",
    "    assert num_examples % batch_size == 0\n",
    "    num_batches = num_examples // batch_size\n",
    "    cnt_correct = 0\n",
    "    loss_avg = 0\n",
    "    for i in range(num_batches):\n",
    "        batch_x = x[i*batch_size:(i+1)*batch_size, :]\n",
    "        batch_y = y[i*batch_size:(i+1)*batch_size, :]\n",
    "        logits = forward_pass(net, batch_x)\n",
    "        yp = np.argmax(logits, 1)\n",
    "        yt = np.argmax(batch_y, 1)\n",
    "        cnt_correct += (yp == yt).sum()\n",
    "        loss_val = loss.forward(logits, batch_y)\n",
    "        loss_avg += loss_val\n",
    "        #print(\"step %d / %d, loss = %.2f\" % (i*batch_size, num_examples, loss_val / batch_size))\n",
    "    valid_acc = cnt_correct / num_examples * 100\n",
    "    loss_avg /= num_batches\n",
    "    print(name + \" accuracy = %.2f\" % valid_acc)\n",
    "    print(name + \" avg loss = %.2f\\n\" % loss_avg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Training without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "tf.app.flags.DEFINE_string('data_dir', \n",
    "  '/tmp/data/', 'Directory for storing data')\n",
    "mnist = input_data.read_data_sets(\n",
    "  tf.app.flags.FLAGS.data_dir, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 0/55000, batch loss = 2.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Anaconda/anaconda/lib/python3.5/site-packages/skimage/util/dtype.py:110: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 250/55000, batch loss = 1.96\n",
      "epoch 1, step 500/55000, batch loss = 1.45\n",
      "epoch 1, step 750/55000, batch loss = 0.94\n",
      "epoch 1, step 1000/55000, batch loss = 0.58\n",
      "epoch 1, step 1250/55000, batch loss = 0.64\n",
      "epoch 1, step 1500/55000, batch loss = 0.47\n",
      "epoch 1, step 1750/55000, batch loss = 0.71\n",
      "epoch 1, step 2000/55000, batch loss = 0.29\n",
      "epoch 1, step 2250/55000, batch loss = 0.44\n",
      "epoch 1, step 2500/55000, batch loss = 0.40\n",
      "Train accuracy = 70.39\n",
      "epoch 1, step 2750/55000, batch loss = 0.18\n",
      "epoch 1, step 3000/55000, batch loss = 0.33\n",
      "epoch 1, step 3250/55000, batch loss = 0.31\n",
      "epoch 1, step 3500/55000, batch loss = 0.38\n",
      "epoch 1, step 3750/55000, batch loss = 0.43\n",
      "epoch 1, step 4000/55000, batch loss = 0.15\n",
      "epoch 1, step 4250/55000, batch loss = 0.50\n",
      "epoch 1, step 4500/55000, batch loss = 0.42\n",
      "epoch 1, step 4750/55000, batch loss = 0.16\n",
      "epoch 1, step 5000/55000, batch loss = 0.30\n",
      "Train accuracy = 80.83\n",
      "epoch 1, step 5250/55000, batch loss = 0.18\n",
      "epoch 1, step 5500/55000, batch loss = 0.13\n",
      "epoch 1, step 5750/55000, batch loss = 0.15\n",
      "epoch 1, step 6000/55000, batch loss = 0.24\n",
      "epoch 1, step 6250/55000, batch loss = 0.13\n",
      "epoch 1, step 6500/55000, batch loss = 0.14\n",
      "epoch 1, step 6750/55000, batch loss = 0.10\n",
      "epoch 1, step 7000/55000, batch loss = 0.11\n",
      "epoch 1, step 7250/55000, batch loss = 0.25\n",
      "epoch 1, step 7500/55000, batch loss = 0.16\n",
      "Train accuracy = 85.36\n",
      "epoch 1, step 7750/55000, batch loss = 0.14\n",
      "epoch 1, step 8000/55000, batch loss = 0.15\n",
      "epoch 1, step 8250/55000, batch loss = 0.08\n",
      "epoch 1, step 8500/55000, batch loss = 0.24\n",
      "epoch 1, step 8750/55000, batch loss = 0.21\n",
      "epoch 1, step 9000/55000, batch loss = 0.18\n",
      "epoch 1, step 9250/55000, batch loss = 0.05\n",
      "epoch 1, step 9500/55000, batch loss = 0.15\n",
      "epoch 1, step 9750/55000, batch loss = 0.25\n",
      "epoch 1, step 10000/55000, batch loss = 0.07\n",
      "Train accuracy = 87.90\n",
      "epoch 1, step 10250/55000, batch loss = 0.24\n",
      "epoch 1, step 10500/55000, batch loss = 0.21\n",
      "epoch 1, step 10750/55000, batch loss = 0.14\n",
      "epoch 1, step 11000/55000, batch loss = 0.11\n",
      "epoch 1, step 11250/55000, batch loss = 0.22\n",
      "epoch 1, step 11500/55000, batch loss = 0.05\n",
      "epoch 1, step 11750/55000, batch loss = 0.15\n",
      "epoch 1, step 12000/55000, batch loss = 0.06\n",
      "epoch 1, step 12250/55000, batch loss = 0.45\n",
      "epoch 1, step 12500/55000, batch loss = 0.06\n",
      "Train accuracy = 89.63\n",
      "epoch 1, step 12750/55000, batch loss = 0.08\n",
      "epoch 1, step 13000/55000, batch loss = 0.18\n",
      "epoch 1, step 13250/55000, batch loss = 0.09\n",
      "epoch 1, step 13500/55000, batch loss = 0.19\n",
      "epoch 1, step 13750/55000, batch loss = 0.17\n",
      "epoch 1, step 14000/55000, batch loss = 0.29\n",
      "epoch 1, step 14250/55000, batch loss = 0.05\n",
      "epoch 1, step 14500/55000, batch loss = 0.11\n",
      "epoch 1, step 14750/55000, batch loss = 0.01\n",
      "epoch 1, step 15000/55000, batch loss = 0.16\n",
      "Train accuracy = 90.78\n",
      "epoch 1, step 15250/55000, batch loss = 0.06\n",
      "epoch 1, step 15500/55000, batch loss = 0.18\n",
      "epoch 1, step 15750/55000, batch loss = 0.08\n",
      "epoch 1, step 16000/55000, batch loss = 0.03\n",
      "epoch 1, step 16250/55000, batch loss = 0.20\n",
      "epoch 1, step 16500/55000, batch loss = 0.08\n",
      "epoch 1, step 16750/55000, batch loss = 0.24\n",
      "epoch 1, step 17000/55000, batch loss = 0.03\n",
      "epoch 1, step 17250/55000, batch loss = 0.16\n",
      "epoch 1, step 17500/55000, batch loss = 0.21\n",
      "Train accuracy = 91.69\n",
      "epoch 1, step 17750/55000, batch loss = 0.09\n",
      "epoch 1, step 18000/55000, batch loss = 0.16\n",
      "epoch 1, step 18250/55000, batch loss = 0.04\n",
      "epoch 1, step 18500/55000, batch loss = 0.12\n",
      "epoch 1, step 18750/55000, batch loss = 0.08\n",
      "epoch 1, step 19000/55000, batch loss = 0.09\n",
      "epoch 1, step 19250/55000, batch loss = 0.21\n",
      "epoch 1, step 19500/55000, batch loss = 0.15\n",
      "epoch 1, step 19750/55000, batch loss = 0.03\n",
      "epoch 1, step 20000/55000, batch loss = 0.04\n",
      "Train accuracy = 92.34\n",
      "epoch 1, step 20250/55000, batch loss = 0.05\n",
      "epoch 1, step 20500/55000, batch loss = 0.08\n",
      "epoch 1, step 20750/55000, batch loss = 0.07\n",
      "epoch 1, step 21000/55000, batch loss = 0.12\n",
      "epoch 1, step 21250/55000, batch loss = 0.05\n",
      "epoch 1, step 21500/55000, batch loss = 0.22\n",
      "epoch 1, step 21750/55000, batch loss = 0.03\n",
      "epoch 1, step 22000/55000, batch loss = 0.08\n",
      "epoch 1, step 22250/55000, batch loss = 0.13\n",
      "epoch 1, step 22500/55000, batch loss = 0.07\n",
      "Train accuracy = 92.87\n",
      "epoch 1, step 22750/55000, batch loss = 0.08\n",
      "epoch 1, step 23000/55000, batch loss = 0.11\n",
      "epoch 1, step 23250/55000, batch loss = 0.05\n",
      "epoch 1, step 23500/55000, batch loss = 0.12\n",
      "epoch 1, step 23750/55000, batch loss = 0.22\n",
      "epoch 1, step 24000/55000, batch loss = 0.14\n",
      "epoch 1, step 24250/55000, batch loss = 0.15\n",
      "epoch 1, step 24500/55000, batch loss = 0.09\n",
      "epoch 1, step 24750/55000, batch loss = 0.19\n",
      "epoch 1, step 25000/55000, batch loss = 0.12\n",
      "Train accuracy = 93.26\n",
      "epoch 1, step 25250/55000, batch loss = 0.10\n",
      "epoch 1, step 25500/55000, batch loss = 0.11\n",
      "epoch 1, step 25750/55000, batch loss = 0.02\n",
      "epoch 1, step 26000/55000, batch loss = 0.26\n",
      "epoch 1, step 26250/55000, batch loss = 0.01\n",
      "epoch 1, step 26500/55000, batch loss = 0.03\n",
      "epoch 1, step 26750/55000, batch loss = 0.03\n",
      "epoch 1, step 27000/55000, batch loss = 0.01\n",
      "epoch 1, step 27250/55000, batch loss = 0.09\n",
      "epoch 1, step 27500/55000, batch loss = 0.11\n",
      "Train accuracy = 93.67\n",
      "epoch 1, step 27750/55000, batch loss = 0.06\n",
      "epoch 1, step 28000/55000, batch loss = 0.16\n",
      "epoch 1, step 28250/55000, batch loss = 0.30\n",
      "epoch 1, step 28500/55000, batch loss = 0.18\n",
      "epoch 1, step 28750/55000, batch loss = 0.01\n",
      "epoch 1, step 29000/55000, batch loss = 0.08\n",
      "epoch 1, step 29250/55000, batch loss = 0.04\n",
      "epoch 1, step 29500/55000, batch loss = 0.02\n",
      "epoch 1, step 29750/55000, batch loss = 0.16\n",
      "epoch 1, step 30000/55000, batch loss = 0.09\n",
      "Train accuracy = 93.96\n",
      "epoch 1, step 30250/55000, batch loss = 0.03\n",
      "epoch 1, step 30500/55000, batch loss = 0.08\n",
      "epoch 1, step 30750/55000, batch loss = 0.01\n",
      "epoch 1, step 31000/55000, batch loss = 0.09\n",
      "epoch 1, step 31250/55000, batch loss = 0.09\n",
      "epoch 1, step 31500/55000, batch loss = 0.16\n",
      "epoch 1, step 31750/55000, batch loss = 0.07\n",
      "epoch 1, step 32000/55000, batch loss = 0.02\n",
      "epoch 1, step 32250/55000, batch loss = 0.03\n",
      "epoch 1, step 32500/55000, batch loss = 0.08\n",
      "Train accuracy = 94.23\n",
      "epoch 1, step 32750/55000, batch loss = 0.13\n",
      "epoch 1, step 33000/55000, batch loss = 0.06\n",
      "epoch 1, step 33250/55000, batch loss = 0.03\n",
      "epoch 1, step 33500/55000, batch loss = 0.05\n",
      "epoch 1, step 33750/55000, batch loss = 0.08\n",
      "epoch 1, step 34000/55000, batch loss = 0.23\n",
      "epoch 1, step 34250/55000, batch loss = 0.02\n",
      "epoch 1, step 34500/55000, batch loss = 0.07\n",
      "epoch 1, step 34750/55000, batch loss = 0.06\n",
      "epoch 1, step 35000/55000, batch loss = 0.21\n",
      "Train accuracy = 94.47\n",
      "epoch 1, step 35250/55000, batch loss = 0.02\n",
      "epoch 1, step 35500/55000, batch loss = 0.18\n",
      "epoch 1, step 35750/55000, batch loss = 0.04\n",
      "epoch 1, step 36000/55000, batch loss = 0.01\n",
      "epoch 1, step 36250/55000, batch loss = 0.04\n",
      "epoch 1, step 36500/55000, batch loss = 0.02\n",
      "epoch 1, step 36750/55000, batch loss = 0.05\n",
      "epoch 1, step 37000/55000, batch loss = 0.08\n",
      "epoch 1, step 37250/55000, batch loss = 0.01\n",
      "epoch 1, step 37500/55000, batch loss = 0.04\n",
      "Train accuracy = 94.67\n",
      "epoch 1, step 37750/55000, batch loss = 0.19\n",
      "epoch 1, step 38000/55000, batch loss = 0.08\n",
      "epoch 1, step 38250/55000, batch loss = 0.06\n",
      "epoch 1, step 38500/55000, batch loss = 0.03\n",
      "epoch 1, step 38750/55000, batch loss = 0.13\n",
      "epoch 1, step 39000/55000, batch loss = 0.02\n",
      "epoch 1, step 39250/55000, batch loss = 0.03\n",
      "epoch 1, step 39500/55000, batch loss = 0.09\n",
      "epoch 1, step 39750/55000, batch loss = 0.07\n",
      "epoch 1, step 40000/55000, batch loss = 0.05\n",
      "Train accuracy = 94.93\n",
      "epoch 1, step 40250/55000, batch loss = 0.15\n",
      "epoch 1, step 40500/55000, batch loss = 0.10\n",
      "epoch 1, step 40750/55000, batch loss = 0.09\n",
      "epoch 1, step 41000/55000, batch loss = 0.05\n",
      "epoch 1, step 41250/55000, batch loss = 0.08\n",
      "epoch 1, step 41500/55000, batch loss = 0.20\n",
      "epoch 1, step 41750/55000, batch loss = 0.06\n",
      "epoch 1, step 42000/55000, batch loss = 0.19\n",
      "epoch 1, step 42250/55000, batch loss = 0.06\n",
      "epoch 1, step 42500/55000, batch loss = 0.15\n",
      "Train accuracy = 95.11\n",
      "epoch 1, step 42750/55000, batch loss = 0.00\n",
      "epoch 1, step 43000/55000, batch loss = 0.03\n",
      "epoch 1, step 43250/55000, batch loss = 0.07\n",
      "epoch 1, step 43500/55000, batch loss = 0.02\n",
      "epoch 1, step 43750/55000, batch loss = 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 44000/55000, batch loss = 0.02\n",
      "epoch 1, step 44250/55000, batch loss = 0.01\n",
      "epoch 1, step 44500/55000, batch loss = 0.02\n",
      "epoch 1, step 44750/55000, batch loss = 0.02\n",
      "epoch 1, step 45000/55000, batch loss = 0.00\n",
      "Train accuracy = 95.28\n",
      "epoch 1, step 45250/55000, batch loss = 0.02\n",
      "epoch 1, step 45500/55000, batch loss = 0.04\n",
      "epoch 1, step 45750/55000, batch loss = 0.02\n",
      "epoch 1, step 46000/55000, batch loss = 0.03\n",
      "epoch 1, step 46250/55000, batch loss = 0.04\n",
      "epoch 1, step 46500/55000, batch loss = 0.07\n",
      "epoch 1, step 46750/55000, batch loss = 0.02\n",
      "epoch 1, step 47000/55000, batch loss = 0.02\n",
      "epoch 1, step 47250/55000, batch loss = 0.10\n",
      "epoch 1, step 47500/55000, batch loss = 0.01\n",
      "Train accuracy = 95.40\n",
      "epoch 1, step 47750/55000, batch loss = 0.08\n",
      "epoch 1, step 48000/55000, batch loss = 0.08\n",
      "epoch 1, step 48250/55000, batch loss = 0.05\n",
      "epoch 1, step 48500/55000, batch loss = 0.02\n",
      "epoch 1, step 48750/55000, batch loss = 0.07\n",
      "epoch 1, step 49000/55000, batch loss = 0.24\n",
      "epoch 1, step 49250/55000, batch loss = 0.03\n",
      "epoch 1, step 49500/55000, batch loss = 0.05\n",
      "epoch 1, step 49750/55000, batch loss = 0.10\n",
      "epoch 1, step 50000/55000, batch loss = 0.04\n",
      "Train accuracy = 95.49\n",
      "epoch 1, step 50250/55000, batch loss = 0.11\n",
      "epoch 1, step 50500/55000, batch loss = 0.08\n",
      "epoch 1, step 50750/55000, batch loss = 0.04\n",
      "epoch 1, step 51000/55000, batch loss = 0.09\n",
      "epoch 1, step 51250/55000, batch loss = 0.04\n",
      "epoch 1, step 51500/55000, batch loss = 0.16\n",
      "epoch 1, step 51750/55000, batch loss = 0.05\n",
      "epoch 1, step 52000/55000, batch loss = 0.14\n",
      "epoch 1, step 52250/55000, batch loss = 0.07\n",
      "epoch 1, step 52500/55000, batch loss = 0.11\n",
      "Train accuracy = 95.60\n",
      "epoch 1, step 52750/55000, batch loss = 0.03\n",
      "epoch 1, step 53000/55000, batch loss = 0.02\n",
      "epoch 1, step 53250/55000, batch loss = 0.10\n",
      "epoch 1, step 53500/55000, batch loss = 0.07\n",
      "epoch 1, step 53750/55000, batch loss = 0.11\n",
      "epoch 1, step 54000/55000, batch loss = 0.00\n",
      "epoch 1, step 54250/55000, batch loss = 0.10\n",
      "epoch 1, step 54500/55000, batch loss = 0.05\n",
      "epoch 1, step 54750/55000, batch loss = 0.03\n",
      "Train accuracy = 95.72\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 98.10\n",
      "Validation avg loss = 0.06\n",
      "\n",
      "epoch 2, step 0/55000, batch loss = 0.02\n",
      "epoch 2, step 250/55000, batch loss = 0.01\n",
      "epoch 2, step 500/55000, batch loss = 0.07\n",
      "epoch 2, step 750/55000, batch loss = 0.18\n",
      "epoch 2, step 1000/55000, batch loss = 0.08\n",
      "epoch 2, step 1250/55000, batch loss = 0.01\n",
      "epoch 2, step 1500/55000, batch loss = 0.07\n",
      "epoch 2, step 1750/55000, batch loss = 0.09\n",
      "epoch 2, step 2000/55000, batch loss = 0.08\n",
      "epoch 2, step 2250/55000, batch loss = 0.06\n",
      "epoch 2, step 2500/55000, batch loss = 0.01\n",
      "Train accuracy = 98.59\n",
      "epoch 2, step 2750/55000, batch loss = 0.02\n",
      "epoch 2, step 3000/55000, batch loss = 0.00\n",
      "epoch 2, step 3250/55000, batch loss = 0.01\n",
      "epoch 2, step 3500/55000, batch loss = 0.13\n",
      "epoch 2, step 3750/55000, batch loss = 0.05\n",
      "epoch 2, step 4000/55000, batch loss = 0.01\n",
      "epoch 2, step 4250/55000, batch loss = 0.02\n",
      "epoch 2, step 4500/55000, batch loss = 0.03\n",
      "epoch 2, step 4750/55000, batch loss = 0.04\n",
      "epoch 2, step 5000/55000, batch loss = 0.02\n",
      "Train accuracy = 98.53\n",
      "epoch 2, step 5250/55000, batch loss = 0.06\n",
      "epoch 2, step 5500/55000, batch loss = 0.02\n",
      "epoch 2, step 5750/55000, batch loss = 0.00\n",
      "epoch 2, step 6000/55000, batch loss = 0.04\n",
      "epoch 2, step 6250/55000, batch loss = 0.03\n",
      "epoch 2, step 6500/55000, batch loss = 0.05\n",
      "epoch 2, step 6750/55000, batch loss = 0.04\n",
      "epoch 2, step 7000/55000, batch loss = 0.01\n",
      "epoch 2, step 7250/55000, batch loss = 0.03\n",
      "epoch 2, step 7500/55000, batch loss = 0.08\n",
      "Train accuracy = 98.60\n",
      "epoch 2, step 7750/55000, batch loss = 0.05\n",
      "epoch 2, step 8000/55000, batch loss = 0.09\n",
      "epoch 2, step 8250/55000, batch loss = 0.01\n",
      "epoch 2, step 8500/55000, batch loss = 0.03\n",
      "epoch 2, step 8750/55000, batch loss = 0.01\n",
      "epoch 2, step 9000/55000, batch loss = 0.00\n",
      "epoch 2, step 9250/55000, batch loss = 0.03\n",
      "epoch 2, step 9500/55000, batch loss = 0.02\n",
      "epoch 2, step 9750/55000, batch loss = 0.01\n",
      "epoch 2, step 10000/55000, batch loss = 0.02\n",
      "Train accuracy = 98.64\n",
      "epoch 2, step 10250/55000, batch loss = 0.17\n",
      "epoch 2, step 10500/55000, batch loss = 0.01\n",
      "epoch 2, step 10750/55000, batch loss = 0.05\n",
      "epoch 2, step 11000/55000, batch loss = 0.02\n",
      "epoch 2, step 11250/55000, batch loss = 0.07\n",
      "epoch 2, step 11500/55000, batch loss = 0.01\n",
      "epoch 2, step 11750/55000, batch loss = 0.02\n",
      "epoch 2, step 12000/55000, batch loss = 0.01\n",
      "epoch 2, step 12250/55000, batch loss = 0.01\n",
      "epoch 2, step 12500/55000, batch loss = 0.02\n",
      "Train accuracy = 98.68\n",
      "epoch 2, step 12750/55000, batch loss = 0.04\n",
      "epoch 2, step 13000/55000, batch loss = 0.01\n",
      "epoch 2, step 13250/55000, batch loss = 0.12\n",
      "epoch 2, step 13500/55000, batch loss = 0.00\n",
      "epoch 2, step 13750/55000, batch loss = 0.00\n",
      "epoch 2, step 14000/55000, batch loss = 0.09\n",
      "epoch 2, step 14250/55000, batch loss = 0.05\n",
      "epoch 2, step 14500/55000, batch loss = 0.01\n",
      "epoch 2, step 14750/55000, batch loss = 0.01\n",
      "epoch 2, step 15000/55000, batch loss = 0.05\n",
      "Train accuracy = 98.64\n",
      "epoch 2, step 15250/55000, batch loss = 0.00\n",
      "epoch 2, step 15500/55000, batch loss = 0.04\n",
      "epoch 2, step 15750/55000, batch loss = 0.12\n",
      "epoch 2, step 16000/55000, batch loss = 0.07\n",
      "epoch 2, step 16250/55000, batch loss = 0.01\n",
      "epoch 2, step 16500/55000, batch loss = 0.01\n",
      "epoch 2, step 16750/55000, batch loss = 0.03\n",
      "epoch 2, step 17000/55000, batch loss = 0.03\n",
      "epoch 2, step 17250/55000, batch loss = 0.06\n",
      "epoch 2, step 17500/55000, batch loss = 0.01\n",
      "Train accuracy = 98.64\n",
      "epoch 2, step 17750/55000, batch loss = 0.00\n",
      "epoch 2, step 18000/55000, batch loss = 0.04\n",
      "epoch 2, step 18250/55000, batch loss = 0.03\n",
      "epoch 2, step 18500/55000, batch loss = 0.06\n",
      "epoch 2, step 18750/55000, batch loss = 0.01\n",
      "epoch 2, step 19000/55000, batch loss = 0.00\n",
      "epoch 2, step 19250/55000, batch loss = 0.05\n",
      "epoch 2, step 19500/55000, batch loss = 0.01\n",
      "epoch 2, step 19750/55000, batch loss = 0.05\n",
      "epoch 2, step 20000/55000, batch loss = 0.14\n",
      "Train accuracy = 98.62\n",
      "epoch 2, step 20250/55000, batch loss = 0.08\n",
      "epoch 2, step 20500/55000, batch loss = 0.07\n",
      "epoch 2, step 20750/55000, batch loss = 0.06\n",
      "epoch 2, step 21000/55000, batch loss = 0.10\n",
      "epoch 2, step 21250/55000, batch loss = 0.04\n",
      "epoch 2, step 21500/55000, batch loss = 0.01\n",
      "epoch 2, step 21750/55000, batch loss = 0.07\n",
      "epoch 2, step 22000/55000, batch loss = 0.12\n",
      "epoch 2, step 22250/55000, batch loss = 0.00\n",
      "epoch 2, step 22500/55000, batch loss = 0.02\n",
      "Train accuracy = 98.59\n",
      "epoch 2, step 22750/55000, batch loss = 0.07\n",
      "epoch 2, step 23000/55000, batch loss = 0.05\n",
      "epoch 2, step 23250/55000, batch loss = 0.00\n",
      "epoch 2, step 23500/55000, batch loss = 0.05\n",
      "epoch 2, step 23750/55000, batch loss = 0.03\n",
      "epoch 2, step 24000/55000, batch loss = 0.07\n",
      "epoch 2, step 24250/55000, batch loss = 0.05\n",
      "epoch 2, step 24500/55000, batch loss = 0.01\n",
      "epoch 2, step 24750/55000, batch loss = 0.09\n",
      "epoch 2, step 25000/55000, batch loss = 0.09\n",
      "Train accuracy = 98.55\n",
      "epoch 2, step 25250/55000, batch loss = 0.01\n",
      "epoch 2, step 25500/55000, batch loss = 0.01\n",
      "epoch 2, step 25750/55000, batch loss = 0.01\n",
      "epoch 2, step 26000/55000, batch loss = 0.00\n",
      "epoch 2, step 26250/55000, batch loss = 0.07\n",
      "epoch 2, step 26500/55000, batch loss = 0.07\n",
      "epoch 2, step 26750/55000, batch loss = 0.06\n",
      "epoch 2, step 27000/55000, batch loss = 0.03\n",
      "epoch 2, step 27250/55000, batch loss = 0.06\n",
      "epoch 2, step 27500/55000, batch loss = 0.01\n",
      "Train accuracy = 98.58\n",
      "epoch 2, step 27750/55000, batch loss = 0.01\n",
      "epoch 2, step 28000/55000, batch loss = 0.03\n",
      "epoch 2, step 28250/55000, batch loss = 0.04\n",
      "epoch 2, step 28500/55000, batch loss = 0.06\n",
      "epoch 2, step 28750/55000, batch loss = 0.05\n",
      "epoch 2, step 29000/55000, batch loss = 0.01\n",
      "epoch 2, step 29250/55000, batch loss = 0.02\n",
      "epoch 2, step 29500/55000, batch loss = 0.04\n",
      "epoch 2, step 29750/55000, batch loss = 0.05\n",
      "epoch 2, step 30000/55000, batch loss = 0.03\n",
      "Train accuracy = 98.58\n",
      "epoch 2, step 30250/55000, batch loss = 0.00\n",
      "epoch 2, step 30500/55000, batch loss = 0.02\n",
      "epoch 2, step 30750/55000, batch loss = 0.00\n",
      "epoch 2, step 31000/55000, batch loss = 0.01\n",
      "epoch 2, step 31250/55000, batch loss = 0.07\n",
      "epoch 2, step 31500/55000, batch loss = 0.18\n",
      "epoch 2, step 31750/55000, batch loss = 0.01\n",
      "epoch 2, step 32000/55000, batch loss = 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, step 32250/55000, batch loss = 0.01\n",
      "epoch 2, step 32500/55000, batch loss = 0.00\n",
      "Train accuracy = 98.61\n",
      "epoch 2, step 32750/55000, batch loss = 0.02\n",
      "epoch 2, step 33000/55000, batch loss = 0.00\n",
      "epoch 2, step 33250/55000, batch loss = 0.08\n",
      "epoch 2, step 33500/55000, batch loss = 0.03\n",
      "epoch 2, step 33750/55000, batch loss = 0.02\n",
      "epoch 2, step 34000/55000, batch loss = 0.07\n",
      "epoch 2, step 34250/55000, batch loss = 0.06\n",
      "epoch 2, step 34500/55000, batch loss = 0.04\n",
      "epoch 2, step 34750/55000, batch loss = 0.03\n",
      "epoch 2, step 35000/55000, batch loss = 0.02\n",
      "Train accuracy = 98.63\n",
      "epoch 2, step 35250/55000, batch loss = 0.05\n",
      "epoch 2, step 35500/55000, batch loss = 0.04\n",
      "epoch 2, step 35750/55000, batch loss = 0.03\n",
      "epoch 2, step 36000/55000, batch loss = 0.04\n",
      "epoch 2, step 36250/55000, batch loss = 0.20\n",
      "epoch 2, step 36500/55000, batch loss = 0.06\n",
      "epoch 2, step 36750/55000, batch loss = 0.05\n",
      "epoch 2, step 37000/55000, batch loss = 0.03\n",
      "epoch 2, step 37250/55000, batch loss = 0.06\n",
      "epoch 2, step 37500/55000, batch loss = 0.02\n",
      "Train accuracy = 98.60\n",
      "epoch 2, step 37750/55000, batch loss = 0.02\n",
      "epoch 2, step 38000/55000, batch loss = 0.09\n",
      "epoch 2, step 38250/55000, batch loss = 0.07\n",
      "epoch 2, step 38500/55000, batch loss = 0.05\n",
      "epoch 2, step 38750/55000, batch loss = 0.00\n",
      "epoch 2, step 39000/55000, batch loss = 0.02\n",
      "epoch 2, step 39250/55000, batch loss = 0.00\n",
      "epoch 2, step 39500/55000, batch loss = 0.01\n",
      "epoch 2, step 39750/55000, batch loss = 0.00\n",
      "epoch 2, step 40000/55000, batch loss = 0.03\n",
      "Train accuracy = 98.61\n",
      "epoch 2, step 40250/55000, batch loss = 0.11\n",
      "epoch 2, step 40500/55000, batch loss = 0.06\n",
      "epoch 2, step 40750/55000, batch loss = 0.01\n",
      "epoch 2, step 41000/55000, batch loss = 0.07\n",
      "epoch 2, step 41250/55000, batch loss = 0.00\n",
      "epoch 2, step 41500/55000, batch loss = 0.02\n",
      "epoch 2, step 41750/55000, batch loss = 0.00\n",
      "epoch 2, step 42000/55000, batch loss = 0.10\n",
      "epoch 2, step 42250/55000, batch loss = 0.05\n",
      "epoch 2, step 42500/55000, batch loss = 0.05\n",
      "Train accuracy = 98.59\n",
      "epoch 2, step 42750/55000, batch loss = 0.10\n",
      "epoch 2, step 43000/55000, batch loss = 0.01\n",
      "epoch 2, step 43250/55000, batch loss = 0.05\n",
      "epoch 2, step 43500/55000, batch loss = 0.00\n",
      "epoch 2, step 43750/55000, batch loss = 0.09\n",
      "epoch 2, step 44000/55000, batch loss = 0.03\n",
      "epoch 2, step 44250/55000, batch loss = 0.01\n",
      "epoch 2, step 44500/55000, batch loss = 0.01\n",
      "epoch 2, step 44750/55000, batch loss = 0.04\n",
      "epoch 2, step 45000/55000, batch loss = 0.01\n",
      "Train accuracy = 98.59\n",
      "epoch 2, step 45250/55000, batch loss = 0.00\n",
      "epoch 2, step 45500/55000, batch loss = 0.06\n",
      "epoch 2, step 45750/55000, batch loss = 0.01\n",
      "epoch 2, step 46000/55000, batch loss = 0.01\n",
      "epoch 2, step 46250/55000, batch loss = 0.08\n",
      "epoch 2, step 46500/55000, batch loss = 0.06\n",
      "epoch 2, step 46750/55000, batch loss = 0.06\n",
      "epoch 2, step 47000/55000, batch loss = 0.01\n",
      "epoch 2, step 47250/55000, batch loss = 0.05\n",
      "epoch 2, step 47500/55000, batch loss = 0.11\n",
      "Train accuracy = 98.59\n",
      "epoch 2, step 47750/55000, batch loss = 0.09\n",
      "epoch 2, step 48000/55000, batch loss = 0.02\n",
      "epoch 2, step 48250/55000, batch loss = 0.01\n",
      "epoch 2, step 48500/55000, batch loss = 0.06\n",
      "epoch 2, step 48750/55000, batch loss = 0.03\n",
      "epoch 2, step 49000/55000, batch loss = 0.01\n",
      "epoch 2, step 49250/55000, batch loss = 0.01\n",
      "epoch 2, step 49500/55000, batch loss = 0.05\n",
      "epoch 2, step 49750/55000, batch loss = 0.03\n",
      "epoch 2, step 50000/55000, batch loss = 0.02\n",
      "Train accuracy = 98.59\n",
      "epoch 2, step 50250/55000, batch loss = 0.05\n",
      "epoch 2, step 50500/55000, batch loss = 0.02\n",
      "epoch 2, step 50750/55000, batch loss = 0.01\n",
      "epoch 2, step 51000/55000, batch loss = 0.00\n",
      "epoch 2, step 51250/55000, batch loss = 0.01\n",
      "epoch 2, step 51500/55000, batch loss = 0.05\n",
      "epoch 2, step 51750/55000, batch loss = 0.05\n",
      "epoch 2, step 52000/55000, batch loss = 0.00\n",
      "epoch 2, step 52250/55000, batch loss = 0.02\n",
      "epoch 2, step 52500/55000, batch loss = 0.01\n",
      "Train accuracy = 98.60\n",
      "epoch 2, step 52750/55000, batch loss = 0.01\n",
      "epoch 2, step 53000/55000, batch loss = 0.02\n",
      "epoch 2, step 53250/55000, batch loss = 0.01\n",
      "epoch 2, step 53500/55000, batch loss = 0.03\n",
      "epoch 2, step 53750/55000, batch loss = 0.05\n",
      "epoch 2, step 54000/55000, batch loss = 0.08\n",
      "epoch 2, step 54250/55000, batch loss = 0.01\n",
      "epoch 2, step 54500/55000, batch loss = 0.02\n",
      "epoch 2, step 54750/55000, batch loss = 0.00\n",
      "Train accuracy = 98.61\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 98.74\n",
      "Validation avg loss = 0.04\n",
      "\n",
      "epoch 3, step 0/55000, batch loss = 0.01\n",
      "epoch 3, step 250/55000, batch loss = 0.03\n",
      "epoch 3, step 500/55000, batch loss = 0.02\n",
      "epoch 3, step 750/55000, batch loss = 0.02\n",
      "epoch 3, step 1000/55000, batch loss = 0.04\n",
      "epoch 3, step 1250/55000, batch loss = 0.04\n",
      "epoch 3, step 1500/55000, batch loss = 0.01\n",
      "epoch 3, step 1750/55000, batch loss = 0.00\n",
      "epoch 3, step 2000/55000, batch loss = 0.01\n",
      "epoch 3, step 2250/55000, batch loss = 0.00\n",
      "epoch 3, step 2500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.06\n",
      "epoch 3, step 2750/55000, batch loss = 0.03\n",
      "epoch 3, step 3000/55000, batch loss = 0.04\n",
      "epoch 3, step 3250/55000, batch loss = 0.02\n",
      "epoch 3, step 3500/55000, batch loss = 0.09\n",
      "epoch 3, step 3750/55000, batch loss = 0.01\n",
      "epoch 3, step 4000/55000, batch loss = 0.03\n",
      "epoch 3, step 4250/55000, batch loss = 0.05\n",
      "epoch 3, step 4500/55000, batch loss = 0.01\n",
      "epoch 3, step 4750/55000, batch loss = 0.01\n",
      "epoch 3, step 5000/55000, batch loss = 0.03\n",
      "Train accuracy = 99.05\n",
      "epoch 3, step 5250/55000, batch loss = 0.01\n",
      "epoch 3, step 5500/55000, batch loss = 0.07\n",
      "epoch 3, step 5750/55000, batch loss = 0.04\n",
      "epoch 3, step 6000/55000, batch loss = 0.01\n",
      "epoch 3, step 6250/55000, batch loss = 0.01\n",
      "epoch 3, step 6500/55000, batch loss = 0.02\n",
      "epoch 3, step 6750/55000, batch loss = 0.04\n",
      "epoch 3, step 7000/55000, batch loss = 0.00\n",
      "epoch 3, step 7250/55000, batch loss = 0.02\n",
      "epoch 3, step 7500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.23\n",
      "epoch 3, step 7750/55000, batch loss = 0.03\n",
      "epoch 3, step 8000/55000, batch loss = 0.01\n",
      "epoch 3, step 8250/55000, batch loss = 0.02\n",
      "epoch 3, step 8500/55000, batch loss = 0.01\n",
      "epoch 3, step 8750/55000, batch loss = 0.00\n",
      "epoch 3, step 9000/55000, batch loss = 0.01\n",
      "epoch 3, step 9250/55000, batch loss = 0.00\n",
      "epoch 3, step 9500/55000, batch loss = 0.13\n",
      "epoch 3, step 9750/55000, batch loss = 0.02\n",
      "epoch 3, step 10000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.34\n",
      "epoch 3, step 10250/55000, batch loss = 0.02\n",
      "epoch 3, step 10500/55000, batch loss = 0.01\n",
      "epoch 3, step 10750/55000, batch loss = 0.00\n",
      "epoch 3, step 11000/55000, batch loss = 0.00\n",
      "epoch 3, step 11250/55000, batch loss = 0.00\n",
      "epoch 3, step 11500/55000, batch loss = 0.05\n",
      "epoch 3, step 11750/55000, batch loss = 0.01\n",
      "epoch 3, step 12000/55000, batch loss = 0.01\n",
      "epoch 3, step 12250/55000, batch loss = 0.01\n",
      "epoch 3, step 12500/55000, batch loss = 0.02\n",
      "Train accuracy = 99.36\n",
      "epoch 3, step 12750/55000, batch loss = 0.01\n",
      "epoch 3, step 13000/55000, batch loss = 0.01\n",
      "epoch 3, step 13250/55000, batch loss = 0.02\n",
      "epoch 3, step 13500/55000, batch loss = 0.01\n",
      "epoch 3, step 13750/55000, batch loss = 0.01\n",
      "epoch 3, step 14000/55000, batch loss = 0.01\n",
      "epoch 3, step 14250/55000, batch loss = 0.09\n",
      "epoch 3, step 14500/55000, batch loss = 0.10\n",
      "epoch 3, step 14750/55000, batch loss = 0.03\n",
      "epoch 3, step 15000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.37\n",
      "epoch 3, step 15250/55000, batch loss = 0.09\n",
      "epoch 3, step 15500/55000, batch loss = 0.01\n",
      "epoch 3, step 15750/55000, batch loss = 0.04\n",
      "epoch 3, step 16000/55000, batch loss = 0.01\n",
      "epoch 3, step 16250/55000, batch loss = 0.02\n",
      "epoch 3, step 16500/55000, batch loss = 0.00\n",
      "epoch 3, step 16750/55000, batch loss = 0.01\n",
      "epoch 3, step 17000/55000, batch loss = 0.01\n",
      "epoch 3, step 17250/55000, batch loss = 0.01\n",
      "epoch 3, step 17500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.38\n",
      "epoch 3, step 17750/55000, batch loss = 0.03\n",
      "epoch 3, step 18000/55000, batch loss = 0.01\n",
      "epoch 3, step 18250/55000, batch loss = 0.01\n",
      "epoch 3, step 18500/55000, batch loss = 0.04\n",
      "epoch 3, step 18750/55000, batch loss = 0.01\n",
      "epoch 3, step 19000/55000, batch loss = 0.02\n",
      "epoch 3, step 19250/55000, batch loss = 0.00\n",
      "epoch 3, step 19500/55000, batch loss = 0.01\n",
      "epoch 3, step 19750/55000, batch loss = 0.01\n",
      "epoch 3, step 20000/55000, batch loss = 0.08\n",
      "Train accuracy = 99.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, step 20250/55000, batch loss = 0.02\n",
      "epoch 3, step 20500/55000, batch loss = 0.01\n",
      "epoch 3, step 20750/55000, batch loss = 0.03\n",
      "epoch 3, step 21000/55000, batch loss = 0.05\n",
      "epoch 3, step 21250/55000, batch loss = 0.02\n",
      "epoch 3, step 21500/55000, batch loss = 0.00\n",
      "epoch 3, step 21750/55000, batch loss = 0.11\n",
      "epoch 3, step 22000/55000, batch loss = 0.01\n",
      "epoch 3, step 22250/55000, batch loss = 0.01\n",
      "epoch 3, step 22500/55000, batch loss = 0.02\n",
      "Train accuracy = 99.37\n",
      "epoch 3, step 22750/55000, batch loss = 0.00\n",
      "epoch 3, step 23000/55000, batch loss = 0.02\n",
      "epoch 3, step 23250/55000, batch loss = 0.00\n",
      "epoch 3, step 23500/55000, batch loss = 0.01\n",
      "epoch 3, step 23750/55000, batch loss = 0.00\n",
      "epoch 3, step 24000/55000, batch loss = 0.02\n",
      "epoch 3, step 24250/55000, batch loss = 0.01\n",
      "epoch 3, step 24500/55000, batch loss = 0.02\n",
      "epoch 3, step 24750/55000, batch loss = 0.00\n",
      "epoch 3, step 25000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.40\n",
      "epoch 3, step 25250/55000, batch loss = 0.01\n",
      "epoch 3, step 25500/55000, batch loss = 0.01\n",
      "epoch 3, step 25750/55000, batch loss = 0.01\n",
      "epoch 3, step 26000/55000, batch loss = 0.01\n",
      "epoch 3, step 26250/55000, batch loss = 0.18\n",
      "epoch 3, step 26500/55000, batch loss = 0.01\n",
      "epoch 3, step 26750/55000, batch loss = 0.00\n",
      "epoch 3, step 27000/55000, batch loss = 0.05\n",
      "epoch 3, step 27250/55000, batch loss = 0.14\n",
      "epoch 3, step 27500/55000, batch loss = 0.02\n",
      "Train accuracy = 99.42\n",
      "epoch 3, step 27750/55000, batch loss = 0.00\n",
      "epoch 3, step 28000/55000, batch loss = 0.01\n",
      "epoch 3, step 28250/55000, batch loss = 0.01\n",
      "epoch 3, step 28500/55000, batch loss = 0.04\n",
      "epoch 3, step 28750/55000, batch loss = 0.04\n",
      "epoch 3, step 29000/55000, batch loss = 0.08\n",
      "epoch 3, step 29250/55000, batch loss = 0.02\n",
      "epoch 3, step 29500/55000, batch loss = 0.00\n",
      "epoch 3, step 29750/55000, batch loss = 0.07\n",
      "epoch 3, step 30000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.41\n",
      "epoch 3, step 30250/55000, batch loss = 0.02\n",
      "epoch 3, step 30500/55000, batch loss = 0.12\n",
      "epoch 3, step 30750/55000, batch loss = 0.02\n",
      "epoch 3, step 31000/55000, batch loss = 0.06\n",
      "epoch 3, step 31250/55000, batch loss = 0.02\n",
      "epoch 3, step 31500/55000, batch loss = 0.01\n",
      "epoch 3, step 31750/55000, batch loss = 0.07\n",
      "epoch 3, step 32000/55000, batch loss = 0.03\n",
      "epoch 3, step 32250/55000, batch loss = 0.00\n",
      "epoch 3, step 32500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.41\n",
      "epoch 3, step 32750/55000, batch loss = 0.01\n",
      "epoch 3, step 33000/55000, batch loss = 0.01\n",
      "epoch 3, step 33250/55000, batch loss = 0.04\n",
      "epoch 3, step 33500/55000, batch loss = 0.00\n",
      "epoch 3, step 33750/55000, batch loss = 0.03\n",
      "epoch 3, step 34000/55000, batch loss = 0.00\n",
      "epoch 3, step 34250/55000, batch loss = 0.00\n",
      "epoch 3, step 34500/55000, batch loss = 0.01\n",
      "epoch 3, step 34750/55000, batch loss = 0.07\n",
      "epoch 3, step 35000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.41\n",
      "epoch 3, step 35250/55000, batch loss = 0.00\n",
      "epoch 3, step 35500/55000, batch loss = 0.01\n",
      "epoch 3, step 35750/55000, batch loss = 0.01\n",
      "epoch 3, step 36000/55000, batch loss = 0.04\n",
      "epoch 3, step 36250/55000, batch loss = 0.01\n",
      "epoch 3, step 36500/55000, batch loss = 0.00\n",
      "epoch 3, step 36750/55000, batch loss = 0.00\n",
      "epoch 3, step 37000/55000, batch loss = 0.05\n",
      "epoch 3, step 37250/55000, batch loss = 0.01\n",
      "epoch 3, step 37500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.43\n",
      "epoch 3, step 37750/55000, batch loss = 0.04\n",
      "epoch 3, step 38000/55000, batch loss = 0.08\n",
      "epoch 3, step 38250/55000, batch loss = 0.00\n",
      "epoch 3, step 38500/55000, batch loss = 0.01\n",
      "epoch 3, step 38750/55000, batch loss = 0.02\n",
      "epoch 3, step 39000/55000, batch loss = 0.00\n",
      "epoch 3, step 39250/55000, batch loss = 0.00\n",
      "epoch 3, step 39500/55000, batch loss = 0.01\n",
      "epoch 3, step 39750/55000, batch loss = 0.06\n",
      "epoch 3, step 40000/55000, batch loss = 0.03\n",
      "Train accuracy = 99.43\n",
      "epoch 3, step 40250/55000, batch loss = 0.00\n",
      "epoch 3, step 40500/55000, batch loss = 0.01\n",
      "epoch 3, step 40750/55000, batch loss = 0.06\n",
      "epoch 3, step 41000/55000, batch loss = 0.01\n",
      "epoch 3, step 41250/55000, batch loss = 0.01\n",
      "epoch 3, step 41500/55000, batch loss = 0.03\n",
      "epoch 3, step 41750/55000, batch loss = 0.00\n",
      "epoch 3, step 42000/55000, batch loss = 0.00\n",
      "epoch 3, step 42250/55000, batch loss = 0.03\n",
      "epoch 3, step 42500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.42\n",
      "epoch 3, step 42750/55000, batch loss = 0.01\n",
      "epoch 3, step 43000/55000, batch loss = 0.02\n",
      "epoch 3, step 43250/55000, batch loss = 0.01\n",
      "epoch 3, step 43500/55000, batch loss = 0.00\n",
      "epoch 3, step 43750/55000, batch loss = 0.01\n",
      "epoch 3, step 44000/55000, batch loss = 0.00\n",
      "epoch 3, step 44250/55000, batch loss = 0.01\n",
      "epoch 3, step 44500/55000, batch loss = 0.01\n",
      "epoch 3, step 44750/55000, batch loss = 0.00\n",
      "epoch 3, step 45000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.43\n",
      "epoch 3, step 45250/55000, batch loss = 0.01\n",
      "epoch 3, step 45500/55000, batch loss = 0.01\n",
      "epoch 3, step 45750/55000, batch loss = 0.01\n",
      "epoch 3, step 46000/55000, batch loss = 0.00\n",
      "epoch 3, step 46250/55000, batch loss = 0.01\n",
      "epoch 3, step 46500/55000, batch loss = 0.01\n",
      "epoch 3, step 46750/55000, batch loss = 0.00\n",
      "epoch 3, step 47000/55000, batch loss = 0.04\n",
      "epoch 3, step 47250/55000, batch loss = 0.01\n",
      "epoch 3, step 47500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.43\n",
      "epoch 3, step 47750/55000, batch loss = 0.01\n",
      "epoch 3, step 48000/55000, batch loss = 0.00\n",
      "epoch 3, step 48250/55000, batch loss = 0.00\n",
      "epoch 3, step 48500/55000, batch loss = 0.05\n",
      "epoch 3, step 48750/55000, batch loss = 0.00\n",
      "epoch 3, step 49000/55000, batch loss = 0.00\n",
      "epoch 3, step 49250/55000, batch loss = 0.01\n",
      "epoch 3, step 49500/55000, batch loss = 0.03\n",
      "epoch 3, step 49750/55000, batch loss = 0.03\n",
      "epoch 3, step 50000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.43\n",
      "epoch 3, step 50250/55000, batch loss = 0.03\n",
      "epoch 3, step 50500/55000, batch loss = 0.01\n",
      "epoch 3, step 50750/55000, batch loss = 0.00\n",
      "epoch 3, step 51000/55000, batch loss = 0.02\n",
      "epoch 3, step 51250/55000, batch loss = 0.05\n",
      "epoch 3, step 51500/55000, batch loss = 0.00\n",
      "epoch 3, step 51750/55000, batch loss = 0.02\n",
      "epoch 3, step 52000/55000, batch loss = 0.03\n",
      "epoch 3, step 52250/55000, batch loss = 0.05\n",
      "epoch 3, step 52500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.44\n",
      "epoch 3, step 52750/55000, batch loss = 0.01\n",
      "epoch 3, step 53000/55000, batch loss = 0.12\n",
      "epoch 3, step 53250/55000, batch loss = 0.02\n",
      "epoch 3, step 53500/55000, batch loss = 0.00\n",
      "epoch 3, step 53750/55000, batch loss = 0.01\n",
      "epoch 3, step 54000/55000, batch loss = 0.01\n",
      "epoch 3, step 54250/55000, batch loss = 0.00\n",
      "epoch 3, step 54500/55000, batch loss = 0.02\n",
      "epoch 3, step 54750/55000, batch loss = 0.00\n",
      "Train accuracy = 99.44\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.16\n",
      "Validation avg loss = 0.03\n",
      "\n",
      "epoch 4, step 0/55000, batch loss = 0.00\n",
      "epoch 4, step 250/55000, batch loss = 0.01\n",
      "epoch 4, step 500/55000, batch loss = 0.02\n",
      "epoch 4, step 750/55000, batch loss = 0.00\n",
      "epoch 4, step 1000/55000, batch loss = 0.09\n",
      "epoch 4, step 1250/55000, batch loss = 0.00\n",
      "epoch 4, step 1500/55000, batch loss = 0.04\n",
      "epoch 4, step 1750/55000, batch loss = 0.01\n",
      "epoch 4, step 2000/55000, batch loss = 0.03\n",
      "epoch 4, step 2250/55000, batch loss = 0.01\n",
      "epoch 4, step 2500/55000, batch loss = 0.03\n",
      "Train accuracy = 99.37\n",
      "epoch 4, step 2750/55000, batch loss = 0.02\n",
      "epoch 4, step 3000/55000, batch loss = 0.01\n",
      "epoch 4, step 3250/55000, batch loss = 0.00\n",
      "epoch 4, step 3500/55000, batch loss = 0.00\n",
      "epoch 4, step 3750/55000, batch loss = 0.00\n",
      "epoch 4, step 4000/55000, batch loss = 0.02\n",
      "epoch 4, step 4250/55000, batch loss = 0.01\n",
      "epoch 4, step 4500/55000, batch loss = 0.01\n",
      "epoch 4, step 4750/55000, batch loss = 0.01\n",
      "epoch 4, step 5000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.49\n",
      "epoch 4, step 5250/55000, batch loss = 0.01\n",
      "epoch 4, step 5500/55000, batch loss = 0.00\n",
      "epoch 4, step 5750/55000, batch loss = 0.01\n",
      "epoch 4, step 6000/55000, batch loss = 0.01\n",
      "epoch 4, step 6250/55000, batch loss = 0.00\n",
      "epoch 4, step 6500/55000, batch loss = 0.00\n",
      "epoch 4, step 6750/55000, batch loss = 0.01\n",
      "epoch 4, step 7000/55000, batch loss = 0.00\n",
      "epoch 4, step 7250/55000, batch loss = 0.00\n",
      "epoch 4, step 7500/55000, batch loss = 0.02\n",
      "Train accuracy = 99.60\n",
      "epoch 4, step 7750/55000, batch loss = 0.00\n",
      "epoch 4, step 8000/55000, batch loss = 0.04\n",
      "epoch 4, step 8250/55000, batch loss = 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, step 8500/55000, batch loss = 0.00\n",
      "epoch 4, step 8750/55000, batch loss = 0.00\n",
      "epoch 4, step 9000/55000, batch loss = 0.03\n",
      "epoch 4, step 9250/55000, batch loss = 0.01\n",
      "epoch 4, step 9500/55000, batch loss = 0.00\n",
      "epoch 4, step 9750/55000, batch loss = 0.00\n",
      "epoch 4, step 10000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.53\n",
      "epoch 4, step 10250/55000, batch loss = 0.00\n",
      "epoch 4, step 10500/55000, batch loss = 0.01\n",
      "epoch 4, step 10750/55000, batch loss = 0.01\n",
      "epoch 4, step 11000/55000, batch loss = 0.00\n",
      "epoch 4, step 11250/55000, batch loss = 0.01\n",
      "epoch 4, step 11500/55000, batch loss = 0.01\n",
      "epoch 4, step 11750/55000, batch loss = 0.02\n",
      "epoch 4, step 12000/55000, batch loss = 0.00\n",
      "epoch 4, step 12250/55000, batch loss = 0.02\n",
      "epoch 4, step 12500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.52\n",
      "epoch 4, step 12750/55000, batch loss = 0.00\n",
      "epoch 4, step 13000/55000, batch loss = 0.03\n",
      "epoch 4, step 13250/55000, batch loss = 0.00\n",
      "epoch 4, step 13500/55000, batch loss = 0.01\n",
      "epoch 4, step 13750/55000, batch loss = 0.04\n",
      "epoch 4, step 14000/55000, batch loss = 0.02\n",
      "epoch 4, step 14250/55000, batch loss = 0.02\n",
      "epoch 4, step 14500/55000, batch loss = 0.04\n",
      "epoch 4, step 14750/55000, batch loss = 0.00\n",
      "epoch 4, step 15000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.50\n",
      "epoch 4, step 15250/55000, batch loss = 0.03\n",
      "epoch 4, step 15500/55000, batch loss = 0.00\n",
      "epoch 4, step 15750/55000, batch loss = 0.04\n",
      "epoch 4, step 16000/55000, batch loss = 0.02\n",
      "epoch 4, step 16250/55000, batch loss = 0.01\n",
      "epoch 4, step 16500/55000, batch loss = 0.00\n",
      "epoch 4, step 16750/55000, batch loss = 0.02\n",
      "epoch 4, step 17000/55000, batch loss = 0.04\n",
      "epoch 4, step 17250/55000, batch loss = 0.00\n",
      "epoch 4, step 17500/55000, batch loss = 0.02\n",
      "Train accuracy = 99.46\n",
      "epoch 4, step 17750/55000, batch loss = 0.06\n",
      "epoch 4, step 18000/55000, batch loss = 0.03\n",
      "epoch 4, step 18250/55000, batch loss = 0.03\n",
      "epoch 4, step 18500/55000, batch loss = 0.13\n",
      "epoch 4, step 18750/55000, batch loss = 0.02\n",
      "epoch 4, step 19000/55000, batch loss = 0.02\n",
      "epoch 4, step 19250/55000, batch loss = 0.00\n",
      "epoch 4, step 19500/55000, batch loss = 0.01\n",
      "epoch 4, step 19750/55000, batch loss = 0.02\n",
      "epoch 4, step 20000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.46\n",
      "epoch 4, step 20250/55000, batch loss = 0.02\n",
      "epoch 4, step 20500/55000, batch loss = 0.00\n",
      "epoch 4, step 20750/55000, batch loss = 0.03\n",
      "epoch 4, step 21000/55000, batch loss = 0.00\n",
      "epoch 4, step 21250/55000, batch loss = 0.02\n",
      "epoch 4, step 21500/55000, batch loss = 0.01\n",
      "epoch 4, step 21750/55000, batch loss = 0.02\n",
      "epoch 4, step 22000/55000, batch loss = 0.00\n",
      "epoch 4, step 22250/55000, batch loss = 0.00\n",
      "epoch 4, step 22500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.48\n",
      "epoch 4, step 22750/55000, batch loss = 0.00\n",
      "epoch 4, step 23000/55000, batch loss = 0.01\n",
      "epoch 4, step 23250/55000, batch loss = 0.01\n",
      "epoch 4, step 23500/55000, batch loss = 0.02\n",
      "epoch 4, step 23750/55000, batch loss = 0.05\n",
      "epoch 4, step 24000/55000, batch loss = 0.01\n",
      "epoch 4, step 24250/55000, batch loss = 0.01\n",
      "epoch 4, step 24500/55000, batch loss = 0.00\n",
      "epoch 4, step 24750/55000, batch loss = 0.04\n",
      "epoch 4, step 25000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.48\n",
      "epoch 4, step 25250/55000, batch loss = 0.01\n",
      "epoch 4, step 25500/55000, batch loss = 0.00\n",
      "epoch 4, step 25750/55000, batch loss = 0.01\n",
      "epoch 4, step 26000/55000, batch loss = 0.01\n",
      "epoch 4, step 26250/55000, batch loss = 0.01\n",
      "epoch 4, step 26500/55000, batch loss = 0.02\n",
      "epoch 4, step 26750/55000, batch loss = 0.01\n",
      "epoch 4, step 27000/55000, batch loss = 0.02\n",
      "epoch 4, step 27250/55000, batch loss = 0.02\n",
      "epoch 4, step 27500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.49\n",
      "epoch 4, step 27750/55000, batch loss = 0.03\n",
      "epoch 4, step 28000/55000, batch loss = 0.01\n",
      "epoch 4, step 28250/55000, batch loss = 0.01\n",
      "epoch 4, step 28500/55000, batch loss = 0.00\n",
      "epoch 4, step 28750/55000, batch loss = 0.02\n",
      "epoch 4, step 29000/55000, batch loss = 0.18\n",
      "epoch 4, step 29250/55000, batch loss = 0.00\n",
      "epoch 4, step 29500/55000, batch loss = 0.00\n",
      "epoch 4, step 29750/55000, batch loss = 0.01\n",
      "epoch 4, step 30000/55000, batch loss = 0.07\n",
      "Train accuracy = 99.48\n",
      "epoch 4, step 30250/55000, batch loss = 0.05\n",
      "epoch 4, step 30500/55000, batch loss = 0.01\n",
      "epoch 4, step 30750/55000, batch loss = 0.00\n",
      "epoch 4, step 31000/55000, batch loss = 0.03\n",
      "epoch 4, step 31250/55000, batch loss = 0.00\n",
      "epoch 4, step 31500/55000, batch loss = 0.00\n",
      "epoch 4, step 31750/55000, batch loss = 0.01\n",
      "epoch 4, step 32000/55000, batch loss = 0.00\n",
      "epoch 4, step 32250/55000, batch loss = 0.00\n",
      "epoch 4, step 32500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.49\n",
      "epoch 4, step 32750/55000, batch loss = 0.00\n",
      "epoch 4, step 33000/55000, batch loss = 0.01\n",
      "epoch 4, step 33250/55000, batch loss = 0.02\n",
      "epoch 4, step 33500/55000, batch loss = 0.01\n",
      "epoch 4, step 33750/55000, batch loss = 0.01\n",
      "epoch 4, step 34000/55000, batch loss = 0.00\n",
      "epoch 4, step 34250/55000, batch loss = 0.01\n",
      "epoch 4, step 34500/55000, batch loss = 0.01\n",
      "epoch 4, step 34750/55000, batch loss = 0.00\n",
      "epoch 4, step 35000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.50\n",
      "epoch 4, step 35250/55000, batch loss = 0.01\n",
      "epoch 4, step 35500/55000, batch loss = 0.00\n",
      "epoch 4, step 35750/55000, batch loss = 0.00\n",
      "epoch 4, step 36000/55000, batch loss = 0.01\n",
      "epoch 4, step 36250/55000, batch loss = 0.00\n",
      "epoch 4, step 36500/55000, batch loss = 0.01\n",
      "epoch 4, step 36750/55000, batch loss = 0.01\n",
      "epoch 4, step 37000/55000, batch loss = 0.00\n",
      "epoch 4, step 37250/55000, batch loss = 0.00\n",
      "epoch 4, step 37500/55000, batch loss = 0.08\n",
      "Train accuracy = 99.51\n",
      "epoch 4, step 37750/55000, batch loss = 0.02\n",
      "epoch 4, step 38000/55000, batch loss = 0.00\n",
      "epoch 4, step 38250/55000, batch loss = 0.01\n",
      "epoch 4, step 38500/55000, batch loss = 0.09\n",
      "epoch 4, step 38750/55000, batch loss = 0.00\n",
      "epoch 4, step 39000/55000, batch loss = 0.02\n",
      "epoch 4, step 39250/55000, batch loss = 0.00\n",
      "epoch 4, step 39500/55000, batch loss = 0.03\n",
      "epoch 4, step 39750/55000, batch loss = 0.00\n",
      "epoch 4, step 40000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.51\n",
      "epoch 4, step 40250/55000, batch loss = 0.01\n",
      "epoch 4, step 40500/55000, batch loss = 0.01\n",
      "epoch 4, step 40750/55000, batch loss = 0.06\n",
      "epoch 4, step 41000/55000, batch loss = 0.07\n",
      "epoch 4, step 41250/55000, batch loss = 0.00\n",
      "epoch 4, step 41500/55000, batch loss = 0.00\n",
      "epoch 4, step 41750/55000, batch loss = 0.01\n",
      "epoch 4, step 42000/55000, batch loss = 0.14\n",
      "epoch 4, step 42250/55000, batch loss = 0.01\n",
      "epoch 4, step 42500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.52\n",
      "epoch 4, step 42750/55000, batch loss = 0.03\n",
      "epoch 4, step 43000/55000, batch loss = 0.00\n",
      "epoch 4, step 43250/55000, batch loss = 0.00\n",
      "epoch 4, step 43500/55000, batch loss = 0.01\n",
      "epoch 4, step 43750/55000, batch loss = 0.03\n",
      "epoch 4, step 44000/55000, batch loss = 0.00\n",
      "epoch 4, step 44250/55000, batch loss = 0.00\n",
      "epoch 4, step 44500/55000, batch loss = 0.00\n",
      "epoch 4, step 44750/55000, batch loss = 0.05\n",
      "epoch 4, step 45000/55000, batch loss = 0.06\n",
      "Train accuracy = 99.51\n",
      "epoch 4, step 45250/55000, batch loss = 0.04\n",
      "epoch 4, step 45500/55000, batch loss = 0.01\n",
      "epoch 4, step 45750/55000, batch loss = 0.03\n",
      "epoch 4, step 46000/55000, batch loss = 0.01\n",
      "epoch 4, step 46250/55000, batch loss = 0.01\n",
      "epoch 4, step 46500/55000, batch loss = 0.01\n",
      "epoch 4, step 46750/55000, batch loss = 0.00\n",
      "epoch 4, step 47000/55000, batch loss = 0.00\n",
      "epoch 4, step 47250/55000, batch loss = 0.01\n",
      "epoch 4, step 47500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.53\n",
      "epoch 4, step 47750/55000, batch loss = 0.09\n",
      "epoch 4, step 48000/55000, batch loss = 0.00\n",
      "epoch 4, step 48250/55000, batch loss = 0.00\n",
      "epoch 4, step 48500/55000, batch loss = 0.02\n",
      "epoch 4, step 48750/55000, batch loss = 0.00\n",
      "epoch 4, step 49000/55000, batch loss = 0.02\n",
      "epoch 4, step 49250/55000, batch loss = 0.00\n",
      "epoch 4, step 49500/55000, batch loss = 0.00\n",
      "epoch 4, step 49750/55000, batch loss = 0.01\n",
      "epoch 4, step 50000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.52\n",
      "epoch 4, step 50250/55000, batch loss = 0.00\n",
      "epoch 4, step 50500/55000, batch loss = 0.03\n",
      "epoch 4, step 50750/55000, batch loss = 0.01\n",
      "epoch 4, step 51000/55000, batch loss = 0.04\n",
      "epoch 4, step 51250/55000, batch loss = 0.06\n",
      "epoch 4, step 51500/55000, batch loss = 0.01\n",
      "epoch 4, step 51750/55000, batch loss = 0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, step 52000/55000, batch loss = 0.08\n",
      "epoch 4, step 52250/55000, batch loss = 0.01\n",
      "epoch 4, step 52500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.52\n",
      "epoch 4, step 52750/55000, batch loss = 0.05\n",
      "epoch 4, step 53000/55000, batch loss = 0.01\n",
      "epoch 4, step 53250/55000, batch loss = 0.01\n",
      "epoch 4, step 53500/55000, batch loss = 0.05\n",
      "epoch 4, step 53750/55000, batch loss = 0.00\n",
      "epoch 4, step 54000/55000, batch loss = 0.00\n",
      "epoch 4, step 54250/55000, batch loss = 0.00\n",
      "epoch 4, step 54500/55000, batch loss = 0.00\n",
      "epoch 4, step 54750/55000, batch loss = 0.04\n",
      "Train accuracy = 99.51\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.18\n",
      "Validation avg loss = 0.03\n",
      "\n",
      "epoch 5, step 0/55000, batch loss = 0.00\n",
      "epoch 5, step 250/55000, batch loss = 0.00\n",
      "epoch 5, step 500/55000, batch loss = 0.02\n",
      "epoch 5, step 750/55000, batch loss = 0.00\n",
      "epoch 5, step 1000/55000, batch loss = 0.01\n",
      "epoch 5, step 1250/55000, batch loss = 0.00\n",
      "epoch 5, step 1500/55000, batch loss = 0.03\n",
      "epoch 5, step 1750/55000, batch loss = 0.01\n",
      "epoch 5, step 2000/55000, batch loss = 0.00\n",
      "epoch 5, step 2250/55000, batch loss = 0.00\n",
      "epoch 5, step 2500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.73\n",
      "epoch 5, step 2750/55000, batch loss = 0.01\n",
      "epoch 5, step 3000/55000, batch loss = 0.00\n",
      "epoch 5, step 3250/55000, batch loss = 0.01\n",
      "epoch 5, step 3500/55000, batch loss = 0.01\n",
      "epoch 5, step 3750/55000, batch loss = 0.00\n",
      "epoch 5, step 4000/55000, batch loss = 0.02\n",
      "epoch 5, step 4250/55000, batch loss = 0.00\n",
      "epoch 5, step 4500/55000, batch loss = 0.01\n",
      "epoch 5, step 4750/55000, batch loss = 0.02\n",
      "epoch 5, step 5000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.68\n",
      "epoch 5, step 5250/55000, batch loss = 0.00\n",
      "epoch 5, step 5500/55000, batch loss = 0.04\n",
      "epoch 5, step 5750/55000, batch loss = 0.03\n",
      "epoch 5, step 6000/55000, batch loss = 0.02\n",
      "epoch 5, step 6250/55000, batch loss = 0.01\n",
      "epoch 5, step 6500/55000, batch loss = 0.00\n",
      "epoch 5, step 6750/55000, batch loss = 0.01\n",
      "epoch 5, step 7000/55000, batch loss = 0.00\n",
      "epoch 5, step 7250/55000, batch loss = 0.01\n",
      "epoch 5, step 7500/55000, batch loss = 0.03\n",
      "Train accuracy = 99.64\n",
      "epoch 5, step 7750/55000, batch loss = 0.03\n",
      "epoch 5, step 8000/55000, batch loss = 0.03\n",
      "epoch 5, step 8250/55000, batch loss = 0.00\n",
      "epoch 5, step 8500/55000, batch loss = 0.00\n",
      "epoch 5, step 8750/55000, batch loss = 0.00\n",
      "epoch 5, step 9000/55000, batch loss = 0.01\n",
      "epoch 5, step 9250/55000, batch loss = 0.00\n",
      "epoch 5, step 9500/55000, batch loss = 0.01\n",
      "epoch 5, step 9750/55000, batch loss = 0.11\n",
      "epoch 5, step 10000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.66\n",
      "epoch 5, step 10250/55000, batch loss = 0.00\n",
      "epoch 5, step 10500/55000, batch loss = 0.01\n",
      "epoch 5, step 10750/55000, batch loss = 0.01\n",
      "epoch 5, step 11000/55000, batch loss = 0.00\n",
      "epoch 5, step 11250/55000, batch loss = 0.02\n",
      "epoch 5, step 11500/55000, batch loss = 0.01\n",
      "epoch 5, step 11750/55000, batch loss = 0.00\n",
      "epoch 5, step 12000/55000, batch loss = 0.02\n",
      "epoch 5, step 12250/55000, batch loss = 0.01\n",
      "epoch 5, step 12500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.70\n",
      "epoch 5, step 12750/55000, batch loss = 0.01\n",
      "epoch 5, step 13000/55000, batch loss = 0.00\n",
      "epoch 5, step 13250/55000, batch loss = 0.00\n",
      "epoch 5, step 13500/55000, batch loss = 0.00\n",
      "epoch 5, step 13750/55000, batch loss = 0.00\n",
      "epoch 5, step 14000/55000, batch loss = 0.00\n",
      "epoch 5, step 14250/55000, batch loss = 0.00\n",
      "epoch 5, step 14500/55000, batch loss = 0.00\n",
      "epoch 5, step 14750/55000, batch loss = 0.00\n",
      "epoch 5, step 15000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.67\n",
      "epoch 5, step 15250/55000, batch loss = 0.01\n",
      "epoch 5, step 15500/55000, batch loss = 0.01\n",
      "epoch 5, step 15750/55000, batch loss = 0.00\n",
      "epoch 5, step 16000/55000, batch loss = 0.01\n",
      "epoch 5, step 16250/55000, batch loss = 0.02\n",
      "epoch 5, step 16500/55000, batch loss = 0.02\n",
      "epoch 5, step 16750/55000, batch loss = 0.02\n",
      "epoch 5, step 17000/55000, batch loss = 0.00\n",
      "epoch 5, step 17250/55000, batch loss = 0.00\n",
      "epoch 5, step 17500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.66\n",
      "epoch 5, step 17750/55000, batch loss = 0.02\n",
      "epoch 5, step 18000/55000, batch loss = 0.00\n",
      "epoch 5, step 18250/55000, batch loss = 0.04\n",
      "epoch 5, step 18500/55000, batch loss = 0.03\n",
      "epoch 5, step 18750/55000, batch loss = 0.01\n",
      "epoch 5, step 19000/55000, batch loss = 0.02\n",
      "epoch 5, step 19250/55000, batch loss = 0.01\n",
      "epoch 5, step 19500/55000, batch loss = 0.00\n",
      "epoch 5, step 19750/55000, batch loss = 0.06\n",
      "epoch 5, step 20000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.63\n",
      "epoch 5, step 20250/55000, batch loss = 0.04\n",
      "epoch 5, step 20500/55000, batch loss = 0.00\n",
      "epoch 5, step 20750/55000, batch loss = 0.05\n",
      "epoch 5, step 21000/55000, batch loss = 0.01\n",
      "epoch 5, step 21250/55000, batch loss = 0.01\n",
      "epoch 5, step 21500/55000, batch loss = 0.03\n",
      "epoch 5, step 21750/55000, batch loss = 0.02\n",
      "epoch 5, step 22000/55000, batch loss = 0.00\n",
      "epoch 5, step 22250/55000, batch loss = 0.06\n",
      "epoch 5, step 22500/55000, batch loss = 0.03\n",
      "Train accuracy = 99.57\n",
      "epoch 5, step 22750/55000, batch loss = 0.00\n",
      "epoch 5, step 23000/55000, batch loss = 0.05\n",
      "epoch 5, step 23250/55000, batch loss = 0.01\n",
      "epoch 5, step 23500/55000, batch loss = 0.02\n",
      "epoch 5, step 23750/55000, batch loss = 0.00\n",
      "epoch 5, step 24000/55000, batch loss = 0.06\n",
      "epoch 5, step 24250/55000, batch loss = 0.00\n",
      "epoch 5, step 24500/55000, batch loss = 0.00\n",
      "epoch 5, step 24750/55000, batch loss = 0.00\n",
      "epoch 5, step 25000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.59\n",
      "epoch 5, step 25250/55000, batch loss = 0.00\n",
      "epoch 5, step 25500/55000, batch loss = 0.01\n",
      "epoch 5, step 25750/55000, batch loss = 0.00\n",
      "epoch 5, step 26000/55000, batch loss = 0.00\n",
      "epoch 5, step 26250/55000, batch loss = 0.00\n",
      "epoch 5, step 26500/55000, batch loss = 0.00\n",
      "epoch 5, step 26750/55000, batch loss = 0.00\n",
      "epoch 5, step 27000/55000, batch loss = 0.02\n",
      "epoch 5, step 27250/55000, batch loss = 0.01\n",
      "epoch 5, step 27500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.60\n",
      "epoch 5, step 27750/55000, batch loss = 0.01\n",
      "epoch 5, step 28000/55000, batch loss = 0.04\n",
      "epoch 5, step 28250/55000, batch loss = 0.00\n",
      "epoch 5, step 28500/55000, batch loss = 0.02\n",
      "epoch 5, step 28750/55000, batch loss = 0.01\n",
      "epoch 5, step 29000/55000, batch loss = 0.00\n",
      "epoch 5, step 29250/55000, batch loss = 0.00\n",
      "epoch 5, step 29500/55000, batch loss = 0.01\n",
      "epoch 5, step 29750/55000, batch loss = 0.00\n",
      "epoch 5, step 30000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.60\n",
      "epoch 5, step 30250/55000, batch loss = 0.00\n",
      "epoch 5, step 30500/55000, batch loss = 0.01\n",
      "epoch 5, step 30750/55000, batch loss = 0.01\n",
      "epoch 5, step 31000/55000, batch loss = 0.00\n",
      "epoch 5, step 31250/55000, batch loss = 0.04\n",
      "epoch 5, step 31500/55000, batch loss = 0.00\n",
      "epoch 5, step 31750/55000, batch loss = 0.03\n",
      "epoch 5, step 32000/55000, batch loss = 0.02\n",
      "epoch 5, step 32250/55000, batch loss = 0.12\n",
      "epoch 5, step 32500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.61\n",
      "epoch 5, step 32750/55000, batch loss = 0.01\n",
      "epoch 5, step 33000/55000, batch loss = 0.00\n",
      "epoch 5, step 33250/55000, batch loss = 0.01\n",
      "epoch 5, step 33500/55000, batch loss = 0.01\n",
      "epoch 5, step 33750/55000, batch loss = 0.01\n",
      "epoch 5, step 34000/55000, batch loss = 0.02\n",
      "epoch 5, step 34250/55000, batch loss = 0.00\n",
      "epoch 5, step 34500/55000, batch loss = 0.01\n",
      "epoch 5, step 34750/55000, batch loss = 0.00\n",
      "epoch 5, step 35000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.62\n",
      "epoch 5, step 35250/55000, batch loss = 0.01\n",
      "epoch 5, step 35500/55000, batch loss = 0.00\n",
      "epoch 5, step 35750/55000, batch loss = 0.00\n",
      "epoch 5, step 36000/55000, batch loss = 0.01\n",
      "epoch 5, step 36250/55000, batch loss = 0.00\n",
      "epoch 5, step 36500/55000, batch loss = 0.00\n",
      "epoch 5, step 36750/55000, batch loss = 0.00\n",
      "epoch 5, step 37000/55000, batch loss = 0.00\n",
      "epoch 5, step 37250/55000, batch loss = 0.02\n",
      "epoch 5, step 37500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.61\n",
      "epoch 5, step 37750/55000, batch loss = 0.00\n",
      "epoch 5, step 38000/55000, batch loss = 0.02\n",
      "epoch 5, step 38250/55000, batch loss = 0.00\n",
      "epoch 5, step 38500/55000, batch loss = 0.00\n",
      "epoch 5, step 38750/55000, batch loss = 0.00\n",
      "epoch 5, step 39000/55000, batch loss = 0.00\n",
      "epoch 5, step 39250/55000, batch loss = 0.05\n",
      "epoch 5, step 39500/55000, batch loss = 0.02\n",
      "epoch 5, step 39750/55000, batch loss = 0.02\n",
      "epoch 5, step 40000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, step 40250/55000, batch loss = 0.00\n",
      "epoch 5, step 40500/55000, batch loss = 0.02\n",
      "epoch 5, step 40750/55000, batch loss = 0.01\n",
      "epoch 5, step 41000/55000, batch loss = 0.01\n",
      "epoch 5, step 41250/55000, batch loss = 0.04\n",
      "epoch 5, step 41500/55000, batch loss = 0.01\n",
      "epoch 5, step 41750/55000, batch loss = 0.01\n",
      "epoch 5, step 42000/55000, batch loss = 0.00\n",
      "epoch 5, step 42250/55000, batch loss = 0.19\n",
      "epoch 5, step 42500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.61\n",
      "epoch 5, step 42750/55000, batch loss = 0.01\n",
      "epoch 5, step 43000/55000, batch loss = 0.01\n",
      "epoch 5, step 43250/55000, batch loss = 0.17\n",
      "epoch 5, step 43500/55000, batch loss = 0.11\n",
      "epoch 5, step 43750/55000, batch loss = 0.00\n",
      "epoch 5, step 44000/55000, batch loss = 0.05\n",
      "epoch 5, step 44250/55000, batch loss = 0.00\n",
      "epoch 5, step 44500/55000, batch loss = 0.02\n",
      "epoch 5, step 44750/55000, batch loss = 0.00\n",
      "epoch 5, step 45000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.60\n",
      "epoch 5, step 45250/55000, batch loss = 0.00\n",
      "epoch 5, step 45500/55000, batch loss = 0.03\n",
      "epoch 5, step 45750/55000, batch loss = 0.03\n",
      "epoch 5, step 46000/55000, batch loss = 0.00\n",
      "epoch 5, step 46250/55000, batch loss = 0.01\n",
      "epoch 5, step 46500/55000, batch loss = 0.11\n",
      "epoch 5, step 46750/55000, batch loss = 0.00\n",
      "epoch 5, step 47000/55000, batch loss = 0.00\n",
      "epoch 5, step 47250/55000, batch loss = 0.03\n",
      "epoch 5, step 47500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.60\n",
      "epoch 5, step 47750/55000, batch loss = 0.00\n",
      "epoch 5, step 48000/55000, batch loss = 0.01\n",
      "epoch 5, step 48250/55000, batch loss = 0.00\n",
      "epoch 5, step 48500/55000, batch loss = 0.00\n",
      "epoch 5, step 48750/55000, batch loss = 0.00\n",
      "epoch 5, step 49000/55000, batch loss = 0.00\n",
      "epoch 5, step 49250/55000, batch loss = 0.03\n",
      "epoch 5, step 49500/55000, batch loss = 0.07\n",
      "epoch 5, step 49750/55000, batch loss = 0.01\n",
      "epoch 5, step 50000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.60\n",
      "epoch 5, step 50250/55000, batch loss = 0.00\n",
      "epoch 5, step 50500/55000, batch loss = 0.03\n",
      "epoch 5, step 50750/55000, batch loss = 0.00\n",
      "epoch 5, step 51000/55000, batch loss = 0.01\n",
      "epoch 5, step 51250/55000, batch loss = 0.00\n",
      "epoch 5, step 51500/55000, batch loss = 0.10\n",
      "epoch 5, step 51750/55000, batch loss = 0.15\n",
      "epoch 5, step 52000/55000, batch loss = 0.02\n",
      "epoch 5, step 52250/55000, batch loss = 0.01\n",
      "epoch 5, step 52500/55000, batch loss = 0.03\n",
      "Train accuracy = 99.60\n",
      "epoch 5, step 52750/55000, batch loss = 0.00\n",
      "epoch 5, step 53000/55000, batch loss = 0.00\n",
      "epoch 5, step 53250/55000, batch loss = 0.04\n",
      "epoch 5, step 53500/55000, batch loss = 0.02\n",
      "epoch 5, step 53750/55000, batch loss = 0.07\n",
      "epoch 5, step 54000/55000, batch loss = 0.00\n",
      "epoch 5, step 54250/55000, batch loss = 0.00\n",
      "epoch 5, step 54500/55000, batch loss = 0.01\n",
      "epoch 5, step 54750/55000, batch loss = 0.07\n",
      "Train accuracy = 99.59\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.20\n",
      "Validation avg loss = 0.03\n",
      "\n",
      "epoch 6, step 0/55000, batch loss = 0.04\n",
      "epoch 6, step 250/55000, batch loss = 0.00\n",
      "epoch 6, step 500/55000, batch loss = 0.00\n",
      "epoch 6, step 750/55000, batch loss = 0.01\n",
      "epoch 6, step 1000/55000, batch loss = 0.00\n",
      "epoch 6, step 1250/55000, batch loss = 0.00\n",
      "epoch 6, step 1500/55000, batch loss = 0.00\n",
      "epoch 6, step 1750/55000, batch loss = 0.02\n",
      "epoch 6, step 2000/55000, batch loss = 0.01\n",
      "epoch 6, step 2250/55000, batch loss = 0.01\n",
      "epoch 6, step 2500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.37\n",
      "epoch 6, step 2750/55000, batch loss = 0.01\n",
      "epoch 6, step 3000/55000, batch loss = 0.00\n",
      "epoch 6, step 3250/55000, batch loss = 0.05\n",
      "epoch 6, step 3500/55000, batch loss = 0.00\n",
      "epoch 6, step 3750/55000, batch loss = 0.00\n",
      "epoch 6, step 4000/55000, batch loss = 0.04\n",
      "epoch 6, step 4250/55000, batch loss = 0.00\n",
      "epoch 6, step 4500/55000, batch loss = 0.00\n",
      "epoch 6, step 4750/55000, batch loss = 0.00\n",
      "epoch 6, step 5000/55000, batch loss = 0.03\n",
      "Train accuracy = 99.47\n",
      "epoch 6, step 5250/55000, batch loss = 0.00\n",
      "epoch 6, step 5500/55000, batch loss = 0.00\n",
      "epoch 6, step 5750/55000, batch loss = 0.00\n",
      "epoch 6, step 6000/55000, batch loss = 0.01\n",
      "epoch 6, step 6250/55000, batch loss = 0.00\n",
      "epoch 6, step 6500/55000, batch loss = 0.01\n",
      "epoch 6, step 6750/55000, batch loss = 0.05\n",
      "epoch 6, step 7000/55000, batch loss = 0.01\n",
      "epoch 6, step 7250/55000, batch loss = 0.01\n",
      "epoch 6, step 7500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.48\n",
      "epoch 6, step 7750/55000, batch loss = 0.00\n",
      "epoch 6, step 8000/55000, batch loss = 0.00\n",
      "epoch 6, step 8250/55000, batch loss = 0.01\n",
      "epoch 6, step 8500/55000, batch loss = 0.04\n",
      "epoch 6, step 8750/55000, batch loss = 0.01\n",
      "epoch 6, step 9000/55000, batch loss = 0.01\n",
      "epoch 6, step 9250/55000, batch loss = 0.00\n",
      "epoch 6, step 9500/55000, batch loss = 0.18\n",
      "epoch 6, step 9750/55000, batch loss = 0.00\n",
      "epoch 6, step 10000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.48\n",
      "epoch 6, step 10250/55000, batch loss = 0.00\n",
      "epoch 6, step 10500/55000, batch loss = 0.00\n",
      "epoch 6, step 10750/55000, batch loss = 0.00\n",
      "epoch 6, step 11000/55000, batch loss = 0.00\n",
      "epoch 6, step 11250/55000, batch loss = 0.01\n",
      "epoch 6, step 11500/55000, batch loss = 0.00\n",
      "epoch 6, step 11750/55000, batch loss = 0.00\n",
      "epoch 6, step 12000/55000, batch loss = 0.01\n",
      "epoch 6, step 12250/55000, batch loss = 0.08\n",
      "epoch 6, step 12500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.50\n",
      "epoch 6, step 12750/55000, batch loss = 0.04\n",
      "epoch 6, step 13000/55000, batch loss = 0.01\n",
      "epoch 6, step 13250/55000, batch loss = 0.02\n",
      "epoch 6, step 13500/55000, batch loss = 0.00\n",
      "epoch 6, step 13750/55000, batch loss = 0.01\n",
      "epoch 6, step 14000/55000, batch loss = 0.03\n",
      "epoch 6, step 14250/55000, batch loss = 0.03\n",
      "epoch 6, step 14500/55000, batch loss = 0.01\n",
      "epoch 6, step 14750/55000, batch loss = 0.01\n",
      "epoch 6, step 15000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.50\n",
      "epoch 6, step 15250/55000, batch loss = 0.01\n",
      "epoch 6, step 15500/55000, batch loss = 0.00\n",
      "epoch 6, step 15750/55000, batch loss = 0.02\n",
      "epoch 6, step 16000/55000, batch loss = 0.02\n",
      "epoch 6, step 16250/55000, batch loss = 0.01\n",
      "epoch 6, step 16500/55000, batch loss = 0.00\n",
      "epoch 6, step 16750/55000, batch loss = 0.05\n",
      "epoch 6, step 17000/55000, batch loss = 0.02\n",
      "epoch 6, step 17250/55000, batch loss = 0.01\n",
      "epoch 6, step 17500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.49\n",
      "epoch 6, step 17750/55000, batch loss = 0.01\n",
      "epoch 6, step 18000/55000, batch loss = 0.01\n",
      "epoch 6, step 18250/55000, batch loss = 0.00\n",
      "epoch 6, step 18500/55000, batch loss = 0.06\n",
      "epoch 6, step 18750/55000, batch loss = 0.00\n",
      "epoch 6, step 19000/55000, batch loss = 0.01\n",
      "epoch 6, step 19250/55000, batch loss = 0.01\n",
      "epoch 6, step 19500/55000, batch loss = 0.00\n",
      "epoch 6, step 19750/55000, batch loss = 0.01\n",
      "epoch 6, step 20000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.52\n",
      "epoch 6, step 20250/55000, batch loss = 0.01\n",
      "epoch 6, step 20500/55000, batch loss = 0.02\n",
      "epoch 6, step 20750/55000, batch loss = 0.01\n",
      "epoch 6, step 21000/55000, batch loss = 0.00\n",
      "epoch 6, step 21250/55000, batch loss = 0.07\n",
      "epoch 6, step 21500/55000, batch loss = 0.02\n",
      "epoch 6, step 21750/55000, batch loss = 0.00\n",
      "epoch 6, step 22000/55000, batch loss = 0.01\n",
      "epoch 6, step 22250/55000, batch loss = 0.01\n",
      "epoch 6, step 22500/55000, batch loss = 0.03\n",
      "Train accuracy = 99.51\n",
      "epoch 6, step 22750/55000, batch loss = 0.00\n",
      "epoch 6, step 23000/55000, batch loss = 0.00\n",
      "epoch 6, step 23250/55000, batch loss = 0.01\n",
      "epoch 6, step 23500/55000, batch loss = 0.00\n",
      "epoch 6, step 23750/55000, batch loss = 0.01\n",
      "epoch 6, step 24000/55000, batch loss = 0.07\n",
      "epoch 6, step 24250/55000, batch loss = 0.00\n",
      "epoch 6, step 24500/55000, batch loss = 0.01\n",
      "epoch 6, step 24750/55000, batch loss = 0.02\n",
      "epoch 6, step 25000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.52\n",
      "epoch 6, step 25250/55000, batch loss = 0.00\n",
      "epoch 6, step 25500/55000, batch loss = 0.01\n",
      "epoch 6, step 25750/55000, batch loss = 0.00\n",
      "epoch 6, step 26000/55000, batch loss = 0.04\n",
      "epoch 6, step 26250/55000, batch loss = 0.00\n",
      "epoch 6, step 26500/55000, batch loss = 0.00\n",
      "epoch 6, step 26750/55000, batch loss = 0.01\n",
      "epoch 6, step 27000/55000, batch loss = 0.00\n",
      "epoch 6, step 27250/55000, batch loss = 0.02\n",
      "epoch 6, step 27500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.52\n",
      "epoch 6, step 27750/55000, batch loss = 0.00\n",
      "epoch 6, step 28000/55000, batch loss = 0.01\n",
      "epoch 6, step 28250/55000, batch loss = 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, step 28500/55000, batch loss = 0.00\n",
      "epoch 6, step 28750/55000, batch loss = 0.03\n",
      "epoch 6, step 29000/55000, batch loss = 0.01\n",
      "epoch 6, step 29250/55000, batch loss = 0.00\n",
      "epoch 6, step 29500/55000, batch loss = 0.02\n",
      "epoch 6, step 29750/55000, batch loss = 0.00\n",
      "epoch 6, step 30000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.53\n",
      "epoch 6, step 30250/55000, batch loss = 0.01\n",
      "epoch 6, step 30500/55000, batch loss = 0.00\n",
      "epoch 6, step 30750/55000, batch loss = 0.02\n",
      "epoch 6, step 31000/55000, batch loss = 0.03\n",
      "epoch 6, step 31250/55000, batch loss = 0.01\n",
      "epoch 6, step 31500/55000, batch loss = 0.05\n",
      "epoch 6, step 31750/55000, batch loss = 0.00\n",
      "epoch 6, step 32000/55000, batch loss = 0.01\n",
      "epoch 6, step 32250/55000, batch loss = 0.00\n",
      "epoch 6, step 32500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.54\n",
      "epoch 6, step 32750/55000, batch loss = 0.01\n",
      "epoch 6, step 33000/55000, batch loss = 0.01\n",
      "epoch 6, step 33250/55000, batch loss = 0.00\n",
      "epoch 6, step 33500/55000, batch loss = 0.03\n",
      "epoch 6, step 33750/55000, batch loss = 0.00\n",
      "epoch 6, step 34000/55000, batch loss = 0.00\n",
      "epoch 6, step 34250/55000, batch loss = 0.01\n",
      "epoch 6, step 34500/55000, batch loss = 0.02\n",
      "epoch 6, step 34750/55000, batch loss = 0.00\n",
      "epoch 6, step 35000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.56\n",
      "epoch 6, step 35250/55000, batch loss = 0.01\n",
      "epoch 6, step 35500/55000, batch loss = 0.01\n",
      "epoch 6, step 35750/55000, batch loss = 0.01\n",
      "epoch 6, step 36000/55000, batch loss = 0.02\n",
      "epoch 6, step 36250/55000, batch loss = 0.03\n",
      "epoch 6, step 36500/55000, batch loss = 0.00\n",
      "epoch 6, step 36750/55000, batch loss = 0.01\n",
      "epoch 6, step 37000/55000, batch loss = 0.03\n",
      "epoch 6, step 37250/55000, batch loss = 0.00\n",
      "epoch 6, step 37500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.55\n",
      "epoch 6, step 37750/55000, batch loss = 0.02\n",
      "epoch 6, step 38000/55000, batch loss = 0.00\n",
      "epoch 6, step 38250/55000, batch loss = 0.00\n",
      "epoch 6, step 38500/55000, batch loss = 0.01\n",
      "epoch 6, step 38750/55000, batch loss = 0.00\n",
      "epoch 6, step 39000/55000, batch loss = 0.01\n",
      "epoch 6, step 39250/55000, batch loss = 0.07\n",
      "epoch 6, step 39500/55000, batch loss = 0.02\n",
      "epoch 6, step 39750/55000, batch loss = 0.01\n",
      "epoch 6, step 40000/55000, batch loss = 0.06\n",
      "Train accuracy = 99.56\n",
      "epoch 6, step 40250/55000, batch loss = 0.01\n",
      "epoch 6, step 40500/55000, batch loss = 0.03\n",
      "epoch 6, step 40750/55000, batch loss = 0.00\n",
      "epoch 6, step 41000/55000, batch loss = 0.01\n",
      "epoch 6, step 41250/55000, batch loss = 0.01\n",
      "epoch 6, step 41500/55000, batch loss = 0.00\n",
      "epoch 6, step 41750/55000, batch loss = 0.00\n",
      "epoch 6, step 42000/55000, batch loss = 0.01\n",
      "epoch 6, step 42250/55000, batch loss = 0.01\n",
      "epoch 6, step 42500/55000, batch loss = 0.03\n",
      "Train accuracy = 99.56\n",
      "epoch 6, step 42750/55000, batch loss = 0.02\n",
      "epoch 6, step 43000/55000, batch loss = 0.02\n",
      "epoch 6, step 43250/55000, batch loss = 0.01\n",
      "epoch 6, step 43500/55000, batch loss = 0.00\n",
      "epoch 6, step 43750/55000, batch loss = 0.00\n",
      "epoch 6, step 44000/55000, batch loss = 0.00\n",
      "epoch 6, step 44250/55000, batch loss = 0.00\n",
      "epoch 6, step 44500/55000, batch loss = 0.03\n",
      "epoch 6, step 44750/55000, batch loss = 0.06\n",
      "epoch 6, step 45000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.56\n",
      "epoch 6, step 45250/55000, batch loss = 0.01\n",
      "epoch 6, step 45500/55000, batch loss = 0.01\n",
      "epoch 6, step 45750/55000, batch loss = 0.01\n",
      "epoch 6, step 46000/55000, batch loss = 0.01\n",
      "epoch 6, step 46250/55000, batch loss = 0.00\n",
      "epoch 6, step 46500/55000, batch loss = 0.00\n",
      "epoch 6, step 46750/55000, batch loss = 0.00\n",
      "epoch 6, step 47000/55000, batch loss = 0.00\n",
      "epoch 6, step 47250/55000, batch loss = 0.00\n",
      "epoch 6, step 47500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.58\n",
      "epoch 6, step 47750/55000, batch loss = 0.01\n",
      "epoch 6, step 48000/55000, batch loss = 0.03\n",
      "epoch 6, step 48250/55000, batch loss = 0.00\n",
      "epoch 6, step 48500/55000, batch loss = 0.02\n",
      "epoch 6, step 48750/55000, batch loss = 0.01\n",
      "epoch 6, step 49000/55000, batch loss = 0.01\n",
      "epoch 6, step 49250/55000, batch loss = 0.01\n",
      "epoch 6, step 49500/55000, batch loss = 0.01\n",
      "epoch 6, step 49750/55000, batch loss = 0.00\n",
      "epoch 6, step 50000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.58\n",
      "epoch 6, step 50250/55000, batch loss = 0.01\n",
      "epoch 6, step 50500/55000, batch loss = 0.03\n",
      "epoch 6, step 50750/55000, batch loss = 0.01\n",
      "epoch 6, step 51000/55000, batch loss = 0.00\n",
      "epoch 6, step 51250/55000, batch loss = 0.01\n",
      "epoch 6, step 51500/55000, batch loss = 0.00\n",
      "epoch 6, step 51750/55000, batch loss = 0.00\n",
      "epoch 6, step 52000/55000, batch loss = 0.01\n",
      "epoch 6, step 52250/55000, batch loss = 0.00\n",
      "epoch 6, step 52500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.58\n",
      "epoch 6, step 52750/55000, batch loss = 0.00\n",
      "epoch 6, step 53000/55000, batch loss = 0.01\n",
      "epoch 6, step 53250/55000, batch loss = 0.01\n",
      "epoch 6, step 53500/55000, batch loss = 0.01\n",
      "epoch 6, step 53750/55000, batch loss = 0.00\n",
      "epoch 6, step 54000/55000, batch loss = 0.00\n",
      "epoch 6, step 54250/55000, batch loss = 0.02\n",
      "epoch 6, step 54500/55000, batch loss = 0.05\n",
      "epoch 6, step 54750/55000, batch loss = 0.03\n",
      "Train accuracy = 99.58\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.18\n",
      "Validation avg loss = 0.03\n",
      "\n",
      "epoch 7, step 0/55000, batch loss = 0.00\n",
      "epoch 7, step 250/55000, batch loss = 0.06\n",
      "epoch 7, step 500/55000, batch loss = 0.06\n",
      "epoch 7, step 750/55000, batch loss = 0.01\n",
      "epoch 7, step 1000/55000, batch loss = 0.01\n",
      "epoch 7, step 1250/55000, batch loss = 0.03\n",
      "epoch 7, step 1500/55000, batch loss = 0.00\n",
      "epoch 7, step 1750/55000, batch loss = 0.01\n",
      "epoch 7, step 2000/55000, batch loss = 0.01\n",
      "epoch 7, step 2250/55000, batch loss = 0.00\n",
      "epoch 7, step 2500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.53\n",
      "epoch 7, step 2750/55000, batch loss = 0.00\n",
      "epoch 7, step 3000/55000, batch loss = 0.00\n",
      "epoch 7, step 3250/55000, batch loss = 0.00\n",
      "epoch 7, step 3500/55000, batch loss = 0.00\n",
      "epoch 7, step 3750/55000, batch loss = 0.00\n",
      "epoch 7, step 4000/55000, batch loss = 0.01\n",
      "epoch 7, step 4250/55000, batch loss = 0.00\n",
      "epoch 7, step 4500/55000, batch loss = 0.01\n",
      "epoch 7, step 4750/55000, batch loss = 0.00\n",
      "epoch 7, step 5000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.54\n",
      "epoch 7, step 5250/55000, batch loss = 0.00\n",
      "epoch 7, step 5500/55000, batch loss = 0.03\n",
      "epoch 7, step 5750/55000, batch loss = 0.02\n",
      "epoch 7, step 6000/55000, batch loss = 0.01\n",
      "epoch 7, step 6250/55000, batch loss = 0.00\n",
      "epoch 7, step 6500/55000, batch loss = 0.00\n",
      "epoch 7, step 6750/55000, batch loss = 0.01\n",
      "epoch 7, step 7000/55000, batch loss = 0.03\n",
      "epoch 7, step 7250/55000, batch loss = 0.00\n",
      "epoch 7, step 7500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.58\n",
      "epoch 7, step 7750/55000, batch loss = 0.02\n",
      "epoch 7, step 8000/55000, batch loss = 0.00\n",
      "epoch 7, step 8250/55000, batch loss = 0.02\n",
      "epoch 7, step 8500/55000, batch loss = 0.00\n",
      "epoch 7, step 8750/55000, batch loss = 0.00\n",
      "epoch 7, step 9000/55000, batch loss = 0.02\n",
      "epoch 7, step 9250/55000, batch loss = 0.00\n",
      "epoch 7, step 9500/55000, batch loss = 0.05\n",
      "epoch 7, step 9750/55000, batch loss = 0.05\n",
      "epoch 7, step 10000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.55\n",
      "epoch 7, step 10250/55000, batch loss = 0.00\n",
      "epoch 7, step 10500/55000, batch loss = 0.02\n",
      "epoch 7, step 10750/55000, batch loss = 0.00\n",
      "epoch 7, step 11000/55000, batch loss = 0.02\n",
      "epoch 7, step 11250/55000, batch loss = 0.03\n",
      "epoch 7, step 11500/55000, batch loss = 0.00\n",
      "epoch 7, step 11750/55000, batch loss = 0.02\n",
      "epoch 7, step 12000/55000, batch loss = 0.03\n",
      "epoch 7, step 12250/55000, batch loss = 0.01\n",
      "epoch 7, step 12500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.59\n",
      "epoch 7, step 12750/55000, batch loss = 0.00\n",
      "epoch 7, step 13000/55000, batch loss = 0.00\n",
      "epoch 7, step 13250/55000, batch loss = 0.00\n",
      "epoch 7, step 13500/55000, batch loss = 0.09\n",
      "epoch 7, step 13750/55000, batch loss = 0.02\n",
      "epoch 7, step 14000/55000, batch loss = 0.01\n",
      "epoch 7, step 14250/55000, batch loss = 0.01\n",
      "epoch 7, step 14500/55000, batch loss = 0.03\n",
      "epoch 7, step 14750/55000, batch loss = 0.02\n",
      "epoch 7, step 15000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.59\n",
      "epoch 7, step 15250/55000, batch loss = 0.01\n",
      "epoch 7, step 15500/55000, batch loss = 0.00\n",
      "epoch 7, step 15750/55000, batch loss = 0.00\n",
      "epoch 7, step 16000/55000, batch loss = 0.00\n",
      "epoch 7, step 16250/55000, batch loss = 0.00\n",
      "epoch 7, step 16500/55000, batch loss = 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, step 16750/55000, batch loss = 0.00\n",
      "epoch 7, step 17000/55000, batch loss = 0.00\n",
      "epoch 7, step 17250/55000, batch loss = 0.00\n",
      "epoch 7, step 17500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.57\n",
      "epoch 7, step 17750/55000, batch loss = 0.01\n",
      "epoch 7, step 18000/55000, batch loss = 0.19\n",
      "epoch 7, step 18250/55000, batch loss = 0.00\n",
      "epoch 7, step 18500/55000, batch loss = 0.06\n",
      "epoch 7, step 18750/55000, batch loss = 0.00\n",
      "epoch 7, step 19000/55000, batch loss = 0.00\n",
      "epoch 7, step 19250/55000, batch loss = 0.01\n",
      "epoch 7, step 19500/55000, batch loss = 0.00\n",
      "epoch 7, step 19750/55000, batch loss = 0.00\n",
      "epoch 7, step 20000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.56\n",
      "epoch 7, step 20250/55000, batch loss = 0.00\n",
      "epoch 7, step 20500/55000, batch loss = 0.01\n",
      "epoch 7, step 20750/55000, batch loss = 0.00\n",
      "epoch 7, step 21000/55000, batch loss = 0.01\n",
      "epoch 7, step 21250/55000, batch loss = 0.01\n",
      "epoch 7, step 21500/55000, batch loss = 0.04\n",
      "epoch 7, step 21750/55000, batch loss = 0.00\n",
      "epoch 7, step 22000/55000, batch loss = 0.01\n",
      "epoch 7, step 22250/55000, batch loss = 0.00\n",
      "epoch 7, step 22500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.54\n",
      "epoch 7, step 22750/55000, batch loss = 0.01\n",
      "epoch 7, step 23000/55000, batch loss = 0.00\n",
      "epoch 7, step 23250/55000, batch loss = 0.00\n",
      "epoch 7, step 23500/55000, batch loss = 0.00\n",
      "epoch 7, step 23750/55000, batch loss = 0.01\n",
      "epoch 7, step 24000/55000, batch loss = 0.01\n",
      "epoch 7, step 24250/55000, batch loss = 0.00\n",
      "epoch 7, step 24500/55000, batch loss = 0.01\n",
      "epoch 7, step 24750/55000, batch loss = 0.01\n",
      "epoch 7, step 25000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.57\n",
      "epoch 7, step 25250/55000, batch loss = 0.00\n",
      "epoch 7, step 25500/55000, batch loss = 0.02\n",
      "epoch 7, step 25750/55000, batch loss = 0.00\n",
      "epoch 7, step 26000/55000, batch loss = 0.00\n",
      "epoch 7, step 26250/55000, batch loss = 0.01\n",
      "epoch 7, step 26500/55000, batch loss = 0.00\n",
      "epoch 7, step 26750/55000, batch loss = 0.00\n",
      "epoch 7, step 27000/55000, batch loss = 0.00\n",
      "epoch 7, step 27250/55000, batch loss = 0.02\n",
      "epoch 7, step 27500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.59\n",
      "epoch 7, step 27750/55000, batch loss = 0.04\n",
      "epoch 7, step 28000/55000, batch loss = 0.01\n",
      "epoch 7, step 28250/55000, batch loss = 0.01\n",
      "epoch 7, step 28500/55000, batch loss = 0.01\n",
      "epoch 7, step 28750/55000, batch loss = 0.00\n",
      "epoch 7, step 29000/55000, batch loss = 0.00\n",
      "epoch 7, step 29250/55000, batch loss = 0.00\n",
      "epoch 7, step 29500/55000, batch loss = 0.00\n",
      "epoch 7, step 29750/55000, batch loss = 0.01\n",
      "epoch 7, step 30000/55000, batch loss = 0.02\n",
      "Train accuracy = 99.60\n",
      "epoch 7, step 30250/55000, batch loss = 0.03\n",
      "epoch 7, step 30500/55000, batch loss = 0.00\n",
      "epoch 7, step 30750/55000, batch loss = 0.02\n",
      "epoch 7, step 31000/55000, batch loss = 0.04\n",
      "epoch 7, step 31250/55000, batch loss = 0.04\n",
      "epoch 7, step 31500/55000, batch loss = 0.00\n",
      "epoch 7, step 31750/55000, batch loss = 0.00\n",
      "epoch 7, step 32000/55000, batch loss = 0.02\n",
      "epoch 7, step 32250/55000, batch loss = 0.00\n",
      "epoch 7, step 32500/55000, batch loss = 0.02\n",
      "Train accuracy = 99.60\n",
      "epoch 7, step 32750/55000, batch loss = 0.00\n",
      "epoch 7, step 33000/55000, batch loss = 0.02\n",
      "epoch 7, step 33250/55000, batch loss = 0.01\n",
      "epoch 7, step 33500/55000, batch loss = 0.00\n",
      "epoch 7, step 33750/55000, batch loss = 0.00\n",
      "epoch 7, step 34000/55000, batch loss = 0.00\n",
      "epoch 7, step 34250/55000, batch loss = 0.02\n",
      "epoch 7, step 34500/55000, batch loss = 0.00\n",
      "epoch 7, step 34750/55000, batch loss = 0.02\n",
      "epoch 7, step 35000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.58\n",
      "epoch 7, step 35250/55000, batch loss = 0.01\n",
      "epoch 7, step 35500/55000, batch loss = 0.00\n",
      "epoch 7, step 35750/55000, batch loss = 0.01\n",
      "epoch 7, step 36000/55000, batch loss = 0.01\n",
      "epoch 7, step 36250/55000, batch loss = 0.06\n",
      "epoch 7, step 36500/55000, batch loss = 0.00\n",
      "epoch 7, step 36750/55000, batch loss = 0.00\n",
      "epoch 7, step 37000/55000, batch loss = 0.02\n",
      "epoch 7, step 37250/55000, batch loss = 0.00\n",
      "epoch 7, step 37500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.59\n",
      "epoch 7, step 37750/55000, batch loss = 0.00\n",
      "epoch 7, step 38000/55000, batch loss = 0.00\n",
      "epoch 7, step 38250/55000, batch loss = 0.01\n",
      "epoch 7, step 38500/55000, batch loss = 0.02\n",
      "epoch 7, step 38750/55000, batch loss = 0.01\n",
      "epoch 7, step 39000/55000, batch loss = 0.03\n",
      "epoch 7, step 39250/55000, batch loss = 0.01\n",
      "epoch 7, step 39500/55000, batch loss = 0.01\n",
      "epoch 7, step 39750/55000, batch loss = 0.09\n",
      "epoch 7, step 40000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.60\n",
      "epoch 7, step 40250/55000, batch loss = 0.03\n",
      "epoch 7, step 40500/55000, batch loss = 0.02\n",
      "epoch 7, step 40750/55000, batch loss = 0.00\n",
      "epoch 7, step 41000/55000, batch loss = 0.00\n",
      "epoch 7, step 41250/55000, batch loss = 0.03\n",
      "epoch 7, step 41500/55000, batch loss = 0.01\n",
      "epoch 7, step 41750/55000, batch loss = 0.03\n",
      "epoch 7, step 42000/55000, batch loss = 0.01\n",
      "epoch 7, step 42250/55000, batch loss = 0.00\n",
      "epoch 7, step 42500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.59\n",
      "epoch 7, step 42750/55000, batch loss = 0.00\n",
      "epoch 7, step 43000/55000, batch loss = 0.02\n",
      "epoch 7, step 43250/55000, batch loss = 0.02\n",
      "epoch 7, step 43500/55000, batch loss = 0.00\n",
      "epoch 7, step 43750/55000, batch loss = 0.01\n",
      "epoch 7, step 44000/55000, batch loss = 0.01\n",
      "epoch 7, step 44250/55000, batch loss = 0.01\n",
      "epoch 7, step 44500/55000, batch loss = 0.00\n",
      "epoch 7, step 44750/55000, batch loss = 0.01\n",
      "epoch 7, step 45000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.60\n",
      "epoch 7, step 45250/55000, batch loss = 0.01\n",
      "epoch 7, step 45500/55000, batch loss = 0.01\n",
      "epoch 7, step 45750/55000, batch loss = 0.02\n",
      "epoch 7, step 46000/55000, batch loss = 0.00\n",
      "epoch 7, step 46250/55000, batch loss = 0.03\n",
      "epoch 7, step 46500/55000, batch loss = 0.02\n",
      "epoch 7, step 46750/55000, batch loss = 0.00\n",
      "epoch 7, step 47000/55000, batch loss = 0.01\n",
      "epoch 7, step 47250/55000, batch loss = 0.03\n",
      "epoch 7, step 47500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.60\n",
      "epoch 7, step 47750/55000, batch loss = 0.00\n",
      "epoch 7, step 48000/55000, batch loss = 0.02\n",
      "epoch 7, step 48250/55000, batch loss = 0.02\n",
      "epoch 7, step 48500/55000, batch loss = 0.00\n",
      "epoch 7, step 48750/55000, batch loss = 0.08\n",
      "epoch 7, step 49000/55000, batch loss = 0.02\n",
      "epoch 7, step 49250/55000, batch loss = 0.01\n",
      "epoch 7, step 49500/55000, batch loss = 0.01\n",
      "epoch 7, step 49750/55000, batch loss = 0.01\n",
      "epoch 7, step 50000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.60\n",
      "epoch 7, step 50250/55000, batch loss = 0.01\n",
      "epoch 7, step 50500/55000, batch loss = 0.04\n",
      "epoch 7, step 50750/55000, batch loss = 0.02\n",
      "epoch 7, step 51000/55000, batch loss = 0.05\n",
      "epoch 7, step 51250/55000, batch loss = 0.00\n",
      "epoch 7, step 51500/55000, batch loss = 0.01\n",
      "epoch 7, step 51750/55000, batch loss = 0.00\n",
      "epoch 7, step 52000/55000, batch loss = 0.00\n",
      "epoch 7, step 52250/55000, batch loss = 0.00\n",
      "epoch 7, step 52500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.60\n",
      "epoch 7, step 52750/55000, batch loss = 0.00\n",
      "epoch 7, step 53000/55000, batch loss = 0.01\n",
      "epoch 7, step 53250/55000, batch loss = 0.01\n",
      "epoch 7, step 53500/55000, batch loss = 0.06\n",
      "epoch 7, step 53750/55000, batch loss = 0.00\n",
      "epoch 7, step 54000/55000, batch loss = 0.01\n",
      "epoch 7, step 54250/55000, batch loss = 0.01\n",
      "epoch 7, step 54500/55000, batch loss = 0.00\n",
      "epoch 7, step 54750/55000, batch loss = 0.00\n",
      "Train accuracy = 99.60\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.18\n",
      "Validation avg loss = 0.03\n",
      "\n",
      "epoch 8, step 0/55000, batch loss = 0.01\n",
      "epoch 8, step 250/55000, batch loss = 0.02\n",
      "epoch 8, step 500/55000, batch loss = 0.03\n",
      "epoch 8, step 750/55000, batch loss = 0.01\n",
      "epoch 8, step 1000/55000, batch loss = 0.01\n",
      "epoch 8, step 1250/55000, batch loss = 0.00\n",
      "epoch 8, step 1500/55000, batch loss = 0.00\n",
      "epoch 8, step 1750/55000, batch loss = 0.02\n",
      "epoch 8, step 2000/55000, batch loss = 0.01\n",
      "epoch 8, step 2250/55000, batch loss = 0.01\n",
      "epoch 8, step 2500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.57\n",
      "epoch 8, step 2750/55000, batch loss = 0.01\n",
      "epoch 8, step 3000/55000, batch loss = 0.01\n",
      "epoch 8, step 3250/55000, batch loss = 0.00\n",
      "epoch 8, step 3500/55000, batch loss = 0.00\n",
      "epoch 8, step 3750/55000, batch loss = 0.01\n",
      "epoch 8, step 4000/55000, batch loss = 0.01\n",
      "epoch 8, step 4250/55000, batch loss = 0.00\n",
      "epoch 8, step 4500/55000, batch loss = 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, step 4750/55000, batch loss = 0.16\n",
      "epoch 8, step 5000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.66\n",
      "epoch 8, step 5250/55000, batch loss = 0.00\n",
      "epoch 8, step 5500/55000, batch loss = 0.03\n",
      "epoch 8, step 5750/55000, batch loss = 0.00\n",
      "epoch 8, step 6000/55000, batch loss = 0.00\n",
      "epoch 8, step 6250/55000, batch loss = 0.01\n",
      "epoch 8, step 6500/55000, batch loss = 0.01\n",
      "epoch 8, step 6750/55000, batch loss = 0.00\n",
      "epoch 8, step 7000/55000, batch loss = 0.04\n",
      "epoch 8, step 7250/55000, batch loss = 0.00\n",
      "epoch 8, step 7500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.66\n",
      "epoch 8, step 7750/55000, batch loss = 0.02\n",
      "epoch 8, step 8000/55000, batch loss = 0.00\n",
      "epoch 8, step 8250/55000, batch loss = 0.01\n",
      "epoch 8, step 8500/55000, batch loss = 0.00\n",
      "epoch 8, step 8750/55000, batch loss = 0.01\n",
      "epoch 8, step 9000/55000, batch loss = 0.01\n",
      "epoch 8, step 9250/55000, batch loss = 0.00\n",
      "epoch 8, step 9500/55000, batch loss = 0.01\n",
      "epoch 8, step 9750/55000, batch loss = 0.01\n",
      "epoch 8, step 10000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.66\n",
      "epoch 8, step 10250/55000, batch loss = 0.00\n",
      "epoch 8, step 10500/55000, batch loss = 0.00\n",
      "epoch 8, step 10750/55000, batch loss = 0.00\n",
      "epoch 8, step 11000/55000, batch loss = 0.02\n",
      "epoch 8, step 11250/55000, batch loss = 0.08\n",
      "epoch 8, step 11500/55000, batch loss = 0.06\n",
      "epoch 8, step 11750/55000, batch loss = 0.00\n",
      "epoch 8, step 12000/55000, batch loss = 0.00\n",
      "epoch 8, step 12250/55000, batch loss = 0.00\n",
      "epoch 8, step 12500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.63\n",
      "epoch 8, step 12750/55000, batch loss = 0.01\n",
      "epoch 8, step 13000/55000, batch loss = 0.05\n",
      "epoch 8, step 13250/55000, batch loss = 0.06\n",
      "epoch 8, step 13500/55000, batch loss = 0.01\n",
      "epoch 8, step 13750/55000, batch loss = 0.00\n",
      "epoch 8, step 14000/55000, batch loss = 0.00\n",
      "epoch 8, step 14250/55000, batch loss = 0.00\n",
      "epoch 8, step 14500/55000, batch loss = 0.02\n",
      "epoch 8, step 14750/55000, batch loss = 0.02\n",
      "epoch 8, step 15000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.63\n",
      "epoch 8, step 15250/55000, batch loss = 0.00\n",
      "epoch 8, step 15500/55000, batch loss = 0.01\n",
      "epoch 8, step 15750/55000, batch loss = 0.00\n",
      "epoch 8, step 16000/55000, batch loss = 0.06\n",
      "epoch 8, step 16250/55000, batch loss = 0.03\n",
      "epoch 8, step 16500/55000, batch loss = 0.00\n",
      "epoch 8, step 16750/55000, batch loss = 0.02\n",
      "epoch 8, step 17000/55000, batch loss = 0.10\n",
      "epoch 8, step 17250/55000, batch loss = 0.00\n",
      "epoch 8, step 17500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.58\n",
      "epoch 8, step 17750/55000, batch loss = 0.00\n",
      "epoch 8, step 18000/55000, batch loss = 0.00\n",
      "epoch 8, step 18250/55000, batch loss = 0.01\n",
      "epoch 8, step 18500/55000, batch loss = 0.01\n",
      "epoch 8, step 18750/55000, batch loss = 0.01\n",
      "epoch 8, step 19000/55000, batch loss = 0.00\n",
      "epoch 8, step 19250/55000, batch loss = 0.01\n",
      "epoch 8, step 19500/55000, batch loss = 0.01\n",
      "epoch 8, step 19750/55000, batch loss = 0.00\n",
      "epoch 8, step 20000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.60\n",
      "epoch 8, step 20250/55000, batch loss = 0.00\n",
      "epoch 8, step 20500/55000, batch loss = 0.08\n",
      "epoch 8, step 20750/55000, batch loss = 0.01\n",
      "epoch 8, step 21000/55000, batch loss = 0.00\n",
      "epoch 8, step 21250/55000, batch loss = 0.01\n",
      "epoch 8, step 21500/55000, batch loss = 0.00\n",
      "epoch 8, step 21750/55000, batch loss = 0.04\n",
      "epoch 8, step 22000/55000, batch loss = 0.04\n",
      "epoch 8, step 22250/55000, batch loss = 0.00\n",
      "epoch 8, step 22500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.61\n",
      "epoch 8, step 22750/55000, batch loss = 0.00\n",
      "epoch 8, step 23000/55000, batch loss = 0.12\n",
      "epoch 8, step 23250/55000, batch loss = 0.00\n",
      "epoch 8, step 23500/55000, batch loss = 0.02\n",
      "epoch 8, step 23750/55000, batch loss = 0.03\n",
      "epoch 8, step 24000/55000, batch loss = 0.01\n",
      "epoch 8, step 24250/55000, batch loss = 0.00\n",
      "epoch 8, step 24500/55000, batch loss = 0.01\n",
      "epoch 8, step 24750/55000, batch loss = 0.01\n",
      "epoch 8, step 25000/55000, batch loss = 0.03\n",
      "Train accuracy = 99.60\n",
      "epoch 8, step 25250/55000, batch loss = 0.00\n",
      "epoch 8, step 25500/55000, batch loss = 0.00\n",
      "epoch 8, step 25750/55000, batch loss = 0.04\n",
      "epoch 8, step 26000/55000, batch loss = 0.00\n",
      "epoch 8, step 26250/55000, batch loss = 0.01\n",
      "epoch 8, step 26500/55000, batch loss = 0.01\n",
      "epoch 8, step 26750/55000, batch loss = 0.00\n",
      "epoch 8, step 27000/55000, batch loss = 0.01\n",
      "epoch 8, step 27250/55000, batch loss = 0.00\n",
      "epoch 8, step 27500/55000, batch loss = 0.02\n",
      "Train accuracy = 99.59\n",
      "epoch 8, step 27750/55000, batch loss = 0.00\n",
      "epoch 8, step 28000/55000, batch loss = 0.03\n",
      "epoch 8, step 28250/55000, batch loss = 0.00\n",
      "epoch 8, step 28500/55000, batch loss = 0.01\n",
      "epoch 8, step 28750/55000, batch loss = 0.01\n",
      "epoch 8, step 29000/55000, batch loss = 0.01\n",
      "epoch 8, step 29250/55000, batch loss = 0.02\n",
      "epoch 8, step 29500/55000, batch loss = 0.00\n",
      "epoch 8, step 29750/55000, batch loss = 0.01\n",
      "epoch 8, step 30000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.60\n",
      "epoch 8, step 30250/55000, batch loss = 0.01\n",
      "epoch 8, step 30500/55000, batch loss = 0.03\n",
      "epoch 8, step 30750/55000, batch loss = 0.00\n",
      "epoch 8, step 31000/55000, batch loss = 0.01\n",
      "epoch 8, step 31250/55000, batch loss = 0.00\n",
      "epoch 8, step 31500/55000, batch loss = 0.02\n",
      "epoch 8, step 31750/55000, batch loss = 0.00\n",
      "epoch 8, step 32000/55000, batch loss = 0.01\n",
      "epoch 8, step 32250/55000, batch loss = 0.00\n",
      "epoch 8, step 32500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.61\n",
      "epoch 8, step 32750/55000, batch loss = 0.01\n",
      "epoch 8, step 33000/55000, batch loss = 0.01\n",
      "epoch 8, step 33250/55000, batch loss = 0.00\n",
      "epoch 8, step 33500/55000, batch loss = 0.01\n",
      "epoch 8, step 33750/55000, batch loss = 0.02\n",
      "epoch 8, step 34000/55000, batch loss = 0.02\n",
      "epoch 8, step 34250/55000, batch loss = 0.00\n",
      "epoch 8, step 34500/55000, batch loss = 0.00\n",
      "epoch 8, step 34750/55000, batch loss = 0.02\n",
      "epoch 8, step 35000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.61\n",
      "epoch 8, step 35250/55000, batch loss = 0.00\n",
      "epoch 8, step 35500/55000, batch loss = 0.01\n",
      "epoch 8, step 35750/55000, batch loss = 0.01\n",
      "epoch 8, step 36000/55000, batch loss = 0.00\n",
      "epoch 8, step 36250/55000, batch loss = 0.00\n",
      "epoch 8, step 36500/55000, batch loss = 0.00\n",
      "epoch 8, step 36750/55000, batch loss = 0.01\n",
      "epoch 8, step 37000/55000, batch loss = 0.01\n",
      "epoch 8, step 37250/55000, batch loss = 0.02\n",
      "epoch 8, step 37500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.61\n",
      "epoch 8, step 37750/55000, batch loss = 0.01\n",
      "epoch 8, step 38000/55000, batch loss = 0.04\n",
      "epoch 8, step 38250/55000, batch loss = 0.05\n",
      "epoch 8, step 38500/55000, batch loss = 0.03\n",
      "epoch 8, step 38750/55000, batch loss = 0.00\n",
      "epoch 8, step 39000/55000, batch loss = 0.01\n",
      "epoch 8, step 39250/55000, batch loss = 0.01\n",
      "epoch 8, step 39500/55000, batch loss = 0.00\n",
      "epoch 8, step 39750/55000, batch loss = 0.15\n",
      "epoch 8, step 40000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.59\n",
      "epoch 8, step 40250/55000, batch loss = 0.01\n",
      "epoch 8, step 40500/55000, batch loss = 0.01\n",
      "epoch 8, step 40750/55000, batch loss = 0.02\n",
      "epoch 8, step 41000/55000, batch loss = 0.01\n",
      "epoch 8, step 41250/55000, batch loss = 0.00\n",
      "epoch 8, step 41500/55000, batch loss = 0.01\n",
      "epoch 8, step 41750/55000, batch loss = 0.01\n",
      "epoch 8, step 42000/55000, batch loss = 0.02\n",
      "epoch 8, step 42250/55000, batch loss = 0.02\n",
      "epoch 8, step 42500/55000, batch loss = 0.01\n",
      "Train accuracy = 99.59\n",
      "epoch 8, step 42750/55000, batch loss = 0.02\n",
      "epoch 8, step 43000/55000, batch loss = 0.00\n",
      "epoch 8, step 43250/55000, batch loss = 0.03\n",
      "epoch 8, step 43500/55000, batch loss = 0.09\n",
      "epoch 8, step 43750/55000, batch loss = 0.00\n",
      "epoch 8, step 44000/55000, batch loss = 0.00\n",
      "epoch 8, step 44250/55000, batch loss = 0.02\n",
      "epoch 8, step 44500/55000, batch loss = 0.01\n",
      "epoch 8, step 44750/55000, batch loss = 0.02\n",
      "epoch 8, step 45000/55000, batch loss = 0.01\n",
      "Train accuracy = 99.59\n",
      "epoch 8, step 45250/55000, batch loss = 0.00\n",
      "epoch 8, step 45500/55000, batch loss = 0.00\n",
      "epoch 8, step 45750/55000, batch loss = 0.01\n",
      "epoch 8, step 46000/55000, batch loss = 0.00\n",
      "epoch 8, step 46250/55000, batch loss = 0.00\n",
      "epoch 8, step 46500/55000, batch loss = 0.00\n",
      "epoch 8, step 46750/55000, batch loss = 0.00\n",
      "epoch 8, step 47000/55000, batch loss = 0.03\n",
      "epoch 8, step 47250/55000, batch loss = 0.01\n",
      "epoch 8, step 47500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.59\n",
      "epoch 8, step 47750/55000, batch loss = 0.01\n",
      "epoch 8, step 48000/55000, batch loss = 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, step 48250/55000, batch loss = 0.00\n",
      "epoch 8, step 48500/55000, batch loss = 0.00\n",
      "epoch 8, step 48750/55000, batch loss = 0.01\n",
      "epoch 8, step 49000/55000, batch loss = 0.00\n",
      "epoch 8, step 49250/55000, batch loss = 0.04\n",
      "epoch 8, step 49500/55000, batch loss = 0.03\n",
      "epoch 8, step 49750/55000, batch loss = 0.00\n",
      "epoch 8, step 50000/55000, batch loss = 0.00\n",
      "Train accuracy = 99.59\n",
      "epoch 8, step 50250/55000, batch loss = 0.02\n",
      "epoch 8, step 50500/55000, batch loss = 0.01\n",
      "epoch 8, step 50750/55000, batch loss = 0.04\n",
      "epoch 8, step 51000/55000, batch loss = 0.01\n",
      "epoch 8, step 51250/55000, batch loss = 0.01\n",
      "epoch 8, step 51500/55000, batch loss = 0.00\n",
      "epoch 8, step 51750/55000, batch loss = 0.00\n",
      "epoch 8, step 52000/55000, batch loss = 0.01\n",
      "epoch 8, step 52250/55000, batch loss = 0.00\n",
      "epoch 8, step 52500/55000, batch loss = 0.00\n",
      "Train accuracy = 99.60\n",
      "epoch 8, step 52750/55000, batch loss = 0.00\n",
      "epoch 8, step 53000/55000, batch loss = 0.04\n",
      "epoch 8, step 53250/55000, batch loss = 0.00\n",
      "epoch 8, step 53500/55000, batch loss = 0.01\n",
      "epoch 8, step 53750/55000, batch loss = 0.01\n",
      "epoch 8, step 54000/55000, batch loss = 0.01\n",
      "epoch 8, step 54250/55000, batch loss = 0.02\n",
      "epoch 8, step 54500/55000, batch loss = 0.00\n",
      "epoch 8, step 54750/55000, batch loss = 0.01\n",
      "Train accuracy = 99.60\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.18\n",
      "Validation avg loss = 0.03\n",
      "\n",
      "\n",
      "Running evaluation:  Test\n",
      "Test accuracy = 99.12\n",
      "Test avg loss = 0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = \"/Users/goran/Documents/III_Semestar/DU/labosi/2_lab/zad1_images/\"\n",
    "\n",
    "config = {}\n",
    "config['max_epochs'] = 8\n",
    "config['batch_size'] = 50\n",
    "config['save_dir'] = SAVE_DIR\n",
    "config['lr_policy'] = {1:{'lr':1e-1}, 3:{'lr':1e-2}, 5:{'lr':1e-3}, 7:{'lr':1e-4}}\n",
    "\n",
    "#np.random.seed(100) \n",
    "np.random.seed(int(time.time() * 1e6) % 2**31)\n",
    "train_x = mnist.train.images\n",
    "train_x = train_x.reshape([-1, 1, 28, 28])\n",
    "train_y = mnist.train.labels\n",
    "valid_x = mnist.validation.images\n",
    "valid_x = valid_x.reshape([-1, 1, 28, 28])\n",
    "valid_y = mnist.validation.labels\n",
    "test_x = mnist.test.images\n",
    "test_x = test_x.reshape([-1, 1, 28, 28])\n",
    "test_y = mnist.test.labels\n",
    "train_mean = train_x.mean()\n",
    "train_x -= train_mean\n",
    "valid_x -= train_mean\n",
    "test_x -= train_mean\n",
    "\n",
    "\n",
    "net = []\n",
    "inputs = np.random.randn(config['batch_size'], 1, 28, 28)\n",
    "net += [Convolution(inputs, 16, 5, \"conv1\")]\n",
    "net += [MaxPooling(net[-1], \"pool1\")]\n",
    "net += [ReLU(net[-1], \"relu1\")]\n",
    "net += [Convolution(net[-1], 32, 5, \"conv2\")]\n",
    "net += [MaxPooling(net[-1], \"pool2\")]\n",
    "net += [ReLU(net[-1], \"relu2\")]\n",
    "# out = 7x7\n",
    "net += [Flatten(net[-1], \"flatten3\")]\n",
    "net += [FC(net[-1], 512, \"fc3\")]\n",
    "net += [ReLU(net[-1], \"relu3\")]\n",
    "net += [FC(net[-1], 10, \"logits\")]\n",
    "\n",
    "loss = SoftmaxCrossEntropyWithLogits()\n",
    "\n",
    "train(train_x, train_y, valid_x, valid_y, net, loss, config)\n",
    "evaluate(\"Test\", test_x, test_y, net, loss, config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ZADATAK\n",
    "U ovom zadatku trebate dodati podr≈°ku za L2 regularizaciju parametara. Dovr≈°ite implementaciju L2Regularizer sloja te nauƒçite regularizirani model iz prethodnog zadatka koji se nalazi u train_l2reg.py. Igrajte se s regularizacijskim parametrom tako da nauƒçite tri razliƒçite mre≈æe Œª=1e‚àí3, Œª=1e‚àí2, Œª=1e‚àí1 te usporedite nauƒçene filtre u prvom sloju i dobivenu toƒçnost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN training with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAMBDA: 0.1 \n",
      "\n",
      "epoch 1, step 0/55000, batch loss = 45.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Anaconda/anaconda/lib/python3.5/site-packages/skimage/util/dtype.py:110: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 250/55000, batch loss = 41.27\n",
      "epoch 1, step 500/55000, batch loss = 37.05\n",
      "epoch 1, step 750/55000, batch loss = 33.79\n",
      "epoch 1, step 1000/55000, batch loss = 30.48\n",
      "epoch 1, step 1250/55000, batch loss = 27.33\n",
      "epoch 1, step 1500/55000, batch loss = 24.70\n",
      "epoch 1, step 1750/55000, batch loss = 22.64\n",
      "epoch 1, step 2000/55000, batch loss = 20.31\n",
      "epoch 1, step 2250/55000, batch loss = 18.35\n",
      "epoch 1, step 2500/55000, batch loss = 16.86\n",
      "Train accuracy = 64.35\n",
      "epoch 1, step 2750/55000, batch loss = 15.18\n",
      "epoch 1, step 3000/55000, batch loss = 14.84\n",
      "epoch 1, step 3250/55000, batch loss = 12.87\n",
      "epoch 1, step 3500/55000, batch loss = 11.50\n",
      "epoch 1, step 3750/55000, batch loss = 10.57\n",
      "epoch 1, step 4000/55000, batch loss = 9.74\n",
      "epoch 1, step 4250/55000, batch loss = 8.68\n",
      "epoch 1, step 4500/55000, batch loss = 7.82\n",
      "epoch 1, step 4750/55000, batch loss = 7.34\n",
      "epoch 1, step 5000/55000, batch loss = 6.61\n",
      "Train accuracy = 73.60\n",
      "epoch 1, step 5250/55000, batch loss = 6.15\n",
      "epoch 1, step 5500/55000, batch loss = 6.08\n",
      "epoch 1, step 5750/55000, batch loss = 5.14\n",
      "epoch 1, step 6000/55000, batch loss = 4.76\n",
      "epoch 1, step 6250/55000, batch loss = 4.28\n",
      "epoch 1, step 6500/55000, batch loss = 4.23\n",
      "epoch 1, step 6750/55000, batch loss = 3.82\n",
      "epoch 1, step 7000/55000, batch loss = 3.45\n",
      "epoch 1, step 7250/55000, batch loss = 3.15\n",
      "epoch 1, step 7500/55000, batch loss = 2.90\n",
      "Train accuracy = 77.87\n",
      "epoch 1, step 7750/55000, batch loss = 3.04\n",
      "epoch 1, step 8000/55000, batch loss = 2.70\n",
      "epoch 1, step 8250/55000, batch loss = 2.35\n",
      "epoch 1, step 8500/55000, batch loss = 2.28\n",
      "epoch 1, step 8750/55000, batch loss = 2.33\n",
      "epoch 1, step 9000/55000, batch loss = 2.02\n",
      "epoch 1, step 9250/55000, batch loss = 1.84\n",
      "epoch 1, step 9500/55000, batch loss = 2.41\n",
      "epoch 1, step 9750/55000, batch loss = 1.61\n",
      "epoch 1, step 10000/55000, batch loss = 1.59\n",
      "Train accuracy = 80.55\n",
      "epoch 1, step 10250/55000, batch loss = 1.46\n",
      "epoch 1, step 10500/55000, batch loss = 1.58\n",
      "epoch 1, step 10750/55000, batch loss = 1.33\n",
      "epoch 1, step 11000/55000, batch loss = 1.37\n",
      "epoch 1, step 11250/55000, batch loss = 1.22\n",
      "epoch 1, step 11500/55000, batch loss = 1.37\n",
      "epoch 1, step 11750/55000, batch loss = 1.25\n",
      "epoch 1, step 12000/55000, batch loss = 1.17\n",
      "epoch 1, step 12250/55000, batch loss = 0.92\n",
      "epoch 1, step 12500/55000, batch loss = 1.39\n",
      "Train accuracy = 82.25\n",
      "epoch 1, step 12750/55000, batch loss = 0.86\n",
      "epoch 1, step 13000/55000, batch loss = 1.05\n",
      "epoch 1, step 13250/55000, batch loss = 0.95\n",
      "epoch 1, step 13500/55000, batch loss = 1.00\n",
      "epoch 1, step 13750/55000, batch loss = 1.17\n",
      "epoch 1, step 14000/55000, batch loss = 0.83\n",
      "epoch 1, step 14250/55000, batch loss = 1.00\n",
      "epoch 1, step 14500/55000, batch loss = 0.79\n",
      "epoch 1, step 14750/55000, batch loss = 0.80\n",
      "epoch 1, step 15000/55000, batch loss = 0.97\n",
      "Train accuracy = 83.43\n",
      "epoch 1, step 15250/55000, batch loss = 0.73\n",
      "epoch 1, step 15500/55000, batch loss = 0.94\n",
      "epoch 1, step 15750/55000, batch loss = 0.72\n",
      "epoch 1, step 16000/55000, batch loss = 0.73\n",
      "epoch 1, step 16250/55000, batch loss = 0.88\n",
      "epoch 1, step 16500/55000, batch loss = 0.75\n",
      "epoch 1, step 16750/55000, batch loss = 0.70\n",
      "epoch 1, step 17000/55000, batch loss = 0.66\n",
      "epoch 1, step 17250/55000, batch loss = 0.68\n",
      "epoch 1, step 17500/55000, batch loss = 0.85\n",
      "Train accuracy = 84.56\n",
      "epoch 1, step 17750/55000, batch loss = 0.76\n",
      "epoch 1, step 18000/55000, batch loss = 0.81\n",
      "epoch 1, step 18250/55000, batch loss = 0.90\n",
      "epoch 1, step 18500/55000, batch loss = 0.59\n",
      "epoch 1, step 18750/55000, batch loss = 0.75\n",
      "epoch 1, step 19000/55000, batch loss = 0.76\n",
      "epoch 1, step 19250/55000, batch loss = 0.65\n",
      "epoch 1, step 19500/55000, batch loss = 0.69\n",
      "epoch 1, step 19750/55000, batch loss = 0.79\n",
      "epoch 1, step 20000/55000, batch loss = 0.97\n",
      "Train accuracy = 85.17\n",
      "epoch 1, step 20250/55000, batch loss = 0.81\n",
      "epoch 1, step 20500/55000, batch loss = 0.63\n",
      "epoch 1, step 20750/55000, batch loss = 0.59\n",
      "epoch 1, step 21000/55000, batch loss = 0.64\n",
      "epoch 1, step 21250/55000, batch loss = 0.88\n",
      "epoch 1, step 21500/55000, batch loss = 0.63\n",
      "epoch 1, step 21750/55000, batch loss = 0.59\n",
      "epoch 1, step 22000/55000, batch loss = 0.87\n",
      "epoch 1, step 22250/55000, batch loss = 0.72\n",
      "epoch 1, step 22500/55000, batch loss = 0.72\n",
      "Train accuracy = 85.82\n",
      "epoch 1, step 22750/55000, batch loss = 0.72\n",
      "epoch 1, step 23000/55000, batch loss = 0.80\n",
      "epoch 1, step 23250/55000, batch loss = 1.52\n",
      "epoch 1, step 23500/55000, batch loss = 0.89\n",
      "epoch 1, step 23750/55000, batch loss = 0.95\n",
      "epoch 1, step 24000/55000, batch loss = 0.71\n",
      "epoch 1, step 24250/55000, batch loss = 0.88\n",
      "epoch 1, step 24500/55000, batch loss = 0.64\n",
      "epoch 1, step 24750/55000, batch loss = 0.81\n",
      "epoch 1, step 25000/55000, batch loss = 0.71\n",
      "Train accuracy = 85.98\n",
      "epoch 1, step 25250/55000, batch loss = 0.68\n",
      "epoch 1, step 25500/55000, batch loss = 0.68\n",
      "epoch 1, step 25750/55000, batch loss = 0.71\n",
      "epoch 1, step 26000/55000, batch loss = 0.73\n",
      "epoch 1, step 26250/55000, batch loss = 0.54\n",
      "epoch 1, step 26500/55000, batch loss = 1.32\n",
      "epoch 1, step 26750/55000, batch loss = 0.78\n",
      "epoch 1, step 27000/55000, batch loss = 0.71\n",
      "epoch 1, step 27250/55000, batch loss = 0.75\n",
      "epoch 1, step 27500/55000, batch loss = 0.71\n",
      "Train accuracy = 86.43\n",
      "epoch 1, step 27750/55000, batch loss = 0.79\n",
      "epoch 1, step 28000/55000, batch loss = 0.63\n",
      "epoch 1, step 28250/55000, batch loss = 0.78\n",
      "epoch 1, step 28500/55000, batch loss = 0.76\n",
      "epoch 1, step 28750/55000, batch loss = 0.82\n",
      "epoch 1, step 29000/55000, batch loss = 0.88\n",
      "epoch 1, step 29250/55000, batch loss = 0.57\n",
      "epoch 1, step 29500/55000, batch loss = 0.70\n",
      "epoch 1, step 29750/55000, batch loss = 0.66\n",
      "epoch 1, step 30000/55000, batch loss = 0.86\n",
      "Train accuracy = 86.75\n",
      "epoch 1, step 30250/55000, batch loss = 0.67\n",
      "epoch 1, step 30500/55000, batch loss = 0.64\n",
      "epoch 1, step 30750/55000, batch loss = 0.64\n",
      "epoch 1, step 31000/55000, batch loss = 0.74\n",
      "epoch 1, step 31250/55000, batch loss = 0.61\n",
      "epoch 1, step 31500/55000, batch loss = 0.81\n",
      "epoch 1, step 31750/55000, batch loss = 0.55\n",
      "epoch 1, step 32000/55000, batch loss = 0.68\n",
      "epoch 1, step 32250/55000, batch loss = 0.63\n",
      "epoch 1, step 32500/55000, batch loss = 0.56\n",
      "Train accuracy = 87.15\n",
      "epoch 1, step 32750/55000, batch loss = 0.67\n",
      "epoch 1, step 33000/55000, batch loss = 0.66\n",
      "epoch 1, step 33250/55000, batch loss = 1.17\n",
      "epoch 1, step 33500/55000, batch loss = 0.60\n",
      "epoch 1, step 33750/55000, batch loss = 0.53\n",
      "epoch 1, step 34000/55000, batch loss = 0.63\n",
      "epoch 1, step 34250/55000, batch loss = 0.74\n",
      "epoch 1, step 34500/55000, batch loss = 0.65\n",
      "epoch 1, step 34750/55000, batch loss = 0.59\n",
      "epoch 1, step 35000/55000, batch loss = 0.94\n",
      "Train accuracy = 87.45\n",
      "epoch 1, step 35250/55000, batch loss = 0.61\n",
      "epoch 1, step 35500/55000, batch loss = 1.08\n",
      "epoch 1, step 35750/55000, batch loss = 0.65\n",
      "epoch 1, step 36000/55000, batch loss = 0.76\n",
      "epoch 1, step 36250/55000, batch loss = 0.67\n",
      "epoch 1, step 36500/55000, batch loss = 1.13\n",
      "epoch 1, step 36750/55000, batch loss = 0.86\n",
      "epoch 1, step 37000/55000, batch loss = 0.67\n",
      "epoch 1, step 37250/55000, batch loss = 0.63\n",
      "epoch 1, step 37500/55000, batch loss = 0.80\n",
      "Train accuracy = 87.54\n",
      "epoch 1, step 37750/55000, batch loss = 0.47\n",
      "epoch 1, step 38000/55000, batch loss = 0.52\n",
      "epoch 1, step 38250/55000, batch loss = 0.70\n",
      "epoch 1, step 38500/55000, batch loss = 0.68\n",
      "epoch 1, step 38750/55000, batch loss = 0.58\n",
      "epoch 1, step 39000/55000, batch loss = 0.61\n",
      "epoch 1, step 39250/55000, batch loss = 0.62\n",
      "epoch 1, step 39500/55000, batch loss = 0.67\n",
      "epoch 1, step 39750/55000, batch loss = 0.56\n",
      "epoch 1, step 40000/55000, batch loss = 0.89\n",
      "Train accuracy = 87.84\n",
      "epoch 1, step 40250/55000, batch loss = 0.60\n",
      "epoch 1, step 40500/55000, batch loss = 0.63\n",
      "epoch 1, step 40750/55000, batch loss = 0.51\n",
      "epoch 1, step 41000/55000, batch loss = 0.67\n",
      "epoch 1, step 41250/55000, batch loss = 0.54\n",
      "epoch 1, step 41500/55000, batch loss = 0.71\n",
      "epoch 1, step 41750/55000, batch loss = 0.53\n",
      "epoch 1, step 42000/55000, batch loss = 0.91\n",
      "epoch 1, step 42250/55000, batch loss = 0.66\n",
      "epoch 1, step 42500/55000, batch loss = 0.75\n",
      "Train accuracy = 88.11\n",
      "epoch 1, step 42750/55000, batch loss = 0.64\n",
      "epoch 1, step 43000/55000, batch loss = 0.67\n",
      "epoch 1, step 43250/55000, batch loss = 0.71\n",
      "epoch 1, step 43500/55000, batch loss = 0.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 43750/55000, batch loss = 0.61\n",
      "epoch 1, step 44000/55000, batch loss = 0.59\n",
      "epoch 1, step 44250/55000, batch loss = 0.52\n",
      "epoch 1, step 44500/55000, batch loss = 0.63\n",
      "epoch 1, step 44750/55000, batch loss = 0.65\n",
      "epoch 1, step 45000/55000, batch loss = 1.03\n",
      "Train accuracy = 88.29\n",
      "epoch 1, step 45250/55000, batch loss = 0.72\n",
      "epoch 1, step 45500/55000, batch loss = 0.68\n",
      "epoch 1, step 45750/55000, batch loss = 0.63\n",
      "epoch 1, step 46000/55000, batch loss = 0.74\n",
      "epoch 1, step 46250/55000, batch loss = 0.58\n",
      "epoch 1, step 46500/55000, batch loss = 1.14\n",
      "epoch 1, step 46750/55000, batch loss = 0.95\n",
      "epoch 1, step 47000/55000, batch loss = 0.80\n",
      "epoch 1, step 47250/55000, batch loss = 0.61\n",
      "epoch 1, step 47500/55000, batch loss = 0.70\n",
      "Train accuracy = 88.30\n",
      "epoch 1, step 47750/55000, batch loss = 0.59\n",
      "epoch 1, step 48000/55000, batch loss = 1.02\n",
      "epoch 1, step 48250/55000, batch loss = 0.60\n",
      "epoch 1, step 48500/55000, batch loss = 0.61\n",
      "epoch 1, step 48750/55000, batch loss = 0.54\n",
      "epoch 1, step 49000/55000, batch loss = 0.61\n",
      "epoch 1, step 49250/55000, batch loss = 0.59\n",
      "epoch 1, step 49500/55000, batch loss = 0.62\n",
      "epoch 1, step 49750/55000, batch loss = 0.58\n",
      "epoch 1, step 50000/55000, batch loss = 0.83\n",
      "Train accuracy = 88.45\n",
      "epoch 1, step 50250/55000, batch loss = 0.65\n",
      "epoch 1, step 50500/55000, batch loss = 0.74\n",
      "epoch 1, step 50750/55000, batch loss = 0.66\n",
      "epoch 1, step 51000/55000, batch loss = 0.78\n",
      "epoch 1, step 51250/55000, batch loss = 0.62\n",
      "epoch 1, step 51500/55000, batch loss = 0.61\n",
      "epoch 1, step 51750/55000, batch loss = 0.75\n",
      "epoch 1, step 52000/55000, batch loss = 0.66\n",
      "epoch 1, step 52250/55000, batch loss = 0.61\n",
      "epoch 1, step 52500/55000, batch loss = 0.67\n",
      "Train accuracy = 88.58\n",
      "epoch 1, step 52750/55000, batch loss = 0.59\n",
      "epoch 1, step 53000/55000, batch loss = 0.51\n",
      "epoch 1, step 53250/55000, batch loss = 0.53\n",
      "epoch 1, step 53500/55000, batch loss = 0.63\n",
      "epoch 1, step 53750/55000, batch loss = 0.57\n",
      "epoch 1, step 54000/55000, batch loss = 0.60\n",
      "epoch 1, step 54250/55000, batch loss = 2.72\n",
      "epoch 1, step 54500/55000, batch loss = 1.18\n",
      "epoch 1, step 54750/55000, batch loss = 1.07\n",
      "Train accuracy = 88.47\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 88.98\n",
      "Validation avg loss = 0.85\n",
      "\n",
      "epoch 2, step 0/55000, batch loss = 0.78\n",
      "epoch 2, step 250/55000, batch loss = 0.74\n",
      "epoch 2, step 500/55000, batch loss = 0.67\n",
      "epoch 2, step 750/55000, batch loss = 0.70\n",
      "epoch 2, step 1000/55000, batch loss = 0.97\n",
      "epoch 2, step 1250/55000, batch loss = 0.75\n",
      "epoch 2, step 1500/55000, batch loss = 0.59\n",
      "epoch 2, step 1750/55000, batch loss = 0.84\n",
      "epoch 2, step 2000/55000, batch loss = 0.80\n",
      "epoch 2, step 2250/55000, batch loss = 0.51\n",
      "epoch 2, step 2500/55000, batch loss = 0.68\n",
      "Train accuracy = 91.18\n",
      "epoch 2, step 2750/55000, batch loss = 0.68\n",
      "epoch 2, step 3000/55000, batch loss = 0.64\n",
      "epoch 2, step 3250/55000, batch loss = 0.67\n",
      "epoch 2, step 3500/55000, batch loss = 0.58\n",
      "epoch 2, step 3750/55000, batch loss = 0.62\n",
      "epoch 2, step 4000/55000, batch loss = 0.88\n",
      "epoch 2, step 4250/55000, batch loss = 0.52\n",
      "epoch 2, step 4500/55000, batch loss = 0.55\n",
      "epoch 2, step 4750/55000, batch loss = 0.78\n",
      "epoch 2, step 5000/55000, batch loss = 0.58\n",
      "Train accuracy = 91.03\n",
      "epoch 2, step 5250/55000, batch loss = 0.44\n",
      "epoch 2, step 5500/55000, batch loss = 0.62\n",
      "epoch 2, step 5750/55000, batch loss = 0.82\n",
      "epoch 2, step 6000/55000, batch loss = 0.78\n",
      "epoch 2, step 6250/55000, batch loss = 0.62\n",
      "epoch 2, step 6500/55000, batch loss = 0.67\n",
      "epoch 2, step 6750/55000, batch loss = 0.52\n",
      "epoch 2, step 7000/55000, batch loss = 0.84\n",
      "epoch 2, step 7250/55000, batch loss = 0.60\n",
      "epoch 2, step 7500/55000, batch loss = 0.78\n",
      "Train accuracy = 90.91\n",
      "epoch 2, step 7750/55000, batch loss = 0.57\n",
      "epoch 2, step 8000/55000, batch loss = 0.57\n",
      "epoch 2, step 8250/55000, batch loss = 0.96\n",
      "epoch 2, step 8500/55000, batch loss = 0.69\n",
      "epoch 2, step 8750/55000, batch loss = 0.67\n",
      "epoch 2, step 9000/55000, batch loss = 0.70\n",
      "epoch 2, step 9250/55000, batch loss = 0.74\n",
      "epoch 2, step 9500/55000, batch loss = 0.61\n",
      "epoch 2, step 9750/55000, batch loss = 0.61\n",
      "epoch 2, step 10000/55000, batch loss = 0.62\n",
      "Train accuracy = 90.90\n",
      "epoch 2, step 10250/55000, batch loss = 0.52\n",
      "epoch 2, step 10500/55000, batch loss = 0.70\n",
      "epoch 2, step 10750/55000, batch loss = 0.50\n",
      "epoch 2, step 11000/55000, batch loss = 0.56\n",
      "epoch 2, step 11250/55000, batch loss = 0.68\n",
      "epoch 2, step 11500/55000, batch loss = 0.54\n",
      "epoch 2, step 11750/55000, batch loss = 0.79\n",
      "epoch 2, step 12000/55000, batch loss = 0.84\n",
      "epoch 2, step 12250/55000, batch loss = 0.66\n",
      "epoch 2, step 12500/55000, batch loss = 0.70\n",
      "Train accuracy = 90.95\n",
      "epoch 2, step 12750/55000, batch loss = 0.67\n",
      "epoch 2, step 13000/55000, batch loss = 0.49\n",
      "epoch 2, step 13250/55000, batch loss = 0.73\n",
      "epoch 2, step 13500/55000, batch loss = 0.60\n",
      "epoch 2, step 13750/55000, batch loss = 0.47\n",
      "epoch 2, step 14000/55000, batch loss = 0.58\n",
      "epoch 2, step 14250/55000, batch loss = 0.55\n",
      "epoch 2, step 14500/55000, batch loss = 0.84\n",
      "epoch 2, step 14750/55000, batch loss = 0.64\n",
      "epoch 2, step 15000/55000, batch loss = 0.75\n",
      "Train accuracy = 91.08\n",
      "epoch 2, step 15250/55000, batch loss = 0.52\n",
      "epoch 2, step 15500/55000, batch loss = 0.66\n",
      "epoch 2, step 15750/55000, batch loss = 0.59\n",
      "epoch 2, step 16000/55000, batch loss = 0.54\n",
      "epoch 2, step 16250/55000, batch loss = 0.68\n",
      "epoch 2, step 16500/55000, batch loss = 0.50\n",
      "epoch 2, step 16750/55000, batch loss = 0.54\n",
      "epoch 2, step 17000/55000, batch loss = 1.08\n",
      "epoch 2, step 17250/55000, batch loss = 0.66\n",
      "epoch 2, step 17500/55000, batch loss = 0.49\n",
      "Train accuracy = 91.09\n",
      "epoch 2, step 17750/55000, batch loss = 0.48\n",
      "epoch 2, step 18000/55000, batch loss = 0.72\n",
      "epoch 2, step 18250/55000, batch loss = 0.64\n",
      "epoch 2, step 18500/55000, batch loss = 0.67\n",
      "epoch 2, step 18750/55000, batch loss = 0.48\n",
      "epoch 2, step 19000/55000, batch loss = 0.78\n",
      "epoch 2, step 19250/55000, batch loss = 0.56\n",
      "epoch 2, step 19500/55000, batch loss = 0.76\n",
      "epoch 2, step 19750/55000, batch loss = 0.70\n",
      "epoch 2, step 20000/55000, batch loss = 0.56\n",
      "Train accuracy = 91.19\n",
      "epoch 2, step 20250/55000, batch loss = 0.61\n",
      "epoch 2, step 20500/55000, batch loss = 0.49\n",
      "epoch 2, step 20750/55000, batch loss = 0.65\n",
      "epoch 2, step 21000/55000, batch loss = 0.54\n",
      "epoch 2, step 21250/55000, batch loss = 0.84\n",
      "epoch 2, step 21500/55000, batch loss = 0.63\n",
      "epoch 2, step 21750/55000, batch loss = 0.53\n",
      "epoch 2, step 22000/55000, batch loss = 0.62\n",
      "epoch 2, step 22250/55000, batch loss = 0.77\n",
      "epoch 2, step 22500/55000, batch loss = 0.54\n",
      "Train accuracy = 91.35\n",
      "epoch 2, step 22750/55000, batch loss = 0.54\n",
      "epoch 2, step 23000/55000, batch loss = 0.64\n",
      "epoch 2, step 23250/55000, batch loss = 0.80\n",
      "epoch 2, step 23500/55000, batch loss = 0.65\n",
      "epoch 2, step 23750/55000, batch loss = 0.53\n",
      "epoch 2, step 24000/55000, batch loss = 0.53\n",
      "epoch 2, step 24250/55000, batch loss = 0.67\n",
      "epoch 2, step 24500/55000, batch loss = 0.73\n",
      "epoch 2, step 24750/55000, batch loss = 0.61\n",
      "epoch 2, step 25000/55000, batch loss = 0.48\n",
      "Train accuracy = 91.40\n",
      "epoch 2, step 25250/55000, batch loss = 0.81\n",
      "epoch 2, step 25500/55000, batch loss = 0.71\n",
      "epoch 2, step 25750/55000, batch loss = 0.75\n",
      "epoch 2, step 26000/55000, batch loss = 0.54\n",
      "epoch 2, step 26250/55000, batch loss = 0.81\n",
      "epoch 2, step 26500/55000, batch loss = 0.50\n",
      "epoch 2, step 26750/55000, batch loss = 0.53\n",
      "epoch 2, step 27000/55000, batch loss = 1.08\n",
      "epoch 2, step 27250/55000, batch loss = 0.98\n",
      "epoch 2, step 27500/55000, batch loss = 0.64\n",
      "Train accuracy = 91.18\n",
      "epoch 2, step 27750/55000, batch loss = 0.80\n",
      "epoch 2, step 28000/55000, batch loss = 0.53\n",
      "epoch 2, step 28250/55000, batch loss = 0.55\n",
      "epoch 2, step 28500/55000, batch loss = 0.93\n",
      "epoch 2, step 28750/55000, batch loss = 0.63\n",
      "epoch 2, step 29000/55000, batch loss = 0.52\n",
      "epoch 2, step 29250/55000, batch loss = 0.75\n",
      "epoch 2, step 29500/55000, batch loss = 0.75\n",
      "epoch 2, step 29750/55000, batch loss = 0.50\n",
      "epoch 2, step 30000/55000, batch loss = 0.53\n",
      "Train accuracy = 91.27\n",
      "epoch 2, step 30250/55000, batch loss = 0.57\n",
      "epoch 2, step 30500/55000, batch loss = 0.58\n",
      "epoch 2, step 30750/55000, batch loss = 0.64\n",
      "epoch 2, step 31000/55000, batch loss = 0.65\n",
      "epoch 2, step 31250/55000, batch loss = 0.48\n",
      "epoch 2, step 31500/55000, batch loss = 0.55\n",
      "epoch 2, step 31750/55000, batch loss = 0.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, step 32000/55000, batch loss = 0.75\n",
      "epoch 2, step 32250/55000, batch loss = 1.23\n",
      "epoch 2, step 32500/55000, batch loss = 0.93\n",
      "Train accuracy = 91.23\n",
      "epoch 2, step 32750/55000, batch loss = 0.55\n",
      "epoch 2, step 33000/55000, batch loss = 0.54\n",
      "epoch 2, step 33250/55000, batch loss = 0.59\n",
      "epoch 2, step 33500/55000, batch loss = 0.53\n",
      "epoch 2, step 33750/55000, batch loss = 0.61\n",
      "epoch 2, step 34000/55000, batch loss = 0.85\n",
      "epoch 2, step 34250/55000, batch loss = 0.54\n",
      "epoch 2, step 34500/55000, batch loss = 0.63\n",
      "epoch 2, step 34750/55000, batch loss = 0.49\n",
      "epoch 2, step 35000/55000, batch loss = 0.63\n",
      "Train accuracy = 91.36\n",
      "epoch 2, step 35250/55000, batch loss = 0.77\n",
      "epoch 2, step 35500/55000, batch loss = 0.56\n",
      "epoch 2, step 35750/55000, batch loss = 0.49\n",
      "epoch 2, step 36000/55000, batch loss = 0.60\n",
      "epoch 2, step 36250/55000, batch loss = 0.49\n",
      "epoch 2, step 36500/55000, batch loss = 0.70\n",
      "epoch 2, step 36750/55000, batch loss = 0.70\n",
      "epoch 2, step 37000/55000, batch loss = 0.58\n",
      "epoch 2, step 37250/55000, batch loss = 0.69\n",
      "epoch 2, step 37500/55000, batch loss = 0.86\n",
      "Train accuracy = 91.38\n",
      "epoch 2, step 37750/55000, batch loss = 0.78\n",
      "epoch 2, step 38000/55000, batch loss = 0.51\n",
      "epoch 2, step 38250/55000, batch loss = 1.07\n",
      "epoch 2, step 38500/55000, batch loss = 0.54\n",
      "epoch 2, step 38750/55000, batch loss = 0.61\n",
      "epoch 2, step 39000/55000, batch loss = 0.47\n",
      "epoch 2, step 39250/55000, batch loss = 0.52\n",
      "epoch 2, step 39500/55000, batch loss = 0.60\n",
      "epoch 2, step 39750/55000, batch loss = 0.61\n",
      "epoch 2, step 40000/55000, batch loss = 0.90\n",
      "Train accuracy = 91.36\n",
      "epoch 2, step 40250/55000, batch loss = 0.92\n",
      "epoch 2, step 40500/55000, batch loss = 0.56\n",
      "epoch 2, step 40750/55000, batch loss = 0.52\n",
      "epoch 2, step 41000/55000, batch loss = 0.54\n",
      "epoch 2, step 41250/55000, batch loss = 0.76\n",
      "epoch 2, step 41500/55000, batch loss = 0.56\n",
      "epoch 2, step 41750/55000, batch loss = 0.62\n",
      "epoch 2, step 42000/55000, batch loss = 0.71\n",
      "epoch 2, step 42250/55000, batch loss = 0.53\n",
      "epoch 2, step 42500/55000, batch loss = 0.49\n",
      "Train accuracy = 91.42\n",
      "epoch 2, step 42750/55000, batch loss = 0.52\n",
      "epoch 2, step 43000/55000, batch loss = 0.59\n",
      "epoch 2, step 43250/55000, batch loss = 0.72\n",
      "epoch 2, step 43500/55000, batch loss = 0.54\n",
      "epoch 2, step 43750/55000, batch loss = 0.68\n",
      "epoch 2, step 44000/55000, batch loss = 1.71\n",
      "epoch 2, step 44250/55000, batch loss = 0.95\n",
      "epoch 2, step 44500/55000, batch loss = 0.68\n",
      "epoch 2, step 44750/55000, batch loss = 0.86\n",
      "epoch 2, step 45000/55000, batch loss = 0.76\n",
      "Train accuracy = 91.30\n",
      "epoch 2, step 45250/55000, batch loss = 1.10\n",
      "epoch 2, step 45500/55000, batch loss = 0.64\n",
      "epoch 2, step 45750/55000, batch loss = 0.54\n",
      "epoch 2, step 46000/55000, batch loss = 0.55\n",
      "epoch 2, step 46250/55000, batch loss = 0.53\n",
      "epoch 2, step 46500/55000, batch loss = 0.75\n",
      "epoch 2, step 46750/55000, batch loss = 0.61\n",
      "epoch 2, step 47000/55000, batch loss = 0.67\n",
      "epoch 2, step 47250/55000, batch loss = 0.75\n",
      "epoch 2, step 47500/55000, batch loss = 0.59\n",
      "Train accuracy = 91.38\n",
      "epoch 2, step 47750/55000, batch loss = 0.56\n",
      "epoch 2, step 48000/55000, batch loss = 0.78\n",
      "epoch 2, step 48250/55000, batch loss = 0.67\n",
      "epoch 2, step 48500/55000, batch loss = 0.64\n",
      "epoch 2, step 48750/55000, batch loss = 0.61\n",
      "epoch 2, step 49000/55000, batch loss = 0.62\n",
      "epoch 2, step 49250/55000, batch loss = 0.54\n",
      "epoch 2, step 49500/55000, batch loss = 0.55\n",
      "epoch 2, step 49750/55000, batch loss = 0.55\n",
      "epoch 2, step 50000/55000, batch loss = 0.78\n",
      "Train accuracy = 91.35\n",
      "epoch 2, step 50250/55000, batch loss = 0.62\n",
      "epoch 2, step 50500/55000, batch loss = 0.49\n",
      "epoch 2, step 50750/55000, batch loss = 0.61\n",
      "epoch 2, step 51000/55000, batch loss = 0.56\n",
      "epoch 2, step 51250/55000, batch loss = 0.48\n",
      "epoch 2, step 51500/55000, batch loss = 0.45\n",
      "epoch 2, step 51750/55000, batch loss = 0.69\n",
      "epoch 2, step 52000/55000, batch loss = 0.53\n",
      "epoch 2, step 52250/55000, batch loss = 0.49\n",
      "epoch 2, step 52500/55000, batch loss = 0.56\n",
      "Train accuracy = 91.46\n",
      "epoch 2, step 52750/55000, batch loss = 0.56\n",
      "epoch 2, step 53000/55000, batch loss = 0.51\n",
      "epoch 2, step 53250/55000, batch loss = 0.64\n",
      "epoch 2, step 53500/55000, batch loss = 0.63\n",
      "epoch 2, step 53750/55000, batch loss = 0.60\n",
      "epoch 2, step 54000/55000, batch loss = 0.56\n",
      "epoch 2, step 54250/55000, batch loss = 0.67\n",
      "epoch 2, step 54500/55000, batch loss = 0.58\n",
      "epoch 2, step 54750/55000, batch loss = 0.48\n",
      "Train accuracy = 91.51\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 89.80\n",
      "Validation avg loss = 0.67\n",
      "\n",
      "epoch 3, step 0/55000, batch loss = 0.71\n",
      "epoch 3, step 250/55000, batch loss = 0.55\n",
      "epoch 3, step 500/55000, batch loss = 0.49\n",
      "epoch 3, step 750/55000, batch loss = 0.51\n",
      "epoch 3, step 1000/55000, batch loss = 0.57\n",
      "epoch 3, step 1250/55000, batch loss = 0.48\n",
      "epoch 3, step 1500/55000, batch loss = 0.47\n",
      "epoch 3, step 1750/55000, batch loss = 0.47\n",
      "epoch 3, step 2000/55000, batch loss = 0.52\n",
      "epoch 3, step 2250/55000, batch loss = 0.39\n",
      "epoch 3, step 2500/55000, batch loss = 0.60\n",
      "Train accuracy = 95.41\n",
      "epoch 3, step 2750/55000, batch loss = 0.61\n",
      "epoch 3, step 3000/55000, batch loss = 0.44\n",
      "epoch 3, step 3250/55000, batch loss = 0.44\n",
      "epoch 3, step 3500/55000, batch loss = 0.40\n",
      "epoch 3, step 3750/55000, batch loss = 0.39\n",
      "epoch 3, step 4000/55000, batch loss = 0.54\n",
      "epoch 3, step 4250/55000, batch loss = 0.54\n",
      "epoch 3, step 4500/55000, batch loss = 0.53\n",
      "epoch 3, step 4750/55000, batch loss = 0.45\n",
      "epoch 3, step 5000/55000, batch loss = 0.46\n",
      "Train accuracy = 95.68\n",
      "epoch 3, step 5250/55000, batch loss = 0.38\n",
      "epoch 3, step 5500/55000, batch loss = 0.48\n",
      "epoch 3, step 5750/55000, batch loss = 0.61\n",
      "epoch 3, step 6000/55000, batch loss = 0.51\n",
      "epoch 3, step 6250/55000, batch loss = 0.47\n",
      "epoch 3, step 6500/55000, batch loss = 0.50\n",
      "epoch 3, step 6750/55000, batch loss = 0.46\n",
      "epoch 3, step 7000/55000, batch loss = 0.54\n",
      "epoch 3, step 7250/55000, batch loss = 0.50\n",
      "epoch 3, step 7500/55000, batch loss = 0.47\n",
      "Train accuracy = 95.64\n",
      "epoch 3, step 7750/55000, batch loss = 0.46\n",
      "epoch 3, step 8000/55000, batch loss = 0.43\n",
      "epoch 3, step 8250/55000, batch loss = 0.36\n",
      "epoch 3, step 8500/55000, batch loss = 0.44\n",
      "epoch 3, step 8750/55000, batch loss = 0.36\n",
      "epoch 3, step 9000/55000, batch loss = 0.39\n",
      "epoch 3, step 9250/55000, batch loss = 0.43\n",
      "epoch 3, step 9500/55000, batch loss = 0.44\n",
      "epoch 3, step 9750/55000, batch loss = 0.40\n",
      "epoch 3, step 10000/55000, batch loss = 0.49\n",
      "Train accuracy = 95.87\n",
      "epoch 3, step 10250/55000, batch loss = 0.36\n",
      "epoch 3, step 10500/55000, batch loss = 0.51\n",
      "epoch 3, step 10750/55000, batch loss = 0.48\n",
      "epoch 3, step 11000/55000, batch loss = 0.51\n",
      "epoch 3, step 11250/55000, batch loss = 0.50\n",
      "epoch 3, step 11500/55000, batch loss = 0.40\n",
      "epoch 3, step 11750/55000, batch loss = 0.41\n",
      "epoch 3, step 12000/55000, batch loss = 0.42\n",
      "epoch 3, step 12250/55000, batch loss = 0.40\n",
      "epoch 3, step 12500/55000, batch loss = 0.58\n",
      "Train accuracy = 95.91\n",
      "epoch 3, step 12750/55000, batch loss = 0.44\n",
      "epoch 3, step 13000/55000, batch loss = 0.55\n",
      "epoch 3, step 13250/55000, batch loss = 0.45\n",
      "epoch 3, step 13500/55000, batch loss = 0.49\n",
      "epoch 3, step 13750/55000, batch loss = 0.51\n",
      "epoch 3, step 14000/55000, batch loss = 0.40\n",
      "epoch 3, step 14250/55000, batch loss = 0.44\n",
      "epoch 3, step 14500/55000, batch loss = 0.49\n",
      "epoch 3, step 14750/55000, batch loss = 0.43\n",
      "epoch 3, step 15000/55000, batch loss = 0.46\n",
      "Train accuracy = 95.83\n",
      "epoch 3, step 15250/55000, batch loss = 0.40\n",
      "epoch 3, step 15500/55000, batch loss = 0.42\n",
      "epoch 3, step 15750/55000, batch loss = 0.43\n",
      "epoch 3, step 16000/55000, batch loss = 0.40\n",
      "epoch 3, step 16250/55000, batch loss = 0.36\n",
      "epoch 3, step 16500/55000, batch loss = 0.48\n",
      "epoch 3, step 16750/55000, batch loss = 0.44\n",
      "epoch 3, step 17000/55000, batch loss = 0.48\n",
      "epoch 3, step 17250/55000, batch loss = 0.41\n",
      "epoch 3, step 17500/55000, batch loss = 0.46\n",
      "Train accuracy = 95.82\n",
      "epoch 3, step 17750/55000, batch loss = 0.42\n",
      "epoch 3, step 18000/55000, batch loss = 0.38\n",
      "epoch 3, step 18250/55000, batch loss = 0.46\n",
      "epoch 3, step 18500/55000, batch loss = 0.44\n",
      "epoch 3, step 18750/55000, batch loss = 0.41\n",
      "epoch 3, step 19000/55000, batch loss = 0.43\n",
      "epoch 3, step 19250/55000, batch loss = 0.45\n",
      "epoch 3, step 19500/55000, batch loss = 0.40\n",
      "epoch 3, step 19750/55000, batch loss = 0.45\n",
      "epoch 3, step 20000/55000, batch loss = 0.69\n",
      "Train accuracy = 95.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, step 20250/55000, batch loss = 0.61\n",
      "epoch 3, step 20500/55000, batch loss = 0.37\n",
      "epoch 3, step 20750/55000, batch loss = 0.41\n",
      "epoch 3, step 21000/55000, batch loss = 0.54\n",
      "epoch 3, step 21250/55000, batch loss = 0.48\n",
      "epoch 3, step 21500/55000, batch loss = 0.52\n",
      "epoch 3, step 21750/55000, batch loss = 0.41\n",
      "epoch 3, step 22000/55000, batch loss = 0.47\n",
      "epoch 3, step 22250/55000, batch loss = 0.41\n",
      "epoch 3, step 22500/55000, batch loss = 0.41\n",
      "Train accuracy = 95.82\n",
      "epoch 3, step 22750/55000, batch loss = 0.43\n",
      "epoch 3, step 23000/55000, batch loss = 0.43\n",
      "epoch 3, step 23250/55000, batch loss = 0.41\n",
      "epoch 3, step 23500/55000, batch loss = 0.46\n",
      "epoch 3, step 23750/55000, batch loss = 0.43\n",
      "epoch 3, step 24000/55000, batch loss = 0.45\n",
      "epoch 3, step 24250/55000, batch loss = 0.39\n",
      "epoch 3, step 24500/55000, batch loss = 0.40\n",
      "epoch 3, step 24750/55000, batch loss = 0.42\n",
      "epoch 3, step 25000/55000, batch loss = 0.61\n",
      "Train accuracy = 95.80\n",
      "epoch 3, step 25250/55000, batch loss = 0.42\n",
      "epoch 3, step 25500/55000, batch loss = 0.51\n",
      "epoch 3, step 25750/55000, batch loss = 0.43\n",
      "epoch 3, step 26000/55000, batch loss = 0.44\n",
      "epoch 3, step 26250/55000, batch loss = 0.47\n",
      "epoch 3, step 26500/55000, batch loss = 0.60\n",
      "epoch 3, step 26750/55000, batch loss = 0.48\n",
      "epoch 3, step 27000/55000, batch loss = 0.51\n",
      "epoch 3, step 27250/55000, batch loss = 0.46\n",
      "epoch 3, step 27500/55000, batch loss = 0.47\n",
      "Train accuracy = 95.79\n",
      "epoch 3, step 27750/55000, batch loss = 0.49\n",
      "epoch 3, step 28000/55000, batch loss = 0.58\n",
      "epoch 3, step 28250/55000, batch loss = 0.52\n",
      "epoch 3, step 28500/55000, batch loss = 0.40\n",
      "epoch 3, step 28750/55000, batch loss = 0.39\n",
      "epoch 3, step 29000/55000, batch loss = 0.39\n",
      "epoch 3, step 29250/55000, batch loss = 0.43\n",
      "epoch 3, step 29500/55000, batch loss = 0.44\n",
      "epoch 3, step 29750/55000, batch loss = 0.40\n",
      "epoch 3, step 30000/55000, batch loss = 0.43\n",
      "Train accuracy = 95.77\n",
      "epoch 3, step 30250/55000, batch loss = 0.40\n",
      "epoch 3, step 30500/55000, batch loss = 0.49\n",
      "epoch 3, step 30750/55000, batch loss = 0.45\n",
      "epoch 3, step 31000/55000, batch loss = 0.41\n",
      "epoch 3, step 31250/55000, batch loss = 0.51\n",
      "epoch 3, step 31500/55000, batch loss = 0.55\n",
      "epoch 3, step 31750/55000, batch loss = 0.46\n",
      "epoch 3, step 32000/55000, batch loss = 0.41\n",
      "epoch 3, step 32250/55000, batch loss = 0.55\n",
      "epoch 3, step 32500/55000, batch loss = 0.48\n",
      "Train accuracy = 95.77\n",
      "epoch 3, step 32750/55000, batch loss = 0.40\n",
      "epoch 3, step 33000/55000, batch loss = 0.38\n",
      "epoch 3, step 33250/55000, batch loss = 0.37\n",
      "epoch 3, step 33500/55000, batch loss = 0.54\n",
      "epoch 3, step 33750/55000, batch loss = 0.46\n",
      "epoch 3, step 34000/55000, batch loss = 0.54\n",
      "epoch 3, step 34250/55000, batch loss = 0.38\n",
      "epoch 3, step 34500/55000, batch loss = 0.39\n",
      "epoch 3, step 34750/55000, batch loss = 0.43\n",
      "epoch 3, step 35000/55000, batch loss = 0.37\n",
      "Train accuracy = 95.81\n",
      "epoch 3, step 35250/55000, batch loss = 0.47\n",
      "epoch 3, step 35500/55000, batch loss = 0.40\n",
      "epoch 3, step 35750/55000, batch loss = 0.39\n",
      "epoch 3, step 36000/55000, batch loss = 0.53\n",
      "epoch 3, step 36250/55000, batch loss = 0.41\n",
      "epoch 3, step 36500/55000, batch loss = 0.42\n",
      "epoch 3, step 36750/55000, batch loss = 0.54\n",
      "epoch 3, step 37000/55000, batch loss = 0.35\n",
      "epoch 3, step 37250/55000, batch loss = 0.51\n",
      "epoch 3, step 37500/55000, batch loss = 0.46\n",
      "Train accuracy = 95.86\n",
      "epoch 3, step 37750/55000, batch loss = 0.38\n",
      "epoch 3, step 38000/55000, batch loss = 0.46\n",
      "epoch 3, step 38250/55000, batch loss = 0.45\n",
      "epoch 3, step 38500/55000, batch loss = 0.49\n",
      "epoch 3, step 38750/55000, batch loss = 0.45\n",
      "epoch 3, step 39000/55000, batch loss = 0.38\n",
      "epoch 3, step 39250/55000, batch loss = 0.39\n",
      "epoch 3, step 39500/55000, batch loss = 0.44\n",
      "epoch 3, step 39750/55000, batch loss = 0.45\n",
      "epoch 3, step 40000/55000, batch loss = 0.51\n",
      "Train accuracy = 95.85\n",
      "epoch 3, step 40250/55000, batch loss = 0.43\n",
      "epoch 3, step 40500/55000, batch loss = 0.48\n",
      "epoch 3, step 40750/55000, batch loss = 0.46\n",
      "epoch 3, step 41000/55000, batch loss = 0.39\n",
      "epoch 3, step 41250/55000, batch loss = 0.43\n",
      "epoch 3, step 41500/55000, batch loss = 0.44\n",
      "epoch 3, step 41750/55000, batch loss = 0.46\n",
      "epoch 3, step 42000/55000, batch loss = 0.43\n",
      "epoch 3, step 42250/55000, batch loss = 0.39\n",
      "epoch 3, step 42500/55000, batch loss = 0.33\n",
      "Train accuracy = 95.88\n",
      "epoch 3, step 42750/55000, batch loss = 0.54\n",
      "epoch 3, step 43000/55000, batch loss = 0.48\n",
      "epoch 3, step 43250/55000, batch loss = 0.45\n",
      "epoch 3, step 43500/55000, batch loss = 0.42\n",
      "epoch 3, step 43750/55000, batch loss = 0.50\n",
      "epoch 3, step 44000/55000, batch loss = 0.42\n",
      "epoch 3, step 44250/55000, batch loss = 0.44\n",
      "epoch 3, step 44500/55000, batch loss = 0.51\n",
      "epoch 3, step 44750/55000, batch loss = 0.53\n",
      "epoch 3, step 45000/55000, batch loss = 0.44\n",
      "Train accuracy = 95.88\n",
      "epoch 3, step 45250/55000, batch loss = 0.50\n",
      "epoch 3, step 45500/55000, batch loss = 0.41\n",
      "epoch 3, step 45750/55000, batch loss = 0.43\n",
      "epoch 3, step 46000/55000, batch loss = 0.38\n",
      "epoch 3, step 46250/55000, batch loss = 0.43\n",
      "epoch 3, step 46500/55000, batch loss = 0.45\n",
      "epoch 3, step 46750/55000, batch loss = 0.51\n",
      "epoch 3, step 47000/55000, batch loss = 0.37\n",
      "epoch 3, step 47250/55000, batch loss = 0.52\n",
      "epoch 3, step 47500/55000, batch loss = 0.44\n",
      "Train accuracy = 95.86\n",
      "epoch 3, step 47750/55000, batch loss = 0.44\n",
      "epoch 3, step 48000/55000, batch loss = 0.45\n",
      "epoch 3, step 48250/55000, batch loss = 0.41\n",
      "epoch 3, step 48500/55000, batch loss = 0.36\n",
      "epoch 3, step 48750/55000, batch loss = 0.40\n",
      "epoch 3, step 49000/55000, batch loss = 0.44\n",
      "epoch 3, step 49250/55000, batch loss = 0.45\n",
      "epoch 3, step 49500/55000, batch loss = 0.41\n",
      "epoch 3, step 49750/55000, batch loss = 0.35\n",
      "epoch 3, step 50000/55000, batch loss = 0.44\n",
      "Train accuracy = 95.88\n",
      "epoch 3, step 50250/55000, batch loss = 0.41\n",
      "epoch 3, step 50500/55000, batch loss = 0.51\n",
      "epoch 3, step 50750/55000, batch loss = 0.42\n",
      "epoch 3, step 51000/55000, batch loss = 0.49\n",
      "epoch 3, step 51250/55000, batch loss = 0.41\n",
      "epoch 3, step 51500/55000, batch loss = 0.41\n",
      "epoch 3, step 51750/55000, batch loss = 0.44\n",
      "epoch 3, step 52000/55000, batch loss = 0.55\n",
      "epoch 3, step 52250/55000, batch loss = 0.43\n",
      "epoch 3, step 52500/55000, batch loss = 0.46\n",
      "Train accuracy = 95.85\n",
      "epoch 3, step 52750/55000, batch loss = 0.42\n",
      "epoch 3, step 53000/55000, batch loss = 0.40\n",
      "epoch 3, step 53250/55000, batch loss = 0.40\n",
      "epoch 3, step 53500/55000, batch loss = 0.45\n",
      "epoch 3, step 53750/55000, batch loss = 0.52\n",
      "epoch 3, step 54000/55000, batch loss = 0.47\n",
      "epoch 3, step 54250/55000, batch loss = 0.48\n",
      "epoch 3, step 54500/55000, batch loss = 0.49\n",
      "epoch 3, step 54750/55000, batch loss = 0.56\n",
      "Train accuracy = 95.80\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 96.44\n",
      "Validation avg loss = 0.43\n",
      "\n",
      "epoch 4, step 0/55000, batch loss = 0.39\n",
      "epoch 4, step 250/55000, batch loss = 0.38\n",
      "epoch 4, step 500/55000, batch loss = 0.43\n",
      "epoch 4, step 750/55000, batch loss = 0.49\n",
      "epoch 4, step 1000/55000, batch loss = 0.65\n",
      "epoch 4, step 1250/55000, batch loss = 0.43\n",
      "epoch 4, step 1500/55000, batch loss = 0.46\n",
      "epoch 4, step 1750/55000, batch loss = 0.38\n",
      "epoch 4, step 2000/55000, batch loss = 0.46\n",
      "epoch 4, step 2250/55000, batch loss = 0.50\n",
      "epoch 4, step 2500/55000, batch loss = 0.45\n",
      "Train accuracy = 95.29\n",
      "epoch 4, step 2750/55000, batch loss = 0.46\n",
      "epoch 4, step 3000/55000, batch loss = 0.45\n",
      "epoch 4, step 3250/55000, batch loss = 0.34\n",
      "epoch 4, step 3500/55000, batch loss = 0.46\n",
      "epoch 4, step 3750/55000, batch loss = 0.55\n",
      "epoch 4, step 4000/55000, batch loss = 0.45\n",
      "epoch 4, step 4250/55000, batch loss = 0.36\n",
      "epoch 4, step 4500/55000, batch loss = 0.34\n",
      "epoch 4, step 4750/55000, batch loss = 0.39\n",
      "epoch 4, step 5000/55000, batch loss = 0.43\n",
      "Train accuracy = 95.78\n",
      "epoch 4, step 5250/55000, batch loss = 0.43\n",
      "epoch 4, step 5500/55000, batch loss = 0.48\n",
      "epoch 4, step 5750/55000, batch loss = 0.44\n",
      "epoch 4, step 6000/55000, batch loss = 0.46\n",
      "epoch 4, step 6250/55000, batch loss = 0.50\n",
      "epoch 4, step 6500/55000, batch loss = 0.41\n",
      "epoch 4, step 6750/55000, batch loss = 0.37\n",
      "epoch 4, step 7000/55000, batch loss = 0.37\n",
      "epoch 4, step 7250/55000, batch loss = 0.51\n",
      "epoch 4, step 7500/55000, batch loss = 0.36\n",
      "Train accuracy = 95.95\n",
      "epoch 4, step 7750/55000, batch loss = 0.38\n",
      "epoch 4, step 8000/55000, batch loss = 0.63\n",
      "epoch 4, step 8250/55000, batch loss = 0.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, step 8500/55000, batch loss = 0.37\n",
      "epoch 4, step 8750/55000, batch loss = 0.43\n",
      "epoch 4, step 9000/55000, batch loss = 0.43\n",
      "epoch 4, step 9250/55000, batch loss = 0.42\n",
      "epoch 4, step 9500/55000, batch loss = 0.49\n",
      "epoch 4, step 9750/55000, batch loss = 0.43\n",
      "epoch 4, step 10000/55000, batch loss = 0.43\n",
      "Train accuracy = 96.08\n",
      "epoch 4, step 10250/55000, batch loss = 0.52\n",
      "epoch 4, step 10500/55000, batch loss = 0.35\n",
      "epoch 4, step 10750/55000, batch loss = 0.43\n",
      "epoch 4, step 11000/55000, batch loss = 0.36\n",
      "epoch 4, step 11250/55000, batch loss = 0.44\n",
      "epoch 4, step 11500/55000, batch loss = 0.46\n",
      "epoch 4, step 11750/55000, batch loss = 0.48\n",
      "epoch 4, step 12000/55000, batch loss = 0.44\n",
      "epoch 4, step 12250/55000, batch loss = 0.41\n",
      "epoch 4, step 12500/55000, batch loss = 0.45\n",
      "Train accuracy = 96.06\n",
      "epoch 4, step 12750/55000, batch loss = 0.43\n",
      "epoch 4, step 13000/55000, batch loss = 0.43\n",
      "epoch 4, step 13250/55000, batch loss = 0.50\n",
      "epoch 4, step 13500/55000, batch loss = 0.46\n",
      "epoch 4, step 13750/55000, batch loss = 0.40\n",
      "epoch 4, step 14000/55000, batch loss = 0.41\n",
      "epoch 4, step 14250/55000, batch loss = 0.45\n",
      "epoch 4, step 14500/55000, batch loss = 0.50\n",
      "epoch 4, step 14750/55000, batch loss = 0.48\n",
      "epoch 4, step 15000/55000, batch loss = 0.42\n",
      "Train accuracy = 96.03\n",
      "epoch 4, step 15250/55000, batch loss = 0.41\n",
      "epoch 4, step 15500/55000, batch loss = 0.42\n",
      "epoch 4, step 15750/55000, batch loss = 0.49\n",
      "epoch 4, step 16000/55000, batch loss = 0.43\n",
      "epoch 4, step 16250/55000, batch loss = 0.48\n",
      "epoch 4, step 16500/55000, batch loss = 0.37\n",
      "epoch 4, step 16750/55000, batch loss = 0.42\n",
      "epoch 4, step 17000/55000, batch loss = 0.47\n",
      "epoch 4, step 17250/55000, batch loss = 0.57\n",
      "epoch 4, step 17500/55000, batch loss = 0.42\n",
      "Train accuracy = 95.99\n",
      "epoch 4, step 17750/55000, batch loss = 0.37\n",
      "epoch 4, step 18000/55000, batch loss = 0.43\n",
      "epoch 4, step 18250/55000, batch loss = 0.39\n",
      "epoch 4, step 18500/55000, batch loss = 0.36\n",
      "epoch 4, step 18750/55000, batch loss = 0.42\n",
      "epoch 4, step 19000/55000, batch loss = 0.38\n",
      "epoch 4, step 19250/55000, batch loss = 0.39\n",
      "epoch 4, step 19500/55000, batch loss = 0.57\n",
      "epoch 4, step 19750/55000, batch loss = 0.41\n",
      "epoch 4, step 20000/55000, batch loss = 0.40\n",
      "Train accuracy = 96.07\n",
      "epoch 4, step 20250/55000, batch loss = 0.50\n",
      "epoch 4, step 20500/55000, batch loss = 0.43\n",
      "epoch 4, step 20750/55000, batch loss = 0.47\n",
      "epoch 4, step 21000/55000, batch loss = 0.49\n",
      "epoch 4, step 21250/55000, batch loss = 0.34\n",
      "epoch 4, step 21500/55000, batch loss = 0.42\n",
      "epoch 4, step 21750/55000, batch loss = 0.40\n",
      "epoch 4, step 22000/55000, batch loss = 0.36\n",
      "epoch 4, step 22250/55000, batch loss = 0.53\n",
      "epoch 4, step 22500/55000, batch loss = 0.42\n",
      "Train accuracy = 96.02\n",
      "epoch 4, step 22750/55000, batch loss = 0.37\n",
      "epoch 4, step 23000/55000, batch loss = 0.39\n",
      "epoch 4, step 23250/55000, batch loss = 0.41\n",
      "epoch 4, step 23500/55000, batch loss = 0.39\n",
      "epoch 4, step 23750/55000, batch loss = 0.63\n",
      "epoch 4, step 24000/55000, batch loss = 0.50\n",
      "epoch 4, step 24250/55000, batch loss = 0.42\n",
      "epoch 4, step 24500/55000, batch loss = 0.45\n",
      "epoch 4, step 24750/55000, batch loss = 0.50\n",
      "epoch 4, step 25000/55000, batch loss = 0.58\n",
      "Train accuracy = 95.97\n",
      "epoch 4, step 25250/55000, batch loss = 0.48\n",
      "epoch 4, step 25500/55000, batch loss = 0.40\n",
      "epoch 4, step 25750/55000, batch loss = 0.42\n",
      "epoch 4, step 26000/55000, batch loss = 0.40\n",
      "epoch 4, step 26250/55000, batch loss = 0.41\n",
      "epoch 4, step 26500/55000, batch loss = 0.33\n",
      "epoch 4, step 26750/55000, batch loss = 0.43\n",
      "epoch 4, step 27000/55000, batch loss = 0.39\n",
      "epoch 4, step 27250/55000, batch loss = 0.40\n",
      "epoch 4, step 27500/55000, batch loss = 0.39\n",
      "Train accuracy = 95.95\n",
      "epoch 4, step 27750/55000, batch loss = 0.46\n",
      "epoch 4, step 28000/55000, batch loss = 0.44\n",
      "epoch 4, step 28250/55000, batch loss = 0.47\n",
      "epoch 4, step 28500/55000, batch loss = 0.41\n",
      "epoch 4, step 28750/55000, batch loss = 0.41\n",
      "epoch 4, step 29000/55000, batch loss = 0.44\n",
      "epoch 4, step 29250/55000, batch loss = 0.47\n",
      "epoch 4, step 29500/55000, batch loss = 0.62\n",
      "epoch 4, step 29750/55000, batch loss = 0.49\n",
      "epoch 4, step 30000/55000, batch loss = 0.47\n",
      "Train accuracy = 95.91\n",
      "epoch 4, step 30250/55000, batch loss = 0.52\n",
      "epoch 4, step 30500/55000, batch loss = 0.47\n",
      "epoch 4, step 30750/55000, batch loss = 0.44\n",
      "epoch 4, step 31000/55000, batch loss = 0.50\n",
      "epoch 4, step 31250/55000, batch loss = 0.36\n",
      "epoch 4, step 31500/55000, batch loss = 0.49\n",
      "epoch 4, step 31750/55000, batch loss = 0.45\n",
      "epoch 4, step 32000/55000, batch loss = 0.44\n",
      "epoch 4, step 32250/55000, batch loss = 0.43\n",
      "epoch 4, step 32500/55000, batch loss = 0.50\n",
      "Train accuracy = 95.92\n",
      "epoch 4, step 32750/55000, batch loss = 0.56\n",
      "epoch 4, step 33000/55000, batch loss = 0.52\n",
      "epoch 4, step 33250/55000, batch loss = 0.54\n",
      "epoch 4, step 33500/55000, batch loss = 0.48\n",
      "epoch 4, step 33750/55000, batch loss = 0.52\n",
      "epoch 4, step 34000/55000, batch loss = 0.43\n",
      "epoch 4, step 34250/55000, batch loss = 0.59\n",
      "epoch 4, step 34500/55000, batch loss = 0.51\n",
      "epoch 4, step 34750/55000, batch loss = 0.42\n",
      "epoch 4, step 35000/55000, batch loss = 0.42\n",
      "Train accuracy = 95.87\n",
      "epoch 4, step 35250/55000, batch loss = 0.43\n",
      "epoch 4, step 35500/55000, batch loss = 0.56\n",
      "epoch 4, step 35750/55000, batch loss = 0.39\n",
      "epoch 4, step 36000/55000, batch loss = 0.40\n",
      "epoch 4, step 36250/55000, batch loss = 0.47\n",
      "epoch 4, step 36500/55000, batch loss = 0.50\n",
      "epoch 4, step 36750/55000, batch loss = 0.42\n",
      "epoch 4, step 37000/55000, batch loss = 0.46\n",
      "epoch 4, step 37250/55000, batch loss = 0.32\n",
      "epoch 4, step 37500/55000, batch loss = 0.40\n",
      "Train accuracy = 95.90\n",
      "epoch 4, step 37750/55000, batch loss = 0.46\n",
      "epoch 4, step 38000/55000, batch loss = 0.44\n",
      "epoch 4, step 38250/55000, batch loss = 0.38\n",
      "epoch 4, step 38500/55000, batch loss = 0.46\n",
      "epoch 4, step 38750/55000, batch loss = 0.36\n",
      "epoch 4, step 39000/55000, batch loss = 0.47\n",
      "epoch 4, step 39250/55000, batch loss = 0.44\n",
      "epoch 4, step 39500/55000, batch loss = 0.52\n",
      "epoch 4, step 39750/55000, batch loss = 0.39\n",
      "epoch 4, step 40000/55000, batch loss = 0.41\n",
      "Train accuracy = 95.91\n",
      "epoch 4, step 40250/55000, batch loss = 0.49\n",
      "epoch 4, step 40500/55000, batch loss = 0.37\n",
      "epoch 4, step 40750/55000, batch loss = 0.41\n",
      "epoch 4, step 41000/55000, batch loss = 0.41\n",
      "epoch 4, step 41250/55000, batch loss = 0.44\n",
      "epoch 4, step 41500/55000, batch loss = 0.38\n",
      "epoch 4, step 41750/55000, batch loss = 0.44\n",
      "epoch 4, step 42000/55000, batch loss = 0.53\n",
      "epoch 4, step 42250/55000, batch loss = 0.55\n",
      "epoch 4, step 42500/55000, batch loss = 0.56\n",
      "Train accuracy = 95.90\n",
      "epoch 4, step 42750/55000, batch loss = 0.57\n",
      "epoch 4, step 43000/55000, batch loss = 0.36\n",
      "epoch 4, step 43250/55000, batch loss = 0.54\n",
      "epoch 4, step 43500/55000, batch loss = 0.42\n",
      "epoch 4, step 43750/55000, batch loss = 0.49\n",
      "epoch 4, step 44000/55000, batch loss = 0.44\n",
      "epoch 4, step 44250/55000, batch loss = 0.52\n",
      "epoch 4, step 44500/55000, batch loss = 0.38\n",
      "epoch 4, step 44750/55000, batch loss = 0.43\n",
      "epoch 4, step 45000/55000, batch loss = 0.46\n",
      "Train accuracy = 95.92\n",
      "epoch 4, step 45250/55000, batch loss = 0.39\n",
      "epoch 4, step 45500/55000, batch loss = 0.50\n",
      "epoch 4, step 45750/55000, batch loss = 0.42\n",
      "epoch 4, step 46000/55000, batch loss = 0.46\n",
      "epoch 4, step 46250/55000, batch loss = 0.39\n",
      "epoch 4, step 46500/55000, batch loss = 0.51\n",
      "epoch 4, step 46750/55000, batch loss = 0.47\n",
      "epoch 4, step 47000/55000, batch loss = 0.43\n",
      "epoch 4, step 47250/55000, batch loss = 0.51\n",
      "epoch 4, step 47500/55000, batch loss = 0.42\n",
      "Train accuracy = 95.90\n",
      "epoch 4, step 47750/55000, batch loss = 0.39\n",
      "epoch 4, step 48000/55000, batch loss = 0.40\n",
      "epoch 4, step 48250/55000, batch loss = 0.35\n",
      "epoch 4, step 48500/55000, batch loss = 0.44\n",
      "epoch 4, step 48750/55000, batch loss = 0.45\n",
      "epoch 4, step 49000/55000, batch loss = 0.50\n",
      "epoch 4, step 49250/55000, batch loss = 0.44\n",
      "epoch 4, step 49500/55000, batch loss = 0.44\n",
      "epoch 4, step 49750/55000, batch loss = 0.35\n",
      "epoch 4, step 50000/55000, batch loss = 0.41\n",
      "Train accuracy = 95.90\n",
      "epoch 4, step 50250/55000, batch loss = 0.49\n",
      "epoch 4, step 50500/55000, batch loss = 0.44\n",
      "epoch 4, step 50750/55000, batch loss = 0.48\n",
      "epoch 4, step 51000/55000, batch loss = 0.43\n",
      "epoch 4, step 51250/55000, batch loss = 0.45\n",
      "epoch 4, step 51500/55000, batch loss = 0.44\n",
      "epoch 4, step 51750/55000, batch loss = 0.40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, step 52000/55000, batch loss = 0.44\n",
      "epoch 4, step 52250/55000, batch loss = 0.49\n",
      "epoch 4, step 52500/55000, batch loss = 0.40\n",
      "Train accuracy = 95.89\n",
      "epoch 4, step 52750/55000, batch loss = 0.38\n",
      "epoch 4, step 53000/55000, batch loss = 0.52\n",
      "epoch 4, step 53250/55000, batch loss = 0.47\n",
      "epoch 4, step 53500/55000, batch loss = 0.38\n",
      "epoch 4, step 53750/55000, batch loss = 0.38\n",
      "epoch 4, step 54000/55000, batch loss = 0.52\n",
      "epoch 4, step 54250/55000, batch loss = 0.46\n",
      "epoch 4, step 54500/55000, batch loss = 0.47\n",
      "epoch 4, step 54750/55000, batch loss = 0.36\n",
      "Train accuracy = 95.88\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 96.38\n",
      "Validation avg loss = 0.42\n",
      "\n",
      "epoch 5, step 0/55000, batch loss = 0.43\n",
      "epoch 5, step 250/55000, batch loss = 0.53\n",
      "epoch 5, step 500/55000, batch loss = 0.47\n",
      "epoch 5, step 750/55000, batch loss = 0.47\n",
      "epoch 5, step 1000/55000, batch loss = 0.42\n",
      "epoch 5, step 1250/55000, batch loss = 0.38\n",
      "epoch 5, step 1500/55000, batch loss = 0.40\n",
      "epoch 5, step 1750/55000, batch loss = 0.47\n",
      "epoch 5, step 2000/55000, batch loss = 0.42\n",
      "epoch 5, step 2250/55000, batch loss = 0.35\n",
      "epoch 5, step 2500/55000, batch loss = 0.34\n",
      "Train accuracy = 96.63\n",
      "epoch 5, step 2750/55000, batch loss = 0.33\n",
      "epoch 5, step 3000/55000, batch loss = 0.43\n",
      "epoch 5, step 3250/55000, batch loss = 0.41\n",
      "epoch 5, step 3500/55000, batch loss = 0.52\n",
      "epoch 5, step 3750/55000, batch loss = 0.45\n",
      "epoch 5, step 4000/55000, batch loss = 0.47\n",
      "epoch 5, step 4250/55000, batch loss = 0.50\n",
      "epoch 5, step 4500/55000, batch loss = 0.45\n",
      "epoch 5, step 4750/55000, batch loss = 0.43\n",
      "epoch 5, step 5000/55000, batch loss = 0.38\n",
      "Train accuracy = 96.40\n",
      "epoch 5, step 5250/55000, batch loss = 0.38\n",
      "epoch 5, step 5500/55000, batch loss = 0.35\n",
      "epoch 5, step 5750/55000, batch loss = 0.33\n",
      "epoch 5, step 6000/55000, batch loss = 0.46\n",
      "epoch 5, step 6250/55000, batch loss = 0.40\n",
      "epoch 5, step 6500/55000, batch loss = 0.40\n",
      "epoch 5, step 6750/55000, batch loss = 0.46\n",
      "epoch 5, step 7000/55000, batch loss = 0.40\n",
      "epoch 5, step 7250/55000, batch loss = 0.51\n",
      "epoch 5, step 7500/55000, batch loss = 0.41\n",
      "Train accuracy = 96.46\n",
      "epoch 5, step 7750/55000, batch loss = 0.44\n",
      "epoch 5, step 8000/55000, batch loss = 0.38\n",
      "epoch 5, step 8250/55000, batch loss = 0.47\n",
      "epoch 5, step 8500/55000, batch loss = 0.44\n",
      "epoch 5, step 8750/55000, batch loss = 0.41\n",
      "epoch 5, step 9000/55000, batch loss = 0.37\n",
      "epoch 5, step 9250/55000, batch loss = 0.39\n",
      "epoch 5, step 9500/55000, batch loss = 0.40\n",
      "epoch 5, step 9750/55000, batch loss = 0.44\n",
      "epoch 5, step 10000/55000, batch loss = 0.52\n",
      "Train accuracy = 96.32\n",
      "epoch 5, step 10250/55000, batch loss = 0.39\n",
      "epoch 5, step 10500/55000, batch loss = 0.47\n",
      "epoch 5, step 10750/55000, batch loss = 0.50\n",
      "epoch 5, step 11000/55000, batch loss = 0.49\n",
      "epoch 5, step 11250/55000, batch loss = 0.43\n",
      "epoch 5, step 11500/55000, batch loss = 0.39\n",
      "epoch 5, step 11750/55000, batch loss = 0.34\n",
      "epoch 5, step 12000/55000, batch loss = 0.41\n",
      "epoch 5, step 12250/55000, batch loss = 0.40\n",
      "epoch 5, step 12500/55000, batch loss = 0.43\n",
      "Train accuracy = 96.27\n",
      "epoch 5, step 12750/55000, batch loss = 0.39\n",
      "epoch 5, step 13000/55000, batch loss = 0.37\n",
      "epoch 5, step 13250/55000, batch loss = 0.37\n",
      "epoch 5, step 13500/55000, batch loss = 0.38\n",
      "epoch 5, step 13750/55000, batch loss = 0.44\n",
      "epoch 5, step 14000/55000, batch loss = 0.41\n",
      "epoch 5, step 14250/55000, batch loss = 0.39\n",
      "epoch 5, step 14500/55000, batch loss = 0.46\n",
      "epoch 5, step 14750/55000, batch loss = 0.40\n",
      "epoch 5, step 15000/55000, batch loss = 0.36\n",
      "Train accuracy = 96.32\n",
      "epoch 5, step 15250/55000, batch loss = 0.53\n",
      "epoch 5, step 15500/55000, batch loss = 0.42\n",
      "epoch 5, step 15750/55000, batch loss = 0.40\n",
      "epoch 5, step 16000/55000, batch loss = 0.35\n",
      "epoch 5, step 16250/55000, batch loss = 0.37\n",
      "epoch 5, step 16500/55000, batch loss = 0.36\n",
      "epoch 5, step 16750/55000, batch loss = 0.40\n",
      "epoch 5, step 17000/55000, batch loss = 0.38\n",
      "epoch 5, step 17250/55000, batch loss = 0.42\n",
      "epoch 5, step 17500/55000, batch loss = 0.48\n",
      "Train accuracy = 96.35\n",
      "epoch 5, step 17750/55000, batch loss = 0.35\n",
      "epoch 5, step 18000/55000, batch loss = 0.63\n",
      "epoch 5, step 18250/55000, batch loss = 0.42\n",
      "epoch 5, step 18500/55000, batch loss = 0.36\n",
      "epoch 5, step 18750/55000, batch loss = 0.33\n",
      "epoch 5, step 19000/55000, batch loss = 0.39\n",
      "epoch 5, step 19250/55000, batch loss = 0.37\n",
      "epoch 5, step 19500/55000, batch loss = 0.56\n",
      "epoch 5, step 19750/55000, batch loss = 0.42\n",
      "epoch 5, step 20000/55000, batch loss = 0.53\n",
      "Train accuracy = 96.27\n",
      "epoch 5, step 20250/55000, batch loss = 0.40\n",
      "epoch 5, step 20500/55000, batch loss = 0.39\n",
      "epoch 5, step 20750/55000, batch loss = 0.36\n",
      "epoch 5, step 21000/55000, batch loss = 0.35\n",
      "epoch 5, step 21250/55000, batch loss = 0.58\n",
      "epoch 5, step 21500/55000, batch loss = 0.52\n",
      "epoch 5, step 21750/55000, batch loss = 0.41\n",
      "epoch 5, step 22000/55000, batch loss = 0.50\n",
      "epoch 5, step 22250/55000, batch loss = 0.46\n",
      "epoch 5, step 22500/55000, batch loss = 0.43\n",
      "Train accuracy = 96.27\n",
      "epoch 5, step 22750/55000, batch loss = 0.42\n",
      "epoch 5, step 23000/55000, batch loss = 0.37\n",
      "epoch 5, step 23250/55000, batch loss = 0.39\n",
      "epoch 5, step 23500/55000, batch loss = 0.39\n",
      "epoch 5, step 23750/55000, batch loss = 0.33\n",
      "epoch 5, step 24000/55000, batch loss = 0.43\n",
      "epoch 5, step 24250/55000, batch loss = 0.36\n",
      "epoch 5, step 24500/55000, batch loss = 0.43\n",
      "epoch 5, step 24750/55000, batch loss = 0.37\n",
      "epoch 5, step 25000/55000, batch loss = 0.50\n",
      "Train accuracy = 96.28\n",
      "epoch 5, step 25250/55000, batch loss = 0.41\n",
      "epoch 5, step 25500/55000, batch loss = 0.46\n",
      "epoch 5, step 25750/55000, batch loss = 0.47\n",
      "epoch 5, step 26000/55000, batch loss = 0.46\n",
      "epoch 5, step 26250/55000, batch loss = 0.37\n",
      "epoch 5, step 26500/55000, batch loss = 0.45\n",
      "epoch 5, step 26750/55000, batch loss = 0.40\n",
      "epoch 5, step 27000/55000, batch loss = 0.47\n",
      "epoch 5, step 27250/55000, batch loss = 0.38\n",
      "epoch 5, step 27500/55000, batch loss = 0.35\n",
      "Train accuracy = 96.32\n",
      "epoch 5, step 27750/55000, batch loss = 0.51\n",
      "epoch 5, step 28000/55000, batch loss = 0.41\n",
      "epoch 5, step 28250/55000, batch loss = 0.44\n",
      "epoch 5, step 28500/55000, batch loss = 0.42\n",
      "epoch 5, step 28750/55000, batch loss = 0.50\n",
      "epoch 5, step 29000/55000, batch loss = 0.40\n",
      "epoch 5, step 29250/55000, batch loss = 0.44\n",
      "epoch 5, step 29500/55000, batch loss = 0.42\n",
      "epoch 5, step 29750/55000, batch loss = 0.38\n",
      "epoch 5, step 30000/55000, batch loss = 0.37\n",
      "Train accuracy = 96.33\n",
      "epoch 5, step 30250/55000, batch loss = 0.45\n",
      "epoch 5, step 30500/55000, batch loss = 0.40\n",
      "epoch 5, step 30750/55000, batch loss = 0.44\n",
      "epoch 5, step 31000/55000, batch loss = 0.46\n",
      "epoch 5, step 31250/55000, batch loss = 0.34\n",
      "epoch 5, step 31500/55000, batch loss = 0.56\n",
      "epoch 5, step 31750/55000, batch loss = 0.44\n",
      "epoch 5, step 32000/55000, batch loss = 0.42\n",
      "epoch 5, step 32250/55000, batch loss = 0.42\n",
      "epoch 5, step 32500/55000, batch loss = 0.48\n",
      "Train accuracy = 96.29\n",
      "epoch 5, step 32750/55000, batch loss = 0.40\n",
      "epoch 5, step 33000/55000, batch loss = 0.40\n",
      "epoch 5, step 33250/55000, batch loss = 0.41\n",
      "epoch 5, step 33500/55000, batch loss = 0.40\n",
      "epoch 5, step 33750/55000, batch loss = 0.38\n",
      "epoch 5, step 34000/55000, batch loss = 0.58\n",
      "epoch 5, step 34250/55000, batch loss = 0.36\n",
      "epoch 5, step 34500/55000, batch loss = 0.39\n",
      "epoch 5, step 34750/55000, batch loss = 0.37\n",
      "epoch 5, step 35000/55000, batch loss = 0.36\n",
      "Train accuracy = 96.31\n",
      "epoch 5, step 35250/55000, batch loss = 0.48\n",
      "epoch 5, step 35500/55000, batch loss = 0.38\n",
      "epoch 5, step 35750/55000, batch loss = 0.41\n",
      "epoch 5, step 36000/55000, batch loss = 0.42\n",
      "epoch 5, step 36250/55000, batch loss = 0.39\n",
      "epoch 5, step 36500/55000, batch loss = 0.44\n",
      "epoch 5, step 36750/55000, batch loss = 0.34\n",
      "epoch 5, step 37000/55000, batch loss = 0.36\n",
      "epoch 5, step 37250/55000, batch loss = 0.40\n",
      "epoch 5, step 37500/55000, batch loss = 0.39\n",
      "Train accuracy = 96.35\n",
      "epoch 5, step 37750/55000, batch loss = 0.34\n",
      "epoch 5, step 38000/55000, batch loss = 0.49\n",
      "epoch 5, step 38250/55000, batch loss = 0.48\n",
      "epoch 5, step 38500/55000, batch loss = 0.45\n",
      "epoch 5, step 38750/55000, batch loss = 0.47\n",
      "epoch 5, step 39000/55000, batch loss = 0.38\n",
      "epoch 5, step 39250/55000, batch loss = 0.38\n",
      "epoch 5, step 39500/55000, batch loss = 0.46\n",
      "epoch 5, step 39750/55000, batch loss = 0.38\n",
      "epoch 5, step 40000/55000, batch loss = 0.37\n",
      "Train accuracy = 96.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, step 40250/55000, batch loss = 0.36\n",
      "epoch 5, step 40500/55000, batch loss = 0.44\n",
      "epoch 5, step 40750/55000, batch loss = 0.37\n",
      "epoch 5, step 41000/55000, batch loss = 0.38\n",
      "epoch 5, step 41250/55000, batch loss = 0.49\n",
      "epoch 5, step 41500/55000, batch loss = 0.46\n",
      "epoch 5, step 41750/55000, batch loss = 0.52\n",
      "epoch 5, step 42000/55000, batch loss = 0.46\n",
      "epoch 5, step 42250/55000, batch loss = 0.48\n",
      "epoch 5, step 42500/55000, batch loss = 0.43\n",
      "Train accuracy = 96.31\n",
      "epoch 5, step 42750/55000, batch loss = 0.45\n",
      "epoch 5, step 43000/55000, batch loss = 0.48\n",
      "epoch 5, step 43250/55000, batch loss = 0.47\n",
      "epoch 5, step 43500/55000, batch loss = 0.44\n",
      "epoch 5, step 43750/55000, batch loss = 0.53\n",
      "epoch 5, step 44000/55000, batch loss = 0.41\n",
      "epoch 5, step 44250/55000, batch loss = 0.54\n",
      "epoch 5, step 44500/55000, batch loss = 0.37\n",
      "epoch 5, step 44750/55000, batch loss = 0.38\n",
      "epoch 5, step 45000/55000, batch loss = 0.48\n",
      "Train accuracy = 96.29\n",
      "epoch 5, step 45250/55000, batch loss = 0.38\n",
      "epoch 5, step 45500/55000, batch loss = 0.40\n",
      "epoch 5, step 45750/55000, batch loss = 0.46\n",
      "epoch 5, step 46000/55000, batch loss = 0.45\n",
      "epoch 5, step 46250/55000, batch loss = 0.36\n",
      "epoch 5, step 46500/55000, batch loss = 0.52\n",
      "epoch 5, step 46750/55000, batch loss = 0.53\n",
      "epoch 5, step 47000/55000, batch loss = 0.37\n",
      "epoch 5, step 47250/55000, batch loss = 0.53\n",
      "epoch 5, step 47500/55000, batch loss = 0.44\n",
      "Train accuracy = 96.32\n",
      "epoch 5, step 47750/55000, batch loss = 0.33\n",
      "epoch 5, step 48000/55000, batch loss = 0.41\n",
      "epoch 5, step 48250/55000, batch loss = 0.47\n",
      "epoch 5, step 48500/55000, batch loss = 0.39\n",
      "epoch 5, step 48750/55000, batch loss = 0.45\n",
      "epoch 5, step 49000/55000, batch loss = 0.38\n",
      "epoch 5, step 49250/55000, batch loss = 0.56\n",
      "epoch 5, step 49500/55000, batch loss = 0.47\n",
      "epoch 5, step 49750/55000, batch loss = 0.37\n",
      "epoch 5, step 50000/55000, batch loss = 0.37\n",
      "Train accuracy = 96.30\n",
      "epoch 5, step 50250/55000, batch loss = 0.32\n",
      "epoch 5, step 50500/55000, batch loss = 0.36\n",
      "epoch 5, step 50750/55000, batch loss = 0.37\n",
      "epoch 5, step 51000/55000, batch loss = 0.37\n",
      "epoch 5, step 51250/55000, batch loss = 0.37\n",
      "epoch 5, step 51500/55000, batch loss = 0.47\n",
      "epoch 5, step 51750/55000, batch loss = 0.39\n",
      "epoch 5, step 52000/55000, batch loss = 0.44\n",
      "epoch 5, step 52250/55000, batch loss = 0.44\n",
      "epoch 5, step 52500/55000, batch loss = 0.36\n",
      "Train accuracy = 96.29\n",
      "epoch 5, step 52750/55000, batch loss = 0.42\n",
      "epoch 5, step 53000/55000, batch loss = 0.52\n",
      "epoch 5, step 53250/55000, batch loss = 0.39\n",
      "epoch 5, step 53500/55000, batch loss = 0.55\n",
      "epoch 5, step 53750/55000, batch loss = 0.43\n",
      "epoch 5, step 54000/55000, batch loss = 0.34\n",
      "epoch 5, step 54250/55000, batch loss = 0.40\n",
      "epoch 5, step 54500/55000, batch loss = 0.46\n",
      "epoch 5, step 54750/55000, batch loss = 0.50\n",
      "Train accuracy = 96.27\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 96.70\n",
      "Validation avg loss = 0.41\n",
      "\n",
      "\n",
      "Running evaluation:  Test\n",
      "Test accuracy = 96.52\n",
      "Test avg loss = 0.41\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LAMBDA: 0.01 \n",
      "\n",
      "epoch 1, step 0/55000, batch loss = 6.70\n",
      "epoch 1, step 250/55000, batch loss = 6.46\n",
      "epoch 1, step 500/55000, batch loss = 5.90\n",
      "epoch 1, step 750/55000, batch loss = 5.85\n",
      "epoch 1, step 1000/55000, batch loss = 5.26\n",
      "epoch 1, step 1250/55000, batch loss = 4.91\n",
      "epoch 1, step 1500/55000, batch loss = 4.72\n",
      "epoch 1, step 1750/55000, batch loss = 4.44\n",
      "epoch 1, step 2000/55000, batch loss = 4.84\n",
      "epoch 1, step 2250/55000, batch loss = 4.26\n",
      "epoch 1, step 2500/55000, batch loss = 4.28\n",
      "Train accuracy = 67.53\n",
      "epoch 1, step 2750/55000, batch loss = 4.66\n",
      "epoch 1, step 3000/55000, batch loss = 4.36\n",
      "epoch 1, step 3250/55000, batch loss = 4.16\n",
      "epoch 1, step 3500/55000, batch loss = 4.36\n",
      "epoch 1, step 3750/55000, batch loss = 4.14\n",
      "epoch 1, step 4000/55000, batch loss = 3.95\n",
      "epoch 1, step 4250/55000, batch loss = 4.01\n",
      "epoch 1, step 4500/55000, batch loss = 3.98\n",
      "epoch 1, step 4750/55000, batch loss = 3.87\n",
      "epoch 1, step 5000/55000, batch loss = 3.88\n",
      "Train accuracy = 78.85\n",
      "epoch 1, step 5250/55000, batch loss = 3.85\n",
      "epoch 1, step 5500/55000, batch loss = 3.68\n",
      "epoch 1, step 5750/55000, batch loss = 3.67\n",
      "epoch 1, step 6000/55000, batch loss = 3.81\n",
      "epoch 1, step 6250/55000, batch loss = 3.78\n",
      "epoch 1, step 6500/55000, batch loss = 3.63\n",
      "epoch 1, step 6750/55000, batch loss = 3.55\n",
      "epoch 1, step 7000/55000, batch loss = 3.56\n",
      "epoch 1, step 7250/55000, batch loss = 3.69\n",
      "epoch 1, step 7500/55000, batch loss = 3.35\n",
      "Train accuracy = 83.54\n",
      "epoch 1, step 7750/55000, batch loss = 3.51\n",
      "epoch 1, step 8000/55000, batch loss = 3.38\n",
      "epoch 1, step 8250/55000, batch loss = 3.38\n",
      "epoch 1, step 8500/55000, batch loss = 3.47\n",
      "epoch 1, step 8750/55000, batch loss = 3.23\n",
      "epoch 1, step 9000/55000, batch loss = 3.39\n",
      "epoch 1, step 9250/55000, batch loss = 3.29\n",
      "epoch 1, step 9500/55000, batch loss = 3.23\n",
      "epoch 1, step 9750/55000, batch loss = 3.19\n",
      "epoch 1, step 10000/55000, batch loss = 3.11\n",
      "Train accuracy = 86.22\n",
      "epoch 1, step 10250/55000, batch loss = 3.05\n",
      "epoch 1, step 10500/55000, batch loss = 3.17\n",
      "epoch 1, step 10750/55000, batch loss = 3.01\n",
      "epoch 1, step 11000/55000, batch loss = 2.99\n",
      "epoch 1, step 11250/55000, batch loss = 3.02\n",
      "epoch 1, step 11500/55000, batch loss = 3.18\n",
      "epoch 1, step 11750/55000, batch loss = 2.87\n",
      "epoch 1, step 12000/55000, batch loss = 2.89\n",
      "epoch 1, step 12250/55000, batch loss = 2.79\n",
      "epoch 1, step 12500/55000, batch loss = 2.83\n",
      "Train accuracy = 88.04\n",
      "epoch 1, step 12750/55000, batch loss = 2.87\n",
      "epoch 1, step 13000/55000, batch loss = 2.80\n",
      "epoch 1, step 13250/55000, batch loss = 2.80\n",
      "epoch 1, step 13500/55000, batch loss = 2.78\n",
      "epoch 1, step 13750/55000, batch loss = 2.71\n",
      "epoch 1, step 14000/55000, batch loss = 2.79\n",
      "epoch 1, step 14250/55000, batch loss = 2.62\n",
      "epoch 1, step 14500/55000, batch loss = 2.56\n",
      "epoch 1, step 14750/55000, batch loss = 2.62\n",
      "epoch 1, step 15000/55000, batch loss = 2.68\n",
      "Train accuracy = 89.22\n",
      "epoch 1, step 15250/55000, batch loss = 2.57\n",
      "epoch 1, step 15500/55000, batch loss = 2.45\n",
      "epoch 1, step 15750/55000, batch loss = 2.65\n",
      "epoch 1, step 16000/55000, batch loss = 2.52\n",
      "epoch 1, step 16250/55000, batch loss = 2.48\n",
      "epoch 1, step 16500/55000, batch loss = 2.52\n",
      "epoch 1, step 16750/55000, batch loss = 2.55\n",
      "epoch 1, step 17000/55000, batch loss = 2.48\n",
      "epoch 1, step 17250/55000, batch loss = 2.35\n",
      "epoch 1, step 17500/55000, batch loss = 2.33\n",
      "Train accuracy = 90.08\n",
      "epoch 1, step 17750/55000, batch loss = 2.27\n",
      "epoch 1, step 18000/55000, batch loss = 2.27\n",
      "epoch 1, step 18250/55000, batch loss = 2.30\n",
      "epoch 1, step 18500/55000, batch loss = 2.24\n",
      "epoch 1, step 18750/55000, batch loss = 2.24\n",
      "epoch 1, step 19000/55000, batch loss = 2.19\n",
      "epoch 1, step 19250/55000, batch loss = 2.14\n",
      "epoch 1, step 19500/55000, batch loss = 2.18\n",
      "epoch 1, step 19750/55000, batch loss = 2.18\n",
      "epoch 1, step 20000/55000, batch loss = 2.19\n",
      "Train accuracy = 90.84\n",
      "epoch 1, step 20250/55000, batch loss = 2.13\n",
      "epoch 1, step 20500/55000, batch loss = 2.04\n",
      "epoch 1, step 20750/55000, batch loss = 2.09\n",
      "epoch 1, step 21000/55000, batch loss = 2.02\n",
      "epoch 1, step 21250/55000, batch loss = 1.97\n",
      "epoch 1, step 21500/55000, batch loss = 2.14\n",
      "epoch 1, step 21750/55000, batch loss = 2.18\n",
      "epoch 1, step 22000/55000, batch loss = 2.00\n",
      "epoch 1, step 22250/55000, batch loss = 1.98\n",
      "epoch 1, step 22500/55000, batch loss = 2.04\n",
      "Train accuracy = 91.43\n",
      "epoch 1, step 22750/55000, batch loss = 1.90\n",
      "epoch 1, step 23000/55000, batch loss = 2.09\n",
      "epoch 1, step 23250/55000, batch loss = 2.23\n",
      "epoch 1, step 23500/55000, batch loss = 1.96\n",
      "epoch 1, step 23750/55000, batch loss = 1.82\n",
      "epoch 1, step 24000/55000, batch loss = 1.78\n",
      "epoch 1, step 24250/55000, batch loss = 1.98\n",
      "epoch 1, step 24500/55000, batch loss = 1.84\n",
      "epoch 1, step 24750/55000, batch loss = 1.90\n",
      "epoch 1, step 25000/55000, batch loss = 1.85\n",
      "Train accuracy = 91.92\n",
      "epoch 1, step 25250/55000, batch loss = 1.77\n",
      "epoch 1, step 25500/55000, batch loss = 1.74\n",
      "epoch 1, step 25750/55000, batch loss = 1.71\n",
      "epoch 1, step 26000/55000, batch loss = 1.77\n",
      "epoch 1, step 26250/55000, batch loss = 1.65\n",
      "epoch 1, step 26500/55000, batch loss = 1.66\n",
      "epoch 1, step 26750/55000, batch loss = 1.62\n",
      "epoch 1, step 27000/55000, batch loss = 1.66\n",
      "epoch 1, step 27250/55000, batch loss = 1.63\n",
      "epoch 1, step 27500/55000, batch loss = 1.65\n",
      "Train accuracy = 92.35\n",
      "epoch 1, step 27750/55000, batch loss = 1.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 28000/55000, batch loss = 1.65\n",
      "epoch 1, step 28250/55000, batch loss = 1.60\n",
      "epoch 1, step 28500/55000, batch loss = 1.69\n",
      "epoch 1, step 28750/55000, batch loss = 1.58\n",
      "epoch 1, step 29000/55000, batch loss = 1.57\n",
      "epoch 1, step 29250/55000, batch loss = 1.84\n",
      "epoch 1, step 29500/55000, batch loss = 1.55\n",
      "epoch 1, step 29750/55000, batch loss = 1.50\n",
      "epoch 1, step 30000/55000, batch loss = 1.42\n",
      "Train accuracy = 92.70\n",
      "epoch 1, step 30250/55000, batch loss = 1.63\n",
      "epoch 1, step 30500/55000, batch loss = 1.50\n",
      "epoch 1, step 30750/55000, batch loss = 1.44\n",
      "epoch 1, step 31000/55000, batch loss = 1.40\n",
      "epoch 1, step 31250/55000, batch loss = 1.44\n",
      "epoch 1, step 31500/55000, batch loss = 1.50\n",
      "epoch 1, step 31750/55000, batch loss = 1.37\n",
      "epoch 1, step 32000/55000, batch loss = 1.32\n",
      "epoch 1, step 32250/55000, batch loss = 1.40\n",
      "epoch 1, step 32500/55000, batch loss = 1.35\n",
      "Train accuracy = 92.99\n",
      "epoch 1, step 32750/55000, batch loss = 1.41\n",
      "epoch 1, step 33000/55000, batch loss = 1.31\n",
      "epoch 1, step 33250/55000, batch loss = 1.28\n",
      "epoch 1, step 33500/55000, batch loss = 1.53\n",
      "epoch 1, step 33750/55000, batch loss = 1.27\n",
      "epoch 1, step 34000/55000, batch loss = 1.33\n",
      "epoch 1, step 34250/55000, batch loss = 1.27\n",
      "epoch 1, step 34500/55000, batch loss = 1.28\n",
      "epoch 1, step 34750/55000, batch loss = 1.21\n",
      "epoch 1, step 35000/55000, batch loss = 1.28\n",
      "Train accuracy = 93.29\n",
      "epoch 1, step 35250/55000, batch loss = 1.18\n",
      "epoch 1, step 35500/55000, batch loss = 1.22\n",
      "epoch 1, step 35750/55000, batch loss = 1.61\n",
      "epoch 1, step 36000/55000, batch loss = 1.26\n",
      "epoch 1, step 36250/55000, batch loss = 1.29\n",
      "epoch 1, step 36500/55000, batch loss = 1.17\n",
      "epoch 1, step 36750/55000, batch loss = 1.20\n",
      "epoch 1, step 37000/55000, batch loss = 1.15\n",
      "epoch 1, step 37250/55000, batch loss = 1.14\n",
      "epoch 1, step 37500/55000, batch loss = 1.11\n",
      "Train accuracy = 93.49\n",
      "epoch 1, step 37750/55000, batch loss = 1.21\n",
      "epoch 1, step 38000/55000, batch loss = 1.16\n",
      "epoch 1, step 38250/55000, batch loss = 1.15\n",
      "epoch 1, step 38500/55000, batch loss = 1.26\n",
      "epoch 1, step 38750/55000, batch loss = 1.12\n",
      "epoch 1, step 39000/55000, batch loss = 1.11\n",
      "epoch 1, step 39250/55000, batch loss = 1.09\n",
      "epoch 1, step 39500/55000, batch loss = 1.04\n",
      "epoch 1, step 39750/55000, batch loss = 1.11\n",
      "epoch 1, step 40000/55000, batch loss = 1.08\n",
      "Train accuracy = 93.70\n",
      "epoch 1, step 40250/55000, batch loss = 1.01\n",
      "epoch 1, step 40500/55000, batch loss = 1.06\n",
      "epoch 1, step 40750/55000, batch loss = 0.97\n",
      "epoch 1, step 41000/55000, batch loss = 0.99\n",
      "epoch 1, step 41250/55000, batch loss = 0.98\n",
      "epoch 1, step 41500/55000, batch loss = 0.99\n",
      "epoch 1, step 41750/55000, batch loss = 1.00\n",
      "epoch 1, step 42000/55000, batch loss = 0.97\n",
      "epoch 1, step 42250/55000, batch loss = 0.94\n",
      "epoch 1, step 42500/55000, batch loss = 0.96\n",
      "Train accuracy = 93.94\n",
      "epoch 1, step 42750/55000, batch loss = 0.93\n",
      "epoch 1, step 43000/55000, batch loss = 1.11\n",
      "epoch 1, step 43250/55000, batch loss = 0.92\n",
      "epoch 1, step 43500/55000, batch loss = 0.93\n",
      "epoch 1, step 43750/55000, batch loss = 0.90\n",
      "epoch 1, step 44000/55000, batch loss = 1.12\n",
      "epoch 1, step 44250/55000, batch loss = 0.91\n",
      "epoch 1, step 44500/55000, batch loss = 0.93\n",
      "epoch 1, step 44750/55000, batch loss = 0.87\n",
      "epoch 1, step 45000/55000, batch loss = 0.98\n",
      "Train accuracy = 94.06\n",
      "epoch 1, step 45250/55000, batch loss = 0.83\n",
      "epoch 1, step 45500/55000, batch loss = 1.12\n",
      "epoch 1, step 45750/55000, batch loss = 0.81\n",
      "epoch 1, step 46000/55000, batch loss = 0.83\n",
      "epoch 1, step 46250/55000, batch loss = 0.98\n",
      "epoch 1, step 46500/55000, batch loss = 0.85\n",
      "epoch 1, step 46750/55000, batch loss = 0.83\n",
      "epoch 1, step 47000/55000, batch loss = 0.81\n",
      "epoch 1, step 47250/55000, batch loss = 0.85\n",
      "epoch 1, step 47500/55000, batch loss = 0.82\n",
      "Train accuracy = 94.24\n",
      "epoch 1, step 47750/55000, batch loss = 0.85\n",
      "epoch 1, step 48000/55000, batch loss = 0.80\n",
      "epoch 1, step 48250/55000, batch loss = 0.79\n",
      "epoch 1, step 48500/55000, batch loss = 0.90\n",
      "epoch 1, step 48750/55000, batch loss = 0.86\n",
      "epoch 1, step 49000/55000, batch loss = 0.85\n",
      "epoch 1, step 49250/55000, batch loss = 0.83\n",
      "epoch 1, step 49500/55000, batch loss = 0.80\n",
      "epoch 1, step 49750/55000, batch loss = 0.80\n",
      "epoch 1, step 50000/55000, batch loss = 0.92\n",
      "Train accuracy = 94.36\n",
      "epoch 1, step 50250/55000, batch loss = 0.75\n",
      "epoch 1, step 50500/55000, batch loss = 0.72\n",
      "epoch 1, step 50750/55000, batch loss = 0.70\n",
      "epoch 1, step 51000/55000, batch loss = 0.70\n",
      "epoch 1, step 51250/55000, batch loss = 0.78\n",
      "epoch 1, step 51500/55000, batch loss = 0.71\n",
      "epoch 1, step 51750/55000, batch loss = 0.87\n",
      "epoch 1, step 52000/55000, batch loss = 0.83\n",
      "epoch 1, step 52250/55000, batch loss = 0.75\n",
      "epoch 1, step 52500/55000, batch loss = 0.67\n",
      "Train accuracy = 94.49\n",
      "epoch 1, step 52750/55000, batch loss = 0.71\n",
      "epoch 1, step 53000/55000, batch loss = 0.68\n",
      "epoch 1, step 53250/55000, batch loss = 0.66\n",
      "epoch 1, step 53500/55000, batch loss = 0.80\n",
      "epoch 1, step 53750/55000, batch loss = 0.64\n",
      "epoch 1, step 54000/55000, batch loss = 0.74\n",
      "epoch 1, step 54250/55000, batch loss = 0.72\n",
      "epoch 1, step 54500/55000, batch loss = 0.67\n",
      "epoch 1, step 54750/55000, batch loss = 0.71\n",
      "Train accuracy = 94.63\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 97.84\n",
      "Validation avg loss = 0.66\n",
      "\n",
      "epoch 2, step 0/55000, batch loss = 0.66\n",
      "epoch 2, step 250/55000, batch loss = 0.68\n",
      "epoch 2, step 500/55000, batch loss = 0.64\n",
      "epoch 2, step 750/55000, batch loss = 0.62\n",
      "epoch 2, step 1000/55000, batch loss = 0.72\n",
      "epoch 2, step 1250/55000, batch loss = 0.61\n",
      "epoch 2, step 1500/55000, batch loss = 0.62\n",
      "epoch 2, step 1750/55000, batch loss = 0.62\n",
      "epoch 2, step 2000/55000, batch loss = 0.66\n",
      "epoch 2, step 2250/55000, batch loss = 0.71\n",
      "epoch 2, step 2500/55000, batch loss = 0.57\n",
      "Train accuracy = 97.18\n",
      "epoch 2, step 2750/55000, batch loss = 0.58\n",
      "epoch 2, step 3000/55000, batch loss = 0.56\n",
      "epoch 2, step 3250/55000, batch loss = 0.59\n",
      "epoch 2, step 3500/55000, batch loss = 0.56\n",
      "epoch 2, step 3750/55000, batch loss = 0.61\n",
      "epoch 2, step 4000/55000, batch loss = 0.52\n",
      "epoch 2, step 4250/55000, batch loss = 0.63\n",
      "epoch 2, step 4500/55000, batch loss = 0.63\n",
      "epoch 2, step 4750/55000, batch loss = 0.71\n",
      "epoch 2, step 5000/55000, batch loss = 0.56\n",
      "Train accuracy = 97.21\n",
      "epoch 2, step 5250/55000, batch loss = 0.57\n",
      "epoch 2, step 5500/55000, batch loss = 0.56\n",
      "epoch 2, step 5750/55000, batch loss = 0.63\n",
      "epoch 2, step 6000/55000, batch loss = 0.62\n",
      "epoch 2, step 6250/55000, batch loss = 0.56\n",
      "epoch 2, step 6500/55000, batch loss = 0.50\n",
      "epoch 2, step 6750/55000, batch loss = 0.59\n",
      "epoch 2, step 7000/55000, batch loss = 0.51\n",
      "epoch 2, step 7250/55000, batch loss = 0.53\n",
      "epoch 2, step 7500/55000, batch loss = 0.69\n",
      "Train accuracy = 97.31\n",
      "epoch 2, step 7750/55000, batch loss = 0.54\n",
      "epoch 2, step 8000/55000, batch loss = 0.50\n",
      "epoch 2, step 8250/55000, batch loss = 0.50\n",
      "epoch 2, step 8500/55000, batch loss = 0.52\n",
      "epoch 2, step 8750/55000, batch loss = 0.58\n",
      "epoch 2, step 9000/55000, batch loss = 0.54\n",
      "epoch 2, step 9250/55000, batch loss = 0.46\n",
      "epoch 2, step 9500/55000, batch loss = 0.46\n",
      "epoch 2, step 9750/55000, batch loss = 0.60\n",
      "epoch 2, step 10000/55000, batch loss = 0.50\n",
      "Train accuracy = 97.30\n",
      "epoch 2, step 10250/55000, batch loss = 0.56\n",
      "epoch 2, step 10500/55000, batch loss = 0.60\n",
      "epoch 2, step 10750/55000, batch loss = 0.48\n",
      "epoch 2, step 11000/55000, batch loss = 0.46\n",
      "epoch 2, step 11250/55000, batch loss = 0.52\n",
      "epoch 2, step 11500/55000, batch loss = 0.57\n",
      "epoch 2, step 11750/55000, batch loss = 0.48\n",
      "epoch 2, step 12000/55000, batch loss = 0.46\n",
      "epoch 2, step 12250/55000, batch loss = 0.47\n",
      "epoch 2, step 12500/55000, batch loss = 0.52\n",
      "Train accuracy = 97.31\n",
      "epoch 2, step 12750/55000, batch loss = 0.48\n",
      "epoch 2, step 13000/55000, batch loss = 0.51\n",
      "epoch 2, step 13250/55000, batch loss = 0.47\n",
      "epoch 2, step 13500/55000, batch loss = 0.59\n",
      "epoch 2, step 13750/55000, batch loss = 0.47\n",
      "epoch 2, step 14000/55000, batch loss = 0.40\n",
      "epoch 2, step 14250/55000, batch loss = 0.42\n",
      "epoch 2, step 14500/55000, batch loss = 0.45\n",
      "epoch 2, step 14750/55000, batch loss = 0.39\n",
      "epoch 2, step 15000/55000, batch loss = 0.42\n",
      "Train accuracy = 97.26\n",
      "epoch 2, step 15250/55000, batch loss = 0.50\n",
      "epoch 2, step 15500/55000, batch loss = 0.64\n",
      "epoch 2, step 15750/55000, batch loss = 0.49\n",
      "epoch 2, step 16000/55000, batch loss = 0.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, step 16250/55000, batch loss = 0.43\n",
      "epoch 2, step 16500/55000, batch loss = 0.39\n",
      "epoch 2, step 16750/55000, batch loss = 0.48\n",
      "epoch 2, step 17000/55000, batch loss = 0.46\n",
      "epoch 2, step 17250/55000, batch loss = 0.44\n",
      "epoch 2, step 17500/55000, batch loss = 0.51\n",
      "Train accuracy = 97.29\n",
      "epoch 2, step 17750/55000, batch loss = 0.46\n",
      "epoch 2, step 18000/55000, batch loss = 0.39\n",
      "epoch 2, step 18250/55000, batch loss = 0.46\n",
      "epoch 2, step 18500/55000, batch loss = 0.44\n",
      "epoch 2, step 18750/55000, batch loss = 0.37\n",
      "epoch 2, step 19000/55000, batch loss = 0.42\n",
      "epoch 2, step 19250/55000, batch loss = 0.36\n",
      "epoch 2, step 19500/55000, batch loss = 0.42\n",
      "epoch 2, step 19750/55000, batch loss = 0.43\n",
      "epoch 2, step 20000/55000, batch loss = 0.48\n",
      "Train accuracy = 97.31\n",
      "epoch 2, step 20250/55000, batch loss = 0.42\n",
      "epoch 2, step 20500/55000, batch loss = 0.46\n",
      "epoch 2, step 20750/55000, batch loss = 0.42\n",
      "epoch 2, step 21000/55000, batch loss = 0.57\n",
      "epoch 2, step 21250/55000, batch loss = 0.37\n",
      "epoch 2, step 21500/55000, batch loss = 0.41\n",
      "epoch 2, step 21750/55000, batch loss = 0.38\n",
      "epoch 2, step 22000/55000, batch loss = 0.55\n",
      "epoch 2, step 22250/55000, batch loss = 0.36\n",
      "epoch 2, step 22500/55000, batch loss = 0.53\n",
      "Train accuracy = 97.30\n",
      "epoch 2, step 22750/55000, batch loss = 0.37\n",
      "epoch 2, step 23000/55000, batch loss = 0.37\n",
      "epoch 2, step 23250/55000, batch loss = 0.35\n",
      "epoch 2, step 23500/55000, batch loss = 0.35\n",
      "epoch 2, step 23750/55000, batch loss = 0.32\n",
      "epoch 2, step 24000/55000, batch loss = 0.33\n",
      "epoch 2, step 24250/55000, batch loss = 0.35\n",
      "epoch 2, step 24500/55000, batch loss = 0.38\n",
      "epoch 2, step 24750/55000, batch loss = 0.48\n",
      "epoch 2, step 25000/55000, batch loss = 0.39\n",
      "Train accuracy = 97.32\n",
      "epoch 2, step 25250/55000, batch loss = 0.45\n",
      "epoch 2, step 25500/55000, batch loss = 0.33\n",
      "epoch 2, step 25750/55000, batch loss = 0.31\n",
      "epoch 2, step 26000/55000, batch loss = 0.39\n",
      "epoch 2, step 26250/55000, batch loss = 0.32\n",
      "epoch 2, step 26500/55000, batch loss = 0.37\n",
      "epoch 2, step 26750/55000, batch loss = 0.41\n",
      "epoch 2, step 27000/55000, batch loss = 0.34\n",
      "epoch 2, step 27250/55000, batch loss = 0.34\n",
      "epoch 2, step 27500/55000, batch loss = 0.40\n",
      "Train accuracy = 97.32\n",
      "epoch 2, step 27750/55000, batch loss = 0.38\n",
      "epoch 2, step 28000/55000, batch loss = 0.27\n",
      "epoch 2, step 28250/55000, batch loss = 0.31\n",
      "epoch 2, step 28500/55000, batch loss = 0.38\n",
      "epoch 2, step 28750/55000, batch loss = 0.33\n",
      "epoch 2, step 29000/55000, batch loss = 0.33\n",
      "epoch 2, step 29250/55000, batch loss = 0.30\n",
      "epoch 2, step 29500/55000, batch loss = 0.27\n",
      "epoch 2, step 29750/55000, batch loss = 0.30\n",
      "epoch 2, step 30000/55000, batch loss = 0.29\n",
      "Train accuracy = 97.33\n",
      "epoch 2, step 30250/55000, batch loss = 0.30\n",
      "epoch 2, step 30500/55000, batch loss = 0.29\n",
      "epoch 2, step 30750/55000, batch loss = 0.39\n",
      "epoch 2, step 31000/55000, batch loss = 0.34\n",
      "epoch 2, step 31250/55000, batch loss = 0.26\n",
      "epoch 2, step 31500/55000, batch loss = 0.27\n",
      "epoch 2, step 31750/55000, batch loss = 0.26\n",
      "epoch 2, step 32000/55000, batch loss = 0.44\n",
      "epoch 2, step 32250/55000, batch loss = 0.27\n",
      "epoch 2, step 32500/55000, batch loss = 0.37\n",
      "Train accuracy = 97.33\n",
      "epoch 2, step 32750/55000, batch loss = 0.34\n",
      "epoch 2, step 33000/55000, batch loss = 0.29\n",
      "epoch 2, step 33250/55000, batch loss = 0.33\n",
      "epoch 2, step 33500/55000, batch loss = 0.32\n",
      "epoch 2, step 33750/55000, batch loss = 0.32\n",
      "epoch 2, step 34000/55000, batch loss = 0.26\n",
      "epoch 2, step 34250/55000, batch loss = 0.27\n",
      "epoch 2, step 34500/55000, batch loss = 0.27\n",
      "epoch 2, step 34750/55000, batch loss = 0.25\n",
      "epoch 2, step 35000/55000, batch loss = 0.33\n",
      "Train accuracy = 97.34\n",
      "epoch 2, step 35250/55000, batch loss = 0.31\n",
      "epoch 2, step 35500/55000, batch loss = 0.32\n",
      "epoch 2, step 35750/55000, batch loss = 0.30\n",
      "epoch 2, step 36000/55000, batch loss = 0.37\n",
      "epoch 2, step 36250/55000, batch loss = 0.26\n",
      "epoch 2, step 36500/55000, batch loss = 0.29\n",
      "epoch 2, step 36750/55000, batch loss = 0.32\n",
      "epoch 2, step 37000/55000, batch loss = 0.27\n",
      "epoch 2, step 37250/55000, batch loss = 0.37\n",
      "epoch 2, step 37500/55000, batch loss = 0.26\n",
      "Train accuracy = 97.36\n",
      "epoch 2, step 37750/55000, batch loss = 0.23\n",
      "epoch 2, step 38000/55000, batch loss = 0.27\n",
      "epoch 2, step 38250/55000, batch loss = 0.33\n",
      "epoch 2, step 38500/55000, batch loss = 0.23\n",
      "epoch 2, step 38750/55000, batch loss = 0.36\n",
      "epoch 2, step 39000/55000, batch loss = 0.33\n",
      "epoch 2, step 39250/55000, batch loss = 0.52\n",
      "epoch 2, step 39500/55000, batch loss = 0.23\n",
      "epoch 2, step 39750/55000, batch loss = 0.25\n",
      "epoch 2, step 40000/55000, batch loss = 0.42\n",
      "Train accuracy = 97.37\n",
      "epoch 2, step 40250/55000, batch loss = 0.27\n",
      "epoch 2, step 40500/55000, batch loss = 0.29\n",
      "epoch 2, step 40750/55000, batch loss = 0.26\n",
      "epoch 2, step 41000/55000, batch loss = 0.26\n",
      "epoch 2, step 41250/55000, batch loss = 0.26\n",
      "epoch 2, step 41500/55000, batch loss = 0.28\n",
      "epoch 2, step 41750/55000, batch loss = 0.23\n",
      "epoch 2, step 42000/55000, batch loss = 0.26\n",
      "epoch 2, step 42250/55000, batch loss = 0.23\n",
      "epoch 2, step 42500/55000, batch loss = 0.36\n",
      "Train accuracy = 97.36\n",
      "epoch 2, step 42750/55000, batch loss = 0.22\n",
      "epoch 2, step 43000/55000, batch loss = 0.39\n",
      "epoch 2, step 43250/55000, batch loss = 0.24\n",
      "epoch 2, step 43500/55000, batch loss = 0.24\n",
      "epoch 2, step 43750/55000, batch loss = 0.25\n",
      "epoch 2, step 44000/55000, batch loss = 0.29\n",
      "epoch 2, step 44250/55000, batch loss = 0.25\n",
      "epoch 2, step 44500/55000, batch loss = 0.21\n",
      "epoch 2, step 44750/55000, batch loss = 0.36\n",
      "epoch 2, step 45000/55000, batch loss = 0.23\n",
      "Train accuracy = 97.35\n",
      "epoch 2, step 45250/55000, batch loss = 0.20\n",
      "epoch 2, step 45500/55000, batch loss = 0.34\n",
      "epoch 2, step 45750/55000, batch loss = 0.28\n",
      "epoch 2, step 46000/55000, batch loss = 0.24\n",
      "epoch 2, step 46250/55000, batch loss = 0.24\n",
      "epoch 2, step 46500/55000, batch loss = 0.24\n",
      "epoch 2, step 46750/55000, batch loss = 0.25\n",
      "epoch 2, step 47000/55000, batch loss = 0.22\n",
      "epoch 2, step 47250/55000, batch loss = 0.19\n",
      "epoch 2, step 47500/55000, batch loss = 0.27\n",
      "Train accuracy = 97.38\n",
      "epoch 2, step 47750/55000, batch loss = 0.27\n",
      "epoch 2, step 48000/55000, batch loss = 0.37\n",
      "epoch 2, step 48250/55000, batch loss = 0.20\n",
      "epoch 2, step 48500/55000, batch loss = 0.25\n",
      "epoch 2, step 48750/55000, batch loss = 0.25\n",
      "epoch 2, step 49000/55000, batch loss = 0.20\n",
      "epoch 2, step 49250/55000, batch loss = 0.28\n",
      "epoch 2, step 49500/55000, batch loss = 0.24\n",
      "epoch 2, step 49750/55000, batch loss = 0.33\n",
      "epoch 2, step 50000/55000, batch loss = 0.20\n",
      "Train accuracy = 97.41\n",
      "epoch 2, step 50250/55000, batch loss = 0.18\n",
      "epoch 2, step 50500/55000, batch loss = 0.28\n",
      "epoch 2, step 50750/55000, batch loss = 0.30\n",
      "epoch 2, step 51000/55000, batch loss = 0.20\n",
      "epoch 2, step 51250/55000, batch loss = 0.21\n",
      "epoch 2, step 51500/55000, batch loss = 0.21\n",
      "epoch 2, step 51750/55000, batch loss = 0.20\n",
      "epoch 2, step 52000/55000, batch loss = 0.19\n",
      "epoch 2, step 52250/55000, batch loss = 0.24\n",
      "epoch 2, step 52500/55000, batch loss = 0.18\n",
      "Train accuracy = 97.40\n",
      "epoch 2, step 52750/55000, batch loss = 0.21\n",
      "epoch 2, step 53000/55000, batch loss = 0.23\n",
      "epoch 2, step 53250/55000, batch loss = 0.22\n",
      "epoch 2, step 53500/55000, batch loss = 0.17\n",
      "epoch 2, step 53750/55000, batch loss = 0.33\n",
      "epoch 2, step 54000/55000, batch loss = 0.33\n",
      "epoch 2, step 54250/55000, batch loss = 0.27\n",
      "epoch 2, step 54500/55000, batch loss = 0.28\n",
      "epoch 2, step 54750/55000, batch loss = 0.22\n",
      "Train accuracy = 97.40\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 97.92\n",
      "Validation avg loss = 0.23\n",
      "\n",
      "epoch 3, step 0/55000, batch loss = 0.23\n",
      "epoch 3, step 250/55000, batch loss = 0.19\n",
      "epoch 3, step 500/55000, batch loss = 0.26\n",
      "epoch 3, step 750/55000, batch loss = 0.25\n",
      "epoch 3, step 1000/55000, batch loss = 0.17\n",
      "epoch 3, step 1250/55000, batch loss = 0.19\n",
      "epoch 3, step 1500/55000, batch loss = 0.19\n",
      "epoch 3, step 1750/55000, batch loss = 0.20\n",
      "epoch 3, step 2000/55000, batch loss = 0.20\n",
      "epoch 3, step 2250/55000, batch loss = 0.24\n",
      "epoch 3, step 2500/55000, batch loss = 0.20\n",
      "Train accuracy = 97.73\n",
      "epoch 3, step 2750/55000, batch loss = 0.16\n",
      "epoch 3, step 3000/55000, batch loss = 0.23\n",
      "epoch 3, step 3250/55000, batch loss = 0.20\n",
      "epoch 3, step 3500/55000, batch loss = 0.22\n",
      "epoch 3, step 3750/55000, batch loss = 0.18\n",
      "epoch 3, step 4000/55000, batch loss = 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, step 4250/55000, batch loss = 0.18\n",
      "epoch 3, step 4500/55000, batch loss = 0.19\n",
      "epoch 3, step 4750/55000, batch loss = 0.31\n",
      "epoch 3, step 5000/55000, batch loss = 0.20\n",
      "Train accuracy = 98.02\n",
      "epoch 3, step 5250/55000, batch loss = 0.28\n",
      "epoch 3, step 5500/55000, batch loss = 0.19\n",
      "epoch 3, step 5750/55000, batch loss = 0.17\n",
      "epoch 3, step 6000/55000, batch loss = 0.17\n",
      "epoch 3, step 6250/55000, batch loss = 0.16\n",
      "epoch 3, step 6500/55000, batch loss = 0.22\n",
      "epoch 3, step 6750/55000, batch loss = 0.18\n",
      "epoch 3, step 7000/55000, batch loss = 0.18\n",
      "epoch 3, step 7250/55000, batch loss = 0.21\n",
      "epoch 3, step 7500/55000, batch loss = 0.19\n",
      "Train accuracy = 98.26\n",
      "epoch 3, step 7750/55000, batch loss = 0.16\n",
      "epoch 3, step 8000/55000, batch loss = 0.23\n",
      "epoch 3, step 8250/55000, batch loss = 0.26\n",
      "epoch 3, step 8500/55000, batch loss = 0.17\n",
      "epoch 3, step 8750/55000, batch loss = 0.19\n",
      "epoch 3, step 9000/55000, batch loss = 0.19\n",
      "epoch 3, step 9250/55000, batch loss = 0.16\n",
      "epoch 3, step 9500/55000, batch loss = 0.17\n",
      "epoch 3, step 9750/55000, batch loss = 0.21\n",
      "epoch 3, step 10000/55000, batch loss = 0.17\n",
      "Train accuracy = 98.36\n",
      "epoch 3, step 10250/55000, batch loss = 0.21\n",
      "epoch 3, step 10500/55000, batch loss = 0.19\n",
      "epoch 3, step 10750/55000, batch loss = 0.22\n",
      "epoch 3, step 11000/55000, batch loss = 0.17\n",
      "epoch 3, step 11250/55000, batch loss = 0.17\n",
      "epoch 3, step 11500/55000, batch loss = 0.20\n",
      "epoch 3, step 11750/55000, batch loss = 0.21\n",
      "epoch 3, step 12000/55000, batch loss = 0.16\n",
      "epoch 3, step 12250/55000, batch loss = 0.21\n",
      "epoch 3, step 12500/55000, batch loss = 0.19\n",
      "Train accuracy = 98.35\n",
      "epoch 3, step 12750/55000, batch loss = 0.24\n",
      "epoch 3, step 13000/55000, batch loss = 0.17\n",
      "epoch 3, step 13250/55000, batch loss = 0.20\n",
      "epoch 3, step 13500/55000, batch loss = 0.22\n",
      "epoch 3, step 13750/55000, batch loss = 0.18\n",
      "epoch 3, step 14000/55000, batch loss = 0.27\n",
      "epoch 3, step 14250/55000, batch loss = 0.24\n",
      "epoch 3, step 14500/55000, batch loss = 0.19\n",
      "epoch 3, step 14750/55000, batch loss = 0.19\n",
      "epoch 3, step 15000/55000, batch loss = 0.19\n",
      "Train accuracy = 98.36\n",
      "epoch 3, step 15250/55000, batch loss = 0.18\n",
      "epoch 3, step 15500/55000, batch loss = 0.16\n",
      "epoch 3, step 15750/55000, batch loss = 0.22\n",
      "epoch 3, step 16000/55000, batch loss = 0.19\n",
      "epoch 3, step 16250/55000, batch loss = 0.19\n",
      "epoch 3, step 16500/55000, batch loss = 0.18\n",
      "epoch 3, step 16750/55000, batch loss = 0.18\n",
      "epoch 3, step 17000/55000, batch loss = 0.16\n",
      "epoch 3, step 17250/55000, batch loss = 0.16\n",
      "epoch 3, step 17500/55000, batch loss = 0.18\n",
      "Train accuracy = 98.44\n",
      "epoch 3, step 17750/55000, batch loss = 0.18\n",
      "epoch 3, step 18000/55000, batch loss = 0.16\n",
      "epoch 3, step 18250/55000, batch loss = 0.16\n",
      "epoch 3, step 18500/55000, batch loss = 0.20\n",
      "epoch 3, step 18750/55000, batch loss = 0.25\n",
      "epoch 3, step 19000/55000, batch loss = 0.24\n",
      "epoch 3, step 19250/55000, batch loss = 0.16\n",
      "epoch 3, step 19500/55000, batch loss = 0.16\n",
      "epoch 3, step 19750/55000, batch loss = 0.22\n",
      "epoch 3, step 20000/55000, batch loss = 0.16\n",
      "Train accuracy = 98.40\n",
      "epoch 3, step 20250/55000, batch loss = 0.39\n",
      "epoch 3, step 20500/55000, batch loss = 0.20\n",
      "epoch 3, step 20750/55000, batch loss = 0.17\n",
      "epoch 3, step 21000/55000, batch loss = 0.25\n",
      "epoch 3, step 21250/55000, batch loss = 0.26\n",
      "epoch 3, step 21500/55000, batch loss = 0.17\n",
      "epoch 3, step 21750/55000, batch loss = 0.23\n",
      "epoch 3, step 22000/55000, batch loss = 0.16\n",
      "epoch 3, step 22250/55000, batch loss = 0.18\n",
      "epoch 3, step 22500/55000, batch loss = 0.16\n",
      "Train accuracy = 98.39\n",
      "epoch 3, step 22750/55000, batch loss = 0.20\n",
      "epoch 3, step 23000/55000, batch loss = 0.21\n",
      "epoch 3, step 23250/55000, batch loss = 0.16\n",
      "epoch 3, step 23500/55000, batch loss = 0.31\n",
      "epoch 3, step 23750/55000, batch loss = 0.18\n",
      "epoch 3, step 24000/55000, batch loss = 0.18\n",
      "epoch 3, step 24250/55000, batch loss = 0.24\n",
      "epoch 3, step 24500/55000, batch loss = 0.19\n",
      "epoch 3, step 24750/55000, batch loss = 0.18\n",
      "epoch 3, step 25000/55000, batch loss = 0.20\n",
      "Train accuracy = 98.41\n",
      "epoch 3, step 25250/55000, batch loss = 0.18\n",
      "epoch 3, step 25500/55000, batch loss = 0.19\n",
      "epoch 3, step 25750/55000, batch loss = 0.25\n",
      "epoch 3, step 26000/55000, batch loss = 0.18\n",
      "epoch 3, step 26250/55000, batch loss = 0.18\n",
      "epoch 3, step 26500/55000, batch loss = 0.25\n",
      "epoch 3, step 26750/55000, batch loss = 0.23\n",
      "epoch 3, step 27000/55000, batch loss = 0.19\n",
      "epoch 3, step 27250/55000, batch loss = 0.17\n",
      "epoch 3, step 27500/55000, batch loss = 0.18\n",
      "Train accuracy = 98.43\n",
      "epoch 3, step 27750/55000, batch loss = 0.18\n",
      "epoch 3, step 28000/55000, batch loss = 0.16\n",
      "epoch 3, step 28250/55000, batch loss = 0.19\n",
      "epoch 3, step 28500/55000, batch loss = 0.22\n",
      "epoch 3, step 28750/55000, batch loss = 0.16\n",
      "epoch 3, step 29000/55000, batch loss = 0.37\n",
      "epoch 3, step 29250/55000, batch loss = 0.36\n",
      "epoch 3, step 29500/55000, batch loss = 0.21\n",
      "epoch 3, step 29750/55000, batch loss = 0.19\n",
      "epoch 3, step 30000/55000, batch loss = 0.18\n",
      "Train accuracy = 98.44\n",
      "epoch 3, step 30250/55000, batch loss = 0.16\n",
      "epoch 3, step 30500/55000, batch loss = 0.17\n",
      "epoch 3, step 30750/55000, batch loss = 0.17\n",
      "epoch 3, step 31000/55000, batch loss = 0.17\n",
      "epoch 3, step 31250/55000, batch loss = 0.23\n",
      "epoch 3, step 31500/55000, batch loss = 0.25\n",
      "epoch 3, step 31750/55000, batch loss = 0.20\n",
      "epoch 3, step 32000/55000, batch loss = 0.21\n",
      "epoch 3, step 32250/55000, batch loss = 0.23\n",
      "epoch 3, step 32500/55000, batch loss = 0.19\n",
      "Train accuracy = 98.45\n",
      "epoch 3, step 32750/55000, batch loss = 0.19\n",
      "epoch 3, step 33000/55000, batch loss = 0.35\n",
      "epoch 3, step 33250/55000, batch loss = 0.15\n",
      "epoch 3, step 33500/55000, batch loss = 0.20\n",
      "epoch 3, step 33750/55000, batch loss = 0.19\n",
      "epoch 3, step 34000/55000, batch loss = 0.17\n",
      "epoch 3, step 34250/55000, batch loss = 0.20\n",
      "epoch 3, step 34500/55000, batch loss = 0.20\n",
      "epoch 3, step 34750/55000, batch loss = 0.17\n",
      "epoch 3, step 35000/55000, batch loss = 0.21\n",
      "Train accuracy = 98.45\n",
      "epoch 3, step 35250/55000, batch loss = 0.21\n",
      "epoch 3, step 35500/55000, batch loss = 0.20\n",
      "epoch 3, step 35750/55000, batch loss = 0.18\n",
      "epoch 3, step 36000/55000, batch loss = 0.20\n",
      "epoch 3, step 36250/55000, batch loss = 0.20\n",
      "epoch 3, step 36500/55000, batch loss = 0.17\n",
      "epoch 3, step 36750/55000, batch loss = 0.18\n",
      "epoch 3, step 37000/55000, batch loss = 0.22\n",
      "epoch 3, step 37250/55000, batch loss = 0.21\n",
      "epoch 3, step 37500/55000, batch loss = 0.17\n",
      "Train accuracy = 98.47\n",
      "epoch 3, step 37750/55000, batch loss = 0.15\n",
      "epoch 3, step 38000/55000, batch loss = 0.24\n",
      "epoch 3, step 38250/55000, batch loss = 0.19\n",
      "epoch 3, step 38500/55000, batch loss = 0.16\n",
      "epoch 3, step 38750/55000, batch loss = 0.20\n",
      "epoch 3, step 39000/55000, batch loss = 0.19\n",
      "epoch 3, step 39250/55000, batch loss = 0.20\n",
      "epoch 3, step 39500/55000, batch loss = 0.24\n",
      "epoch 3, step 39750/55000, batch loss = 0.19\n",
      "epoch 3, step 40000/55000, batch loss = 0.18\n",
      "Train accuracy = 98.47\n",
      "epoch 3, step 40250/55000, batch loss = 0.15\n",
      "epoch 3, step 40500/55000, batch loss = 0.21\n",
      "epoch 3, step 40750/55000, batch loss = 0.15\n",
      "epoch 3, step 41000/55000, batch loss = 0.19\n",
      "epoch 3, step 41250/55000, batch loss = 0.15\n",
      "epoch 3, step 41500/55000, batch loss = 0.15\n",
      "epoch 3, step 41750/55000, batch loss = 0.18\n",
      "epoch 3, step 42000/55000, batch loss = 0.26\n",
      "epoch 3, step 42250/55000, batch loss = 0.15\n",
      "epoch 3, step 42500/55000, batch loss = 0.16\n",
      "Train accuracy = 98.47\n",
      "epoch 3, step 42750/55000, batch loss = 0.18\n",
      "epoch 3, step 43000/55000, batch loss = 0.16\n",
      "epoch 3, step 43250/55000, batch loss = 0.28\n",
      "epoch 3, step 43500/55000, batch loss = 0.23\n",
      "epoch 3, step 43750/55000, batch loss = 0.26\n",
      "epoch 3, step 44000/55000, batch loss = 0.34\n",
      "epoch 3, step 44250/55000, batch loss = 0.15\n",
      "epoch 3, step 44500/55000, batch loss = 0.23\n",
      "epoch 3, step 44750/55000, batch loss = 0.18\n",
      "epoch 3, step 45000/55000, batch loss = 0.18\n",
      "Train accuracy = 98.46\n",
      "epoch 3, step 45250/55000, batch loss = 0.17\n",
      "epoch 3, step 45500/55000, batch loss = 0.15\n",
      "epoch 3, step 45750/55000, batch loss = 0.24\n",
      "epoch 3, step 46000/55000, batch loss = 0.17\n",
      "epoch 3, step 46250/55000, batch loss = 0.19\n",
      "epoch 3, step 46500/55000, batch loss = 0.31\n",
      "epoch 3, step 46750/55000, batch loss = 0.17\n",
      "epoch 3, step 47000/55000, batch loss = 0.16\n",
      "epoch 3, step 47250/55000, batch loss = 0.17\n",
      "epoch 3, step 47500/55000, batch loss = 0.16\n",
      "Train accuracy = 98.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, step 47750/55000, batch loss = 0.18\n",
      "epoch 3, step 48000/55000, batch loss = 0.21\n",
      "epoch 3, step 48250/55000, batch loss = 0.17\n",
      "epoch 3, step 48500/55000, batch loss = 0.19\n",
      "epoch 3, step 48750/55000, batch loss = 0.18\n",
      "epoch 3, step 49000/55000, batch loss = 0.18\n",
      "epoch 3, step 49250/55000, batch loss = 0.18\n",
      "epoch 3, step 49500/55000, batch loss = 0.24\n",
      "epoch 3, step 49750/55000, batch loss = 0.18\n",
      "epoch 3, step 50000/55000, batch loss = 0.17\n",
      "Train accuracy = 98.47\n",
      "epoch 3, step 50250/55000, batch loss = 0.21\n",
      "epoch 3, step 50500/55000, batch loss = 0.20\n",
      "epoch 3, step 50750/55000, batch loss = 0.16\n",
      "epoch 3, step 51000/55000, batch loss = 0.15\n",
      "epoch 3, step 51250/55000, batch loss = 0.24\n",
      "epoch 3, step 51500/55000, batch loss = 0.20\n",
      "epoch 3, step 51750/55000, batch loss = 0.15\n",
      "epoch 3, step 52000/55000, batch loss = 0.18\n",
      "epoch 3, step 52250/55000, batch loss = 0.15\n",
      "epoch 3, step 52500/55000, batch loss = 0.15\n",
      "Train accuracy = 98.47\n",
      "epoch 3, step 52750/55000, batch loss = 0.21\n",
      "epoch 3, step 53000/55000, batch loss = 0.18\n",
      "epoch 3, step 53250/55000, batch loss = 0.23\n",
      "epoch 3, step 53500/55000, batch loss = 0.21\n",
      "epoch 3, step 53750/55000, batch loss = 0.22\n",
      "epoch 3, step 54000/55000, batch loss = 0.22\n",
      "epoch 3, step 54250/55000, batch loss = 0.20\n",
      "epoch 3, step 54500/55000, batch loss = 0.16\n",
      "epoch 3, step 54750/55000, batch loss = 0.21\n",
      "Train accuracy = 98.45\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 98.60\n",
      "Validation avg loss = 0.19\n",
      "\n",
      "epoch 4, step 0/55000, batch loss = 0.17\n",
      "epoch 4, step 250/55000, batch loss = 0.15\n",
      "epoch 4, step 500/55000, batch loss = 0.19\n",
      "epoch 4, step 750/55000, batch loss = 0.15\n",
      "epoch 4, step 1000/55000, batch loss = 0.21\n",
      "epoch 4, step 1250/55000, batch loss = 0.18\n",
      "epoch 4, step 1500/55000, batch loss = 0.16\n",
      "epoch 4, step 1750/55000, batch loss = 0.27\n",
      "epoch 4, step 2000/55000, batch loss = 0.16\n",
      "epoch 4, step 2250/55000, batch loss = 0.16\n",
      "epoch 4, step 2500/55000, batch loss = 0.22\n",
      "Train accuracy = 98.75\n",
      "epoch 4, step 2750/55000, batch loss = 0.15\n",
      "epoch 4, step 3000/55000, batch loss = 0.20\n",
      "epoch 4, step 3250/55000, batch loss = 0.15\n",
      "epoch 4, step 3500/55000, batch loss = 0.16\n",
      "epoch 4, step 3750/55000, batch loss = 0.27\n",
      "epoch 4, step 4000/55000, batch loss = 0.20\n",
      "epoch 4, step 4250/55000, batch loss = 0.21\n",
      "epoch 4, step 4500/55000, batch loss = 0.17\n",
      "epoch 4, step 4750/55000, batch loss = 0.23\n",
      "epoch 4, step 5000/55000, batch loss = 0.20\n",
      "Train accuracy = 98.55\n",
      "epoch 4, step 5250/55000, batch loss = 0.20\n",
      "epoch 4, step 5500/55000, batch loss = 0.18\n",
      "epoch 4, step 5750/55000, batch loss = 0.24\n",
      "epoch 4, step 6000/55000, batch loss = 0.15\n",
      "epoch 4, step 6250/55000, batch loss = 0.15\n",
      "epoch 4, step 6500/55000, batch loss = 0.20\n",
      "epoch 4, step 6750/55000, batch loss = 0.15\n",
      "epoch 4, step 7000/55000, batch loss = 0.16\n",
      "epoch 4, step 7250/55000, batch loss = 0.18\n",
      "epoch 4, step 7500/55000, batch loss = 0.16\n",
      "Train accuracy = 98.64\n",
      "epoch 4, step 7750/55000, batch loss = 0.19\n",
      "epoch 4, step 8000/55000, batch loss = 0.19\n",
      "epoch 4, step 8250/55000, batch loss = 0.22\n",
      "epoch 4, step 8500/55000, batch loss = 0.24\n",
      "epoch 4, step 8750/55000, batch loss = 0.21\n",
      "epoch 4, step 9000/55000, batch loss = 0.20\n",
      "epoch 4, step 9250/55000, batch loss = 0.17\n",
      "epoch 4, step 9500/55000, batch loss = 0.16\n",
      "epoch 4, step 9750/55000, batch loss = 0.14\n",
      "epoch 4, step 10000/55000, batch loss = 0.25\n",
      "Train accuracy = 98.57\n",
      "epoch 4, step 10250/55000, batch loss = 0.15\n",
      "epoch 4, step 10500/55000, batch loss = 0.16\n",
      "epoch 4, step 10750/55000, batch loss = 0.15\n",
      "epoch 4, step 11000/55000, batch loss = 0.20\n",
      "epoch 4, step 11250/55000, batch loss = 0.22\n",
      "epoch 4, step 11500/55000, batch loss = 0.15\n",
      "epoch 4, step 11750/55000, batch loss = 0.20\n",
      "epoch 4, step 12000/55000, batch loss = 0.17\n",
      "epoch 4, step 12250/55000, batch loss = 0.16\n",
      "epoch 4, step 12500/55000, batch loss = 0.20\n",
      "Train accuracy = 98.62\n",
      "epoch 4, step 12750/55000, batch loss = 0.15\n",
      "epoch 4, step 13000/55000, batch loss = 0.18\n",
      "epoch 4, step 13250/55000, batch loss = 0.19\n",
      "epoch 4, step 13500/55000, batch loss = 0.15\n",
      "epoch 4, step 13750/55000, batch loss = 0.17\n",
      "epoch 4, step 14000/55000, batch loss = 0.37\n",
      "epoch 4, step 14250/55000, batch loss = 0.15\n",
      "epoch 4, step 14500/55000, batch loss = 0.17\n",
      "epoch 4, step 14750/55000, batch loss = 0.15\n",
      "epoch 4, step 15000/55000, batch loss = 0.17\n",
      "Train accuracy = 98.61\n",
      "epoch 4, step 15250/55000, batch loss = 0.18\n",
      "epoch 4, step 15500/55000, batch loss = 0.15\n",
      "epoch 4, step 15750/55000, batch loss = 0.19\n",
      "epoch 4, step 16000/55000, batch loss = 0.29\n",
      "epoch 4, step 16250/55000, batch loss = 0.19\n",
      "epoch 4, step 16500/55000, batch loss = 0.17\n",
      "epoch 4, step 16750/55000, batch loss = 0.17\n",
      "epoch 4, step 17000/55000, batch loss = 0.15\n",
      "epoch 4, step 17250/55000, batch loss = 0.19\n",
      "epoch 4, step 17500/55000, batch loss = 0.27\n",
      "Train accuracy = 98.56\n",
      "epoch 4, step 17750/55000, batch loss = 0.17\n",
      "epoch 4, step 18000/55000, batch loss = 0.14\n",
      "epoch 4, step 18250/55000, batch loss = 0.15\n",
      "epoch 4, step 18500/55000, batch loss = 0.15\n",
      "epoch 4, step 18750/55000, batch loss = 0.16\n",
      "epoch 4, step 19000/55000, batch loss = 0.22\n",
      "epoch 4, step 19250/55000, batch loss = 0.16\n",
      "epoch 4, step 19500/55000, batch loss = 0.17\n",
      "epoch 4, step 19750/55000, batch loss = 0.16\n",
      "epoch 4, step 20000/55000, batch loss = 0.17\n",
      "Train accuracy = 98.58\n",
      "epoch 4, step 20250/55000, batch loss = 0.18\n",
      "epoch 4, step 20500/55000, batch loss = 0.15\n",
      "epoch 4, step 20750/55000, batch loss = 0.15\n",
      "epoch 4, step 21000/55000, batch loss = 0.17\n",
      "epoch 4, step 21250/55000, batch loss = 0.26\n",
      "epoch 4, step 21500/55000, batch loss = 0.20\n",
      "epoch 4, step 21750/55000, batch loss = 0.16\n",
      "epoch 4, step 22000/55000, batch loss = 0.22\n",
      "epoch 4, step 22250/55000, batch loss = 0.16\n",
      "epoch 4, step 22500/55000, batch loss = 0.17\n",
      "Train accuracy = 98.60\n",
      "epoch 4, step 22750/55000, batch loss = 0.16\n",
      "epoch 4, step 23000/55000, batch loss = 0.17\n",
      "epoch 4, step 23250/55000, batch loss = 0.15\n",
      "epoch 4, step 23500/55000, batch loss = 0.18\n",
      "epoch 4, step 23750/55000, batch loss = 0.17\n",
      "epoch 4, step 24000/55000, batch loss = 0.15\n",
      "epoch 4, step 24250/55000, batch loss = 0.18\n",
      "epoch 4, step 24500/55000, batch loss = 0.20\n",
      "epoch 4, step 24750/55000, batch loss = 0.17\n",
      "epoch 4, step 25000/55000, batch loss = 0.31\n",
      "Train accuracy = 98.60\n",
      "epoch 4, step 25250/55000, batch loss = 0.18\n",
      "epoch 4, step 25500/55000, batch loss = 0.16\n",
      "epoch 4, step 25750/55000, batch loss = 0.21\n",
      "epoch 4, step 26000/55000, batch loss = 0.18\n",
      "epoch 4, step 26250/55000, batch loss = 0.16\n",
      "epoch 4, step 26500/55000, batch loss = 0.19\n",
      "epoch 4, step 26750/55000, batch loss = 0.17\n",
      "epoch 4, step 27000/55000, batch loss = 0.14\n",
      "epoch 4, step 27250/55000, batch loss = 0.15\n",
      "epoch 4, step 27500/55000, batch loss = 0.16\n",
      "Train accuracy = 98.59\n",
      "epoch 4, step 27750/55000, batch loss = 0.17\n",
      "epoch 4, step 28000/55000, batch loss = 0.21\n",
      "epoch 4, step 28250/55000, batch loss = 0.15\n",
      "epoch 4, step 28500/55000, batch loss = 0.19\n",
      "epoch 4, step 28750/55000, batch loss = 0.16\n",
      "epoch 4, step 29000/55000, batch loss = 0.17\n",
      "epoch 4, step 29250/55000, batch loss = 0.14\n",
      "epoch 4, step 29500/55000, batch loss = 0.18\n",
      "epoch 4, step 29750/55000, batch loss = 0.15\n",
      "epoch 4, step 30000/55000, batch loss = 0.26\n",
      "Train accuracy = 98.59\n",
      "epoch 4, step 30250/55000, batch loss = 0.14\n",
      "epoch 4, step 30500/55000, batch loss = 0.23\n",
      "epoch 4, step 30750/55000, batch loss = 0.17\n",
      "epoch 4, step 31000/55000, batch loss = 0.19\n",
      "epoch 4, step 31250/55000, batch loss = 0.17\n",
      "epoch 4, step 31500/55000, batch loss = 0.20\n",
      "epoch 4, step 31750/55000, batch loss = 0.20\n",
      "epoch 4, step 32000/55000, batch loss = 0.18\n",
      "epoch 4, step 32250/55000, batch loss = 0.13\n",
      "epoch 4, step 32500/55000, batch loss = 0.15\n",
      "Train accuracy = 98.61\n",
      "epoch 4, step 32750/55000, batch loss = 0.22\n",
      "epoch 4, step 33000/55000, batch loss = 0.19\n",
      "epoch 4, step 33250/55000, batch loss = 0.17\n",
      "epoch 4, step 33500/55000, batch loss = 0.15\n",
      "epoch 4, step 33750/55000, batch loss = 0.16\n",
      "epoch 4, step 34000/55000, batch loss = 0.21\n",
      "epoch 4, step 34250/55000, batch loss = 0.16\n",
      "epoch 4, step 34500/55000, batch loss = 0.20\n",
      "epoch 4, step 34750/55000, batch loss = 0.25\n",
      "epoch 4, step 35000/55000, batch loss = 0.20\n",
      "Train accuracy = 98.63\n",
      "epoch 4, step 35250/55000, batch loss = 0.15\n",
      "epoch 4, step 35500/55000, batch loss = 0.20\n",
      "epoch 4, step 35750/55000, batch loss = 0.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, step 36000/55000, batch loss = 0.16\n",
      "epoch 4, step 36250/55000, batch loss = 0.16\n",
      "epoch 4, step 36500/55000, batch loss = 0.17\n",
      "epoch 4, step 36750/55000, batch loss = 0.17\n",
      "epoch 4, step 37000/55000, batch loss = 0.18\n",
      "epoch 4, step 37250/55000, batch loss = 0.25\n",
      "epoch 4, step 37500/55000, batch loss = 0.16\n",
      "Train accuracy = 98.62\n",
      "epoch 4, step 37750/55000, batch loss = 0.17\n",
      "epoch 4, step 38000/55000, batch loss = 0.22\n",
      "epoch 4, step 38250/55000, batch loss = 0.27\n",
      "epoch 4, step 38500/55000, batch loss = 0.18\n",
      "epoch 4, step 38750/55000, batch loss = 0.23\n",
      "epoch 4, step 39000/55000, batch loss = 0.17\n",
      "epoch 4, step 39250/55000, batch loss = 0.16\n",
      "epoch 4, step 39500/55000, batch loss = 0.17\n",
      "epoch 4, step 39750/55000, batch loss = 0.16\n",
      "epoch 4, step 40000/55000, batch loss = 0.20\n",
      "Train accuracy = 98.63\n",
      "epoch 4, step 40250/55000, batch loss = 0.19\n",
      "epoch 4, step 40500/55000, batch loss = 0.34\n",
      "epoch 4, step 40750/55000, batch loss = 0.16\n",
      "epoch 4, step 41000/55000, batch loss = 0.14\n",
      "epoch 4, step 41250/55000, batch loss = 0.20\n",
      "epoch 4, step 41500/55000, batch loss = 0.16\n",
      "epoch 4, step 41750/55000, batch loss = 0.26\n",
      "epoch 4, step 42000/55000, batch loss = 0.20\n",
      "epoch 4, step 42250/55000, batch loss = 0.17\n",
      "epoch 4, step 42500/55000, batch loss = 0.16\n",
      "Train accuracy = 98.63\n",
      "epoch 4, step 42750/55000, batch loss = 0.15\n",
      "epoch 4, step 43000/55000, batch loss = 0.14\n",
      "epoch 4, step 43250/55000, batch loss = 0.17\n",
      "epoch 4, step 43500/55000, batch loss = 0.17\n",
      "epoch 4, step 43750/55000, batch loss = 0.22\n",
      "epoch 4, step 44000/55000, batch loss = 0.18\n",
      "epoch 4, step 44250/55000, batch loss = 0.21\n",
      "epoch 4, step 44500/55000, batch loss = 0.25\n",
      "epoch 4, step 44750/55000, batch loss = 0.16\n",
      "epoch 4, step 45000/55000, batch loss = 0.15\n",
      "Train accuracy = 98.63\n",
      "epoch 4, step 45250/55000, batch loss = 0.21\n",
      "epoch 4, step 45500/55000, batch loss = 0.17\n",
      "epoch 4, step 45750/55000, batch loss = 0.14\n",
      "epoch 4, step 46000/55000, batch loss = 0.16\n",
      "epoch 4, step 46250/55000, batch loss = 0.17\n",
      "epoch 4, step 46500/55000, batch loss = 0.21\n",
      "epoch 4, step 46750/55000, batch loss = 0.18\n",
      "epoch 4, step 47000/55000, batch loss = 0.15\n",
      "epoch 4, step 47250/55000, batch loss = 0.19\n",
      "epoch 4, step 47500/55000, batch loss = 0.17\n",
      "Train accuracy = 98.60\n",
      "epoch 4, step 47750/55000, batch loss = 0.18\n",
      "epoch 4, step 48000/55000, batch loss = 0.19\n",
      "epoch 4, step 48250/55000, batch loss = 0.16\n",
      "epoch 4, step 48500/55000, batch loss = 0.16\n",
      "epoch 4, step 48750/55000, batch loss = 0.16\n",
      "epoch 4, step 49000/55000, batch loss = 0.21\n",
      "epoch 4, step 49250/55000, batch loss = 0.16\n",
      "epoch 4, step 49500/55000, batch loss = 0.13\n",
      "epoch 4, step 49750/55000, batch loss = 0.19\n",
      "epoch 4, step 50000/55000, batch loss = 0.17\n",
      "Train accuracy = 98.60\n",
      "epoch 4, step 50250/55000, batch loss = 0.19\n",
      "epoch 4, step 50500/55000, batch loss = 0.22\n",
      "epoch 4, step 50750/55000, batch loss = 0.18\n",
      "epoch 4, step 51000/55000, batch loss = 0.17\n",
      "epoch 4, step 51250/55000, batch loss = 0.18\n",
      "epoch 4, step 51500/55000, batch loss = 0.17\n",
      "epoch 4, step 51750/55000, batch loss = 0.15\n",
      "epoch 4, step 52000/55000, batch loss = 0.25\n",
      "epoch 4, step 52250/55000, batch loss = 0.17\n",
      "epoch 4, step 52500/55000, batch loss = 0.17\n",
      "Train accuracy = 98.59\n",
      "epoch 4, step 52750/55000, batch loss = 0.25\n",
      "epoch 4, step 53000/55000, batch loss = 0.15\n",
      "epoch 4, step 53250/55000, batch loss = 0.23\n",
      "epoch 4, step 53500/55000, batch loss = 0.16\n",
      "epoch 4, step 53750/55000, batch loss = 0.17\n",
      "epoch 4, step 54000/55000, batch loss = 0.14\n",
      "epoch 4, step 54250/55000, batch loss = 0.19\n",
      "epoch 4, step 54500/55000, batch loss = 0.16\n",
      "epoch 4, step 54750/55000, batch loss = 0.18\n",
      "Train accuracy = 98.59\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 98.60\n",
      "Validation avg loss = 0.18\n",
      "\n",
      "epoch 5, step 0/55000, batch loss = 0.14\n",
      "epoch 5, step 250/55000, batch loss = 0.18\n",
      "epoch 5, step 500/55000, batch loss = 0.15\n",
      "epoch 5, step 750/55000, batch loss = 0.24\n",
      "epoch 5, step 1000/55000, batch loss = 0.19\n",
      "epoch 5, step 1250/55000, batch loss = 0.15\n",
      "epoch 5, step 1500/55000, batch loss = 0.14\n",
      "epoch 5, step 1750/55000, batch loss = 0.15\n",
      "epoch 5, step 2000/55000, batch loss = 0.22\n",
      "epoch 5, step 2250/55000, batch loss = 0.16\n",
      "epoch 5, step 2500/55000, batch loss = 0.20\n",
      "Train accuracy = 98.71\n",
      "epoch 5, step 2750/55000, batch loss = 0.25\n",
      "epoch 5, step 3000/55000, batch loss = 0.16\n",
      "epoch 5, step 3250/55000, batch loss = 0.16\n",
      "epoch 5, step 3500/55000, batch loss = 0.19\n",
      "epoch 5, step 3750/55000, batch loss = 0.21\n",
      "epoch 5, step 4000/55000, batch loss = 0.14\n",
      "epoch 5, step 4250/55000, batch loss = 0.14\n",
      "epoch 5, step 4500/55000, batch loss = 0.15\n",
      "epoch 5, step 4750/55000, batch loss = 0.14\n",
      "epoch 5, step 5000/55000, batch loss = 0.15\n",
      "Train accuracy = 98.85\n",
      "epoch 5, step 5250/55000, batch loss = 0.19\n",
      "epoch 5, step 5500/55000, batch loss = 0.21\n",
      "epoch 5, step 5750/55000, batch loss = 0.20\n",
      "epoch 5, step 6000/55000, batch loss = 0.16\n",
      "epoch 5, step 6250/55000, batch loss = 0.14\n",
      "epoch 5, step 6500/55000, batch loss = 0.14\n",
      "epoch 5, step 6750/55000, batch loss = 0.15\n",
      "epoch 5, step 7000/55000, batch loss = 0.20\n",
      "epoch 5, step 7250/55000, batch loss = 0.17\n",
      "epoch 5, step 7500/55000, batch loss = 0.17\n",
      "Train accuracy = 98.77\n",
      "epoch 5, step 7750/55000, batch loss = 0.28\n",
      "epoch 5, step 8000/55000, batch loss = 0.20\n",
      "epoch 5, step 8250/55000, batch loss = 0.15\n",
      "epoch 5, step 8500/55000, batch loss = 0.17\n",
      "epoch 5, step 8750/55000, batch loss = 0.23\n",
      "epoch 5, step 9000/55000, batch loss = 0.20\n",
      "epoch 5, step 9250/55000, batch loss = 0.19\n",
      "epoch 5, step 9500/55000, batch loss = 0.20\n",
      "epoch 5, step 9750/55000, batch loss = 0.19\n",
      "epoch 5, step 10000/55000, batch loss = 0.18\n",
      "Train accuracy = 98.56\n",
      "epoch 5, step 10250/55000, batch loss = 0.16\n",
      "epoch 5, step 10500/55000, batch loss = 0.15\n",
      "epoch 5, step 10750/55000, batch loss = 0.15\n",
      "epoch 5, step 11000/55000, batch loss = 0.21\n",
      "epoch 5, step 11250/55000, batch loss = 0.19\n",
      "epoch 5, step 11500/55000, batch loss = 0.25\n",
      "epoch 5, step 11750/55000, batch loss = 0.16\n",
      "epoch 5, step 12000/55000, batch loss = 0.16\n",
      "epoch 5, step 12250/55000, batch loss = 0.15\n",
      "epoch 5, step 12500/55000, batch loss = 0.14\n",
      "Train accuracy = 98.62\n",
      "epoch 5, step 12750/55000, batch loss = 0.16\n",
      "epoch 5, step 13000/55000, batch loss = 0.14\n",
      "epoch 5, step 13250/55000, batch loss = 0.15\n",
      "epoch 5, step 13500/55000, batch loss = 0.19\n",
      "epoch 5, step 13750/55000, batch loss = 0.16\n",
      "epoch 5, step 14000/55000, batch loss = 0.21\n",
      "epoch 5, step 14250/55000, batch loss = 0.16\n",
      "epoch 5, step 14500/55000, batch loss = 0.14\n",
      "epoch 5, step 14750/55000, batch loss = 0.16\n",
      "epoch 5, step 15000/55000, batch loss = 0.16\n",
      "Train accuracy = 98.67\n",
      "epoch 5, step 15250/55000, batch loss = 0.18\n",
      "epoch 5, step 15500/55000, batch loss = 0.15\n",
      "epoch 5, step 15750/55000, batch loss = 0.14\n",
      "epoch 5, step 16000/55000, batch loss = 0.20\n",
      "epoch 5, step 16250/55000, batch loss = 0.23\n",
      "epoch 5, step 16500/55000, batch loss = 0.23\n",
      "epoch 5, step 16750/55000, batch loss = 0.15\n",
      "epoch 5, step 17000/55000, batch loss = 0.14\n",
      "epoch 5, step 17250/55000, batch loss = 0.17\n",
      "epoch 5, step 17500/55000, batch loss = 0.20\n",
      "Train accuracy = 98.65\n",
      "epoch 5, step 17750/55000, batch loss = 0.15\n",
      "epoch 5, step 18000/55000, batch loss = 0.20\n",
      "epoch 5, step 18250/55000, batch loss = 0.18\n",
      "epoch 5, step 18500/55000, batch loss = 0.23\n",
      "epoch 5, step 18750/55000, batch loss = 0.18\n",
      "epoch 5, step 19000/55000, batch loss = 0.16\n",
      "epoch 5, step 19250/55000, batch loss = 0.21\n",
      "epoch 5, step 19500/55000, batch loss = 0.29\n",
      "epoch 5, step 19750/55000, batch loss = 0.15\n",
      "epoch 5, step 20000/55000, batch loss = 0.16\n",
      "Train accuracy = 98.59\n",
      "epoch 5, step 20250/55000, batch loss = 0.21\n",
      "epoch 5, step 20500/55000, batch loss = 0.13\n",
      "epoch 5, step 20750/55000, batch loss = 0.13\n",
      "epoch 5, step 21000/55000, batch loss = 0.19\n",
      "epoch 5, step 21250/55000, batch loss = 0.21\n",
      "epoch 5, step 21500/55000, batch loss = 0.15\n",
      "epoch 5, step 21750/55000, batch loss = 0.16\n",
      "epoch 5, step 22000/55000, batch loss = 0.20\n",
      "epoch 5, step 22250/55000, batch loss = 0.24\n",
      "epoch 5, step 22500/55000, batch loss = 0.25\n",
      "Train accuracy = 98.60\n",
      "epoch 5, step 22750/55000, batch loss = 0.14\n",
      "epoch 5, step 23000/55000, batch loss = 0.15\n",
      "epoch 5, step 23250/55000, batch loss = 0.19\n",
      "epoch 5, step 23500/55000, batch loss = 0.15\n",
      "epoch 5, step 23750/55000, batch loss = 0.16\n",
      "epoch 5, step 24000/55000, batch loss = 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, step 24250/55000, batch loss = 0.14\n",
      "epoch 5, step 24500/55000, batch loss = 0.14\n",
      "epoch 5, step 24750/55000, batch loss = 0.23\n",
      "epoch 5, step 25000/55000, batch loss = 0.16\n",
      "Train accuracy = 98.65\n",
      "epoch 5, step 25250/55000, batch loss = 0.15\n",
      "epoch 5, step 25500/55000, batch loss = 0.14\n",
      "epoch 5, step 25750/55000, batch loss = 0.18\n",
      "epoch 5, step 26000/55000, batch loss = 0.17\n",
      "epoch 5, step 26250/55000, batch loss = 0.14\n",
      "epoch 5, step 26500/55000, batch loss = 0.16\n",
      "epoch 5, step 26750/55000, batch loss = 0.14\n",
      "epoch 5, step 27000/55000, batch loss = 0.18\n",
      "epoch 5, step 27250/55000, batch loss = 0.16\n",
      "epoch 5, step 27500/55000, batch loss = 0.28\n",
      "Train accuracy = 98.68\n",
      "epoch 5, step 27750/55000, batch loss = 0.25\n",
      "epoch 5, step 28000/55000, batch loss = 0.28\n",
      "epoch 5, step 28250/55000, batch loss = 0.21\n",
      "epoch 5, step 28500/55000, batch loss = 0.20\n",
      "epoch 5, step 28750/55000, batch loss = 0.19\n",
      "epoch 5, step 29000/55000, batch loss = 0.17\n",
      "epoch 5, step 29250/55000, batch loss = 0.14\n",
      "epoch 5, step 29500/55000, batch loss = 0.13\n",
      "epoch 5, step 29750/55000, batch loss = 0.19\n",
      "epoch 5, step 30000/55000, batch loss = 0.15\n",
      "Train accuracy = 98.66\n",
      "epoch 5, step 30250/55000, batch loss = 0.17\n",
      "epoch 5, step 30500/55000, batch loss = 0.17\n",
      "epoch 5, step 30750/55000, batch loss = 0.20\n",
      "epoch 5, step 31000/55000, batch loss = 0.19\n",
      "epoch 5, step 31250/55000, batch loss = 0.16\n",
      "epoch 5, step 31500/55000, batch loss = 0.22\n",
      "epoch 5, step 31750/55000, batch loss = 0.19\n",
      "epoch 5, step 32000/55000, batch loss = 0.22\n",
      "epoch 5, step 32250/55000, batch loss = 0.20\n",
      "epoch 5, step 32500/55000, batch loss = 0.15\n",
      "Train accuracy = 98.66\n",
      "epoch 5, step 32750/55000, batch loss = 0.16\n",
      "epoch 5, step 33000/55000, batch loss = 0.18\n",
      "epoch 5, step 33250/55000, batch loss = 0.17\n",
      "epoch 5, step 33500/55000, batch loss = 0.14\n",
      "epoch 5, step 33750/55000, batch loss = 0.16\n",
      "epoch 5, step 34000/55000, batch loss = 0.18\n",
      "epoch 5, step 34250/55000, batch loss = 0.15\n",
      "epoch 5, step 34500/55000, batch loss = 0.15\n",
      "epoch 5, step 34750/55000, batch loss = 0.17\n",
      "epoch 5, step 35000/55000, batch loss = 0.15\n",
      "Train accuracy = 98.67\n",
      "epoch 5, step 35250/55000, batch loss = 0.16\n",
      "epoch 5, step 35500/55000, batch loss = 0.14\n",
      "epoch 5, step 35750/55000, batch loss = 0.19\n",
      "epoch 5, step 36000/55000, batch loss = 0.13\n",
      "epoch 5, step 36250/55000, batch loss = 0.20\n",
      "epoch 5, step 36500/55000, batch loss = 0.14\n",
      "epoch 5, step 36750/55000, batch loss = 0.13\n",
      "epoch 5, step 37000/55000, batch loss = 0.15\n",
      "epoch 5, step 37250/55000, batch loss = 0.13\n",
      "epoch 5, step 37500/55000, batch loss = 0.17\n",
      "Train accuracy = 98.71\n",
      "epoch 5, step 37750/55000, batch loss = 0.14\n",
      "epoch 5, step 38000/55000, batch loss = 0.15\n",
      "epoch 5, step 38250/55000, batch loss = 0.15\n",
      "epoch 5, step 38500/55000, batch loss = 0.28\n",
      "epoch 5, step 38750/55000, batch loss = 0.20\n",
      "epoch 5, step 39000/55000, batch loss = 0.23\n",
      "epoch 5, step 39250/55000, batch loss = 0.18\n",
      "epoch 5, step 39500/55000, batch loss = 0.20\n",
      "epoch 5, step 39750/55000, batch loss = 0.14\n",
      "epoch 5, step 40000/55000, batch loss = 0.16\n",
      "Train accuracy = 98.72\n",
      "epoch 5, step 40250/55000, batch loss = 0.17\n",
      "epoch 5, step 40500/55000, batch loss = 0.17\n",
      "epoch 5, step 40750/55000, batch loss = 0.16\n",
      "epoch 5, step 41000/55000, batch loss = 0.14\n",
      "epoch 5, step 41250/55000, batch loss = 0.21\n",
      "epoch 5, step 41500/55000, batch loss = 0.22\n",
      "epoch 5, step 41750/55000, batch loss = 0.14\n",
      "epoch 5, step 42000/55000, batch loss = 0.18\n",
      "epoch 5, step 42250/55000, batch loss = 0.13\n",
      "epoch 5, step 42500/55000, batch loss = 0.32\n",
      "Train accuracy = 98.71\n",
      "epoch 5, step 42750/55000, batch loss = 0.15\n",
      "epoch 5, step 43000/55000, batch loss = 0.14\n",
      "epoch 5, step 43250/55000, batch loss = 0.14\n",
      "epoch 5, step 43500/55000, batch loss = 0.14\n",
      "epoch 5, step 43750/55000, batch loss = 0.20\n",
      "epoch 5, step 44000/55000, batch loss = 0.19\n",
      "epoch 5, step 44250/55000, batch loss = 0.17\n",
      "epoch 5, step 44500/55000, batch loss = 0.14\n",
      "epoch 5, step 44750/55000, batch loss = 0.15\n",
      "epoch 5, step 45000/55000, batch loss = 0.15\n",
      "Train accuracy = 98.71\n",
      "epoch 5, step 45250/55000, batch loss = 0.18\n",
      "epoch 5, step 45500/55000, batch loss = 0.18\n",
      "epoch 5, step 45750/55000, batch loss = 0.15\n",
      "epoch 5, step 46000/55000, batch loss = 0.15\n",
      "epoch 5, step 46250/55000, batch loss = 0.14\n",
      "epoch 5, step 46500/55000, batch loss = 0.22\n",
      "epoch 5, step 46750/55000, batch loss = 0.19\n",
      "epoch 5, step 47000/55000, batch loss = 0.19\n",
      "epoch 5, step 47250/55000, batch loss = 0.17\n",
      "epoch 5, step 47500/55000, batch loss = 0.23\n",
      "Train accuracy = 98.70\n",
      "epoch 5, step 47750/55000, batch loss = 0.15\n",
      "epoch 5, step 48000/55000, batch loss = 0.15\n",
      "epoch 5, step 48250/55000, batch loss = 0.14\n",
      "epoch 5, step 48500/55000, batch loss = 0.22\n",
      "epoch 5, step 48750/55000, batch loss = 0.19\n",
      "epoch 5, step 49000/55000, batch loss = 0.15\n",
      "epoch 5, step 49250/55000, batch loss = 0.17\n",
      "epoch 5, step 49500/55000, batch loss = 0.25\n",
      "epoch 5, step 49750/55000, batch loss = 0.14\n",
      "epoch 5, step 50000/55000, batch loss = 0.16\n",
      "Train accuracy = 98.69\n",
      "epoch 5, step 50250/55000, batch loss = 0.14\n",
      "epoch 5, step 50500/55000, batch loss = 0.15\n",
      "epoch 5, step 50750/55000, batch loss = 0.14\n",
      "epoch 5, step 51000/55000, batch loss = 0.19\n",
      "epoch 5, step 51250/55000, batch loss = 0.17\n",
      "epoch 5, step 51500/55000, batch loss = 0.16\n",
      "epoch 5, step 51750/55000, batch loss = 0.20\n",
      "epoch 5, step 52000/55000, batch loss = 0.15\n",
      "epoch 5, step 52250/55000, batch loss = 0.17\n",
      "epoch 5, step 52500/55000, batch loss = 0.15\n",
      "Train accuracy = 98.71\n",
      "epoch 5, step 52750/55000, batch loss = 0.14\n",
      "epoch 5, step 53000/55000, batch loss = 0.14\n",
      "epoch 5, step 53250/55000, batch loss = 0.17\n",
      "epoch 5, step 53500/55000, batch loss = 0.14\n",
      "epoch 5, step 53750/55000, batch loss = 0.16\n",
      "epoch 5, step 54000/55000, batch loss = 0.25\n",
      "epoch 5, step 54250/55000, batch loss = 0.17\n",
      "epoch 5, step 54500/55000, batch loss = 0.14\n",
      "epoch 5, step 54750/55000, batch loss = 0.16\n",
      "Train accuracy = 98.73\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 98.74\n",
      "Validation avg loss = 0.17\n",
      "\n",
      "\n",
      "Running evaluation:  Test\n",
      "Test accuracy = 98.75\n",
      "Test avg loss = 0.17\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LAMBDA: 0.001 \n",
      "\n",
      "epoch 1, step 0/55000, batch loss = 2.71\n",
      "epoch 1, step 250/55000, batch loss = 2.25\n",
      "epoch 1, step 500/55000, batch loss = 2.07\n",
      "epoch 1, step 750/55000, batch loss = 2.02\n",
      "epoch 1, step 1000/55000, batch loss = 1.27\n",
      "epoch 1, step 1250/55000, batch loss = 1.24\n",
      "epoch 1, step 1500/55000, batch loss = 0.99\n",
      "epoch 1, step 1750/55000, batch loss = 1.09\n",
      "epoch 1, step 2000/55000, batch loss = 1.06\n",
      "epoch 1, step 2250/55000, batch loss = 0.87\n",
      "epoch 1, step 2500/55000, batch loss = 0.92\n",
      "Train accuracy = 69.41\n",
      "epoch 1, step 2750/55000, batch loss = 0.64\n",
      "epoch 1, step 3000/55000, batch loss = 0.84\n",
      "epoch 1, step 3250/55000, batch loss = 0.58\n",
      "epoch 1, step 3500/55000, batch loss = 0.76\n",
      "epoch 1, step 3750/55000, batch loss = 0.77\n",
      "epoch 1, step 4000/55000, batch loss = 0.73\n",
      "epoch 1, step 4250/55000, batch loss = 0.64\n",
      "epoch 1, step 4500/55000, batch loss = 0.65\n",
      "epoch 1, step 4750/55000, batch loss = 0.75\n",
      "epoch 1, step 5000/55000, batch loss = 0.71\n",
      "Train accuracy = 80.42\n",
      "epoch 1, step 5250/55000, batch loss = 0.67\n",
      "epoch 1, step 5500/55000, batch loss = 0.63\n",
      "epoch 1, step 5750/55000, batch loss = 0.61\n",
      "epoch 1, step 6000/55000, batch loss = 0.63\n",
      "epoch 1, step 6250/55000, batch loss = 0.75\n",
      "epoch 1, step 6500/55000, batch loss = 0.46\n",
      "epoch 1, step 6750/55000, batch loss = 0.66\n",
      "epoch 1, step 7000/55000, batch loss = 0.61\n",
      "epoch 1, step 7250/55000, batch loss = 0.78\n",
      "epoch 1, step 7500/55000, batch loss = 0.48\n",
      "Train accuracy = 84.81\n",
      "epoch 1, step 7750/55000, batch loss = 0.57\n",
      "epoch 1, step 8000/55000, batch loss = 0.53\n",
      "epoch 1, step 8250/55000, batch loss = 0.60\n",
      "epoch 1, step 8500/55000, batch loss = 0.50\n",
      "epoch 1, step 8750/55000, batch loss = 0.62\n",
      "epoch 1, step 9000/55000, batch loss = 0.55\n",
      "epoch 1, step 9250/55000, batch loss = 0.57\n",
      "epoch 1, step 9500/55000, batch loss = 0.52\n",
      "epoch 1, step 9750/55000, batch loss = 0.55\n",
      "epoch 1, step 10000/55000, batch loss = 0.53\n",
      "Train accuracy = 87.41\n",
      "epoch 1, step 10250/55000, batch loss = 0.54\n",
      "epoch 1, step 10500/55000, batch loss = 0.63\n",
      "epoch 1, step 10750/55000, batch loss = 0.51\n",
      "epoch 1, step 11000/55000, batch loss = 0.53\n",
      "epoch 1, step 11250/55000, batch loss = 0.57\n",
      "epoch 1, step 11500/55000, batch loss = 0.57\n",
      "epoch 1, step 11750/55000, batch loss = 0.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 12000/55000, batch loss = 0.49\n",
      "epoch 1, step 12250/55000, batch loss = 0.60\n",
      "epoch 1, step 12500/55000, batch loss = 0.49\n",
      "Train accuracy = 89.08\n",
      "epoch 1, step 12750/55000, batch loss = 0.60\n",
      "epoch 1, step 13000/55000, batch loss = 0.66\n",
      "epoch 1, step 13250/55000, batch loss = 0.47\n",
      "epoch 1, step 13500/55000, batch loss = 0.55\n",
      "epoch 1, step 13750/55000, batch loss = 0.43\n",
      "epoch 1, step 14000/55000, batch loss = 0.62\n",
      "epoch 1, step 14250/55000, batch loss = 0.60\n",
      "epoch 1, step 14500/55000, batch loss = 0.45\n",
      "epoch 1, step 14750/55000, batch loss = 0.50\n",
      "epoch 1, step 15000/55000, batch loss = 0.55\n",
      "Train accuracy = 90.19\n",
      "epoch 1, step 15250/55000, batch loss = 0.50\n",
      "epoch 1, step 15500/55000, batch loss = 0.48\n",
      "epoch 1, step 15750/55000, batch loss = 0.49\n",
      "epoch 1, step 16000/55000, batch loss = 0.59\n",
      "epoch 1, step 16250/55000, batch loss = 0.53\n",
      "epoch 1, step 16500/55000, batch loss = 0.56\n",
      "epoch 1, step 16750/55000, batch loss = 0.45\n",
      "epoch 1, step 17000/55000, batch loss = 0.56\n",
      "epoch 1, step 17250/55000, batch loss = 0.47\n",
      "epoch 1, step 17500/55000, batch loss = 0.46\n",
      "Train accuracy = 90.97\n",
      "epoch 1, step 17750/55000, batch loss = 0.44\n",
      "epoch 1, step 18000/55000, batch loss = 0.54\n",
      "epoch 1, step 18250/55000, batch loss = 0.49\n",
      "epoch 1, step 18500/55000, batch loss = 0.59\n",
      "epoch 1, step 18750/55000, batch loss = 0.47\n",
      "epoch 1, step 19000/55000, batch loss = 0.47\n",
      "epoch 1, step 19250/55000, batch loss = 0.48\n",
      "epoch 1, step 19500/55000, batch loss = 0.48\n",
      "epoch 1, step 19750/55000, batch loss = 0.79\n",
      "epoch 1, step 20000/55000, batch loss = 0.46\n",
      "Train accuracy = 91.66\n",
      "epoch 1, step 20250/55000, batch loss = 0.51\n",
      "epoch 1, step 20500/55000, batch loss = 0.44\n",
      "epoch 1, step 20750/55000, batch loss = 0.57\n",
      "epoch 1, step 21000/55000, batch loss = 0.61\n",
      "epoch 1, step 21250/55000, batch loss = 0.51\n",
      "epoch 1, step 21500/55000, batch loss = 0.51\n",
      "epoch 1, step 21750/55000, batch loss = 0.63\n",
      "epoch 1, step 22000/55000, batch loss = 0.42\n",
      "epoch 1, step 22250/55000, batch loss = 0.59\n",
      "epoch 1, step 22500/55000, batch loss = 0.46\n",
      "Train accuracy = 92.26\n",
      "epoch 1, step 22750/55000, batch loss = 0.45\n",
      "epoch 1, step 23000/55000, batch loss = 0.57\n",
      "epoch 1, step 23250/55000, batch loss = 0.63\n",
      "epoch 1, step 23500/55000, batch loss = 0.58\n",
      "epoch 1, step 23750/55000, batch loss = 0.54\n",
      "epoch 1, step 24000/55000, batch loss = 0.42\n",
      "epoch 1, step 24250/55000, batch loss = 0.47\n",
      "epoch 1, step 24500/55000, batch loss = 0.51\n",
      "epoch 1, step 24750/55000, batch loss = 0.53\n",
      "epoch 1, step 25000/55000, batch loss = 0.53\n",
      "Train accuracy = 92.71\n",
      "epoch 1, step 25250/55000, batch loss = 0.45\n",
      "epoch 1, step 25500/55000, batch loss = 0.42\n",
      "epoch 1, step 25750/55000, batch loss = 0.46\n",
      "epoch 1, step 26000/55000, batch loss = 0.48\n",
      "epoch 1, step 26250/55000, batch loss = 0.65\n",
      "epoch 1, step 26500/55000, batch loss = 0.52\n",
      "epoch 1, step 26750/55000, batch loss = 0.43\n",
      "epoch 1, step 27000/55000, batch loss = 0.44\n",
      "epoch 1, step 27250/55000, batch loss = 0.47\n",
      "epoch 1, step 27500/55000, batch loss = 0.54\n",
      "Train accuracy = 93.06\n",
      "epoch 1, step 27750/55000, batch loss = 0.43\n",
      "epoch 1, step 28000/55000, batch loss = 0.52\n",
      "epoch 1, step 28250/55000, batch loss = 0.42\n",
      "epoch 1, step 28500/55000, batch loss = 0.57\n",
      "epoch 1, step 28750/55000, batch loss = 0.47\n",
      "epoch 1, step 29000/55000, batch loss = 0.44\n",
      "epoch 1, step 29250/55000, batch loss = 0.45\n",
      "epoch 1, step 29500/55000, batch loss = 0.49\n",
      "epoch 1, step 29750/55000, batch loss = 0.51\n",
      "epoch 1, step 30000/55000, batch loss = 0.51\n",
      "Train accuracy = 93.42\n",
      "epoch 1, step 30250/55000, batch loss = 0.51\n",
      "epoch 1, step 30500/55000, batch loss = 0.49\n",
      "epoch 1, step 30750/55000, batch loss = 0.45\n",
      "epoch 1, step 31000/55000, batch loss = 0.53\n",
      "epoch 1, step 31250/55000, batch loss = 0.42\n",
      "epoch 1, step 31500/55000, batch loss = 0.59\n",
      "epoch 1, step 31750/55000, batch loss = 0.45\n",
      "epoch 1, step 32000/55000, batch loss = 0.47\n",
      "epoch 1, step 32250/55000, batch loss = 0.41\n",
      "epoch 1, step 32500/55000, batch loss = 0.46\n",
      "Train accuracy = 93.75\n",
      "epoch 1, step 32750/55000, batch loss = 0.41\n",
      "epoch 1, step 33000/55000, batch loss = 0.41\n",
      "epoch 1, step 33250/55000, batch loss = 0.53\n",
      "epoch 1, step 33500/55000, batch loss = 0.42\n",
      "epoch 1, step 33750/55000, batch loss = 0.51\n",
      "epoch 1, step 34000/55000, batch loss = 0.45\n",
      "epoch 1, step 34250/55000, batch loss = 0.42\n",
      "epoch 1, step 34500/55000, batch loss = 0.46\n",
      "epoch 1, step 34750/55000, batch loss = 0.43\n",
      "epoch 1, step 35000/55000, batch loss = 0.56\n",
      "Train accuracy = 94.04\n",
      "epoch 1, step 35250/55000, batch loss = 0.44\n",
      "epoch 1, step 35500/55000, batch loss = 0.51\n",
      "epoch 1, step 35750/55000, batch loss = 0.44\n",
      "epoch 1, step 36000/55000, batch loss = 0.45\n",
      "epoch 1, step 36250/55000, batch loss = 0.42\n",
      "epoch 1, step 36500/55000, batch loss = 0.46\n",
      "epoch 1, step 36750/55000, batch loss = 0.42\n",
      "epoch 1, step 37000/55000, batch loss = 0.42\n",
      "epoch 1, step 37250/55000, batch loss = 0.45\n",
      "epoch 1, step 37500/55000, batch loss = 0.46\n",
      "Train accuracy = 94.29\n",
      "epoch 1, step 37750/55000, batch loss = 0.55\n",
      "epoch 1, step 38000/55000, batch loss = 0.42\n",
      "epoch 1, step 38250/55000, batch loss = 0.51\n",
      "epoch 1, step 38500/55000, batch loss = 0.50\n",
      "epoch 1, step 38750/55000, batch loss = 0.46\n",
      "epoch 1, step 39000/55000, batch loss = 0.48\n",
      "epoch 1, step 39250/55000, batch loss = 0.64\n",
      "epoch 1, step 39500/55000, batch loss = 0.39\n",
      "epoch 1, step 39750/55000, batch loss = 0.51\n",
      "epoch 1, step 40000/55000, batch loss = 0.43\n",
      "Train accuracy = 94.48\n",
      "epoch 1, step 40250/55000, batch loss = 0.48\n",
      "epoch 1, step 40500/55000, batch loss = 0.42\n",
      "epoch 1, step 40750/55000, batch loss = 0.53\n",
      "epoch 1, step 41000/55000, batch loss = 0.39\n",
      "epoch 1, step 41250/55000, batch loss = 0.42\n",
      "epoch 1, step 41500/55000, batch loss = 0.48\n",
      "epoch 1, step 41750/55000, batch loss = 0.45\n",
      "epoch 1, step 42000/55000, batch loss = 0.41\n",
      "epoch 1, step 42250/55000, batch loss = 0.40\n",
      "epoch 1, step 42500/55000, batch loss = 0.48\n",
      "Train accuracy = 94.67\n",
      "epoch 1, step 42750/55000, batch loss = 0.47\n",
      "epoch 1, step 43000/55000, batch loss = 0.40\n",
      "epoch 1, step 43250/55000, batch loss = 0.39\n",
      "epoch 1, step 43500/55000, batch loss = 0.41\n",
      "epoch 1, step 43750/55000, batch loss = 0.49\n",
      "epoch 1, step 44000/55000, batch loss = 0.43\n",
      "epoch 1, step 44250/55000, batch loss = 0.42\n",
      "epoch 1, step 44500/55000, batch loss = 0.44\n",
      "epoch 1, step 44750/55000, batch loss = 0.40\n",
      "epoch 1, step 45000/55000, batch loss = 0.39\n",
      "Train accuracy = 94.87\n",
      "epoch 1, step 45250/55000, batch loss = 0.39\n",
      "epoch 1, step 45500/55000, batch loss = 0.60\n",
      "epoch 1, step 45750/55000, batch loss = 0.49\n",
      "epoch 1, step 46000/55000, batch loss = 0.42\n",
      "epoch 1, step 46250/55000, batch loss = 0.42\n",
      "epoch 1, step 46500/55000, batch loss = 0.48\n",
      "epoch 1, step 46750/55000, batch loss = 0.39\n",
      "epoch 1, step 47000/55000, batch loss = 0.48\n",
      "epoch 1, step 47250/55000, batch loss = 0.59\n",
      "epoch 1, step 47500/55000, batch loss = 0.51\n",
      "Train accuracy = 95.02\n",
      "epoch 1, step 47750/55000, batch loss = 0.43\n",
      "epoch 1, step 48000/55000, batch loss = 0.39\n",
      "epoch 1, step 48250/55000, batch loss = 0.38\n",
      "epoch 1, step 48500/55000, batch loss = 0.49\n",
      "epoch 1, step 48750/55000, batch loss = 0.64\n",
      "epoch 1, step 49000/55000, batch loss = 0.51\n",
      "epoch 1, step 49250/55000, batch loss = 0.41\n",
      "epoch 1, step 49500/55000, batch loss = 0.47\n",
      "epoch 1, step 49750/55000, batch loss = 0.40\n",
      "epoch 1, step 50000/55000, batch loss = 0.56\n",
      "Train accuracy = 95.14\n",
      "epoch 1, step 50250/55000, batch loss = 0.39\n",
      "epoch 1, step 50500/55000, batch loss = 0.55\n",
      "epoch 1, step 50750/55000, batch loss = 0.44\n",
      "epoch 1, step 51000/55000, batch loss = 0.55\n",
      "epoch 1, step 51250/55000, batch loss = 0.58\n",
      "epoch 1, step 51500/55000, batch loss = 0.40\n",
      "epoch 1, step 51750/55000, batch loss = 0.54\n",
      "epoch 1, step 52000/55000, batch loss = 0.55\n",
      "epoch 1, step 52250/55000, batch loss = 0.52\n",
      "epoch 1, step 52500/55000, batch loss = 0.39\n",
      "Train accuracy = 95.26\n",
      "epoch 1, step 52750/55000, batch loss = 0.40\n",
      "epoch 1, step 53000/55000, batch loss = 0.53\n",
      "epoch 1, step 53250/55000, batch loss = 0.47\n",
      "epoch 1, step 53500/55000, batch loss = 0.44\n",
      "epoch 1, step 53750/55000, batch loss = 0.44\n",
      "epoch 1, step 54000/55000, batch loss = 0.44\n",
      "epoch 1, step 54250/55000, batch loss = 0.42\n",
      "epoch 1, step 54500/55000, batch loss = 0.38\n",
      "epoch 1, step 54750/55000, batch loss = 0.46\n",
      "Train accuracy = 95.39\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 98.34\n",
      "Validation avg loss = 0.42\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, step 0/55000, batch loss = 0.38\n",
      "epoch 2, step 250/55000, batch loss = 0.43\n",
      "epoch 2, step 500/55000, batch loss = 0.50\n",
      "epoch 2, step 750/55000, batch loss = 0.41\n",
      "epoch 2, step 1000/55000, batch loss = 0.43\n",
      "epoch 2, step 1250/55000, batch loss = 0.37\n",
      "epoch 2, step 1500/55000, batch loss = 0.37\n",
      "epoch 2, step 1750/55000, batch loss = 0.53\n",
      "epoch 2, step 2000/55000, batch loss = 0.37\n",
      "epoch 2, step 2250/55000, batch loss = 0.37\n",
      "epoch 2, step 2500/55000, batch loss = 0.38\n",
      "Train accuracy = 98.08\n",
      "epoch 2, step 2750/55000, batch loss = 0.39\n",
      "epoch 2, step 3000/55000, batch loss = 0.44\n",
      "epoch 2, step 3250/55000, batch loss = 0.39\n",
      "epoch 2, step 3500/55000, batch loss = 0.38\n",
      "epoch 2, step 3750/55000, batch loss = 0.36\n",
      "epoch 2, step 4000/55000, batch loss = 0.36\n",
      "epoch 2, step 4250/55000, batch loss = 0.38\n",
      "epoch 2, step 4500/55000, batch loss = 0.40\n",
      "epoch 2, step 4750/55000, batch loss = 0.39\n",
      "epoch 2, step 5000/55000, batch loss = 0.41\n",
      "Train accuracy = 98.22\n",
      "epoch 2, step 5250/55000, batch loss = 0.38\n",
      "epoch 2, step 5500/55000, batch loss = 0.37\n",
      "epoch 2, step 5750/55000, batch loss = 0.37\n",
      "epoch 2, step 6000/55000, batch loss = 0.44\n",
      "epoch 2, step 6250/55000, batch loss = 0.37\n",
      "epoch 2, step 6500/55000, batch loss = 0.36\n",
      "epoch 2, step 6750/55000, batch loss = 0.36\n",
      "epoch 2, step 7000/55000, batch loss = 0.42\n",
      "epoch 2, step 7250/55000, batch loss = 0.38\n",
      "epoch 2, step 7500/55000, batch loss = 0.43\n",
      "Train accuracy = 98.23\n",
      "epoch 2, step 7750/55000, batch loss = 0.36\n",
      "epoch 2, step 8000/55000, batch loss = 0.37\n",
      "epoch 2, step 8250/55000, batch loss = 0.53\n",
      "epoch 2, step 8500/55000, batch loss = 0.48\n",
      "epoch 2, step 8750/55000, batch loss = 0.38\n",
      "epoch 2, step 9000/55000, batch loss = 0.36\n",
      "epoch 2, step 9250/55000, batch loss = 0.36\n",
      "epoch 2, step 9500/55000, batch loss = 0.41\n",
      "epoch 2, step 9750/55000, batch loss = 0.40\n",
      "epoch 2, step 10000/55000, batch loss = 0.38\n",
      "Train accuracy = 98.09\n",
      "epoch 2, step 10250/55000, batch loss = 0.37\n",
      "epoch 2, step 10500/55000, batch loss = 0.39\n",
      "epoch 2, step 10750/55000, batch loss = 0.48\n",
      "epoch 2, step 11000/55000, batch loss = 0.35\n",
      "epoch 2, step 11250/55000, batch loss = 0.37\n",
      "epoch 2, step 11500/55000, batch loss = 0.41\n",
      "epoch 2, step 11750/55000, batch loss = 0.39\n",
      "epoch 2, step 12000/55000, batch loss = 0.39\n",
      "epoch 2, step 12250/55000, batch loss = 0.37\n",
      "epoch 2, step 12500/55000, batch loss = 0.37\n",
      "Train accuracy = 98.17\n",
      "epoch 2, step 12750/55000, batch loss = 0.36\n",
      "epoch 2, step 13000/55000, batch loss = 0.36\n",
      "epoch 2, step 13250/55000, batch loss = 0.37\n",
      "epoch 2, step 13500/55000, batch loss = 0.37\n",
      "epoch 2, step 13750/55000, batch loss = 0.37\n",
      "epoch 2, step 14000/55000, batch loss = 0.50\n",
      "epoch 2, step 14250/55000, batch loss = 0.41\n",
      "epoch 2, step 14500/55000, batch loss = 0.44\n",
      "epoch 2, step 14750/55000, batch loss = 0.44\n",
      "epoch 2, step 15000/55000, batch loss = 0.35\n",
      "Train accuracy = 98.21\n",
      "epoch 2, step 15250/55000, batch loss = 0.37\n",
      "epoch 2, step 15500/55000, batch loss = 0.35\n",
      "epoch 2, step 15750/55000, batch loss = 0.38\n",
      "epoch 2, step 16000/55000, batch loss = 0.52\n",
      "epoch 2, step 16250/55000, batch loss = 0.38\n",
      "epoch 2, step 16500/55000, batch loss = 0.37\n",
      "epoch 2, step 16750/55000, batch loss = 0.43\n",
      "epoch 2, step 17000/55000, batch loss = 0.36\n",
      "epoch 2, step 17250/55000, batch loss = 0.42\n",
      "epoch 2, step 17500/55000, batch loss = 0.35\n",
      "Train accuracy = 98.25\n",
      "epoch 2, step 17750/55000, batch loss = 0.38\n",
      "epoch 2, step 18000/55000, batch loss = 0.38\n",
      "epoch 2, step 18250/55000, batch loss = 0.35\n",
      "epoch 2, step 18500/55000, batch loss = 0.35\n",
      "epoch 2, step 18750/55000, batch loss = 0.37\n",
      "epoch 2, step 19000/55000, batch loss = 0.37\n",
      "epoch 2, step 19250/55000, batch loss = 0.35\n",
      "epoch 2, step 19500/55000, batch loss = 0.35\n",
      "epoch 2, step 19750/55000, batch loss = 0.41\n",
      "epoch 2, step 20000/55000, batch loss = 0.36\n",
      "Train accuracy = 98.29\n",
      "epoch 2, step 20250/55000, batch loss = 0.38\n",
      "epoch 2, step 20500/55000, batch loss = 0.38\n",
      "epoch 2, step 20750/55000, batch loss = 0.38\n",
      "epoch 2, step 21000/55000, batch loss = 0.39\n",
      "epoch 2, step 21250/55000, batch loss = 0.36\n",
      "epoch 2, step 21500/55000, batch loss = 0.37\n",
      "epoch 2, step 21750/55000, batch loss = 0.35\n",
      "epoch 2, step 22000/55000, batch loss = 0.38\n",
      "epoch 2, step 22250/55000, batch loss = 0.36\n",
      "epoch 2, step 22500/55000, batch loss = 0.38\n",
      "Train accuracy = 98.32\n",
      "epoch 2, step 22750/55000, batch loss = 0.35\n",
      "epoch 2, step 23000/55000, batch loss = 0.35\n",
      "epoch 2, step 23250/55000, batch loss = 0.48\n",
      "epoch 2, step 23500/55000, batch loss = 0.37\n",
      "epoch 2, step 23750/55000, batch loss = 0.53\n",
      "epoch 2, step 24000/55000, batch loss = 0.56\n",
      "epoch 2, step 24250/55000, batch loss = 0.35\n",
      "epoch 2, step 24500/55000, batch loss = 0.40\n",
      "epoch 2, step 24750/55000, batch loss = 0.37\n",
      "epoch 2, step 25000/55000, batch loss = 0.34\n",
      "Train accuracy = 98.37\n",
      "epoch 2, step 25250/55000, batch loss = 0.43\n",
      "epoch 2, step 25500/55000, batch loss = 0.40\n",
      "epoch 2, step 25750/55000, batch loss = 0.38\n",
      "epoch 2, step 26000/55000, batch loss = 0.35\n",
      "epoch 2, step 26250/55000, batch loss = 0.34\n",
      "epoch 2, step 26500/55000, batch loss = 0.35\n",
      "epoch 2, step 26750/55000, batch loss = 0.36\n",
      "epoch 2, step 27000/55000, batch loss = 0.36\n",
      "epoch 2, step 27250/55000, batch loss = 0.40\n",
      "epoch 2, step 27500/55000, batch loss = 0.37\n",
      "Train accuracy = 98.41\n",
      "epoch 2, step 27750/55000, batch loss = 0.45\n",
      "epoch 2, step 28000/55000, batch loss = 0.52\n",
      "epoch 2, step 28250/55000, batch loss = 0.38\n",
      "epoch 2, step 28500/55000, batch loss = 0.35\n",
      "epoch 2, step 28750/55000, batch loss = 0.38\n",
      "epoch 2, step 29000/55000, batch loss = 0.35\n",
      "epoch 2, step 29250/55000, batch loss = 0.39\n",
      "epoch 2, step 29500/55000, batch loss = 0.43\n",
      "epoch 2, step 29750/55000, batch loss = 0.42\n",
      "epoch 2, step 30000/55000, batch loss = 0.44\n",
      "Train accuracy = 98.39\n",
      "epoch 2, step 30250/55000, batch loss = 0.36\n",
      "epoch 2, step 30500/55000, batch loss = 0.35\n",
      "epoch 2, step 30750/55000, batch loss = 0.37\n",
      "epoch 2, step 31000/55000, batch loss = 0.42\n",
      "epoch 2, step 31250/55000, batch loss = 0.35\n",
      "epoch 2, step 31500/55000, batch loss = 0.34\n",
      "epoch 2, step 31750/55000, batch loss = 0.34\n",
      "epoch 2, step 32000/55000, batch loss = 0.34\n",
      "epoch 2, step 32250/55000, batch loss = 0.35\n",
      "epoch 2, step 32500/55000, batch loss = 0.35\n",
      "Train accuracy = 98.41\n",
      "epoch 2, step 32750/55000, batch loss = 0.42\n",
      "epoch 2, step 33000/55000, batch loss = 0.35\n",
      "epoch 2, step 33250/55000, batch loss = 0.39\n",
      "epoch 2, step 33500/55000, batch loss = 0.49\n",
      "epoch 2, step 33750/55000, batch loss = 0.33\n",
      "epoch 2, step 34000/55000, batch loss = 0.33\n",
      "epoch 2, step 34250/55000, batch loss = 0.35\n",
      "epoch 2, step 34500/55000, batch loss = 0.37\n",
      "epoch 2, step 34750/55000, batch loss = 0.42\n",
      "epoch 2, step 35000/55000, batch loss = 0.34\n",
      "Train accuracy = 98.39\n",
      "epoch 2, step 35250/55000, batch loss = 0.33\n",
      "epoch 2, step 35500/55000, batch loss = 0.41\n",
      "epoch 2, step 35750/55000, batch loss = 0.33\n",
      "epoch 2, step 36000/55000, batch loss = 0.36\n",
      "epoch 2, step 36250/55000, batch loss = 0.33\n",
      "epoch 2, step 36500/55000, batch loss = 0.34\n",
      "epoch 2, step 36750/55000, batch loss = 0.37\n",
      "epoch 2, step 37000/55000, batch loss = 0.39\n",
      "epoch 2, step 37250/55000, batch loss = 0.34\n",
      "epoch 2, step 37500/55000, batch loss = 0.35\n",
      "Train accuracy = 98.40\n",
      "epoch 2, step 37750/55000, batch loss = 0.42\n",
      "epoch 2, step 38000/55000, batch loss = 0.37\n",
      "epoch 2, step 38250/55000, batch loss = 0.33\n",
      "epoch 2, step 38500/55000, batch loss = 0.38\n",
      "epoch 2, step 38750/55000, batch loss = 0.32\n",
      "epoch 2, step 39000/55000, batch loss = 0.32\n",
      "epoch 2, step 39250/55000, batch loss = 0.33\n",
      "epoch 2, step 39500/55000, batch loss = 0.35\n",
      "epoch 2, step 39750/55000, batch loss = 0.35\n",
      "epoch 2, step 40000/55000, batch loss = 0.48\n",
      "Train accuracy = 98.42\n",
      "epoch 2, step 40250/55000, batch loss = 0.33\n",
      "epoch 2, step 40500/55000, batch loss = 0.32\n",
      "epoch 2, step 40750/55000, batch loss = 0.47\n",
      "epoch 2, step 41000/55000, batch loss = 0.34\n",
      "epoch 2, step 41250/55000, batch loss = 0.36\n",
      "epoch 2, step 41500/55000, batch loss = 0.36\n",
      "epoch 2, step 41750/55000, batch loss = 0.35\n",
      "epoch 2, step 42000/55000, batch loss = 0.37\n",
      "epoch 2, step 42250/55000, batch loss = 0.32\n",
      "epoch 2, step 42500/55000, batch loss = 0.37\n",
      "Train accuracy = 98.43\n",
      "epoch 2, step 42750/55000, batch loss = 0.41\n",
      "epoch 2, step 43000/55000, batch loss = 0.32\n",
      "epoch 2, step 43250/55000, batch loss = 0.36\n",
      "epoch 2, step 43500/55000, batch loss = 0.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, step 43750/55000, batch loss = 0.35\n",
      "epoch 2, step 44000/55000, batch loss = 0.34\n",
      "epoch 2, step 44250/55000, batch loss = 0.32\n",
      "epoch 2, step 44500/55000, batch loss = 0.38\n",
      "epoch 2, step 44750/55000, batch loss = 0.33\n",
      "epoch 2, step 45000/55000, batch loss = 0.43\n",
      "Train accuracy = 98.45\n",
      "epoch 2, step 45250/55000, batch loss = 0.34\n",
      "epoch 2, step 45500/55000, batch loss = 0.32\n",
      "epoch 2, step 45750/55000, batch loss = 0.32\n",
      "epoch 2, step 46000/55000, batch loss = 0.33\n",
      "epoch 2, step 46250/55000, batch loss = 0.42\n",
      "epoch 2, step 46500/55000, batch loss = 0.32\n",
      "epoch 2, step 46750/55000, batch loss = 0.31\n",
      "epoch 2, step 47000/55000, batch loss = 0.39\n",
      "epoch 2, step 47250/55000, batch loss = 0.40\n",
      "epoch 2, step 47500/55000, batch loss = 0.33\n",
      "Train accuracy = 98.46\n",
      "epoch 2, step 47750/55000, batch loss = 0.40\n",
      "epoch 2, step 48000/55000, batch loss = 0.31\n",
      "epoch 2, step 48250/55000, batch loss = 0.32\n",
      "epoch 2, step 48500/55000, batch loss = 0.43\n",
      "epoch 2, step 48750/55000, batch loss = 0.33\n",
      "epoch 2, step 49000/55000, batch loss = 0.34\n",
      "epoch 2, step 49250/55000, batch loss = 0.37\n",
      "epoch 2, step 49500/55000, batch loss = 0.33\n",
      "epoch 2, step 49750/55000, batch loss = 0.39\n",
      "epoch 2, step 50000/55000, batch loss = 0.39\n",
      "Train accuracy = 98.47\n",
      "epoch 2, step 50250/55000, batch loss = 0.32\n",
      "epoch 2, step 50500/55000, batch loss = 0.34\n",
      "epoch 2, step 50750/55000, batch loss = 0.35\n",
      "epoch 2, step 51000/55000, batch loss = 0.39\n",
      "epoch 2, step 51250/55000, batch loss = 0.33\n",
      "epoch 2, step 51500/55000, batch loss = 0.35\n",
      "epoch 2, step 51750/55000, batch loss = 0.32\n",
      "epoch 2, step 52000/55000, batch loss = 0.39\n",
      "epoch 2, step 52250/55000, batch loss = 0.32\n",
      "epoch 2, step 52500/55000, batch loss = 0.32\n",
      "Train accuracy = 98.46\n",
      "epoch 2, step 52750/55000, batch loss = 0.34\n",
      "epoch 2, step 53000/55000, batch loss = 0.38\n",
      "epoch 2, step 53250/55000, batch loss = 0.31\n",
      "epoch 2, step 53500/55000, batch loss = 0.35\n",
      "epoch 2, step 53750/55000, batch loss = 0.33\n",
      "epoch 2, step 54000/55000, batch loss = 0.33\n",
      "epoch 2, step 54250/55000, batch loss = 0.31\n",
      "epoch 2, step 54500/55000, batch loss = 0.34\n",
      "epoch 2, step 54750/55000, batch loss = 0.44\n",
      "Train accuracy = 98.47\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 98.56\n",
      "Validation avg loss = 0.35\n",
      "\n",
      "epoch 3, step 0/55000, batch loss = 0.38\n",
      "epoch 3, step 250/55000, batch loss = 0.31\n",
      "epoch 3, step 500/55000, batch loss = 0.37\n",
      "epoch 3, step 750/55000, batch loss = 0.33\n",
      "epoch 3, step 1000/55000, batch loss = 0.31\n",
      "epoch 3, step 1250/55000, batch loss = 0.30\n",
      "epoch 3, step 1500/55000, batch loss = 0.30\n",
      "epoch 3, step 1750/55000, batch loss = 0.30\n",
      "epoch 3, step 2000/55000, batch loss = 0.35\n",
      "epoch 3, step 2250/55000, batch loss = 0.33\n",
      "epoch 3, step 2500/55000, batch loss = 0.31\n",
      "Train accuracy = 99.10\n",
      "epoch 3, step 2750/55000, batch loss = 0.30\n",
      "epoch 3, step 3000/55000, batch loss = 0.30\n",
      "epoch 3, step 3250/55000, batch loss = 0.31\n",
      "epoch 3, step 3500/55000, batch loss = 0.33\n",
      "epoch 3, step 3750/55000, batch loss = 0.33\n",
      "epoch 3, step 4000/55000, batch loss = 0.31\n",
      "epoch 3, step 4250/55000, batch loss = 0.33\n",
      "epoch 3, step 4500/55000, batch loss = 0.31\n",
      "epoch 3, step 4750/55000, batch loss = 0.30\n",
      "epoch 3, step 5000/55000, batch loss = 0.31\n",
      "Train accuracy = 99.23\n",
      "epoch 3, step 5250/55000, batch loss = 0.42\n",
      "epoch 3, step 5500/55000, batch loss = 0.32\n",
      "epoch 3, step 5750/55000, batch loss = 0.32\n",
      "epoch 3, step 6000/55000, batch loss = 0.43\n",
      "epoch 3, step 6250/55000, batch loss = 0.30\n",
      "epoch 3, step 6500/55000, batch loss = 0.30\n",
      "epoch 3, step 6750/55000, batch loss = 0.31\n",
      "epoch 3, step 7000/55000, batch loss = 0.31\n",
      "epoch 3, step 7250/55000, batch loss = 0.33\n",
      "epoch 3, step 7500/55000, batch loss = 0.31\n",
      "Train accuracy = 99.14\n",
      "epoch 3, step 7750/55000, batch loss = 0.30\n",
      "epoch 3, step 8000/55000, batch loss = 0.31\n",
      "epoch 3, step 8250/55000, batch loss = 0.31\n",
      "epoch 3, step 8500/55000, batch loss = 0.33\n",
      "epoch 3, step 8750/55000, batch loss = 0.32\n",
      "epoch 3, step 9000/55000, batch loss = 0.31\n",
      "epoch 3, step 9250/55000, batch loss = 0.35\n",
      "epoch 3, step 9500/55000, batch loss = 0.41\n",
      "epoch 3, step 9750/55000, batch loss = 0.31\n",
      "epoch 3, step 10000/55000, batch loss = 0.32\n",
      "Train accuracy = 99.21\n",
      "epoch 3, step 10250/55000, batch loss = 0.40\n",
      "epoch 3, step 10500/55000, batch loss = 0.32\n",
      "epoch 3, step 10750/55000, batch loss = 0.32\n",
      "epoch 3, step 11000/55000, batch loss = 0.33\n",
      "epoch 3, step 11250/55000, batch loss = 0.31\n",
      "epoch 3, step 11500/55000, batch loss = 0.32\n",
      "epoch 3, step 11750/55000, batch loss = 0.30\n",
      "epoch 3, step 12000/55000, batch loss = 0.32\n",
      "epoch 3, step 12250/55000, batch loss = 0.40\n",
      "epoch 3, step 12500/55000, batch loss = 0.50\n",
      "Train accuracy = 99.24\n",
      "epoch 3, step 12750/55000, batch loss = 0.30\n",
      "epoch 3, step 13000/55000, batch loss = 0.30\n",
      "epoch 3, step 13250/55000, batch loss = 0.30\n",
      "epoch 3, step 13500/55000, batch loss = 0.31\n",
      "epoch 3, step 13750/55000, batch loss = 0.30\n",
      "epoch 3, step 14000/55000, batch loss = 0.36\n",
      "epoch 3, step 14250/55000, batch loss = 0.32\n",
      "epoch 3, step 14500/55000, batch loss = 0.31\n",
      "epoch 3, step 14750/55000, batch loss = 0.30\n",
      "epoch 3, step 15000/55000, batch loss = 0.31\n",
      "Train accuracy = 99.28\n",
      "epoch 3, step 15250/55000, batch loss = 0.32\n",
      "epoch 3, step 15500/55000, batch loss = 0.31\n",
      "epoch 3, step 15750/55000, batch loss = 0.36\n",
      "epoch 3, step 16000/55000, batch loss = 0.31\n",
      "epoch 3, step 16250/55000, batch loss = 0.30\n",
      "epoch 3, step 16500/55000, batch loss = 0.38\n",
      "epoch 3, step 16750/55000, batch loss = 0.32\n",
      "epoch 3, step 17000/55000, batch loss = 0.31\n",
      "epoch 3, step 17250/55000, batch loss = 0.33\n",
      "epoch 3, step 17500/55000, batch loss = 0.34\n",
      "Train accuracy = 99.26\n",
      "epoch 3, step 17750/55000, batch loss = 0.30\n",
      "epoch 3, step 18000/55000, batch loss = 0.32\n",
      "epoch 3, step 18250/55000, batch loss = 0.30\n",
      "epoch 3, step 18500/55000, batch loss = 0.37\n",
      "epoch 3, step 18750/55000, batch loss = 0.30\n",
      "epoch 3, step 19000/55000, batch loss = 0.31\n",
      "epoch 3, step 19250/55000, batch loss = 0.32\n",
      "epoch 3, step 19500/55000, batch loss = 0.31\n",
      "epoch 3, step 19750/55000, batch loss = 0.31\n",
      "epoch 3, step 20000/55000, batch loss = 0.32\n",
      "Train accuracy = 99.28\n",
      "epoch 3, step 20250/55000, batch loss = 0.31\n",
      "epoch 3, step 20500/55000, batch loss = 0.33\n",
      "epoch 3, step 20750/55000, batch loss = 0.32\n",
      "epoch 3, step 21000/55000, batch loss = 0.31\n",
      "epoch 3, step 21250/55000, batch loss = 0.35\n",
      "epoch 3, step 21500/55000, batch loss = 0.30\n",
      "epoch 3, step 21750/55000, batch loss = 0.34\n",
      "epoch 3, step 22000/55000, batch loss = 0.30\n",
      "epoch 3, step 22250/55000, batch loss = 0.38\n",
      "epoch 3, step 22500/55000, batch loss = 0.31\n",
      "Train accuracy = 99.30\n",
      "epoch 3, step 22750/55000, batch loss = 0.31\n",
      "epoch 3, step 23000/55000, batch loss = 0.30\n",
      "epoch 3, step 23250/55000, batch loss = 0.30\n",
      "epoch 3, step 23500/55000, batch loss = 0.32\n",
      "epoch 3, step 23750/55000, batch loss = 0.35\n",
      "epoch 3, step 24000/55000, batch loss = 0.31\n",
      "epoch 3, step 24250/55000, batch loss = 0.35\n",
      "epoch 3, step 24500/55000, batch loss = 0.30\n",
      "epoch 3, step 24750/55000, batch loss = 0.30\n",
      "epoch 3, step 25000/55000, batch loss = 0.36\n",
      "Train accuracy = 99.26\n",
      "epoch 3, step 25250/55000, batch loss = 0.32\n",
      "epoch 3, step 25500/55000, batch loss = 0.33\n",
      "epoch 3, step 25750/55000, batch loss = 0.30\n",
      "epoch 3, step 26000/55000, batch loss = 0.31\n",
      "epoch 3, step 26250/55000, batch loss = 0.44\n",
      "epoch 3, step 26500/55000, batch loss = 0.31\n",
      "epoch 3, step 26750/55000, batch loss = 0.31\n",
      "epoch 3, step 27000/55000, batch loss = 0.30\n",
      "epoch 3, step 27250/55000, batch loss = 0.30\n",
      "epoch 3, step 27500/55000, batch loss = 0.30\n",
      "Train accuracy = 99.25\n",
      "epoch 3, step 27750/55000, batch loss = 0.31\n",
      "epoch 3, step 28000/55000, batch loss = 0.32\n",
      "epoch 3, step 28250/55000, batch loss = 0.35\n",
      "epoch 3, step 28500/55000, batch loss = 0.33\n",
      "epoch 3, step 28750/55000, batch loss = 0.32\n",
      "epoch 3, step 29000/55000, batch loss = 0.30\n",
      "epoch 3, step 29250/55000, batch loss = 0.30\n",
      "epoch 3, step 29500/55000, batch loss = 0.34\n",
      "epoch 3, step 29750/55000, batch loss = 0.30\n",
      "epoch 3, step 30000/55000, batch loss = 0.30\n",
      "Train accuracy = 99.24\n",
      "epoch 3, step 30250/55000, batch loss = 0.34\n",
      "epoch 3, step 30500/55000, batch loss = 0.32\n",
      "epoch 3, step 30750/55000, batch loss = 0.33\n",
      "epoch 3, step 31000/55000, batch loss = 0.30\n",
      "epoch 3, step 31250/55000, batch loss = 0.30\n",
      "epoch 3, step 31500/55000, batch loss = 0.33\n",
      "epoch 3, step 31750/55000, batch loss = 0.30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, step 32000/55000, batch loss = 0.31\n",
      "epoch 3, step 32250/55000, batch loss = 0.30\n",
      "epoch 3, step 32500/55000, batch loss = 0.32\n",
      "Train accuracy = 99.24\n",
      "epoch 3, step 32750/55000, batch loss = 0.33\n",
      "epoch 3, step 33000/55000, batch loss = 0.31\n",
      "epoch 3, step 33250/55000, batch loss = 0.31\n",
      "epoch 3, step 33500/55000, batch loss = 0.31\n",
      "epoch 3, step 33750/55000, batch loss = 0.31\n",
      "epoch 3, step 34000/55000, batch loss = 0.30\n",
      "epoch 3, step 34250/55000, batch loss = 0.37\n",
      "epoch 3, step 34500/55000, batch loss = 0.32\n",
      "epoch 3, step 34750/55000, batch loss = 0.30\n",
      "epoch 3, step 35000/55000, batch loss = 0.32\n",
      "Train accuracy = 99.24\n",
      "epoch 3, step 35250/55000, batch loss = 0.32\n",
      "epoch 3, step 35500/55000, batch loss = 0.30\n",
      "epoch 3, step 35750/55000, batch loss = 0.30\n",
      "epoch 3, step 36000/55000, batch loss = 0.33\n",
      "epoch 3, step 36250/55000, batch loss = 0.32\n",
      "epoch 3, step 36500/55000, batch loss = 0.35\n",
      "epoch 3, step 36750/55000, batch loss = 0.30\n",
      "epoch 3, step 37000/55000, batch loss = 0.33\n",
      "epoch 3, step 37250/55000, batch loss = 0.40\n",
      "epoch 3, step 37500/55000, batch loss = 0.31\n",
      "Train accuracy = 99.23\n",
      "epoch 3, step 37750/55000, batch loss = 0.33\n",
      "epoch 3, step 38000/55000, batch loss = 0.30\n",
      "epoch 3, step 38250/55000, batch loss = 0.38\n",
      "epoch 3, step 38500/55000, batch loss = 0.30\n",
      "epoch 3, step 38750/55000, batch loss = 0.32\n",
      "epoch 3, step 39000/55000, batch loss = 0.31\n",
      "epoch 3, step 39250/55000, batch loss = 0.37\n",
      "epoch 3, step 39500/55000, batch loss = 0.30\n",
      "epoch 3, step 39750/55000, batch loss = 0.33\n",
      "epoch 3, step 40000/55000, batch loss = 0.35\n",
      "Train accuracy = 99.22\n",
      "epoch 3, step 40250/55000, batch loss = 0.30\n",
      "epoch 3, step 40500/55000, batch loss = 0.33\n",
      "epoch 3, step 40750/55000, batch loss = 0.30\n",
      "epoch 3, step 41000/55000, batch loss = 0.30\n",
      "epoch 3, step 41250/55000, batch loss = 0.30\n",
      "epoch 3, step 41500/55000, batch loss = 0.30\n",
      "epoch 3, step 41750/55000, batch loss = 0.30\n",
      "epoch 3, step 42000/55000, batch loss = 0.31\n",
      "epoch 3, step 42250/55000, batch loss = 0.38\n",
      "epoch 3, step 42500/55000, batch loss = 0.35\n",
      "Train accuracy = 99.22\n",
      "epoch 3, step 42750/55000, batch loss = 0.30\n",
      "epoch 3, step 43000/55000, batch loss = 0.32\n",
      "epoch 3, step 43250/55000, batch loss = 0.31\n",
      "epoch 3, step 43500/55000, batch loss = 0.31\n",
      "epoch 3, step 43750/55000, batch loss = 0.32\n",
      "epoch 3, step 44000/55000, batch loss = 0.30\n",
      "epoch 3, step 44250/55000, batch loss = 0.32\n",
      "epoch 3, step 44500/55000, batch loss = 0.30\n",
      "epoch 3, step 44750/55000, batch loss = 0.32\n",
      "epoch 3, step 45000/55000, batch loss = 0.31\n",
      "Train accuracy = 99.24\n",
      "epoch 3, step 45250/55000, batch loss = 0.30\n",
      "epoch 3, step 45500/55000, batch loss = 0.35\n",
      "epoch 3, step 45750/55000, batch loss = 0.30\n",
      "epoch 3, step 46000/55000, batch loss = 0.30\n",
      "epoch 3, step 46250/55000, batch loss = 0.31\n",
      "epoch 3, step 46500/55000, batch loss = 0.31\n",
      "epoch 3, step 46750/55000, batch loss = 0.30\n",
      "epoch 3, step 47000/55000, batch loss = 0.30\n",
      "epoch 3, step 47250/55000, batch loss = 0.33\n",
      "epoch 3, step 47500/55000, batch loss = 0.30\n",
      "Train accuracy = 99.25\n",
      "epoch 3, step 47750/55000, batch loss = 0.32\n",
      "epoch 3, step 48000/55000, batch loss = 0.49\n",
      "epoch 3, step 48250/55000, batch loss = 0.33\n",
      "epoch 3, step 48500/55000, batch loss = 0.30\n",
      "epoch 3, step 48750/55000, batch loss = 0.32\n",
      "epoch 3, step 49000/55000, batch loss = 0.30\n",
      "epoch 3, step 49250/55000, batch loss = 0.30\n",
      "epoch 3, step 49500/55000, batch loss = 0.36\n",
      "epoch 3, step 49750/55000, batch loss = 0.33\n",
      "epoch 3, step 50000/55000, batch loss = 0.30\n",
      "Train accuracy = 99.26\n",
      "epoch 3, step 50250/55000, batch loss = 0.44\n",
      "epoch 3, step 50500/55000, batch loss = 0.31\n",
      "epoch 3, step 50750/55000, batch loss = 0.30\n",
      "epoch 3, step 51000/55000, batch loss = 0.31\n",
      "epoch 3, step 51250/55000, batch loss = 0.30\n",
      "epoch 3, step 51500/55000, batch loss = 0.30\n",
      "epoch 3, step 51750/55000, batch loss = 0.30\n",
      "epoch 3, step 52000/55000, batch loss = 0.41\n",
      "epoch 3, step 52250/55000, batch loss = 0.30\n",
      "epoch 3, step 52500/55000, batch loss = 0.30\n",
      "Train accuracy = 99.26\n",
      "epoch 3, step 52750/55000, batch loss = 0.46\n",
      "epoch 3, step 53000/55000, batch loss = 0.30\n",
      "epoch 3, step 53250/55000, batch loss = 0.31\n",
      "epoch 3, step 53500/55000, batch loss = 0.30\n",
      "epoch 3, step 53750/55000, batch loss = 0.34\n",
      "epoch 3, step 54000/55000, batch loss = 0.35\n",
      "epoch 3, step 54250/55000, batch loss = 0.32\n",
      "epoch 3, step 54500/55000, batch loss = 0.31\n",
      "epoch 3, step 54750/55000, batch loss = 0.31\n",
      "Train accuracy = 99.26\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.08\n",
      "Validation avg loss = 0.33\n",
      "\n",
      "epoch 4, step 0/55000, batch loss = 0.34\n",
      "epoch 4, step 250/55000, batch loss = 0.32\n",
      "epoch 4, step 500/55000, batch loss = 0.32\n",
      "epoch 4, step 750/55000, batch loss = 0.29\n",
      "epoch 4, step 1000/55000, batch loss = 0.30\n",
      "epoch 4, step 1250/55000, batch loss = 0.34\n",
      "epoch 4, step 1500/55000, batch loss = 0.30\n",
      "epoch 4, step 1750/55000, batch loss = 0.30\n",
      "epoch 4, step 2000/55000, batch loss = 0.29\n",
      "epoch 4, step 2250/55000, batch loss = 0.30\n",
      "epoch 4, step 2500/55000, batch loss = 0.32\n",
      "Train accuracy = 99.73\n",
      "epoch 4, step 2750/55000, batch loss = 0.29\n",
      "epoch 4, step 3000/55000, batch loss = 0.30\n",
      "epoch 4, step 3250/55000, batch loss = 0.32\n",
      "epoch 4, step 3500/55000, batch loss = 0.31\n",
      "epoch 4, step 3750/55000, batch loss = 0.30\n",
      "epoch 4, step 4000/55000, batch loss = 0.30\n",
      "epoch 4, step 4250/55000, batch loss = 0.30\n",
      "epoch 4, step 4500/55000, batch loss = 0.31\n",
      "epoch 4, step 4750/55000, batch loss = 0.30\n",
      "epoch 4, step 5000/55000, batch loss = 0.41\n",
      "Train accuracy = 99.47\n",
      "epoch 4, step 5250/55000, batch loss = 0.32\n",
      "epoch 4, step 5500/55000, batch loss = 0.31\n",
      "epoch 4, step 5750/55000, batch loss = 0.31\n",
      "epoch 4, step 6000/55000, batch loss = 0.30\n",
      "epoch 4, step 6250/55000, batch loss = 0.41\n",
      "epoch 4, step 6500/55000, batch loss = 0.30\n",
      "epoch 4, step 6750/55000, batch loss = 0.29\n",
      "epoch 4, step 7000/55000, batch loss = 0.30\n",
      "epoch 4, step 7250/55000, batch loss = 0.29\n",
      "epoch 4, step 7500/55000, batch loss = 0.29\n",
      "Train accuracy = 99.40\n",
      "epoch 4, step 7750/55000, batch loss = 0.33\n",
      "epoch 4, step 8000/55000, batch loss = 0.33\n",
      "epoch 4, step 8250/55000, batch loss = 0.30\n",
      "epoch 4, step 8500/55000, batch loss = 0.33\n",
      "epoch 4, step 8750/55000, batch loss = 0.30\n",
      "epoch 4, step 9000/55000, batch loss = 0.30\n",
      "epoch 4, step 9250/55000, batch loss = 0.29\n",
      "epoch 4, step 9500/55000, batch loss = 0.30\n",
      "epoch 4, step 9750/55000, batch loss = 0.31\n",
      "epoch 4, step 10000/55000, batch loss = 0.30\n",
      "Train accuracy = 99.42\n",
      "epoch 4, step 10250/55000, batch loss = 0.29\n",
      "epoch 4, step 10500/55000, batch loss = 0.30\n",
      "epoch 4, step 10750/55000, batch loss = 0.31\n",
      "epoch 4, step 11000/55000, batch loss = 0.30\n",
      "epoch 4, step 11250/55000, batch loss = 0.30\n",
      "epoch 4, step 11500/55000, batch loss = 0.33\n",
      "epoch 4, step 11750/55000, batch loss = 0.31\n",
      "epoch 4, step 12000/55000, batch loss = 0.30\n",
      "epoch 4, step 12250/55000, batch loss = 0.29\n",
      "epoch 4, step 12500/55000, batch loss = 0.29\n",
      "Train accuracy = 99.45\n",
      "epoch 4, step 12750/55000, batch loss = 0.30\n",
      "epoch 4, step 13000/55000, batch loss = 0.32\n",
      "epoch 4, step 13250/55000, batch loss = 0.32\n",
      "epoch 4, step 13500/55000, batch loss = 0.30\n",
      "epoch 4, step 13750/55000, batch loss = 0.31\n",
      "epoch 4, step 14000/55000, batch loss = 0.32\n",
      "epoch 4, step 14250/55000, batch loss = 0.32\n",
      "epoch 4, step 14500/55000, batch loss = 0.32\n",
      "epoch 4, step 14750/55000, batch loss = 0.31\n",
      "epoch 4, step 15000/55000, batch loss = 0.30\n",
      "Train accuracy = 99.44\n",
      "epoch 4, step 15250/55000, batch loss = 0.30\n",
      "epoch 4, step 15500/55000, batch loss = 0.35\n",
      "epoch 4, step 15750/55000, batch loss = 0.31\n",
      "epoch 4, step 16000/55000, batch loss = 0.29\n",
      "epoch 4, step 16250/55000, batch loss = 0.33\n",
      "epoch 4, step 16500/55000, batch loss = 0.29\n",
      "epoch 4, step 16750/55000, batch loss = 0.32\n",
      "epoch 4, step 17000/55000, batch loss = 0.39\n",
      "epoch 4, step 17250/55000, batch loss = 0.31\n",
      "epoch 4, step 17500/55000, batch loss = 0.30\n",
      "Train accuracy = 99.38\n",
      "epoch 4, step 17750/55000, batch loss = 0.30\n",
      "epoch 4, step 18000/55000, batch loss = 0.30\n",
      "epoch 4, step 18250/55000, batch loss = 0.33\n",
      "epoch 4, step 18500/55000, batch loss = 0.31\n",
      "epoch 4, step 18750/55000, batch loss = 0.30\n",
      "epoch 4, step 19000/55000, batch loss = 0.30\n",
      "epoch 4, step 19250/55000, batch loss = 0.31\n",
      "epoch 4, step 19500/55000, batch loss = 0.29\n",
      "epoch 4, step 19750/55000, batch loss = 0.31\n",
      "epoch 4, step 20000/55000, batch loss = 0.33\n",
      "Train accuracy = 99.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, step 20250/55000, batch loss = 0.29\n",
      "epoch 4, step 20500/55000, batch loss = 0.33\n",
      "epoch 4, step 20750/55000, batch loss = 0.30\n",
      "epoch 4, step 21000/55000, batch loss = 0.30\n",
      "epoch 4, step 21250/55000, batch loss = 0.30\n",
      "epoch 4, step 21500/55000, batch loss = 0.31\n",
      "epoch 4, step 21750/55000, batch loss = 0.31\n",
      "epoch 4, step 22000/55000, batch loss = 0.30\n",
      "epoch 4, step 22250/55000, batch loss = 0.34\n",
      "epoch 4, step 22500/55000, batch loss = 0.29\n",
      "Train accuracy = 99.33\n",
      "epoch 4, step 22750/55000, batch loss = 0.30\n",
      "epoch 4, step 23000/55000, batch loss = 0.31\n",
      "epoch 4, step 23250/55000, batch loss = 0.33\n",
      "epoch 4, step 23500/55000, batch loss = 0.31\n",
      "epoch 4, step 23750/55000, batch loss = 0.31\n",
      "epoch 4, step 24000/55000, batch loss = 0.29\n",
      "epoch 4, step 24250/55000, batch loss = 0.30\n",
      "epoch 4, step 24500/55000, batch loss = 0.30\n",
      "epoch 4, step 24750/55000, batch loss = 0.30\n",
      "epoch 4, step 25000/55000, batch loss = 0.30\n",
      "Train accuracy = 99.35\n",
      "epoch 4, step 25250/55000, batch loss = 0.29\n",
      "epoch 4, step 25500/55000, batch loss = 0.32\n",
      "epoch 4, step 25750/55000, batch loss = 0.29\n",
      "epoch 4, step 26000/55000, batch loss = 0.37\n",
      "epoch 4, step 26250/55000, batch loss = 0.30\n",
      "epoch 4, step 26500/55000, batch loss = 0.30\n",
      "epoch 4, step 26750/55000, batch loss = 0.31\n",
      "epoch 4, step 27000/55000, batch loss = 0.30\n",
      "epoch 4, step 27250/55000, batch loss = 0.30\n",
      "epoch 4, step 27500/55000, batch loss = 0.29\n",
      "Train accuracy = 99.36\n",
      "epoch 4, step 27750/55000, batch loss = 0.30\n",
      "epoch 4, step 28000/55000, batch loss = 0.31\n",
      "epoch 4, step 28250/55000, batch loss = 0.30\n",
      "epoch 4, step 28500/55000, batch loss = 0.34\n",
      "epoch 4, step 28750/55000, batch loss = 0.32\n",
      "epoch 4, step 29000/55000, batch loss = 0.31\n",
      "epoch 4, step 29250/55000, batch loss = 0.34\n",
      "epoch 4, step 29500/55000, batch loss = 0.29\n",
      "epoch 4, step 29750/55000, batch loss = 0.30\n",
      "epoch 4, step 30000/55000, batch loss = 0.38\n",
      "Train accuracy = 99.35\n",
      "epoch 4, step 30250/55000, batch loss = 0.29\n",
      "epoch 4, step 30500/55000, batch loss = 0.30\n",
      "epoch 4, step 30750/55000, batch loss = 0.30\n",
      "epoch 4, step 31000/55000, batch loss = 0.40\n",
      "epoch 4, step 31250/55000, batch loss = 0.29\n",
      "epoch 4, step 31500/55000, batch loss = 0.32\n",
      "epoch 4, step 31750/55000, batch loss = 0.31\n",
      "epoch 4, step 32000/55000, batch loss = 0.30\n",
      "epoch 4, step 32250/55000, batch loss = 0.41\n",
      "epoch 4, step 32500/55000, batch loss = 0.30\n",
      "Train accuracy = 99.36\n",
      "epoch 4, step 32750/55000, batch loss = 0.29\n",
      "epoch 4, step 33000/55000, batch loss = 0.29\n",
      "epoch 4, step 33250/55000, batch loss = 0.30\n",
      "epoch 4, step 33500/55000, batch loss = 0.29\n",
      "epoch 4, step 33750/55000, batch loss = 0.37\n",
      "epoch 4, step 34000/55000, batch loss = 0.30\n",
      "epoch 4, step 34250/55000, batch loss = 0.29\n",
      "epoch 4, step 34500/55000, batch loss = 0.30\n",
      "epoch 4, step 34750/55000, batch loss = 0.32\n",
      "epoch 4, step 35000/55000, batch loss = 0.29\n",
      "Train accuracy = 99.37\n",
      "epoch 4, step 35250/55000, batch loss = 0.32\n",
      "epoch 4, step 35500/55000, batch loss = 0.30\n",
      "epoch 4, step 35750/55000, batch loss = 0.30\n",
      "epoch 4, step 36000/55000, batch loss = 0.35\n",
      "epoch 4, step 36250/55000, batch loss = 0.31\n",
      "epoch 4, step 36500/55000, batch loss = 0.30\n",
      "epoch 4, step 36750/55000, batch loss = 0.31\n",
      "epoch 4, step 37000/55000, batch loss = 0.30\n",
      "epoch 4, step 37250/55000, batch loss = 0.29\n",
      "epoch 4, step 37500/55000, batch loss = 0.29\n",
      "Train accuracy = 99.38\n",
      "epoch 4, step 37750/55000, batch loss = 0.40\n",
      "epoch 4, step 38000/55000, batch loss = 0.34\n",
      "epoch 4, step 38250/55000, batch loss = 0.29\n",
      "epoch 4, step 38500/55000, batch loss = 0.34\n",
      "epoch 4, step 38750/55000, batch loss = 0.30\n",
      "epoch 4, step 39000/55000, batch loss = 0.32\n",
      "epoch 4, step 39250/55000, batch loss = 0.30\n",
      "epoch 4, step 39500/55000, batch loss = 0.32\n",
      "epoch 4, step 39750/55000, batch loss = 0.30\n",
      "epoch 4, step 40000/55000, batch loss = 0.30\n",
      "Train accuracy = 99.37\n",
      "epoch 4, step 40250/55000, batch loss = 0.32\n",
      "epoch 4, step 40500/55000, batch loss = 0.31\n",
      "epoch 4, step 40750/55000, batch loss = 0.29\n",
      "epoch 4, step 41000/55000, batch loss = 0.30\n",
      "epoch 4, step 41250/55000, batch loss = 0.30\n",
      "epoch 4, step 41500/55000, batch loss = 0.30\n",
      "epoch 4, step 41750/55000, batch loss = 0.29\n",
      "epoch 4, step 42000/55000, batch loss = 0.31\n",
      "epoch 4, step 42250/55000, batch loss = 0.31\n",
      "epoch 4, step 42500/55000, batch loss = 0.33\n",
      "Train accuracy = 99.37\n",
      "epoch 4, step 42750/55000, batch loss = 0.29\n",
      "epoch 4, step 43000/55000, batch loss = 0.40\n",
      "epoch 4, step 43250/55000, batch loss = 0.30\n",
      "epoch 4, step 43500/55000, batch loss = 0.30\n",
      "epoch 4, step 43750/55000, batch loss = 0.30\n",
      "epoch 4, step 44000/55000, batch loss = 0.30\n",
      "epoch 4, step 44250/55000, batch loss = 0.30\n",
      "epoch 4, step 44500/55000, batch loss = 0.29\n",
      "epoch 4, step 44750/55000, batch loss = 0.29\n",
      "epoch 4, step 45000/55000, batch loss = 0.30\n",
      "Train accuracy = 99.38\n",
      "epoch 4, step 45250/55000, batch loss = 0.29\n",
      "epoch 4, step 45500/55000, batch loss = 0.29\n",
      "epoch 4, step 45750/55000, batch loss = 0.30\n",
      "epoch 4, step 46000/55000, batch loss = 0.29\n",
      "epoch 4, step 46250/55000, batch loss = 0.29\n",
      "epoch 4, step 46500/55000, batch loss = 0.29\n",
      "epoch 4, step 46750/55000, batch loss = 0.30\n",
      "epoch 4, step 47000/55000, batch loss = 0.33\n",
      "epoch 4, step 47250/55000, batch loss = 0.29\n",
      "epoch 4, step 47500/55000, batch loss = 0.29\n",
      "Train accuracy = 99.38\n",
      "epoch 4, step 47750/55000, batch loss = 0.30\n",
      "epoch 4, step 48000/55000, batch loss = 0.30\n",
      "epoch 4, step 48250/55000, batch loss = 0.29\n",
      "epoch 4, step 48500/55000, batch loss = 0.34\n",
      "epoch 4, step 48750/55000, batch loss = 0.29\n",
      "epoch 4, step 49000/55000, batch loss = 0.30\n",
      "epoch 4, step 49250/55000, batch loss = 0.30\n",
      "epoch 4, step 49500/55000, batch loss = 0.29\n",
      "epoch 4, step 49750/55000, batch loss = 0.31\n",
      "epoch 4, step 50000/55000, batch loss = 0.30\n",
      "Train accuracy = 99.38\n",
      "epoch 4, step 50250/55000, batch loss = 0.31\n",
      "epoch 4, step 50500/55000, batch loss = 0.29\n",
      "epoch 4, step 50750/55000, batch loss = 0.29\n",
      "epoch 4, step 51000/55000, batch loss = 0.29\n",
      "epoch 4, step 51250/55000, batch loss = 0.31\n",
      "epoch 4, step 51500/55000, batch loss = 0.30\n",
      "epoch 4, step 51750/55000, batch loss = 0.29\n",
      "epoch 4, step 52000/55000, batch loss = 0.31\n",
      "epoch 4, step 52250/55000, batch loss = 0.29\n",
      "epoch 4, step 52500/55000, batch loss = 0.29\n",
      "Train accuracy = 99.39\n",
      "epoch 4, step 52750/55000, batch loss = 0.34\n",
      "epoch 4, step 53000/55000, batch loss = 0.30\n",
      "epoch 4, step 53250/55000, batch loss = 0.32\n",
      "epoch 4, step 53500/55000, batch loss = 0.30\n",
      "epoch 4, step 53750/55000, batch loss = 0.29\n",
      "epoch 4, step 54000/55000, batch loss = 0.29\n",
      "epoch 4, step 54250/55000, batch loss = 0.31\n",
      "epoch 4, step 54500/55000, batch loss = 0.29\n",
      "epoch 4, step 54750/55000, batch loss = 0.29\n",
      "Train accuracy = 99.38\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.04\n",
      "Validation avg loss = 0.32\n",
      "\n",
      "epoch 5, step 0/55000, batch loss = 0.33\n",
      "epoch 5, step 250/55000, batch loss = 0.29\n",
      "epoch 5, step 500/55000, batch loss = 0.31\n",
      "epoch 5, step 750/55000, batch loss = 0.33\n",
      "epoch 5, step 1000/55000, batch loss = 0.47\n",
      "epoch 5, step 1250/55000, batch loss = 0.30\n",
      "epoch 5, step 1500/55000, batch loss = 0.39\n",
      "epoch 5, step 1750/55000, batch loss = 0.30\n",
      "epoch 5, step 2000/55000, batch loss = 0.30\n",
      "epoch 5, step 2250/55000, batch loss = 0.29\n",
      "epoch 5, step 2500/55000, batch loss = 0.29\n",
      "Train accuracy = 99.41\n",
      "epoch 5, step 2750/55000, batch loss = 0.33\n",
      "epoch 5, step 3000/55000, batch loss = 0.31\n",
      "epoch 5, step 3250/55000, batch loss = 0.36\n",
      "epoch 5, step 3500/55000, batch loss = 0.36\n",
      "epoch 5, step 3750/55000, batch loss = 0.30\n",
      "epoch 5, step 4000/55000, batch loss = 0.30\n",
      "epoch 5, step 4250/55000, batch loss = 0.29\n",
      "epoch 5, step 4500/55000, batch loss = 0.29\n",
      "epoch 5, step 4750/55000, batch loss = 0.39\n",
      "epoch 5, step 5000/55000, batch loss = 0.29\n",
      "Train accuracy = 99.49\n",
      "epoch 5, step 5250/55000, batch loss = 0.29\n",
      "epoch 5, step 5500/55000, batch loss = 0.30\n",
      "epoch 5, step 5750/55000, batch loss = 0.29\n",
      "epoch 5, step 6000/55000, batch loss = 0.36\n",
      "epoch 5, step 6250/55000, batch loss = 0.30\n",
      "epoch 5, step 6500/55000, batch loss = 0.36\n",
      "epoch 5, step 6750/55000, batch loss = 0.30\n",
      "epoch 5, step 7000/55000, batch loss = 0.29\n",
      "epoch 5, step 7250/55000, batch loss = 0.29\n",
      "epoch 5, step 7500/55000, batch loss = 0.30\n",
      "Train accuracy = 99.46\n",
      "epoch 5, step 7750/55000, batch loss = 0.29\n",
      "epoch 5, step 8000/55000, batch loss = 0.29\n",
      "epoch 5, step 8250/55000, batch loss = 0.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, step 8500/55000, batch loss = 0.37\n",
      "epoch 5, step 8750/55000, batch loss = 0.29\n",
      "epoch 5, step 9000/55000, batch loss = 0.29\n",
      "epoch 5, step 9250/55000, batch loss = 0.29\n",
      "epoch 5, step 9500/55000, batch loss = 0.30\n",
      "epoch 5, step 9750/55000, batch loss = 0.30\n",
      "epoch 5, step 10000/55000, batch loss = 0.42\n",
      "Train accuracy = 99.46\n",
      "epoch 5, step 10250/55000, batch loss = 0.33\n",
      "epoch 5, step 10500/55000, batch loss = 0.30\n",
      "epoch 5, step 10750/55000, batch loss = 0.30\n",
      "epoch 5, step 11000/55000, batch loss = 0.32\n",
      "epoch 5, step 11250/55000, batch loss = 0.29\n",
      "epoch 5, step 11500/55000, batch loss = 0.39\n",
      "epoch 5, step 11750/55000, batch loss = 0.29\n",
      "epoch 5, step 12000/55000, batch loss = 0.29\n",
      "epoch 5, step 12250/55000, batch loss = 0.29\n",
      "epoch 5, step 12500/55000, batch loss = 0.30\n",
      "Train accuracy = 99.47\n",
      "epoch 5, step 12750/55000, batch loss = 0.31\n",
      "epoch 5, step 13000/55000, batch loss = 0.60\n",
      "epoch 5, step 13250/55000, batch loss = 0.29\n",
      "epoch 5, step 13500/55000, batch loss = 0.29\n",
      "epoch 5, step 13750/55000, batch loss = 0.32\n",
      "epoch 5, step 14000/55000, batch loss = 0.30\n",
      "epoch 5, step 14250/55000, batch loss = 0.31\n",
      "epoch 5, step 14500/55000, batch loss = 0.29\n",
      "epoch 5, step 14750/55000, batch loss = 0.31\n",
      "epoch 5, step 15000/55000, batch loss = 0.30\n",
      "Train accuracy = 99.46\n",
      "epoch 5, step 15250/55000, batch loss = 0.31\n",
      "epoch 5, step 15500/55000, batch loss = 0.29\n",
      "epoch 5, step 15750/55000, batch loss = 0.30\n",
      "epoch 5, step 16000/55000, batch loss = 0.30\n",
      "epoch 5, step 16250/55000, batch loss = 0.31\n",
      "epoch 5, step 16500/55000, batch loss = 0.29\n",
      "epoch 5, step 16750/55000, batch loss = 0.29\n",
      "epoch 5, step 17000/55000, batch loss = 0.30\n",
      "epoch 5, step 17250/55000, batch loss = 0.29\n",
      "epoch 5, step 17500/55000, batch loss = 0.29\n",
      "Train accuracy = 99.46\n",
      "epoch 5, step 17750/55000, batch loss = 0.29\n",
      "epoch 5, step 18000/55000, batch loss = 0.30\n",
      "epoch 5, step 18250/55000, batch loss = 0.30\n",
      "epoch 5, step 18500/55000, batch loss = 0.31\n",
      "epoch 5, step 18750/55000, batch loss = 0.29\n",
      "epoch 5, step 19000/55000, batch loss = 0.30\n",
      "epoch 5, step 19250/55000, batch loss = 0.31\n",
      "epoch 5, step 19500/55000, batch loss = 0.30\n",
      "epoch 5, step 19750/55000, batch loss = 0.29\n",
      "epoch 5, step 20000/55000, batch loss = 0.33\n",
      "Train accuracy = 99.46\n",
      "epoch 5, step 20250/55000, batch loss = 0.31\n",
      "epoch 5, step 20500/55000, batch loss = 0.32\n",
      "epoch 5, step 20750/55000, batch loss = 0.29\n",
      "epoch 5, step 21000/55000, batch loss = 0.30\n",
      "epoch 5, step 21250/55000, batch loss = 0.30\n",
      "epoch 5, step 21500/55000, batch loss = 0.30\n",
      "epoch 5, step 21750/55000, batch loss = 0.31\n",
      "epoch 5, step 22000/55000, batch loss = 0.32\n",
      "epoch 5, step 22250/55000, batch loss = 0.30\n",
      "epoch 5, step 22500/55000, batch loss = 0.29\n",
      "Train accuracy = 99.49\n",
      "epoch 5, step 22750/55000, batch loss = 0.32\n",
      "epoch 5, step 23000/55000, batch loss = 0.30\n",
      "epoch 5, step 23250/55000, batch loss = 0.29\n",
      "epoch 5, step 23500/55000, batch loss = 0.34\n",
      "epoch 5, step 23750/55000, batch loss = 0.32\n",
      "epoch 5, step 24000/55000, batch loss = 0.34\n",
      "epoch 5, step 24250/55000, batch loss = 0.29\n",
      "epoch 5, step 24500/55000, batch loss = 0.30\n",
      "epoch 5, step 24750/55000, batch loss = 0.29\n",
      "epoch 5, step 25000/55000, batch loss = 0.36\n",
      "Train accuracy = 99.45\n",
      "epoch 5, step 25250/55000, batch loss = 0.29\n",
      "epoch 5, step 25500/55000, batch loss = 0.33\n",
      "epoch 5, step 25750/55000, batch loss = 0.30\n",
      "epoch 5, step 26000/55000, batch loss = 0.29\n",
      "epoch 5, step 26250/55000, batch loss = 0.31\n",
      "epoch 5, step 26500/55000, batch loss = 0.31\n",
      "epoch 5, step 26750/55000, batch loss = 0.33\n",
      "epoch 5, step 27000/55000, batch loss = 0.29\n",
      "epoch 5, step 27250/55000, batch loss = 0.29\n",
      "epoch 5, step 27500/55000, batch loss = 0.29\n",
      "Train accuracy = 99.44\n",
      "epoch 5, step 27750/55000, batch loss = 0.29\n",
      "epoch 5, step 28000/55000, batch loss = 0.30\n",
      "epoch 5, step 28250/55000, batch loss = 0.29\n",
      "epoch 5, step 28500/55000, batch loss = 0.34\n",
      "epoch 5, step 28750/55000, batch loss = 0.30\n",
      "epoch 5, step 29000/55000, batch loss = 0.34\n",
      "epoch 5, step 29250/55000, batch loss = 0.31\n",
      "epoch 5, step 29500/55000, batch loss = 0.32\n",
      "epoch 5, step 29750/55000, batch loss = 0.44\n",
      "epoch 5, step 30000/55000, batch loss = 0.30\n",
      "Train accuracy = 99.45\n",
      "epoch 5, step 30250/55000, batch loss = 0.29\n",
      "epoch 5, step 30500/55000, batch loss = 0.31\n",
      "epoch 5, step 30750/55000, batch loss = 0.29\n",
      "epoch 5, step 31000/55000, batch loss = 0.31\n",
      "epoch 5, step 31250/55000, batch loss = 0.30\n",
      "epoch 5, step 31500/55000, batch loss = 0.36\n",
      "epoch 5, step 31750/55000, batch loss = 0.30\n",
      "epoch 5, step 32000/55000, batch loss = 0.31\n",
      "epoch 5, step 32250/55000, batch loss = 0.31\n",
      "epoch 5, step 32500/55000, batch loss = 0.29\n",
      "Train accuracy = 99.44\n",
      "epoch 5, step 32750/55000, batch loss = 0.29\n",
      "epoch 5, step 33000/55000, batch loss = 0.30\n",
      "epoch 5, step 33250/55000, batch loss = 0.34\n",
      "epoch 5, step 33500/55000, batch loss = 0.29\n",
      "epoch 5, step 33750/55000, batch loss = 0.29\n",
      "epoch 5, step 34000/55000, batch loss = 0.31\n",
      "epoch 5, step 34250/55000, batch loss = 0.35\n",
      "epoch 5, step 34500/55000, batch loss = 0.31\n",
      "epoch 5, step 34750/55000, batch loss = 0.29\n",
      "epoch 5, step 35000/55000, batch loss = 0.35\n",
      "Train accuracy = 99.44\n",
      "epoch 5, step 35250/55000, batch loss = 0.29\n",
      "epoch 5, step 35500/55000, batch loss = 0.29\n",
      "epoch 5, step 35750/55000, batch loss = 0.29\n",
      "epoch 5, step 36000/55000, batch loss = 0.35\n",
      "epoch 5, step 36250/55000, batch loss = 0.32\n",
      "epoch 5, step 36500/55000, batch loss = 0.30\n",
      "epoch 5, step 36750/55000, batch loss = 0.30\n",
      "epoch 5, step 37000/55000, batch loss = 0.29\n",
      "epoch 5, step 37250/55000, batch loss = 0.30\n",
      "epoch 5, step 37500/55000, batch loss = 0.29\n",
      "Train accuracy = 99.44\n",
      "epoch 5, step 37750/55000, batch loss = 0.29\n",
      "epoch 5, step 38000/55000, batch loss = 0.31\n",
      "epoch 5, step 38250/55000, batch loss = 0.29\n",
      "epoch 5, step 38500/55000, batch loss = 0.30\n",
      "epoch 5, step 38750/55000, batch loss = 0.29\n",
      "epoch 5, step 39000/55000, batch loss = 0.29\n",
      "epoch 5, step 39250/55000, batch loss = 0.30\n",
      "epoch 5, step 39500/55000, batch loss = 0.29\n",
      "epoch 5, step 39750/55000, batch loss = 0.34\n",
      "epoch 5, step 40000/55000, batch loss = 0.29\n",
      "Train accuracy = 99.44\n",
      "epoch 5, step 40250/55000, batch loss = 0.29\n",
      "epoch 5, step 40500/55000, batch loss = 0.30\n",
      "epoch 5, step 40750/55000, batch loss = 0.30\n",
      "epoch 5, step 41000/55000, batch loss = 0.29\n",
      "epoch 5, step 41250/55000, batch loss = 0.30\n",
      "epoch 5, step 41500/55000, batch loss = 0.29\n",
      "epoch 5, step 41750/55000, batch loss = 0.31\n",
      "epoch 5, step 42000/55000, batch loss = 0.30\n",
      "epoch 5, step 42250/55000, batch loss = 0.29\n",
      "epoch 5, step 42500/55000, batch loss = 0.31\n",
      "Train accuracy = 99.44\n",
      "epoch 5, step 42750/55000, batch loss = 0.31\n",
      "epoch 5, step 43000/55000, batch loss = 0.29\n",
      "epoch 5, step 43250/55000, batch loss = 0.30\n",
      "epoch 5, step 43500/55000, batch loss = 0.30\n",
      "epoch 5, step 43750/55000, batch loss = 0.36\n",
      "epoch 5, step 44000/55000, batch loss = 0.29\n",
      "epoch 5, step 44250/55000, batch loss = 0.37\n",
      "epoch 5, step 44500/55000, batch loss = 0.32\n",
      "epoch 5, step 44750/55000, batch loss = 0.29\n",
      "epoch 5, step 45000/55000, batch loss = 0.29\n",
      "Train accuracy = 99.43\n",
      "epoch 5, step 45250/55000, batch loss = 0.32\n",
      "epoch 5, step 45500/55000, batch loss = 0.31\n",
      "epoch 5, step 45750/55000, batch loss = 0.33\n",
      "epoch 5, step 46000/55000, batch loss = 0.30\n",
      "epoch 5, step 46250/55000, batch loss = 0.31\n",
      "epoch 5, step 46500/55000, batch loss = 0.31\n",
      "epoch 5, step 46750/55000, batch loss = 0.32\n",
      "epoch 5, step 47000/55000, batch loss = 0.31\n",
      "epoch 5, step 47250/55000, batch loss = 0.29\n",
      "epoch 5, step 47500/55000, batch loss = 0.29\n",
      "Train accuracy = 99.44\n",
      "epoch 5, step 47750/55000, batch loss = 0.29\n",
      "epoch 5, step 48000/55000, batch loss = 0.29\n",
      "epoch 5, step 48250/55000, batch loss = 0.30\n",
      "epoch 5, step 48500/55000, batch loss = 0.29\n",
      "epoch 5, step 48750/55000, batch loss = 0.30\n",
      "epoch 5, step 49000/55000, batch loss = 0.42\n",
      "epoch 5, step 49250/55000, batch loss = 0.29\n",
      "epoch 5, step 49500/55000, batch loss = 0.29\n",
      "epoch 5, step 49750/55000, batch loss = 0.32\n",
      "epoch 5, step 50000/55000, batch loss = 0.30\n",
      "Train accuracy = 99.45\n",
      "epoch 5, step 50250/55000, batch loss = 0.29\n",
      "epoch 5, step 50500/55000, batch loss = 0.31\n",
      "epoch 5, step 50750/55000, batch loss = 0.29\n",
      "epoch 5, step 51000/55000, batch loss = 0.33\n",
      "epoch 5, step 51250/55000, batch loss = 0.30\n",
      "epoch 5, step 51500/55000, batch loss = 0.30\n",
      "epoch 5, step 51750/55000, batch loss = 0.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, step 52000/55000, batch loss = 0.30\n",
      "epoch 5, step 52250/55000, batch loss = 0.29\n",
      "epoch 5, step 52500/55000, batch loss = 0.32\n",
      "Train accuracy = 99.43\n",
      "epoch 5, step 52750/55000, batch loss = 0.30\n",
      "epoch 5, step 53000/55000, batch loss = 0.29\n",
      "epoch 5, step 53250/55000, batch loss = 0.30\n",
      "epoch 5, step 53500/55000, batch loss = 0.29\n",
      "epoch 5, step 53750/55000, batch loss = 0.36\n",
      "epoch 5, step 54000/55000, batch loss = 0.29\n",
      "epoch 5, step 54250/55000, batch loss = 0.35\n",
      "epoch 5, step 54500/55000, batch loss = 0.31\n",
      "epoch 5, step 54750/55000, batch loss = 0.31\n",
      "Train accuracy = 99.43\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.16\n",
      "Validation avg loss = 0.32\n",
      "\n",
      "\n",
      "Running evaluation:  Test\n",
      "Test accuracy = 99.09\n",
      "Test avg loss = 0.31\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = \"/Users/goran/Documents/III_Semestar/DU/labosi/2_lab/zad2_images/\"\n",
    "\n",
    "\n",
    "config = {}\n",
    "config['max_epochs'] = 5\n",
    "config['batch_size'] = 50\n",
    "config['save_dir'] = SAVE_DIR\n",
    "config['lr_policy'] = {1:{'lr':1e-1}, 3:{'lr':1e-2}, 5:{'lr':1e-3}, 7:{'lr':1e-4}}\n",
    "\n",
    "#np.random.seed(100)\n",
    "i = 0\n",
    "names = [\"0_1\", \"0_01\", \"0_001\"]\n",
    "for lmbd in [1e-1, 1e-2, 1e-3]:\n",
    "    print(\"LAMBDA:\", lmbd, \"\\n\")\n",
    "    SAVE_DIR = \"/Users/goran/Documents/III_Semestar/DU/labosi/2_lab/zad2_images/\" + names[i] + \"/\"\n",
    "    i += 1\n",
    "    config['save_dir'] = SAVE_DIR\n",
    "    np.random.seed(int(time.time() * 1e6) % 2**31)\n",
    "\n",
    "    train_x = mnist.train.images\n",
    "    train_x = train_x.reshape([-1, 1, 28, 28])\n",
    "    train_y = mnist.train.labels\n",
    "\n",
    "    valid_x = mnist.validation.images\n",
    "    valid_x = valid_x.reshape([-1, 1, 28, 28])\n",
    "    valid_y = mnist.validation.labels\n",
    "\n",
    "    test_x = mnist.test.images\n",
    "    test_x = test_x.reshape([-1, 1, 28, 28])\n",
    "    test_y = mnist.test.labels\n",
    "\n",
    "    train_mean = train_x.mean()\n",
    "    train_x -= train_mean\n",
    "    valid_x -= train_mean\n",
    "    test_x -= train_mean\n",
    "\n",
    "    weight_decay = lmbd\n",
    "    net = []\n",
    "\n",
    "    regularizers = []\n",
    "    inputs = np.random.randn(config['batch_size'], 1, 28, 28)\n",
    "    net += [Convolution(inputs, 16, 5, \"conv1\")]\n",
    "    regularizers += [L2Regularizer(net[-1].weights, weight_decay, 'conv1_l2reg')]\n",
    "    net += [MaxPooling(net[-1], \"pool1\")]\n",
    "    net += [ReLU(net[-1], \"relu1\")]\n",
    "    net += [Convolution(net[-1], 32, 5, \"conv2\")]\n",
    "    regularizers += [L2Regularizer(net[-1].weights, weight_decay, 'conv2_l2reg')]\n",
    "    net += [MaxPooling(net[-1], \"pool2\")]\n",
    "    net += [ReLU(net[-1], \"relu2\")]\n",
    "    ## 7x7\n",
    "    net += [Flatten(net[-1], \"flatten3\")]\n",
    "    net += [FC(net[-1], 512, \"fc3\")]\n",
    "    regularizers += [L2Regularizer(net[-1].weights, weight_decay, 'fc3_l2reg')]\n",
    "    net += [ReLU(net[-1], \"relu3\")]\n",
    "    net += [FC(net[-1], 10, \"logits\")]\n",
    "\n",
    "    data_loss = SoftmaxCrossEntropyWithLogits()\n",
    "    loss = RegularizedLoss(data_loss, regularizers)\n",
    "\n",
    "    train(train_x, train_y, valid_x, valid_y, net, loss, config)\n",
    "    evaluate(\"Test\", test_x, test_y, net, loss, config)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ZADATAK - usporedba s Tensorflowom\n",
    "\n",
    "U Tensorflowu definirajte i nauƒçite model koji je ekvivalentan regulariziranom modelu iz 2. zadatka. Korisite identiƒçnu arhitekturu i parametre uƒçenja da biste reproducirali rezultate. Tijekom uƒçenja vizualizirajte filtre u prvom sloju kao u prethodnoj vje≈æbi. Kako biste u graf dodali operaciju konvolucije koristite tf.nn.conv2d ili tf.contrib.layers.convolution2d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"C:\\\\Users\\\\Korisnik\\\\Desktop\\\\du_lab2\\\\Deep-Learning\\\\2_lab\\\\zad3_images\\\\\"\n",
    "\n",
    "config = {}\n",
    "config['max_epochs'] = 8\n",
    "config['batch_size'] = 50\n",
    "config['save_dir'] = SAVE_DIR\n",
    "config['weight_decay'] = 1e-4\n",
    "config['lr_policy'] = {1:{'lr':1e-1}, 3:{'lr':1e-2}, 5:{'lr':1e-3}, 7:{'lr':1e-4}}\n",
    "\n",
    "np.random.seed(int(time.time() * 1e6) % 2**31)\n",
    "train_x = mnist.train.images\n",
    "train_x = train_x.reshape([-1, 28, 28, 1])\n",
    "train_y = mnist.train.labels\n",
    "\n",
    "valid_x = mnist.validation.images\n",
    "valid_x = valid_x.reshape([-1, 28, 28, 1])\n",
    "valid_y = mnist.validation.labels\n",
    "\n",
    "test_x = mnist.test.images\n",
    "test_x = test_x.reshape([-1, 28, 28, 1])\n",
    "test_y = mnist.test.labels\n",
    "\n",
    "train_mean = train_x.mean()\n",
    "train_x -= train_mean\n",
    "valid_x -= train_mean\n",
    "test_x -= train_mean\n",
    "\n",
    "weight_decay = config['weight_decay']\n",
    "\n",
    "n_input = 768\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l2_loss(weights):\n",
    "    regularization = 0;\n",
    "    for w in weights:\n",
    "        regularization += tf.nn.l2_loss(w)\n",
    "    return regularization\n",
    "        \n",
    "def conv2d(x, W, b, activation=tf.nn.relu, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return activation(x)\n",
    "\n",
    "def maxpool2d(x, k=2, stride=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "def fc(x, W, b, activation=None):\n",
    "    x = tf.reshape(x, [-1, W.get_shape().as_list()[0]])\n",
    "    if activation :\n",
    "        return activation(tf.matmul(x, W) +  b)    \n",
    "    return tf.matmul(x, W) +  b\n",
    "\n",
    "def init_var(shape, fin):\n",
    "    sigma = np.sqrt(2/fin)\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import xavier_initializer_conv2d as xavier_conv2d\n",
    "from tensorflow.contrib.layers import xavier_initializer as xavier\n",
    "tf.reset_default_graph()\n",
    "\n",
    "weights = {\n",
    "    'conv1': tf.get_variable('w_conv1', [5, 5, 1, 16], initializer=xavier_conv2d()),\n",
    "    'conv2': tf.get_variable('w_conv2', [5, 5, 16, 32], initializer=xavier_conv2d()),\n",
    "    \n",
    "    'fc3': tf.get_variable('w_fc3', [7*7*32, 512], initializer=xavier()),\n",
    "    'fc4': tf.get_variable('w_fc4', [512, n_classes], initializer=xavier())\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'conv1': tf.Variable(tf.zeros([16]), name='b_conv1'),\n",
    "    'conv2': tf.Variable(tf.zeros([32]), name='b_conv2'),\n",
    "    'fc3': tf.Variable(tf.zeros([512]), name='b_fc3'),\n",
    "    'fc4': tf.Variable(tf.zeros([n_classes]), name='b_fc4')\n",
    "}\n",
    "\n",
    "\n",
    "def convnet(x, weights, biases):\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    net = conv2d(x, weights['conv1'], biases['conv1'], tf.nn.relu)\n",
    "    net = maxpool2d(net, k=2)\n",
    "    \n",
    "    net = conv2d(net, weights['conv2'], biases['conv2'], tf.nn.relu)\n",
    "    net = maxpool2d(net, k=2)\n",
    "    \n",
    "    net = fc(net, weights['fc3'],  biases['fc3'], tf.nn.relu)\n",
    "    net = fc(net, weights['fc4'],  biases['fc4'])\n",
    "    return net\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Yoh_ = tf.placeholder(tf.float32, [None, n_classes])\n",
    "logits = convnet(X, weights, biases)\n",
    "\n",
    "# loss\n",
    "regularizers = l2_loss([weights['conv1'], weights['conv2'], weights['fc3']])\n",
    "data_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Yoh_))\n",
    "loss = data_loss + weight_decay*regularizers\n",
    "\n",
    "lr = tf.placeholder(tf.float32)\n",
    "train_step =  tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_tf(session, train_x, train_y, valid_x, valid_y, config):\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    lr_policy = config['lr_policy']\n",
    "    batch_size = config['batch_size']\n",
    "    max_epochs = config['max_epochs']\n",
    "    save_dir = config['save_dir']\n",
    "    \n",
    "    num_examples = train_x.shape[0]\n",
    "    assert num_examples % batch_size == 0\n",
    "    num_batches = num_examples // batch_size\n",
    "    \n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        if epoch in lr_policy:\n",
    "            solver_config = lr_policy[epoch]\n",
    "            \n",
    "        cnt_correct = 0\n",
    "\n",
    "        permutation_idx = np.random.permutation(num_examples)\n",
    "        train_x = train_x[permutation_idx]\n",
    "        train_y = train_y[permutation_idx]\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            # store mini-batch to ndarray\n",
    "            batch_x = train_x[i*batch_size:(i+1)*batch_size, :]\n",
    "            batch_y = train_y[i*batch_size:(i+1)*batch_size, :]\n",
    "               \n",
    "            data_dict = {X: batch_x, Yoh_: batch_y, lr:solver_config['lr']}\n",
    "            logits_val, loss_val, _ = session.run([logits, loss, train_step] ,feed_dict=data_dict)\n",
    "            \n",
    "            # compute classification accuracy\n",
    "            yp = np.argmax(logits_val, axis=1)\n",
    "            yt = np.argmax(batch_y, axis=1)\n",
    "            cnt_correct += (yp == yt).sum()\n",
    "            \n",
    "            if i % 5 == 0:\n",
    "                print(\"epoch %d, step %d/%d, batch loss = %.2f\" % (epoch, i*batch_size, num_examples, loss_val))\n",
    "            if i % 100 == 0:\n",
    "                w = session.run(weights['conv1'])\n",
    "                draw_conv_filters(epoch, i*batch_size, \"conv1\", w, save_dir)\n",
    "            if i > 0 and i % 50 == 0:\n",
    "                print(\"Train accuracy = %.2f\" % (cnt_correct / ((i+1)*batch_size) * 100))\n",
    "        \n",
    "        print(\"Train accuracy = %.2f\" % (cnt_correct / num_examples * 100))\n",
    "        evaluate_tf(session, \"Validation\", valid_x, valid_y, config)\n",
    "\n",
    "\n",
    "def evaluate_tf(session, name, x, y, config):\n",
    "    print(\"\\nRunning evaluation: \", name)\n",
    "    batch_size = config['batch_size']\n",
    "    num_examples = x.shape[0]\n",
    "    assert num_examples % batch_size == 0\n",
    "    num_batches = num_examples // batch_size\n",
    "    cnt_correct = 0\n",
    "    loss_avg = 0\n",
    "    for i in range(num_batches):\n",
    "        batch_x = x[i*batch_size:(i+1)*batch_size, :]\n",
    "        batch_y = y[i*batch_size:(i+1)*batch_size, :]\n",
    "        \n",
    "        data_dict = {X: batch_x, Yoh_: batch_y}\n",
    "        logits_val, loss_val = session.run([logits, loss] ,feed_dict=data_dict)\n",
    "    \n",
    "        yp = np.argmax(logits_val, axis=1)\n",
    "        yt = np.argmax(batch_y, axis=1)\n",
    "        cnt_correct += (yp == yt).sum()\n",
    "        \n",
    "        loss_avg += loss_val\n",
    "    valid_acc = cnt_correct / num_examples * 100\n",
    "    loss_avg /= num_batches\n",
    "    print(name + \" accuracy = %.2f\" % valid_acc)\n",
    "    print(name + \" avg loss = %.2f\\n\" % loss_avg)\n",
    "    \n",
    "def draw_conv_filters(epoch, step, name, weights, save_dir):\n",
    "    # kxkxCxn_filters\n",
    "    k, k, C, num_filters = weights.shape\n",
    "\n",
    "    w = weights.copy().swapaxes(0, 3).swapaxes(1,2)\n",
    "    w = w.reshape(num_filters, C, k, k)\n",
    "    w -= w.min()\n",
    "    w /= w.max()\n",
    "\n",
    "    border = 1\n",
    "    cols = 8\n",
    "    rows = math.ceil(num_filters / cols)\n",
    "    width = cols * k + (cols-1) * border\n",
    "    height = rows * k + (rows-1) * border\n",
    "\n",
    "    for i in range(1):\n",
    "        img = np.zeros([height, width])\n",
    "        for j in range(num_filters):\n",
    "            r = int(j / cols) * (k + border)\n",
    "            c = int(j % cols) * (k + border)\n",
    "            img[r:r+k,c:c+k] = w[j,i]\n",
    "        filename = '%s_epoch_%02d_step_%06d_input_%03d.png' % (name, epoch, step, i)\n",
    "        ski.io.imsave(os.path.join(save_dir, filename), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 0/55000, batch loss = 2.37\n",
      "epoch 1, step 250/55000, batch loss = 2.22\n",
      "epoch 1, step 500/55000, batch loss = 2.05\n",
      "epoch 1, step 750/55000, batch loss = 1.95\n",
      "epoch 1, step 1000/55000, batch loss = 1.52\n",
      "epoch 1, step 1250/55000, batch loss = 0.90\n",
      "epoch 1, step 1500/55000, batch loss = 1.32\n",
      "epoch 1, step 1750/55000, batch loss = 0.63\n",
      "epoch 1, step 2000/55000, batch loss = 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Korisnik\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 2250/55000, batch loss = 0.56\n",
      "epoch 1, step 2500/55000, batch loss = 0.47\n",
      "Train accuracy = 57.18\n",
      "epoch 1, step 2750/55000, batch loss = 0.77\n",
      "epoch 1, step 3000/55000, batch loss = 0.60\n",
      "epoch 1, step 3250/55000, batch loss = 0.38\n",
      "epoch 1, step 3500/55000, batch loss = 0.47\n",
      "epoch 1, step 3750/55000, batch loss = 0.58\n",
      "epoch 1, step 4000/55000, batch loss = 0.27\n",
      "epoch 1, step 4250/55000, batch loss = 0.49\n",
      "epoch 1, step 4500/55000, batch loss = 0.30\n",
      "epoch 1, step 4750/55000, batch loss = 0.36\n",
      "epoch 1, step 5000/55000, batch loss = 0.32\n",
      "Train accuracy = 72.34\n",
      "epoch 1, step 5250/55000, batch loss = 0.32\n",
      "epoch 1, step 5500/55000, batch loss = 0.50\n",
      "epoch 1, step 5750/55000, batch loss = 0.24\n",
      "epoch 1, step 6000/55000, batch loss = 0.34\n",
      "epoch 1, step 6250/55000, batch loss = 0.38\n",
      "epoch 1, step 6500/55000, batch loss = 0.24\n",
      "epoch 1, step 6750/55000, batch loss = 0.13\n",
      "epoch 1, step 7000/55000, batch loss = 0.24\n",
      "epoch 1, step 7250/55000, batch loss = 0.31\n",
      "epoch 1, step 7500/55000, batch loss = 0.37\n",
      "Train accuracy = 78.64\n",
      "epoch 1, step 7750/55000, batch loss = 0.41\n",
      "epoch 1, step 8000/55000, batch loss = 0.16\n",
      "epoch 1, step 8250/55000, batch loss = 0.22\n",
      "epoch 1, step 8500/55000, batch loss = 0.16\n",
      "epoch 1, step 8750/55000, batch loss = 0.24\n",
      "epoch 1, step 9000/55000, batch loss = 0.18\n",
      "epoch 1, step 9250/55000, batch loss = 0.14\n",
      "epoch 1, step 9500/55000, batch loss = 0.36\n",
      "epoch 1, step 9750/55000, batch loss = 0.22\n",
      "epoch 1, step 10000/55000, batch loss = 0.13\n",
      "Train accuracy = 82.45\n",
      "epoch 1, step 10250/55000, batch loss = 0.23\n",
      "epoch 1, step 10500/55000, batch loss = 0.36\n",
      "epoch 1, step 10750/55000, batch loss = 0.17\n",
      "epoch 1, step 11000/55000, batch loss = 0.16\n",
      "epoch 1, step 11250/55000, batch loss = 0.24\n",
      "epoch 1, step 11500/55000, batch loss = 0.18\n",
      "epoch 1, step 11750/55000, batch loss = 0.11\n",
      "epoch 1, step 12000/55000, batch loss = 0.25\n",
      "epoch 1, step 12250/55000, batch loss = 0.20\n",
      "epoch 1, step 12500/55000, batch loss = 0.22\n",
      "Train accuracy = 85.05\n",
      "epoch 1, step 12750/55000, batch loss = 0.29\n",
      "epoch 1, step 13000/55000, batch loss = 0.12\n",
      "epoch 1, step 13250/55000, batch loss = 0.17\n",
      "epoch 1, step 13500/55000, batch loss = 0.13\n",
      "epoch 1, step 13750/55000, batch loss = 0.10\n",
      "epoch 1, step 14000/55000, batch loss = 0.17\n",
      "epoch 1, step 14250/55000, batch loss = 0.09\n",
      "epoch 1, step 14500/55000, batch loss = 0.29\n",
      "epoch 1, step 14750/55000, batch loss = 0.15\n",
      "epoch 1, step 15000/55000, batch loss = 0.26\n",
      "Train accuracy = 86.71\n",
      "epoch 1, step 15250/55000, batch loss = 0.07\n",
      "epoch 1, step 15500/55000, batch loss = 0.25\n",
      "epoch 1, step 15750/55000, batch loss = 0.15\n",
      "epoch 1, step 16000/55000, batch loss = 0.14\n",
      "epoch 1, step 16250/55000, batch loss = 0.27\n",
      "epoch 1, step 16500/55000, batch loss = 0.13\n",
      "epoch 1, step 16750/55000, batch loss = 0.07\n",
      "epoch 1, step 17000/55000, batch loss = 0.09\n",
      "epoch 1, step 17250/55000, batch loss = 0.08\n",
      "epoch 1, step 17500/55000, batch loss = 0.24\n",
      "Train accuracy = 88.07\n",
      "epoch 1, step 17750/55000, batch loss = 0.27\n",
      "epoch 1, step 18000/55000, batch loss = 0.07\n",
      "epoch 1, step 18250/55000, batch loss = 0.17\n",
      "epoch 1, step 18500/55000, batch loss = 0.22\n",
      "epoch 1, step 18750/55000, batch loss = 0.11\n",
      "epoch 1, step 19000/55000, batch loss = 0.25\n",
      "epoch 1, step 19250/55000, batch loss = 0.06\n",
      "epoch 1, step 19500/55000, batch loss = 0.13\n",
      "epoch 1, step 19750/55000, batch loss = 0.26\n",
      "epoch 1, step 20000/55000, batch loss = 0.11\n",
      "Train accuracy = 89.05\n",
      "epoch 1, step 20250/55000, batch loss = 0.20\n",
      "epoch 1, step 20500/55000, batch loss = 0.22\n",
      "epoch 1, step 20750/55000, batch loss = 0.16\n",
      "epoch 1, step 21000/55000, batch loss = 0.22\n",
      "epoch 1, step 21250/55000, batch loss = 0.10\n",
      "epoch 1, step 21500/55000, batch loss = 0.09\n",
      "epoch 1, step 21750/55000, batch loss = 0.13\n",
      "epoch 1, step 22000/55000, batch loss = 0.14\n",
      "epoch 1, step 22250/55000, batch loss = 0.10\n",
      "epoch 1, step 22500/55000, batch loss = 0.16\n",
      "Train accuracy = 89.84\n",
      "epoch 1, step 22750/55000, batch loss = 0.17\n",
      "epoch 1, step 23000/55000, batch loss = 0.16\n",
      "epoch 1, step 23250/55000, batch loss = 0.29\n",
      "epoch 1, step 23500/55000, batch loss = 0.22\n",
      "epoch 1, step 23750/55000, batch loss = 0.09\n",
      "epoch 1, step 24000/55000, batch loss = 0.14\n",
      "epoch 1, step 24250/55000, batch loss = 0.12\n",
      "epoch 1, step 24500/55000, batch loss = 0.12\n",
      "epoch 1, step 24750/55000, batch loss = 0.09\n",
      "epoch 1, step 25000/55000, batch loss = 0.17\n",
      "Train accuracy = 90.51\n",
      "epoch 1, step 25250/55000, batch loss = 0.15\n",
      "epoch 1, step 25500/55000, batch loss = 0.06\n",
      "epoch 1, step 25750/55000, batch loss = 0.20\n",
      "epoch 1, step 26000/55000, batch loss = 0.23\n",
      "epoch 1, step 26250/55000, batch loss = 0.15\n",
      "epoch 1, step 26500/55000, batch loss = 0.40\n",
      "epoch 1, step 26750/55000, batch loss = 0.21\n",
      "epoch 1, step 27000/55000, batch loss = 0.05\n",
      "epoch 1, step 27250/55000, batch loss = 0.07\n",
      "epoch 1, step 27500/55000, batch loss = 0.13\n",
      "Train accuracy = 91.10\n",
      "epoch 1, step 27750/55000, batch loss = 0.30\n",
      "epoch 1, step 28000/55000, batch loss = 0.08\n",
      "epoch 1, step 28250/55000, batch loss = 0.22\n",
      "epoch 1, step 28500/55000, batch loss = 0.17\n",
      "epoch 1, step 28750/55000, batch loss = 0.16\n",
      "epoch 1, step 29000/55000, batch loss = 0.07\n",
      "epoch 1, step 29250/55000, batch loss = 0.06\n",
      "epoch 1, step 29500/55000, batch loss = 0.15\n",
      "epoch 1, step 29750/55000, batch loss = 0.17\n",
      "epoch 1, step 30000/55000, batch loss = 0.09\n",
      "Train accuracy = 91.59\n",
      "epoch 1, step 30250/55000, batch loss = 0.08\n",
      "epoch 1, step 30500/55000, batch loss = 0.12\n",
      "epoch 1, step 30750/55000, batch loss = 0.09\n",
      "epoch 1, step 31000/55000, batch loss = 0.26\n",
      "epoch 1, step 31250/55000, batch loss = 0.23\n",
      "epoch 1, step 31500/55000, batch loss = 0.14\n",
      "epoch 1, step 31750/55000, batch loss = 0.08\n",
      "epoch 1, step 32000/55000, batch loss = 0.13\n",
      "epoch 1, step 32250/55000, batch loss = 0.07\n",
      "epoch 1, step 32500/55000, batch loss = 0.22\n",
      "Train accuracy = 92.10\n",
      "epoch 1, step 32750/55000, batch loss = 0.07\n",
      "epoch 1, step 33000/55000, batch loss = 0.10\n",
      "epoch 1, step 33250/55000, batch loss = 0.13\n",
      "epoch 1, step 33500/55000, batch loss = 0.20\n",
      "epoch 1, step 33750/55000, batch loss = 0.12\n",
      "epoch 1, step 34000/55000, batch loss = 0.15\n",
      "epoch 1, step 34250/55000, batch loss = 0.12\n",
      "epoch 1, step 34500/55000, batch loss = 0.10\n",
      "epoch 1, step 34750/55000, batch loss = 0.15\n",
      "epoch 1, step 35000/55000, batch loss = 0.12\n",
      "Train accuracy = 92.45\n",
      "epoch 1, step 35250/55000, batch loss = 0.06\n",
      "epoch 1, step 35500/55000, batch loss = 0.06\n",
      "epoch 1, step 35750/55000, batch loss = 0.28\n",
      "epoch 1, step 36000/55000, batch loss = 0.09\n",
      "epoch 1, step 36250/55000, batch loss = 0.06\n",
      "epoch 1, step 36500/55000, batch loss = 0.08\n",
      "epoch 1, step 36750/55000, batch loss = 0.13\n",
      "epoch 1, step 37000/55000, batch loss = 0.09\n",
      "epoch 1, step 37250/55000, batch loss = 0.14\n",
      "epoch 1, step 37500/55000, batch loss = 0.07\n",
      "Train accuracy = 92.79\n",
      "epoch 1, step 37750/55000, batch loss = 0.07\n",
      "epoch 1, step 38000/55000, batch loss = 0.05\n",
      "epoch 1, step 38250/55000, batch loss = 0.08\n",
      "epoch 1, step 38500/55000, batch loss = 0.05\n",
      "epoch 1, step 38750/55000, batch loss = 0.24\n",
      "epoch 1, step 39000/55000, batch loss = 0.09\n",
      "epoch 1, step 39250/55000, batch loss = 0.06\n",
      "epoch 1, step 39500/55000, batch loss = 0.11\n",
      "epoch 1, step 39750/55000, batch loss = 0.07\n",
      "epoch 1, step 40000/55000, batch loss = 0.19\n",
      "Train accuracy = 93.08\n",
      "epoch 1, step 40250/55000, batch loss = 0.19\n",
      "epoch 1, step 40500/55000, batch loss = 0.13\n",
      "epoch 1, step 40750/55000, batch loss = 0.10\n",
      "epoch 1, step 41000/55000, batch loss = 0.12\n",
      "epoch 1, step 41250/55000, batch loss = 0.22\n",
      "epoch 1, step 41500/55000, batch loss = 0.24\n",
      "epoch 1, step 41750/55000, batch loss = 0.11\n",
      "epoch 1, step 42000/55000, batch loss = 0.08\n",
      "epoch 1, step 42250/55000, batch loss = 0.08\n",
      "epoch 1, step 42500/55000, batch loss = 0.05\n",
      "Train accuracy = 93.30\n",
      "epoch 1, step 42750/55000, batch loss = 0.12\n",
      "epoch 1, step 43000/55000, batch loss = 0.05\n",
      "epoch 1, step 43250/55000, batch loss = 0.10\n",
      "epoch 1, step 43500/55000, batch loss = 0.07\n",
      "epoch 1, step 43750/55000, batch loss = 0.07\n",
      "epoch 1, step 44000/55000, batch loss = 0.13\n",
      "epoch 1, step 44250/55000, batch loss = 0.07\n",
      "epoch 1, step 44500/55000, batch loss = 0.09\n",
      "epoch 1, step 44750/55000, batch loss = 0.05\n",
      "epoch 1, step 45000/55000, batch loss = 0.23\n",
      "Train accuracy = 93.54\n",
      "epoch 1, step 45250/55000, batch loss = 0.05\n",
      "epoch 1, step 45500/55000, batch loss = 0.09\n",
      "epoch 1, step 45750/55000, batch loss = 0.15\n",
      "epoch 1, step 46000/55000, batch loss = 0.15\n",
      "epoch 1, step 46250/55000, batch loss = 0.06\n",
      "epoch 1, step 46500/55000, batch loss = 0.15\n",
      "epoch 1, step 46750/55000, batch loss = 0.26\n",
      "epoch 1, step 47000/55000, batch loss = 0.20\n",
      "epoch 1, step 47250/55000, batch loss = 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 47500/55000, batch loss = 0.14\n",
      "Train accuracy = 93.73\n",
      "epoch 1, step 47750/55000, batch loss = 0.07\n",
      "epoch 1, step 48000/55000, batch loss = 0.10\n",
      "epoch 1, step 48250/55000, batch loss = 0.11\n",
      "epoch 1, step 48500/55000, batch loss = 0.14\n",
      "epoch 1, step 48750/55000, batch loss = 0.17\n",
      "epoch 1, step 49000/55000, batch loss = 0.06\n",
      "epoch 1, step 49250/55000, batch loss = 0.12\n",
      "epoch 1, step 49500/55000, batch loss = 0.15\n",
      "epoch 1, step 49750/55000, batch loss = 0.07\n",
      "epoch 1, step 50000/55000, batch loss = 0.29\n",
      "Train accuracy = 93.91\n",
      "epoch 1, step 50250/55000, batch loss = 0.13\n",
      "epoch 1, step 50500/55000, batch loss = 0.09\n",
      "epoch 1, step 50750/55000, batch loss = 0.16\n",
      "epoch 1, step 51000/55000, batch loss = 0.07\n",
      "epoch 1, step 51250/55000, batch loss = 0.07\n",
      "epoch 1, step 51500/55000, batch loss = 0.10\n",
      "epoch 1, step 51750/55000, batch loss = 0.09\n",
      "epoch 1, step 52000/55000, batch loss = 0.07\n",
      "epoch 1, step 52250/55000, batch loss = 0.15\n",
      "epoch 1, step 52500/55000, batch loss = 0.08\n",
      "Train accuracy = 94.11\n",
      "epoch 1, step 52750/55000, batch loss = 0.10\n",
      "epoch 1, step 53000/55000, batch loss = 0.18\n",
      "epoch 1, step 53250/55000, batch loss = 0.07\n",
      "epoch 1, step 53500/55000, batch loss = 0.05\n",
      "epoch 1, step 53750/55000, batch loss = 0.28\n",
      "epoch 1, step 54000/55000, batch loss = 0.11\n",
      "epoch 1, step 54250/55000, batch loss = 0.14\n",
      "epoch 1, step 54500/55000, batch loss = 0.05\n",
      "epoch 1, step 54750/55000, batch loss = 0.07\n",
      "Train accuracy = 94.25\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 98.40\n",
      "Validation avg loss = 0.10\n",
      "\n",
      "epoch 2, step 0/55000, batch loss = 0.04\n",
      "epoch 2, step 250/55000, batch loss = 0.08\n",
      "epoch 2, step 500/55000, batch loss = 0.10\n",
      "epoch 2, step 750/55000, batch loss = 0.06\n",
      "epoch 2, step 1000/55000, batch loss = 0.11\n",
      "epoch 2, step 1250/55000, batch loss = 0.18\n",
      "epoch 2, step 1500/55000, batch loss = 0.08\n",
      "epoch 2, step 1750/55000, batch loss = 0.06\n",
      "epoch 2, step 2000/55000, batch loss = 0.14\n",
      "epoch 2, step 2250/55000, batch loss = 0.09\n",
      "epoch 2, step 2500/55000, batch loss = 0.06\n",
      "Train accuracy = 98.20\n",
      "epoch 2, step 2750/55000, batch loss = 0.25\n",
      "epoch 2, step 3000/55000, batch loss = 0.07\n",
      "epoch 2, step 3250/55000, batch loss = 0.10\n",
      "epoch 2, step 3500/55000, batch loss = 0.05\n",
      "epoch 2, step 3750/55000, batch loss = 0.05\n",
      "epoch 2, step 4000/55000, batch loss = 0.13\n",
      "epoch 2, step 4250/55000, batch loss = 0.05\n",
      "epoch 2, step 4500/55000, batch loss = 0.10\n",
      "epoch 2, step 4750/55000, batch loss = 0.23\n",
      "epoch 2, step 5000/55000, batch loss = 0.11\n",
      "Train accuracy = 98.16\n",
      "epoch 2, step 5250/55000, batch loss = 0.14\n",
      "epoch 2, step 5500/55000, batch loss = 0.05\n",
      "epoch 2, step 5750/55000, batch loss = 0.05\n",
      "epoch 2, step 6000/55000, batch loss = 0.22\n",
      "epoch 2, step 6250/55000, batch loss = 0.16\n",
      "epoch 2, step 6500/55000, batch loss = 0.05\n",
      "epoch 2, step 6750/55000, batch loss = 0.05\n",
      "epoch 2, step 7000/55000, batch loss = 0.19\n",
      "epoch 2, step 7250/55000, batch loss = 0.05\n",
      "epoch 2, step 7500/55000, batch loss = 0.06\n",
      "Train accuracy = 98.19\n",
      "epoch 2, step 7750/55000, batch loss = 0.19\n",
      "epoch 2, step 8000/55000, batch loss = 0.05\n",
      "epoch 2, step 8250/55000, batch loss = 0.16\n",
      "epoch 2, step 8500/55000, batch loss = 0.09\n",
      "epoch 2, step 8750/55000, batch loss = 0.07\n",
      "epoch 2, step 9000/55000, batch loss = 0.06\n",
      "epoch 2, step 9250/55000, batch loss = 0.07\n",
      "epoch 2, step 9500/55000, batch loss = 0.06\n",
      "epoch 2, step 9750/55000, batch loss = 0.08\n",
      "epoch 2, step 10000/55000, batch loss = 0.10\n",
      "Train accuracy = 98.29\n",
      "epoch 2, step 10250/55000, batch loss = 0.06\n",
      "epoch 2, step 10500/55000, batch loss = 0.06\n",
      "epoch 2, step 10750/55000, batch loss = 0.14\n",
      "epoch 2, step 11000/55000, batch loss = 0.13\n",
      "epoch 2, step 11250/55000, batch loss = 0.14\n",
      "epoch 2, step 11500/55000, batch loss = 0.10\n",
      "epoch 2, step 11750/55000, batch loss = 0.09\n",
      "epoch 2, step 12000/55000, batch loss = 0.05\n",
      "epoch 2, step 12250/55000, batch loss = 0.06\n",
      "epoch 2, step 12500/55000, batch loss = 0.09\n",
      "Train accuracy = 98.30\n",
      "epoch 2, step 12750/55000, batch loss = 0.05\n",
      "epoch 2, step 13000/55000, batch loss = 0.21\n",
      "epoch 2, step 13250/55000, batch loss = 0.07\n",
      "epoch 2, step 13500/55000, batch loss = 0.17\n",
      "epoch 2, step 13750/55000, batch loss = 0.16\n",
      "epoch 2, step 14000/55000, batch loss = 0.06\n",
      "epoch 2, step 14250/55000, batch loss = 0.10\n",
      "epoch 2, step 14500/55000, batch loss = 0.05\n",
      "epoch 2, step 14750/55000, batch loss = 0.08\n",
      "epoch 2, step 15000/55000, batch loss = 0.05\n",
      "Train accuracy = 98.22\n",
      "epoch 2, step 15250/55000, batch loss = 0.05\n",
      "epoch 2, step 15500/55000, batch loss = 0.24\n",
      "epoch 2, step 15750/55000, batch loss = 0.14\n",
      "epoch 2, step 16000/55000, batch loss = 0.07\n",
      "epoch 2, step 16250/55000, batch loss = 0.06\n",
      "epoch 2, step 16500/55000, batch loss = 0.07\n",
      "epoch 2, step 16750/55000, batch loss = 0.17\n",
      "epoch 2, step 17000/55000, batch loss = 0.15\n",
      "epoch 2, step 17250/55000, batch loss = 0.12\n",
      "epoch 2, step 17500/55000, batch loss = 0.05\n",
      "Train accuracy = 98.16\n",
      "epoch 2, step 17750/55000, batch loss = 0.07\n",
      "epoch 2, step 18000/55000, batch loss = 0.06\n",
      "epoch 2, step 18250/55000, batch loss = 0.05\n",
      "epoch 2, step 18500/55000, batch loss = 0.08\n",
      "epoch 2, step 18750/55000, batch loss = 0.05\n",
      "epoch 2, step 19000/55000, batch loss = 0.06\n",
      "epoch 2, step 19250/55000, batch loss = 0.05\n",
      "epoch 2, step 19500/55000, batch loss = 0.07\n",
      "epoch 2, step 19750/55000, batch loss = 0.08\n",
      "epoch 2, step 20000/55000, batch loss = 0.06\n",
      "Train accuracy = 98.25\n",
      "epoch 2, step 20250/55000, batch loss = 0.14\n",
      "epoch 2, step 20500/55000, batch loss = 0.14\n",
      "epoch 2, step 20750/55000, batch loss = 0.08\n",
      "epoch 2, step 21000/55000, batch loss = 0.08\n",
      "epoch 2, step 21250/55000, batch loss = 0.13\n",
      "epoch 2, step 21500/55000, batch loss = 0.07\n",
      "epoch 2, step 21750/55000, batch loss = 0.07\n",
      "epoch 2, step 22000/55000, batch loss = 0.06\n",
      "epoch 2, step 22250/55000, batch loss = 0.05\n",
      "epoch 2, step 22500/55000, batch loss = 0.19\n",
      "Train accuracy = 98.29\n",
      "epoch 2, step 22750/55000, batch loss = 0.11\n",
      "epoch 2, step 23000/55000, batch loss = 0.05\n",
      "epoch 2, step 23250/55000, batch loss = 0.07\n",
      "epoch 2, step 23500/55000, batch loss = 0.16\n",
      "epoch 2, step 23750/55000, batch loss = 0.07\n",
      "epoch 2, step 24000/55000, batch loss = 0.14\n",
      "epoch 2, step 24250/55000, batch loss = 0.07\n",
      "epoch 2, step 24500/55000, batch loss = 0.16\n",
      "epoch 2, step 24750/55000, batch loss = 0.08\n",
      "epoch 2, step 25000/55000, batch loss = 0.19\n",
      "Train accuracy = 98.30\n",
      "epoch 2, step 25250/55000, batch loss = 0.05\n",
      "epoch 2, step 25500/55000, batch loss = 0.06\n",
      "epoch 2, step 25750/55000, batch loss = 0.07\n",
      "epoch 2, step 26000/55000, batch loss = 0.14\n",
      "epoch 2, step 26250/55000, batch loss = 0.10\n",
      "epoch 2, step 26500/55000, batch loss = 0.10\n",
      "epoch 2, step 26750/55000, batch loss = 0.13\n",
      "epoch 2, step 27000/55000, batch loss = 0.07\n",
      "epoch 2, step 27250/55000, batch loss = 0.07\n",
      "epoch 2, step 27500/55000, batch loss = 0.16\n",
      "Train accuracy = 98.26\n",
      "epoch 2, step 27750/55000, batch loss = 0.12\n",
      "epoch 2, step 28000/55000, batch loss = 0.09\n",
      "epoch 2, step 28250/55000, batch loss = 0.06\n",
      "epoch 2, step 28500/55000, batch loss = 0.13\n",
      "epoch 2, step 28750/55000, batch loss = 0.08\n",
      "epoch 2, step 29000/55000, batch loss = 0.17\n",
      "epoch 2, step 29250/55000, batch loss = 0.07\n",
      "epoch 2, step 29500/55000, batch loss = 0.09\n",
      "epoch 2, step 29750/55000, batch loss = 0.08\n",
      "epoch 2, step 30000/55000, batch loss = 0.10\n",
      "Train accuracy = 98.28\n",
      "epoch 2, step 30250/55000, batch loss = 0.27\n",
      "epoch 2, step 30500/55000, batch loss = 0.17\n",
      "epoch 2, step 30750/55000, batch loss = 0.17\n",
      "epoch 2, step 31000/55000, batch loss = 0.08\n",
      "epoch 2, step 31250/55000, batch loss = 0.21\n",
      "epoch 2, step 31500/55000, batch loss = 0.07\n",
      "epoch 2, step 31750/55000, batch loss = 0.09\n",
      "epoch 2, step 32000/55000, batch loss = 0.12\n",
      "epoch 2, step 32250/55000, batch loss = 0.13\n",
      "epoch 2, step 32500/55000, batch loss = 0.24\n",
      "Train accuracy = 98.27\n",
      "epoch 2, step 32750/55000, batch loss = 0.09\n",
      "epoch 2, step 33000/55000, batch loss = 0.08\n",
      "epoch 2, step 33250/55000, batch loss = 0.13\n",
      "epoch 2, step 33500/55000, batch loss = 0.07\n",
      "epoch 2, step 33750/55000, batch loss = 0.06\n",
      "epoch 2, step 34000/55000, batch loss = 0.08\n",
      "epoch 2, step 34250/55000, batch loss = 0.08\n",
      "epoch 2, step 34500/55000, batch loss = 0.06\n",
      "epoch 2, step 34750/55000, batch loss = 0.10\n",
      "epoch 2, step 35000/55000, batch loss = 0.05\n",
      "Train accuracy = 98.31\n",
      "epoch 2, step 35250/55000, batch loss = 0.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, step 35500/55000, batch loss = 0.07\n",
      "epoch 2, step 35750/55000, batch loss = 0.16\n",
      "epoch 2, step 36000/55000, batch loss = 0.09\n",
      "epoch 2, step 36250/55000, batch loss = 0.06\n",
      "epoch 2, step 36500/55000, batch loss = 0.14\n",
      "epoch 2, step 36750/55000, batch loss = 0.14\n",
      "epoch 2, step 37000/55000, batch loss = 0.05\n",
      "epoch 2, step 37250/55000, batch loss = 0.05\n",
      "epoch 2, step 37500/55000, batch loss = 0.05\n",
      "Train accuracy = 98.31\n",
      "epoch 2, step 37750/55000, batch loss = 0.07\n",
      "epoch 2, step 38000/55000, batch loss = 0.14\n",
      "epoch 2, step 38250/55000, batch loss = 0.25\n",
      "epoch 2, step 38500/55000, batch loss = 0.10\n",
      "epoch 2, step 38750/55000, batch loss = 0.07\n",
      "epoch 2, step 39000/55000, batch loss = 0.07\n",
      "epoch 2, step 39250/55000, batch loss = 0.09\n",
      "epoch 2, step 39500/55000, batch loss = 0.22\n",
      "epoch 2, step 39750/55000, batch loss = 0.05\n",
      "epoch 2, step 40000/55000, batch loss = 0.08\n",
      "Train accuracy = 98.31\n",
      "epoch 2, step 40250/55000, batch loss = 0.06\n",
      "epoch 2, step 40500/55000, batch loss = 0.13\n",
      "epoch 2, step 40750/55000, batch loss = 0.05\n",
      "epoch 2, step 41000/55000, batch loss = 0.09\n",
      "epoch 2, step 41250/55000, batch loss = 0.09\n",
      "epoch 2, step 41500/55000, batch loss = 0.13\n",
      "epoch 2, step 41750/55000, batch loss = 0.05\n",
      "epoch 2, step 42000/55000, batch loss = 0.14\n",
      "epoch 2, step 42250/55000, batch loss = 0.08\n",
      "epoch 2, step 42500/55000, batch loss = 0.07\n",
      "Train accuracy = 98.33\n",
      "epoch 2, step 42750/55000, batch loss = 0.07\n",
      "epoch 2, step 43000/55000, batch loss = 0.11\n",
      "epoch 2, step 43250/55000, batch loss = 0.16\n",
      "epoch 2, step 43500/55000, batch loss = 0.07\n",
      "epoch 2, step 43750/55000, batch loss = 0.05\n",
      "epoch 2, step 44000/55000, batch loss = 0.05\n",
      "epoch 2, step 44250/55000, batch loss = 0.07\n",
      "epoch 2, step 44500/55000, batch loss = 0.08\n",
      "epoch 2, step 44750/55000, batch loss = 0.07\n",
      "epoch 2, step 45000/55000, batch loss = 0.07\n",
      "Train accuracy = 98.34\n",
      "epoch 2, step 45250/55000, batch loss = 0.08\n",
      "epoch 2, step 45500/55000, batch loss = 0.11\n",
      "epoch 2, step 45750/55000, batch loss = 0.09\n",
      "epoch 2, step 46000/55000, batch loss = 0.04\n",
      "epoch 2, step 46250/55000, batch loss = 0.07\n",
      "epoch 2, step 46500/55000, batch loss = 0.06\n",
      "epoch 2, step 46750/55000, batch loss = 0.14\n",
      "epoch 2, step 47000/55000, batch loss = 0.06\n",
      "epoch 2, step 47250/55000, batch loss = 0.21\n",
      "epoch 2, step 47500/55000, batch loss = 0.04\n",
      "Train accuracy = 98.32\n",
      "epoch 2, step 47750/55000, batch loss = 0.12\n",
      "epoch 2, step 48000/55000, batch loss = 0.04\n",
      "epoch 2, step 48250/55000, batch loss = 0.05\n",
      "epoch 2, step 48500/55000, batch loss = 0.06\n",
      "epoch 2, step 48750/55000, batch loss = 0.08\n",
      "epoch 2, step 49000/55000, batch loss = 0.07\n",
      "epoch 2, step 49250/55000, batch loss = 0.05\n",
      "epoch 2, step 49500/55000, batch loss = 0.07\n",
      "epoch 2, step 49750/55000, batch loss = 0.11\n",
      "epoch 2, step 50000/55000, batch loss = 0.06\n",
      "Train accuracy = 98.34\n",
      "epoch 2, step 50250/55000, batch loss = 0.11\n",
      "epoch 2, step 50500/55000, batch loss = 0.09\n",
      "epoch 2, step 50750/55000, batch loss = 0.13\n",
      "epoch 2, step 51000/55000, batch loss = 0.09\n",
      "epoch 2, step 51250/55000, batch loss = 0.05\n",
      "epoch 2, step 51500/55000, batch loss = 0.06\n",
      "epoch 2, step 51750/55000, batch loss = 0.05\n",
      "epoch 2, step 52000/55000, batch loss = 0.05\n",
      "epoch 2, step 52250/55000, batch loss = 0.06\n",
      "epoch 2, step 52500/55000, batch loss = 0.23\n",
      "Train accuracy = 98.35\n",
      "epoch 2, step 52750/55000, batch loss = 0.11\n",
      "epoch 2, step 53000/55000, batch loss = 0.06\n",
      "epoch 2, step 53250/55000, batch loss = 0.07\n",
      "epoch 2, step 53500/55000, batch loss = 0.06\n",
      "epoch 2, step 53750/55000, batch loss = 0.16\n",
      "epoch 2, step 54000/55000, batch loss = 0.11\n",
      "epoch 2, step 54250/55000, batch loss = 0.08\n",
      "epoch 2, step 54500/55000, batch loss = 0.04\n",
      "epoch 2, step 54750/55000, batch loss = 0.18\n",
      "Train accuracy = 98.36\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 98.60\n",
      "Validation avg loss = 0.09\n",
      "\n",
      "epoch 3, step 0/55000, batch loss = 0.06\n",
      "epoch 3, step 250/55000, batch loss = 0.05\n",
      "epoch 3, step 500/55000, batch loss = 0.34\n",
      "epoch 3, step 750/55000, batch loss = 0.04\n",
      "epoch 3, step 1000/55000, batch loss = 0.04\n",
      "epoch 3, step 1250/55000, batch loss = 0.07\n",
      "epoch 3, step 1500/55000, batch loss = 0.04\n",
      "epoch 3, step 1750/55000, batch loss = 0.05\n",
      "epoch 3, step 2000/55000, batch loss = 0.05\n",
      "epoch 3, step 2250/55000, batch loss = 0.04\n",
      "epoch 3, step 2500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.10\n",
      "epoch 3, step 2750/55000, batch loss = 0.06\n",
      "epoch 3, step 3000/55000, batch loss = 0.05\n",
      "epoch 3, step 3250/55000, batch loss = 0.06\n",
      "epoch 3, step 3500/55000, batch loss = 0.07\n",
      "epoch 3, step 3750/55000, batch loss = 0.06\n",
      "epoch 3, step 4000/55000, batch loss = 0.04\n",
      "epoch 3, step 4250/55000, batch loss = 0.10\n",
      "epoch 3, step 4500/55000, batch loss = 0.06\n",
      "epoch 3, step 4750/55000, batch loss = 0.06\n",
      "epoch 3, step 5000/55000, batch loss = 0.06\n",
      "Train accuracy = 99.07\n",
      "epoch 3, step 5250/55000, batch loss = 0.07\n",
      "epoch 3, step 5500/55000, batch loss = 0.10\n",
      "epoch 3, step 5750/55000, batch loss = 0.05\n",
      "epoch 3, step 6000/55000, batch loss = 0.04\n",
      "epoch 3, step 6250/55000, batch loss = 0.10\n",
      "epoch 3, step 6500/55000, batch loss = 0.07\n",
      "epoch 3, step 6750/55000, batch loss = 0.04\n",
      "epoch 3, step 7000/55000, batch loss = 0.09\n",
      "epoch 3, step 7250/55000, batch loss = 0.05\n",
      "epoch 3, step 7500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.15\n",
      "epoch 3, step 7750/55000, batch loss = 0.05\n",
      "epoch 3, step 8000/55000, batch loss = 0.05\n",
      "epoch 3, step 8250/55000, batch loss = 0.05\n",
      "epoch 3, step 8500/55000, batch loss = 0.05\n",
      "epoch 3, step 8750/55000, batch loss = 0.09\n",
      "epoch 3, step 9000/55000, batch loss = 0.19\n",
      "epoch 3, step 9250/55000, batch loss = 0.06\n",
      "epoch 3, step 9500/55000, batch loss = 0.10\n",
      "epoch 3, step 9750/55000, batch loss = 0.06\n",
      "epoch 3, step 10000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.19\n",
      "epoch 3, step 10250/55000, batch loss = 0.04\n",
      "epoch 3, step 10500/55000, batch loss = 0.08\n",
      "epoch 3, step 10750/55000, batch loss = 0.08\n",
      "epoch 3, step 11000/55000, batch loss = 0.05\n",
      "epoch 3, step 11250/55000, batch loss = 0.13\n",
      "epoch 3, step 11500/55000, batch loss = 0.12\n",
      "epoch 3, step 11750/55000, batch loss = 0.05\n",
      "epoch 3, step 12000/55000, batch loss = 0.04\n",
      "epoch 3, step 12250/55000, batch loss = 0.07\n",
      "epoch 3, step 12500/55000, batch loss = 0.11\n",
      "Train accuracy = 99.16\n",
      "epoch 3, step 12750/55000, batch loss = 0.05\n",
      "epoch 3, step 13000/55000, batch loss = 0.04\n",
      "epoch 3, step 13250/55000, batch loss = 0.04\n",
      "epoch 3, step 13500/55000, batch loss = 0.04\n",
      "epoch 3, step 13750/55000, batch loss = 0.10\n",
      "epoch 3, step 14000/55000, batch loss = 0.05\n",
      "epoch 3, step 14250/55000, batch loss = 0.05\n",
      "epoch 3, step 14500/55000, batch loss = 0.07\n",
      "epoch 3, step 14750/55000, batch loss = 0.05\n",
      "epoch 3, step 15000/55000, batch loss = 0.06\n",
      "Train accuracy = 99.17\n",
      "epoch 3, step 15250/55000, batch loss = 0.04\n",
      "epoch 3, step 15500/55000, batch loss = 0.13\n",
      "epoch 3, step 15750/55000, batch loss = 0.05\n",
      "epoch 3, step 16000/55000, batch loss = 0.05\n",
      "epoch 3, step 16250/55000, batch loss = 0.05\n",
      "epoch 3, step 16500/55000, batch loss = 0.07\n",
      "epoch 3, step 16750/55000, batch loss = 0.05\n",
      "epoch 3, step 17000/55000, batch loss = 0.05\n",
      "epoch 3, step 17250/55000, batch loss = 0.12\n",
      "epoch 3, step 17500/55000, batch loss = 0.11\n",
      "Train accuracy = 99.18\n",
      "epoch 3, step 17750/55000, batch loss = 0.04\n",
      "epoch 3, step 18000/55000, batch loss = 0.04\n",
      "epoch 3, step 18250/55000, batch loss = 0.05\n",
      "epoch 3, step 18500/55000, batch loss = 0.06\n",
      "epoch 3, step 18750/55000, batch loss = 0.10\n",
      "epoch 3, step 19000/55000, batch loss = 0.04\n",
      "epoch 3, step 19250/55000, batch loss = 0.05\n",
      "epoch 3, step 19500/55000, batch loss = 0.04\n",
      "epoch 3, step 19750/55000, batch loss = 0.07\n",
      "epoch 3, step 20000/55000, batch loss = 0.08\n",
      "Train accuracy = 99.20\n",
      "epoch 3, step 20250/55000, batch loss = 0.12\n",
      "epoch 3, step 20500/55000, batch loss = 0.08\n",
      "epoch 3, step 20750/55000, batch loss = 0.05\n",
      "epoch 3, step 21000/55000, batch loss = 0.05\n",
      "epoch 3, step 21250/55000, batch loss = 0.06\n",
      "epoch 3, step 21500/55000, batch loss = 0.08\n",
      "epoch 3, step 21750/55000, batch loss = 0.04\n",
      "epoch 3, step 22000/55000, batch loss = 0.05\n",
      "epoch 3, step 22250/55000, batch loss = 0.05\n",
      "epoch 3, step 22500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.22\n",
      "epoch 3, step 22750/55000, batch loss = 0.08\n",
      "epoch 3, step 23000/55000, batch loss = 0.05\n",
      "epoch 3, step 23250/55000, batch loss = 0.06\n",
      "epoch 3, step 23500/55000, batch loss = 0.05\n",
      "epoch 3, step 23750/55000, batch loss = 0.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, step 24000/55000, batch loss = 0.05\n",
      "epoch 3, step 24250/55000, batch loss = 0.05\n",
      "epoch 3, step 24500/55000, batch loss = 0.07\n",
      "epoch 3, step 24750/55000, batch loss = 0.06\n",
      "epoch 3, step 25000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.23\n",
      "epoch 3, step 25250/55000, batch loss = 0.05\n",
      "epoch 3, step 25500/55000, batch loss = 0.06\n",
      "epoch 3, step 25750/55000, batch loss = 0.05\n",
      "epoch 3, step 26000/55000, batch loss = 0.05\n",
      "epoch 3, step 26250/55000, batch loss = 0.06\n",
      "epoch 3, step 26500/55000, batch loss = 0.11\n",
      "epoch 3, step 26750/55000, batch loss = 0.06\n",
      "epoch 3, step 27000/55000, batch loss = 0.06\n",
      "epoch 3, step 27250/55000, batch loss = 0.05\n",
      "epoch 3, step 27500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.22\n",
      "epoch 3, step 27750/55000, batch loss = 0.05\n",
      "epoch 3, step 28000/55000, batch loss = 0.04\n",
      "epoch 3, step 28250/55000, batch loss = 0.07\n",
      "epoch 3, step 28500/55000, batch loss = 0.13\n",
      "epoch 3, step 28750/55000, batch loss = 0.04\n",
      "epoch 3, step 29000/55000, batch loss = 0.10\n",
      "epoch 3, step 29250/55000, batch loss = 0.10\n",
      "epoch 3, step 29500/55000, batch loss = 0.09\n",
      "epoch 3, step 29750/55000, batch loss = 0.05\n",
      "epoch 3, step 30000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.21\n",
      "epoch 3, step 30250/55000, batch loss = 0.11\n",
      "epoch 3, step 30500/55000, batch loss = 0.09\n",
      "epoch 3, step 30750/55000, batch loss = 0.05\n",
      "epoch 3, step 31000/55000, batch loss = 0.04\n",
      "epoch 3, step 31250/55000, batch loss = 0.07\n",
      "epoch 3, step 31500/55000, batch loss = 0.16\n",
      "epoch 3, step 31750/55000, batch loss = 0.05\n",
      "epoch 3, step 32000/55000, batch loss = 0.04\n",
      "epoch 3, step 32250/55000, batch loss = 0.17\n",
      "epoch 3, step 32500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.21\n",
      "epoch 3, step 32750/55000, batch loss = 0.06\n",
      "epoch 3, step 33000/55000, batch loss = 0.05\n",
      "epoch 3, step 33250/55000, batch loss = 0.04\n",
      "epoch 3, step 33500/55000, batch loss = 0.04\n",
      "epoch 3, step 33750/55000, batch loss = 0.05\n",
      "epoch 3, step 34000/55000, batch loss = 0.08\n",
      "epoch 3, step 34250/55000, batch loss = 0.07\n",
      "epoch 3, step 34500/55000, batch loss = 0.04\n",
      "epoch 3, step 34750/55000, batch loss = 0.05\n",
      "epoch 3, step 35000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.22\n",
      "epoch 3, step 35250/55000, batch loss = 0.05\n",
      "epoch 3, step 35500/55000, batch loss = 0.08\n",
      "epoch 3, step 35750/55000, batch loss = 0.05\n",
      "epoch 3, step 36000/55000, batch loss = 0.07\n",
      "epoch 3, step 36250/55000, batch loss = 0.05\n",
      "epoch 3, step 36500/55000, batch loss = 0.06\n",
      "epoch 3, step 36750/55000, batch loss = 0.05\n",
      "epoch 3, step 37000/55000, batch loss = 0.10\n",
      "epoch 3, step 37250/55000, batch loss = 0.05\n",
      "epoch 3, step 37500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.23\n",
      "epoch 3, step 37750/55000, batch loss = 0.05\n",
      "epoch 3, step 38000/55000, batch loss = 0.06\n",
      "epoch 3, step 38250/55000, batch loss = 0.16\n",
      "epoch 3, step 38500/55000, batch loss = 0.10\n",
      "epoch 3, step 38750/55000, batch loss = 0.04\n",
      "epoch 3, step 39000/55000, batch loss = 0.07\n",
      "epoch 3, step 39250/55000, batch loss = 0.05\n",
      "epoch 3, step 39500/55000, batch loss = 0.04\n",
      "epoch 3, step 39750/55000, batch loss = 0.09\n",
      "epoch 3, step 40000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.23\n",
      "epoch 3, step 40250/55000, batch loss = 0.05\n",
      "epoch 3, step 40500/55000, batch loss = 0.05\n",
      "epoch 3, step 40750/55000, batch loss = 0.05\n",
      "epoch 3, step 41000/55000, batch loss = 0.05\n",
      "epoch 3, step 41250/55000, batch loss = 0.06\n",
      "epoch 3, step 41500/55000, batch loss = 0.06\n",
      "epoch 3, step 41750/55000, batch loss = 0.05\n",
      "epoch 3, step 42000/55000, batch loss = 0.06\n",
      "epoch 3, step 42250/55000, batch loss = 0.11\n",
      "epoch 3, step 42500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.23\n",
      "epoch 3, step 42750/55000, batch loss = 0.04\n",
      "epoch 3, step 43000/55000, batch loss = 0.05\n",
      "epoch 3, step 43250/55000, batch loss = 0.05\n",
      "epoch 3, step 43500/55000, batch loss = 0.06\n",
      "epoch 3, step 43750/55000, batch loss = 0.07\n",
      "epoch 3, step 44000/55000, batch loss = 0.07\n",
      "epoch 3, step 44250/55000, batch loss = 0.04\n",
      "epoch 3, step 44500/55000, batch loss = 0.05\n",
      "epoch 3, step 44750/55000, batch loss = 0.05\n",
      "epoch 3, step 45000/55000, batch loss = 0.11\n",
      "Train accuracy = 99.23\n",
      "epoch 3, step 45250/55000, batch loss = 0.05\n",
      "epoch 3, step 45500/55000, batch loss = 0.20\n",
      "epoch 3, step 45750/55000, batch loss = 0.04\n",
      "epoch 3, step 46000/55000, batch loss = 0.06\n",
      "epoch 3, step 46250/55000, batch loss = 0.05\n",
      "epoch 3, step 46500/55000, batch loss = 0.09\n",
      "epoch 3, step 46750/55000, batch loss = 0.05\n",
      "epoch 3, step 47000/55000, batch loss = 0.06\n",
      "epoch 3, step 47250/55000, batch loss = 0.08\n",
      "epoch 3, step 47500/55000, batch loss = 0.06\n",
      "Train accuracy = 99.23\n",
      "epoch 3, step 47750/55000, batch loss = 0.05\n",
      "epoch 3, step 48000/55000, batch loss = 0.08\n",
      "epoch 3, step 48250/55000, batch loss = 0.05\n",
      "epoch 3, step 48500/55000, batch loss = 0.04\n",
      "epoch 3, step 48750/55000, batch loss = 0.05\n",
      "epoch 3, step 49000/55000, batch loss = 0.05\n",
      "epoch 3, step 49250/55000, batch loss = 0.05\n",
      "epoch 3, step 49500/55000, batch loss = 0.04\n",
      "epoch 3, step 49750/55000, batch loss = 0.05\n",
      "epoch 3, step 50000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.24\n",
      "epoch 3, step 50250/55000, batch loss = 0.05\n",
      "epoch 3, step 50500/55000, batch loss = 0.06\n",
      "epoch 3, step 50750/55000, batch loss = 0.05\n",
      "epoch 3, step 51000/55000, batch loss = 0.04\n",
      "epoch 3, step 51250/55000, batch loss = 0.04\n",
      "epoch 3, step 51500/55000, batch loss = 0.12\n",
      "epoch 3, step 51750/55000, batch loss = 0.04\n",
      "epoch 3, step 52000/55000, batch loss = 0.09\n",
      "epoch 3, step 52250/55000, batch loss = 0.05\n",
      "epoch 3, step 52500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.23\n",
      "epoch 3, step 52750/55000, batch loss = 0.04\n",
      "epoch 3, step 53000/55000, batch loss = 0.07\n",
      "epoch 3, step 53250/55000, batch loss = 0.04\n",
      "epoch 3, step 53500/55000, batch loss = 0.04\n",
      "epoch 3, step 53750/55000, batch loss = 0.05\n",
      "epoch 3, step 54000/55000, batch loss = 0.05\n",
      "epoch 3, step 54250/55000, batch loss = 0.05\n",
      "epoch 3, step 54500/55000, batch loss = 0.08\n",
      "epoch 3, step 54750/55000, batch loss = 0.05\n",
      "Train accuracy = 99.23\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.04\n",
      "Validation avg loss = 0.07\n",
      "\n",
      "epoch 4, step 0/55000, batch loss = 0.11\n",
      "epoch 4, step 250/55000, batch loss = 0.06\n",
      "epoch 4, step 500/55000, batch loss = 0.06\n",
      "epoch 4, step 750/55000, batch loss = 0.08\n",
      "epoch 4, step 1000/55000, batch loss = 0.30\n",
      "epoch 4, step 1250/55000, batch loss = 0.05\n",
      "epoch 4, step 1500/55000, batch loss = 0.04\n",
      "epoch 4, step 1750/55000, batch loss = 0.06\n",
      "epoch 4, step 2000/55000, batch loss = 0.04\n",
      "epoch 4, step 2250/55000, batch loss = 0.13\n",
      "epoch 4, step 2500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.37\n",
      "epoch 4, step 2750/55000, batch loss = 0.08\n",
      "epoch 4, step 3000/55000, batch loss = 0.07\n",
      "epoch 4, step 3250/55000, batch loss = 0.08\n",
      "epoch 4, step 3500/55000, batch loss = 0.05\n",
      "epoch 4, step 3750/55000, batch loss = 0.05\n",
      "epoch 4, step 4000/55000, batch loss = 0.17\n",
      "epoch 4, step 4250/55000, batch loss = 0.07\n",
      "epoch 4, step 4500/55000, batch loss = 0.08\n",
      "epoch 4, step 4750/55000, batch loss = 0.05\n",
      "epoch 4, step 5000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.31\n",
      "epoch 4, step 5250/55000, batch loss = 0.05\n",
      "epoch 4, step 5500/55000, batch loss = 0.05\n",
      "epoch 4, step 5750/55000, batch loss = 0.05\n",
      "epoch 4, step 6000/55000, batch loss = 0.09\n",
      "epoch 4, step 6250/55000, batch loss = 0.07\n",
      "epoch 4, step 6500/55000, batch loss = 0.05\n",
      "epoch 4, step 6750/55000, batch loss = 0.05\n",
      "epoch 4, step 7000/55000, batch loss = 0.04\n",
      "epoch 4, step 7250/55000, batch loss = 0.05\n",
      "epoch 4, step 7500/55000, batch loss = 0.06\n",
      "Train accuracy = 99.38\n",
      "epoch 4, step 7750/55000, batch loss = 0.05\n",
      "epoch 4, step 8000/55000, batch loss = 0.04\n",
      "epoch 4, step 8250/55000, batch loss = 0.04\n",
      "epoch 4, step 8500/55000, batch loss = 0.06\n",
      "epoch 4, step 8750/55000, batch loss = 0.05\n",
      "epoch 4, step 9000/55000, batch loss = 0.04\n",
      "epoch 4, step 9250/55000, batch loss = 0.06\n",
      "epoch 4, step 9500/55000, batch loss = 0.08\n",
      "epoch 4, step 9750/55000, batch loss = 0.04\n",
      "epoch 4, step 10000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.36\n",
      "epoch 4, step 10250/55000, batch loss = 0.08\n",
      "epoch 4, step 10500/55000, batch loss = 0.04\n",
      "epoch 4, step 10750/55000, batch loss = 0.04\n",
      "epoch 4, step 11000/55000, batch loss = 0.07\n",
      "epoch 4, step 11250/55000, batch loss = 0.09\n",
      "epoch 4, step 11500/55000, batch loss = 0.06\n",
      "epoch 4, step 11750/55000, batch loss = 0.05\n",
      "epoch 4, step 12000/55000, batch loss = 0.05\n",
      "epoch 4, step 12250/55000, batch loss = 0.10\n",
      "epoch 4, step 12500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, step 12750/55000, batch loss = 0.07\n",
      "epoch 4, step 13000/55000, batch loss = 0.05\n",
      "epoch 4, step 13250/55000, batch loss = 0.04\n",
      "epoch 4, step 13500/55000, batch loss = 0.04\n",
      "epoch 4, step 13750/55000, batch loss = 0.05\n",
      "epoch 4, step 14000/55000, batch loss = 0.05\n",
      "epoch 4, step 14250/55000, batch loss = 0.05\n",
      "epoch 4, step 14500/55000, batch loss = 0.09\n",
      "epoch 4, step 14750/55000, batch loss = 0.06\n",
      "epoch 4, step 15000/55000, batch loss = 0.06\n",
      "Train accuracy = 99.34\n",
      "epoch 4, step 15250/55000, batch loss = 0.05\n",
      "epoch 4, step 15500/55000, batch loss = 0.04\n",
      "epoch 4, step 15750/55000, batch loss = 0.08\n",
      "epoch 4, step 16000/55000, batch loss = 0.14\n",
      "epoch 4, step 16250/55000, batch loss = 0.07\n",
      "epoch 4, step 16500/55000, batch loss = 0.04\n",
      "epoch 4, step 16750/55000, batch loss = 0.04\n",
      "epoch 4, step 17000/55000, batch loss = 0.04\n",
      "epoch 4, step 17250/55000, batch loss = 0.07\n",
      "epoch 4, step 17500/55000, batch loss = 0.06\n",
      "Train accuracy = 99.33\n",
      "epoch 4, step 17750/55000, batch loss = 0.04\n",
      "epoch 4, step 18000/55000, batch loss = 0.04\n",
      "epoch 4, step 18250/55000, batch loss = 0.05\n",
      "epoch 4, step 18500/55000, batch loss = 0.04\n",
      "epoch 4, step 18750/55000, batch loss = 0.06\n",
      "epoch 4, step 19000/55000, batch loss = 0.07\n",
      "epoch 4, step 19250/55000, batch loss = 0.04\n",
      "epoch 4, step 19500/55000, batch loss = 0.05\n",
      "epoch 4, step 19750/55000, batch loss = 0.11\n",
      "epoch 4, step 20000/55000, batch loss = 0.06\n",
      "Train accuracy = 99.30\n",
      "epoch 4, step 20250/55000, batch loss = 0.05\n",
      "epoch 4, step 20500/55000, batch loss = 0.07\n",
      "epoch 4, step 20750/55000, batch loss = 0.05\n",
      "epoch 4, step 21000/55000, batch loss = 0.05\n",
      "epoch 4, step 21250/55000, batch loss = 0.08\n",
      "epoch 4, step 21500/55000, batch loss = 0.05\n",
      "epoch 4, step 21750/55000, batch loss = 0.05\n",
      "epoch 4, step 22000/55000, batch loss = 0.04\n",
      "epoch 4, step 22250/55000, batch loss = 0.05\n",
      "epoch 4, step 22500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.34\n",
      "epoch 4, step 22750/55000, batch loss = 0.17\n",
      "epoch 4, step 23000/55000, batch loss = 0.05\n",
      "epoch 4, step 23250/55000, batch loss = 0.04\n",
      "epoch 4, step 23500/55000, batch loss = 0.06\n",
      "epoch 4, step 23750/55000, batch loss = 0.08\n",
      "epoch 4, step 24000/55000, batch loss = 0.06\n",
      "epoch 4, step 24250/55000, batch loss = 0.06\n",
      "epoch 4, step 24500/55000, batch loss = 0.05\n",
      "epoch 4, step 24750/55000, batch loss = 0.04\n",
      "epoch 4, step 25000/55000, batch loss = 0.06\n",
      "Train accuracy = 99.34\n",
      "epoch 4, step 25250/55000, batch loss = 0.07\n",
      "epoch 4, step 25500/55000, batch loss = 0.05\n",
      "epoch 4, step 25750/55000, batch loss = 0.04\n",
      "epoch 4, step 26000/55000, batch loss = 0.16\n",
      "epoch 4, step 26250/55000, batch loss = 0.05\n",
      "epoch 4, step 26500/55000, batch loss = 0.04\n",
      "epoch 4, step 26750/55000, batch loss = 0.06\n",
      "epoch 4, step 27000/55000, batch loss = 0.07\n",
      "epoch 4, step 27250/55000, batch loss = 0.05\n",
      "epoch 4, step 27500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.35\n",
      "epoch 4, step 27750/55000, batch loss = 0.06\n",
      "epoch 4, step 28000/55000, batch loss = 0.05\n",
      "epoch 4, step 28250/55000, batch loss = 0.04\n",
      "epoch 4, step 28500/55000, batch loss = 0.05\n",
      "epoch 4, step 28750/55000, batch loss = 0.06\n",
      "epoch 4, step 29000/55000, batch loss = 0.05\n",
      "epoch 4, step 29250/55000, batch loss = 0.05\n",
      "epoch 4, step 29500/55000, batch loss = 0.05\n",
      "epoch 4, step 29750/55000, batch loss = 0.05\n",
      "epoch 4, step 30000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.36\n",
      "epoch 4, step 30250/55000, batch loss = 0.04\n",
      "epoch 4, step 30500/55000, batch loss = 0.06\n",
      "epoch 4, step 30750/55000, batch loss = 0.06\n",
      "epoch 4, step 31000/55000, batch loss = 0.05\n",
      "epoch 4, step 31250/55000, batch loss = 0.05\n",
      "epoch 4, step 31500/55000, batch loss = 0.05\n",
      "epoch 4, step 31750/55000, batch loss = 0.05\n",
      "epoch 4, step 32000/55000, batch loss = 0.05\n",
      "epoch 4, step 32250/55000, batch loss = 0.04\n",
      "epoch 4, step 32500/55000, batch loss = 0.06\n",
      "Train accuracy = 99.36\n",
      "epoch 4, step 32750/55000, batch loss = 0.04\n",
      "epoch 4, step 33000/55000, batch loss = 0.04\n",
      "epoch 4, step 33250/55000, batch loss = 0.08\n",
      "epoch 4, step 33500/55000, batch loss = 0.06\n",
      "epoch 4, step 33750/55000, batch loss = 0.05\n",
      "epoch 4, step 34000/55000, batch loss = 0.05\n",
      "epoch 4, step 34250/55000, batch loss = 0.06\n",
      "epoch 4, step 34500/55000, batch loss = 0.04\n",
      "epoch 4, step 34750/55000, batch loss = 0.05\n",
      "epoch 4, step 35000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.36\n",
      "epoch 4, step 35250/55000, batch loss = 0.05\n",
      "epoch 4, step 35500/55000, batch loss = 0.09\n",
      "epoch 4, step 35750/55000, batch loss = 0.08\n",
      "epoch 4, step 36000/55000, batch loss = 0.07\n",
      "epoch 4, step 36250/55000, batch loss = 0.04\n",
      "epoch 4, step 36500/55000, batch loss = 0.05\n",
      "epoch 4, step 36750/55000, batch loss = 0.04\n",
      "epoch 4, step 37000/55000, batch loss = 0.05\n",
      "epoch 4, step 37250/55000, batch loss = 0.04\n",
      "epoch 4, step 37500/55000, batch loss = 0.07\n",
      "Train accuracy = 99.36\n",
      "epoch 4, step 37750/55000, batch loss = 0.05\n",
      "epoch 4, step 38000/55000, batch loss = 0.04\n",
      "epoch 4, step 38250/55000, batch loss = 0.04\n",
      "epoch 4, step 38500/55000, batch loss = 0.05\n",
      "epoch 4, step 38750/55000, batch loss = 0.08\n",
      "epoch 4, step 39000/55000, batch loss = 0.07\n",
      "epoch 4, step 39250/55000, batch loss = 0.05\n",
      "epoch 4, step 39500/55000, batch loss = 0.04\n",
      "epoch 4, step 39750/55000, batch loss = 0.05\n",
      "epoch 4, step 40000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.36\n",
      "epoch 4, step 40250/55000, batch loss = 0.05\n",
      "epoch 4, step 40500/55000, batch loss = 0.04\n",
      "epoch 4, step 40750/55000, batch loss = 0.07\n",
      "epoch 4, step 41000/55000, batch loss = 0.05\n",
      "epoch 4, step 41250/55000, batch loss = 0.04\n",
      "epoch 4, step 41500/55000, batch loss = 0.04\n",
      "epoch 4, step 41750/55000, batch loss = 0.08\n",
      "epoch 4, step 42000/55000, batch loss = 0.05\n",
      "epoch 4, step 42250/55000, batch loss = 0.04\n",
      "epoch 4, step 42500/55000, batch loss = 0.07\n",
      "Train accuracy = 99.36\n",
      "epoch 4, step 42750/55000, batch loss = 0.04\n",
      "epoch 4, step 43000/55000, batch loss = 0.05\n",
      "epoch 4, step 43250/55000, batch loss = 0.07\n",
      "epoch 4, step 43500/55000, batch loss = 0.07\n",
      "epoch 4, step 43750/55000, batch loss = 0.07\n",
      "epoch 4, step 44000/55000, batch loss = 0.05\n",
      "epoch 4, step 44250/55000, batch loss = 0.06\n",
      "epoch 4, step 44500/55000, batch loss = 0.06\n",
      "epoch 4, step 44750/55000, batch loss = 0.04\n",
      "epoch 4, step 45000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.35\n",
      "epoch 4, step 45250/55000, batch loss = 0.06\n",
      "epoch 4, step 45500/55000, batch loss = 0.04\n",
      "epoch 4, step 45750/55000, batch loss = 0.05\n",
      "epoch 4, step 46000/55000, batch loss = 0.04\n",
      "epoch 4, step 46250/55000, batch loss = 0.05\n",
      "epoch 4, step 46500/55000, batch loss = 0.04\n",
      "epoch 4, step 46750/55000, batch loss = 0.06\n",
      "epoch 4, step 47000/55000, batch loss = 0.08\n",
      "epoch 4, step 47250/55000, batch loss = 0.04\n",
      "epoch 4, step 47500/55000, batch loss = 0.08\n",
      "Train accuracy = 99.35\n",
      "epoch 4, step 47750/55000, batch loss = 0.05\n",
      "epoch 4, step 48000/55000, batch loss = 0.10\n",
      "epoch 4, step 48250/55000, batch loss = 0.09\n",
      "epoch 4, step 48500/55000, batch loss = 0.04\n",
      "epoch 4, step 48750/55000, batch loss = 0.04\n",
      "epoch 4, step 49000/55000, batch loss = 0.04\n",
      "epoch 4, step 49250/55000, batch loss = 0.11\n",
      "epoch 4, step 49500/55000, batch loss = 0.05\n",
      "epoch 4, step 49750/55000, batch loss = 0.05\n",
      "epoch 4, step 50000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.35\n",
      "epoch 4, step 50250/55000, batch loss = 0.06\n",
      "epoch 4, step 50500/55000, batch loss = 0.05\n",
      "epoch 4, step 50750/55000, batch loss = 0.05\n",
      "epoch 4, step 51000/55000, batch loss = 0.05\n",
      "epoch 4, step 51250/55000, batch loss = 0.05\n",
      "epoch 4, step 51500/55000, batch loss = 0.05\n",
      "epoch 4, step 51750/55000, batch loss = 0.05\n",
      "epoch 4, step 52000/55000, batch loss = 0.04\n",
      "epoch 4, step 52250/55000, batch loss = 0.06\n",
      "epoch 4, step 52500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.35\n",
      "epoch 4, step 52750/55000, batch loss = 0.11\n",
      "epoch 4, step 53000/55000, batch loss = 0.08\n",
      "epoch 4, step 53250/55000, batch loss = 0.05\n",
      "epoch 4, step 53500/55000, batch loss = 0.07\n",
      "epoch 4, step 53750/55000, batch loss = 0.07\n",
      "epoch 4, step 54000/55000, batch loss = 0.05\n",
      "epoch 4, step 54250/55000, batch loss = 0.10\n",
      "epoch 4, step 54500/55000, batch loss = 0.04\n",
      "epoch 4, step 54750/55000, batch loss = 0.06\n",
      "Train accuracy = 99.35\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.12\n",
      "Validation avg loss = 0.07\n",
      "\n",
      "epoch 5, step 0/55000, batch loss = 0.06\n",
      "epoch 5, step 250/55000, batch loss = 0.09\n",
      "epoch 5, step 500/55000, batch loss = 0.04\n",
      "epoch 5, step 750/55000, batch loss = 0.08\n",
      "epoch 5, step 1000/55000, batch loss = 0.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, step 1250/55000, batch loss = 0.07\n",
      "epoch 5, step 1500/55000, batch loss = 0.05\n",
      "epoch 5, step 1750/55000, batch loss = 0.04\n",
      "epoch 5, step 2000/55000, batch loss = 0.05\n",
      "epoch 5, step 2250/55000, batch loss = 0.04\n",
      "epoch 5, step 2500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.37\n",
      "epoch 5, step 2750/55000, batch loss = 0.05\n",
      "epoch 5, step 3000/55000, batch loss = 0.07\n",
      "epoch 5, step 3250/55000, batch loss = 0.05\n",
      "epoch 5, step 3500/55000, batch loss = 0.05\n",
      "epoch 5, step 3750/55000, batch loss = 0.04\n",
      "epoch 5, step 4000/55000, batch loss = 0.05\n",
      "epoch 5, step 4250/55000, batch loss = 0.07\n",
      "epoch 5, step 4500/55000, batch loss = 0.15\n",
      "epoch 5, step 4750/55000, batch loss = 0.04\n",
      "epoch 5, step 5000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.33\n",
      "epoch 5, step 5250/55000, batch loss = 0.07\n",
      "epoch 5, step 5500/55000, batch loss = 0.04\n",
      "epoch 5, step 5750/55000, batch loss = 0.05\n",
      "epoch 5, step 6000/55000, batch loss = 0.04\n",
      "epoch 5, step 6250/55000, batch loss = 0.07\n",
      "epoch 5, step 6500/55000, batch loss = 0.05\n",
      "epoch 5, step 6750/55000, batch loss = 0.04\n",
      "epoch 5, step 7000/55000, batch loss = 0.04\n",
      "epoch 5, step 7250/55000, batch loss = 0.04\n",
      "epoch 5, step 7500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.39\n",
      "epoch 5, step 7750/55000, batch loss = 0.06\n",
      "epoch 5, step 8000/55000, batch loss = 0.04\n",
      "epoch 5, step 8250/55000, batch loss = 0.05\n",
      "epoch 5, step 8500/55000, batch loss = 0.10\n",
      "epoch 5, step 8750/55000, batch loss = 0.05\n",
      "epoch 5, step 9000/55000, batch loss = 0.06\n",
      "epoch 5, step 9250/55000, batch loss = 0.04\n",
      "epoch 5, step 9500/55000, batch loss = 0.05\n",
      "epoch 5, step 9750/55000, batch loss = 0.09\n",
      "epoch 5, step 10000/55000, batch loss = 0.09\n",
      "Train accuracy = 99.35\n",
      "epoch 5, step 10250/55000, batch loss = 0.05\n",
      "epoch 5, step 10500/55000, batch loss = 0.06\n",
      "epoch 5, step 10750/55000, batch loss = 0.04\n",
      "epoch 5, step 11000/55000, batch loss = 0.11\n",
      "epoch 5, step 11250/55000, batch loss = 0.05\n",
      "epoch 5, step 11500/55000, batch loss = 0.04\n",
      "epoch 5, step 11750/55000, batch loss = 0.16\n",
      "epoch 5, step 12000/55000, batch loss = 0.05\n",
      "epoch 5, step 12250/55000, batch loss = 0.04\n",
      "epoch 5, step 12500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.31\n",
      "epoch 5, step 12750/55000, batch loss = 0.07\n",
      "epoch 5, step 13000/55000, batch loss = 0.10\n",
      "epoch 5, step 13250/55000, batch loss = 0.08\n",
      "epoch 5, step 13500/55000, batch loss = 0.04\n",
      "epoch 5, step 13750/55000, batch loss = 0.06\n",
      "epoch 5, step 14000/55000, batch loss = 0.05\n",
      "epoch 5, step 14250/55000, batch loss = 0.08\n",
      "epoch 5, step 14500/55000, batch loss = 0.04\n",
      "epoch 5, step 14750/55000, batch loss = 0.06\n",
      "epoch 5, step 15000/55000, batch loss = 0.10\n",
      "Train accuracy = 99.34\n",
      "epoch 5, step 15250/55000, batch loss = 0.05\n",
      "epoch 5, step 15500/55000, batch loss = 0.05\n",
      "epoch 5, step 15750/55000, batch loss = 0.05\n",
      "epoch 5, step 16000/55000, batch loss = 0.05\n",
      "epoch 5, step 16250/55000, batch loss = 0.05\n",
      "epoch 5, step 16500/55000, batch loss = 0.05\n",
      "epoch 5, step 16750/55000, batch loss = 0.04\n",
      "epoch 5, step 17000/55000, batch loss = 0.05\n",
      "epoch 5, step 17250/55000, batch loss = 0.09\n",
      "epoch 5, step 17500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.36\n",
      "epoch 5, step 17750/55000, batch loss = 0.05\n",
      "epoch 5, step 18000/55000, batch loss = 0.05\n",
      "epoch 5, step 18250/55000, batch loss = 0.06\n",
      "epoch 5, step 18500/55000, batch loss = 0.07\n",
      "epoch 5, step 18750/55000, batch loss = 0.04\n",
      "epoch 5, step 19000/55000, batch loss = 0.06\n",
      "epoch 5, step 19250/55000, batch loss = 0.04\n",
      "epoch 5, step 19500/55000, batch loss = 0.05\n",
      "epoch 5, step 19750/55000, batch loss = 0.05\n",
      "epoch 5, step 20000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.37\n",
      "epoch 5, step 20250/55000, batch loss = 0.04\n",
      "epoch 5, step 20500/55000, batch loss = 0.07\n",
      "epoch 5, step 20750/55000, batch loss = 0.05\n",
      "epoch 5, step 21000/55000, batch loss = 0.05\n",
      "epoch 5, step 21250/55000, batch loss = 0.04\n",
      "epoch 5, step 21500/55000, batch loss = 0.04\n",
      "epoch 5, step 21750/55000, batch loss = 0.07\n",
      "epoch 5, step 22000/55000, batch loss = 0.05\n",
      "epoch 5, step 22250/55000, batch loss = 0.10\n",
      "epoch 5, step 22500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.38\n",
      "epoch 5, step 22750/55000, batch loss = 0.04\n",
      "epoch 5, step 23000/55000, batch loss = 0.14\n",
      "epoch 5, step 23250/55000, batch loss = 0.07\n",
      "epoch 5, step 23500/55000, batch loss = 0.04\n",
      "epoch 5, step 23750/55000, batch loss = 0.04\n",
      "epoch 5, step 24000/55000, batch loss = 0.05\n",
      "epoch 5, step 24250/55000, batch loss = 0.10\n",
      "epoch 5, step 24500/55000, batch loss = 0.07\n",
      "epoch 5, step 24750/55000, batch loss = 0.07\n",
      "epoch 5, step 25000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.38\n",
      "epoch 5, step 25250/55000, batch loss = 0.06\n",
      "epoch 5, step 25500/55000, batch loss = 0.05\n",
      "epoch 5, step 25750/55000, batch loss = 0.04\n",
      "epoch 5, step 26000/55000, batch loss = 0.04\n",
      "epoch 5, step 26250/55000, batch loss = 0.04\n",
      "epoch 5, step 26500/55000, batch loss = 0.08\n",
      "epoch 5, step 26750/55000, batch loss = 0.04\n",
      "epoch 5, step 27000/55000, batch loss = 0.08\n",
      "epoch 5, step 27250/55000, batch loss = 0.04\n",
      "epoch 5, step 27500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.38\n",
      "epoch 5, step 27750/55000, batch loss = 0.04\n",
      "epoch 5, step 28000/55000, batch loss = 0.07\n",
      "epoch 5, step 28250/55000, batch loss = 0.10\n",
      "epoch 5, step 28500/55000, batch loss = 0.04\n",
      "epoch 5, step 28750/55000, batch loss = 0.04\n",
      "epoch 5, step 29000/55000, batch loss = 0.04\n",
      "epoch 5, step 29250/55000, batch loss = 0.06\n",
      "epoch 5, step 29500/55000, batch loss = 0.05\n",
      "epoch 5, step 29750/55000, batch loss = 0.05\n",
      "epoch 5, step 30000/55000, batch loss = 0.08\n",
      "Train accuracy = 99.37\n",
      "epoch 5, step 30250/55000, batch loss = 0.04\n",
      "epoch 5, step 30500/55000, batch loss = 0.04\n",
      "epoch 5, step 30750/55000, batch loss = 0.05\n",
      "epoch 5, step 31000/55000, batch loss = 0.04\n",
      "epoch 5, step 31250/55000, batch loss = 0.08\n",
      "epoch 5, step 31500/55000, batch loss = 0.07\n",
      "epoch 5, step 31750/55000, batch loss = 0.07\n",
      "epoch 5, step 32000/55000, batch loss = 0.04\n",
      "epoch 5, step 32250/55000, batch loss = 0.05\n",
      "epoch 5, step 32500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.39\n",
      "epoch 5, step 32750/55000, batch loss = 0.05\n",
      "epoch 5, step 33000/55000, batch loss = 0.06\n",
      "epoch 5, step 33250/55000, batch loss = 0.05\n",
      "epoch 5, step 33500/55000, batch loss = 0.05\n",
      "epoch 5, step 33750/55000, batch loss = 0.05\n",
      "epoch 5, step 34000/55000, batch loss = 0.06\n",
      "epoch 5, step 34250/55000, batch loss = 0.06\n",
      "epoch 5, step 34500/55000, batch loss = 0.05\n",
      "epoch 5, step 34750/55000, batch loss = 0.05\n",
      "epoch 5, step 35000/55000, batch loss = 0.06\n",
      "Train accuracy = 99.40\n",
      "epoch 5, step 35250/55000, batch loss = 0.04\n",
      "epoch 5, step 35500/55000, batch loss = 0.05\n",
      "epoch 5, step 35750/55000, batch loss = 0.12\n",
      "epoch 5, step 36000/55000, batch loss = 0.04\n",
      "epoch 5, step 36250/55000, batch loss = 0.17\n",
      "epoch 5, step 36500/55000, batch loss = 0.06\n",
      "epoch 5, step 36750/55000, batch loss = 0.06\n",
      "epoch 5, step 37000/55000, batch loss = 0.09\n",
      "epoch 5, step 37250/55000, batch loss = 0.04\n",
      "epoch 5, step 37500/55000, batch loss = 0.10\n",
      "Train accuracy = 99.40\n",
      "epoch 5, step 37750/55000, batch loss = 0.10\n",
      "epoch 5, step 38000/55000, batch loss = 0.06\n",
      "epoch 5, step 38250/55000, batch loss = 0.06\n",
      "epoch 5, step 38500/55000, batch loss = 0.06\n",
      "epoch 5, step 38750/55000, batch loss = 0.13\n",
      "epoch 5, step 39000/55000, batch loss = 0.05\n",
      "epoch 5, step 39250/55000, batch loss = 0.08\n",
      "epoch 5, step 39500/55000, batch loss = 0.05\n",
      "epoch 5, step 39750/55000, batch loss = 0.05\n",
      "epoch 5, step 40000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.42\n",
      "epoch 5, step 40250/55000, batch loss = 0.05\n",
      "epoch 5, step 40500/55000, batch loss = 0.04\n",
      "epoch 5, step 40750/55000, batch loss = 0.04\n",
      "epoch 5, step 41000/55000, batch loss = 0.09\n",
      "epoch 5, step 41250/55000, batch loss = 0.04\n",
      "epoch 5, step 41500/55000, batch loss = 0.05\n",
      "epoch 5, step 41750/55000, batch loss = 0.04\n",
      "epoch 5, step 42000/55000, batch loss = 0.09\n",
      "epoch 5, step 42250/55000, batch loss = 0.04\n",
      "epoch 5, step 42500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.41\n",
      "epoch 5, step 42750/55000, batch loss = 0.05\n",
      "epoch 5, step 43000/55000, batch loss = 0.04\n",
      "epoch 5, step 43250/55000, batch loss = 0.06\n",
      "epoch 5, step 43500/55000, batch loss = 0.04\n",
      "epoch 5, step 43750/55000, batch loss = 0.05\n",
      "epoch 5, step 44000/55000, batch loss = 0.05\n",
      "epoch 5, step 44250/55000, batch loss = 0.04\n",
      "epoch 5, step 44500/55000, batch loss = 0.11\n",
      "epoch 5, step 44750/55000, batch loss = 0.04\n",
      "epoch 5, step 45000/55000, batch loss = 0.06\n",
      "Train accuracy = 99.41\n",
      "epoch 5, step 45250/55000, batch loss = 0.10\n",
      "epoch 5, step 45500/55000, batch loss = 0.09\n",
      "epoch 5, step 45750/55000, batch loss = 0.05\n",
      "epoch 5, step 46000/55000, batch loss = 0.06\n",
      "epoch 5, step 46250/55000, batch loss = 0.04\n",
      "epoch 5, step 46500/55000, batch loss = 0.05\n",
      "epoch 5, step 46750/55000, batch loss = 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, step 47000/55000, batch loss = 0.04\n",
      "epoch 5, step 47250/55000, batch loss = 0.05\n",
      "epoch 5, step 47500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.41\n",
      "epoch 5, step 47750/55000, batch loss = 0.05\n",
      "epoch 5, step 48000/55000, batch loss = 0.07\n",
      "epoch 5, step 48250/55000, batch loss = 0.05\n",
      "epoch 5, step 48500/55000, batch loss = 0.08\n",
      "epoch 5, step 48750/55000, batch loss = 0.05\n",
      "epoch 5, step 49000/55000, batch loss = 0.04\n",
      "epoch 5, step 49250/55000, batch loss = 0.04\n",
      "epoch 5, step 49500/55000, batch loss = 0.09\n",
      "epoch 5, step 49750/55000, batch loss = 0.04\n",
      "epoch 5, step 50000/55000, batch loss = 0.06\n",
      "Train accuracy = 99.42\n",
      "epoch 5, step 50250/55000, batch loss = 0.04\n",
      "epoch 5, step 50500/55000, batch loss = 0.05\n",
      "epoch 5, step 50750/55000, batch loss = 0.05\n",
      "epoch 5, step 51000/55000, batch loss = 0.14\n",
      "epoch 5, step 51250/55000, batch loss = 0.06\n",
      "epoch 5, step 51500/55000, batch loss = 0.04\n",
      "epoch 5, step 51750/55000, batch loss = 0.04\n",
      "epoch 5, step 52000/55000, batch loss = 0.04\n",
      "epoch 5, step 52250/55000, batch loss = 0.04\n",
      "epoch 5, step 52500/55000, batch loss = 0.07\n",
      "Train accuracy = 99.44\n",
      "epoch 5, step 52750/55000, batch loss = 0.05\n",
      "epoch 5, step 53000/55000, batch loss = 0.06\n",
      "epoch 5, step 53250/55000, batch loss = 0.05\n",
      "epoch 5, step 53500/55000, batch loss = 0.05\n",
      "epoch 5, step 53750/55000, batch loss = 0.08\n",
      "epoch 5, step 54000/55000, batch loss = 0.04\n",
      "epoch 5, step 54250/55000, batch loss = 0.05\n",
      "epoch 5, step 54500/55000, batch loss = 0.05\n",
      "epoch 5, step 54750/55000, batch loss = 0.06\n",
      "Train accuracy = 99.44\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.08\n",
      "Validation avg loss = 0.07\n",
      "\n",
      "epoch 6, step 0/55000, batch loss = 0.09\n",
      "epoch 6, step 250/55000, batch loss = 0.04\n",
      "epoch 6, step 500/55000, batch loss = 0.14\n",
      "epoch 6, step 750/55000, batch loss = 0.07\n",
      "epoch 6, step 1000/55000, batch loss = 0.06\n",
      "epoch 6, step 1250/55000, batch loss = 0.05\n",
      "epoch 6, step 1500/55000, batch loss = 0.05\n",
      "epoch 6, step 1750/55000, batch loss = 0.06\n",
      "epoch 6, step 2000/55000, batch loss = 0.05\n",
      "epoch 6, step 2250/55000, batch loss = 0.05\n",
      "epoch 6, step 2500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.61\n",
      "epoch 6, step 2750/55000, batch loss = 0.07\n",
      "epoch 6, step 3000/55000, batch loss = 0.06\n",
      "epoch 6, step 3250/55000, batch loss = 0.05\n",
      "epoch 6, step 3500/55000, batch loss = 0.04\n",
      "epoch 6, step 3750/55000, batch loss = 0.15\n",
      "epoch 6, step 4000/55000, batch loss = 0.08\n",
      "epoch 6, step 4250/55000, batch loss = 0.06\n",
      "epoch 6, step 4500/55000, batch loss = 0.07\n",
      "epoch 6, step 4750/55000, batch loss = 0.10\n",
      "epoch 6, step 5000/55000, batch loss = 0.07\n",
      "Train accuracy = 99.47\n",
      "epoch 6, step 5250/55000, batch loss = 0.04\n",
      "epoch 6, step 5500/55000, batch loss = 0.08\n",
      "epoch 6, step 5750/55000, batch loss = 0.04\n",
      "epoch 6, step 6000/55000, batch loss = 0.07\n",
      "epoch 6, step 6250/55000, batch loss = 0.10\n",
      "epoch 6, step 6500/55000, batch loss = 0.05\n",
      "epoch 6, step 6750/55000, batch loss = 0.04\n",
      "epoch 6, step 7000/55000, batch loss = 0.04\n",
      "epoch 6, step 7250/55000, batch loss = 0.05\n",
      "epoch 6, step 7500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.54\n",
      "epoch 6, step 7750/55000, batch loss = 0.05\n",
      "epoch 6, step 8000/55000, batch loss = 0.06\n",
      "epoch 6, step 8250/55000, batch loss = 0.12\n",
      "epoch 6, step 8500/55000, batch loss = 0.05\n",
      "epoch 6, step 8750/55000, batch loss = 0.05\n",
      "epoch 6, step 9000/55000, batch loss = 0.05\n",
      "epoch 6, step 9250/55000, batch loss = 0.06\n",
      "epoch 6, step 9500/55000, batch loss = 0.10\n",
      "epoch 6, step 9750/55000, batch loss = 0.06\n",
      "epoch 6, step 10000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.53\n",
      "epoch 6, step 10250/55000, batch loss = 0.04\n",
      "epoch 6, step 10500/55000, batch loss = 0.04\n",
      "epoch 6, step 10750/55000, batch loss = 0.04\n",
      "epoch 6, step 11000/55000, batch loss = 0.34\n",
      "epoch 6, step 11250/55000, batch loss = 0.05\n",
      "epoch 6, step 11500/55000, batch loss = 0.04\n",
      "epoch 6, step 11750/55000, batch loss = 0.05\n",
      "epoch 6, step 12000/55000, batch loss = 0.04\n",
      "epoch 6, step 12250/55000, batch loss = 0.04\n",
      "epoch 6, step 12500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.55\n",
      "epoch 6, step 12750/55000, batch loss = 0.04\n",
      "epoch 6, step 13000/55000, batch loss = 0.04\n",
      "epoch 6, step 13250/55000, batch loss = 0.05\n",
      "epoch 6, step 13500/55000, batch loss = 0.05\n",
      "epoch 6, step 13750/55000, batch loss = 0.05\n",
      "epoch 6, step 14000/55000, batch loss = 0.07\n",
      "epoch 6, step 14250/55000, batch loss = 0.06\n",
      "epoch 6, step 14500/55000, batch loss = 0.06\n",
      "epoch 6, step 14750/55000, batch loss = 0.05\n",
      "epoch 6, step 15000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.57\n",
      "epoch 6, step 15250/55000, batch loss = 0.06\n",
      "epoch 6, step 15500/55000, batch loss = 0.04\n",
      "epoch 6, step 15750/55000, batch loss = 0.04\n",
      "epoch 6, step 16000/55000, batch loss = 0.06\n",
      "epoch 6, step 16250/55000, batch loss = 0.06\n",
      "epoch 6, step 16500/55000, batch loss = 0.05\n",
      "epoch 6, step 16750/55000, batch loss = 0.09\n",
      "epoch 6, step 17000/55000, batch loss = 0.04\n",
      "epoch 6, step 17250/55000, batch loss = 0.04\n",
      "epoch 6, step 17500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.54\n",
      "epoch 6, step 17750/55000, batch loss = 0.05\n",
      "epoch 6, step 18000/55000, batch loss = 0.05\n",
      "epoch 6, step 18250/55000, batch loss = 0.04\n",
      "epoch 6, step 18500/55000, batch loss = 0.04\n",
      "epoch 6, step 18750/55000, batch loss = 0.04\n",
      "epoch 6, step 19000/55000, batch loss = 0.08\n",
      "epoch 6, step 19250/55000, batch loss = 0.06\n",
      "epoch 6, step 19500/55000, batch loss = 0.05\n",
      "epoch 6, step 19750/55000, batch loss = 0.04\n",
      "epoch 6, step 20000/55000, batch loss = 0.09\n",
      "Train accuracy = 99.53\n",
      "epoch 6, step 20250/55000, batch loss = 0.06\n",
      "epoch 6, step 20500/55000, batch loss = 0.05\n",
      "epoch 6, step 20750/55000, batch loss = 0.06\n",
      "epoch 6, step 21000/55000, batch loss = 0.05\n",
      "epoch 6, step 21250/55000, batch loss = 0.13\n",
      "epoch 6, step 21500/55000, batch loss = 0.04\n",
      "epoch 6, step 21750/55000, batch loss = 0.05\n",
      "epoch 6, step 22000/55000, batch loss = 0.05\n",
      "epoch 6, step 22250/55000, batch loss = 0.04\n",
      "epoch 6, step 22500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.50\n",
      "epoch 6, step 22750/55000, batch loss = 0.12\n",
      "epoch 6, step 23000/55000, batch loss = 0.04\n",
      "epoch 6, step 23250/55000, batch loss = 0.08\n",
      "epoch 6, step 23500/55000, batch loss = 0.05\n",
      "epoch 6, step 23750/55000, batch loss = 0.04\n",
      "epoch 6, step 24000/55000, batch loss = 0.09\n",
      "epoch 6, step 24250/55000, batch loss = 0.06\n",
      "epoch 6, step 24500/55000, batch loss = 0.06\n",
      "epoch 6, step 24750/55000, batch loss = 0.07\n",
      "epoch 6, step 25000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.47\n",
      "epoch 6, step 25250/55000, batch loss = 0.04\n",
      "epoch 6, step 25500/55000, batch loss = 0.10\n",
      "epoch 6, step 25750/55000, batch loss = 0.04\n",
      "epoch 6, step 26000/55000, batch loss = 0.04\n",
      "epoch 6, step 26250/55000, batch loss = 0.04\n",
      "epoch 6, step 26500/55000, batch loss = 0.06\n",
      "epoch 6, step 26750/55000, batch loss = 0.05\n",
      "epoch 6, step 27000/55000, batch loss = 0.05\n",
      "epoch 6, step 27250/55000, batch loss = 0.06\n",
      "epoch 6, step 27500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.48\n",
      "epoch 6, step 27750/55000, batch loss = 0.05\n",
      "epoch 6, step 28000/55000, batch loss = 0.06\n",
      "epoch 6, step 28250/55000, batch loss = 0.06\n",
      "epoch 6, step 28500/55000, batch loss = 0.04\n",
      "epoch 6, step 28750/55000, batch loss = 0.05\n",
      "epoch 6, step 29000/55000, batch loss = 0.05\n",
      "epoch 6, step 29250/55000, batch loss = 0.05\n",
      "epoch 6, step 29500/55000, batch loss = 0.04\n",
      "epoch 6, step 29750/55000, batch loss = 0.09\n",
      "epoch 6, step 30000/55000, batch loss = 0.06\n",
      "Train accuracy = 99.49\n",
      "epoch 6, step 30250/55000, batch loss = 0.04\n",
      "epoch 6, step 30500/55000, batch loss = 0.04\n",
      "epoch 6, step 30750/55000, batch loss = 0.04\n",
      "epoch 6, step 31000/55000, batch loss = 0.23\n",
      "epoch 6, step 31250/55000, batch loss = 0.09\n",
      "epoch 6, step 31500/55000, batch loss = 0.04\n",
      "epoch 6, step 31750/55000, batch loss = 0.05\n",
      "epoch 6, step 32000/55000, batch loss = 0.06\n",
      "epoch 6, step 32250/55000, batch loss = 0.04\n",
      "epoch 6, step 32500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.47\n",
      "epoch 6, step 32750/55000, batch loss = 0.04\n",
      "epoch 6, step 33000/55000, batch loss = 0.04\n",
      "epoch 6, step 33250/55000, batch loss = 0.07\n",
      "epoch 6, step 33500/55000, batch loss = 0.06\n",
      "epoch 6, step 33750/55000, batch loss = 0.07\n",
      "epoch 6, step 34000/55000, batch loss = 0.07\n",
      "epoch 6, step 34250/55000, batch loss = 0.06\n",
      "epoch 6, step 34500/55000, batch loss = 0.04\n",
      "epoch 6, step 34750/55000, batch loss = 0.04\n",
      "epoch 6, step 35000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.46\n",
      "epoch 6, step 35250/55000, batch loss = 0.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, step 35500/55000, batch loss = 0.04\n",
      "epoch 6, step 35750/55000, batch loss = 0.05\n",
      "epoch 6, step 36000/55000, batch loss = 0.07\n",
      "epoch 6, step 36250/55000, batch loss = 0.08\n",
      "epoch 6, step 36500/55000, batch loss = 0.07\n",
      "epoch 6, step 36750/55000, batch loss = 0.06\n",
      "epoch 6, step 37000/55000, batch loss = 0.05\n",
      "epoch 6, step 37250/55000, batch loss = 0.04\n",
      "epoch 6, step 37500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.47\n",
      "epoch 6, step 37750/55000, batch loss = 0.06\n",
      "epoch 6, step 38000/55000, batch loss = 0.05\n",
      "epoch 6, step 38250/55000, batch loss = 0.06\n",
      "epoch 6, step 38500/55000, batch loss = 0.14\n",
      "epoch 6, step 38750/55000, batch loss = 0.04\n",
      "epoch 6, step 39000/55000, batch loss = 0.04\n",
      "epoch 6, step 39250/55000, batch loss = 0.15\n",
      "epoch 6, step 39500/55000, batch loss = 0.04\n",
      "epoch 6, step 39750/55000, batch loss = 0.05\n",
      "epoch 6, step 40000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.47\n",
      "epoch 6, step 40250/55000, batch loss = 0.04\n",
      "epoch 6, step 40500/55000, batch loss = 0.04\n",
      "epoch 6, step 40750/55000, batch loss = 0.06\n",
      "epoch 6, step 41000/55000, batch loss = 0.04\n",
      "epoch 6, step 41250/55000, batch loss = 0.10\n",
      "epoch 6, step 41500/55000, batch loss = 0.05\n",
      "epoch 6, step 41750/55000, batch loss = 0.05\n",
      "epoch 6, step 42000/55000, batch loss = 0.04\n",
      "epoch 6, step 42250/55000, batch loss = 0.05\n",
      "epoch 6, step 42500/55000, batch loss = 0.06\n",
      "Train accuracy = 99.46\n",
      "epoch 6, step 42750/55000, batch loss = 0.07\n",
      "epoch 6, step 43000/55000, batch loss = 0.04\n",
      "epoch 6, step 43250/55000, batch loss = 0.04\n",
      "epoch 6, step 43500/55000, batch loss = 0.04\n",
      "epoch 6, step 43750/55000, batch loss = 0.05\n",
      "epoch 6, step 44000/55000, batch loss = 0.04\n",
      "epoch 6, step 44250/55000, batch loss = 0.05\n",
      "epoch 6, step 44500/55000, batch loss = 0.07\n",
      "epoch 6, step 44750/55000, batch loss = 0.05\n",
      "epoch 6, step 45000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.46\n",
      "epoch 6, step 45250/55000, batch loss = 0.08\n",
      "epoch 6, step 45500/55000, batch loss = 0.05\n",
      "epoch 6, step 45750/55000, batch loss = 0.06\n",
      "epoch 6, step 46000/55000, batch loss = 0.04\n",
      "epoch 6, step 46250/55000, batch loss = 0.27\n",
      "epoch 6, step 46500/55000, batch loss = 0.04\n",
      "epoch 6, step 46750/55000, batch loss = 0.07\n",
      "epoch 6, step 47000/55000, batch loss = 0.07\n",
      "epoch 6, step 47250/55000, batch loss = 0.09\n",
      "epoch 6, step 47500/55000, batch loss = 0.10\n",
      "Train accuracy = 99.46\n",
      "epoch 6, step 47750/55000, batch loss = 0.05\n",
      "epoch 6, step 48000/55000, batch loss = 0.04\n",
      "epoch 6, step 48250/55000, batch loss = 0.07\n",
      "epoch 6, step 48500/55000, batch loss = 0.04\n",
      "epoch 6, step 48750/55000, batch loss = 0.06\n",
      "epoch 6, step 49000/55000, batch loss = 0.11\n",
      "epoch 6, step 49250/55000, batch loss = 0.04\n",
      "epoch 6, step 49500/55000, batch loss = 0.04\n",
      "epoch 6, step 49750/55000, batch loss = 0.05\n",
      "epoch 6, step 50000/55000, batch loss = 0.08\n",
      "Train accuracy = 99.46\n",
      "epoch 6, step 50250/55000, batch loss = 0.15\n",
      "epoch 6, step 50500/55000, batch loss = 0.09\n",
      "epoch 6, step 50750/55000, batch loss = 0.12\n",
      "epoch 6, step 51000/55000, batch loss = 0.05\n",
      "epoch 6, step 51250/55000, batch loss = 0.04\n",
      "epoch 6, step 51500/55000, batch loss = 0.05\n",
      "epoch 6, step 51750/55000, batch loss = 0.06\n",
      "epoch 6, step 52000/55000, batch loss = 0.04\n",
      "epoch 6, step 52250/55000, batch loss = 0.14\n",
      "epoch 6, step 52500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.46\n",
      "epoch 6, step 52750/55000, batch loss = 0.04\n",
      "epoch 6, step 53000/55000, batch loss = 0.05\n",
      "epoch 6, step 53250/55000, batch loss = 0.04\n",
      "epoch 6, step 53500/55000, batch loss = 0.06\n",
      "epoch 6, step 53750/55000, batch loss = 0.05\n",
      "epoch 6, step 54000/55000, batch loss = 0.08\n",
      "epoch 6, step 54250/55000, batch loss = 0.05\n",
      "epoch 6, step 54500/55000, batch loss = 0.05\n",
      "epoch 6, step 54750/55000, batch loss = 0.05\n",
      "Train accuracy = 99.45\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.08\n",
      "Validation avg loss = 0.07\n",
      "\n",
      "epoch 7, step 0/55000, batch loss = 0.10\n",
      "epoch 7, step 250/55000, batch loss = 0.06\n",
      "epoch 7, step 500/55000, batch loss = 0.05\n",
      "epoch 7, step 750/55000, batch loss = 0.12\n",
      "epoch 7, step 1000/55000, batch loss = 0.04\n",
      "epoch 7, step 1250/55000, batch loss = 0.05\n",
      "epoch 7, step 1500/55000, batch loss = 0.07\n",
      "epoch 7, step 1750/55000, batch loss = 0.06\n",
      "epoch 7, step 2000/55000, batch loss = 0.06\n",
      "epoch 7, step 2250/55000, batch loss = 0.09\n",
      "epoch 7, step 2500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.53\n",
      "epoch 7, step 2750/55000, batch loss = 0.07\n",
      "epoch 7, step 3000/55000, batch loss = 0.06\n",
      "epoch 7, step 3250/55000, batch loss = 0.05\n",
      "epoch 7, step 3500/55000, batch loss = 0.08\n",
      "epoch 7, step 3750/55000, batch loss = 0.08\n",
      "epoch 7, step 4000/55000, batch loss = 0.05\n",
      "epoch 7, step 4250/55000, batch loss = 0.04\n",
      "epoch 7, step 4500/55000, batch loss = 0.04\n",
      "epoch 7, step 4750/55000, batch loss = 0.13\n",
      "epoch 7, step 5000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.39\n",
      "epoch 7, step 5250/55000, batch loss = 0.05\n",
      "epoch 7, step 5500/55000, batch loss = 0.08\n",
      "epoch 7, step 5750/55000, batch loss = 0.04\n",
      "epoch 7, step 6000/55000, batch loss = 0.04\n",
      "epoch 7, step 6250/55000, batch loss = 0.05\n",
      "epoch 7, step 6500/55000, batch loss = 0.07\n",
      "epoch 7, step 6750/55000, batch loss = 0.05\n",
      "epoch 7, step 7000/55000, batch loss = 0.04\n",
      "epoch 7, step 7250/55000, batch loss = 0.04\n",
      "epoch 7, step 7500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.47\n",
      "epoch 7, step 7750/55000, batch loss = 0.04\n",
      "epoch 7, step 8000/55000, batch loss = 0.06\n",
      "epoch 7, step 8250/55000, batch loss = 0.04\n",
      "epoch 7, step 8500/55000, batch loss = 0.04\n",
      "epoch 7, step 8750/55000, batch loss = 0.04\n",
      "epoch 7, step 9000/55000, batch loss = 0.05\n",
      "epoch 7, step 9250/55000, batch loss = 0.05\n",
      "epoch 7, step 9500/55000, batch loss = 0.05\n",
      "epoch 7, step 9750/55000, batch loss = 0.04\n",
      "epoch 7, step 10000/55000, batch loss = 0.08\n",
      "Train accuracy = 99.46\n",
      "epoch 7, step 10250/55000, batch loss = 0.05\n",
      "epoch 7, step 10500/55000, batch loss = 0.05\n",
      "epoch 7, step 10750/55000, batch loss = 0.05\n",
      "epoch 7, step 11000/55000, batch loss = 0.09\n",
      "epoch 7, step 11250/55000, batch loss = 0.05\n",
      "epoch 7, step 11500/55000, batch loss = 0.08\n",
      "epoch 7, step 11750/55000, batch loss = 0.04\n",
      "epoch 7, step 12000/55000, batch loss = 0.04\n",
      "epoch 7, step 12250/55000, batch loss = 0.05\n",
      "epoch 7, step 12500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.47\n",
      "epoch 7, step 12750/55000, batch loss = 0.05\n",
      "epoch 7, step 13000/55000, batch loss = 0.05\n",
      "epoch 7, step 13250/55000, batch loss = 0.12\n",
      "epoch 7, step 13500/55000, batch loss = 0.04\n",
      "epoch 7, step 13750/55000, batch loss = 0.04\n",
      "epoch 7, step 14000/55000, batch loss = 0.05\n",
      "epoch 7, step 14250/55000, batch loss = 0.06\n",
      "epoch 7, step 14500/55000, batch loss = 0.05\n",
      "epoch 7, step 14750/55000, batch loss = 0.05\n",
      "epoch 7, step 15000/55000, batch loss = 0.08\n",
      "Train accuracy = 99.49\n",
      "epoch 7, step 15250/55000, batch loss = 0.05\n",
      "epoch 7, step 15500/55000, batch loss = 0.06\n",
      "epoch 7, step 15750/55000, batch loss = 0.06\n",
      "epoch 7, step 16000/55000, batch loss = 0.04\n",
      "epoch 7, step 16250/55000, batch loss = 0.04\n",
      "epoch 7, step 16500/55000, batch loss = 0.05\n",
      "epoch 7, step 16750/55000, batch loss = 0.04\n",
      "epoch 7, step 17000/55000, batch loss = 0.05\n",
      "epoch 7, step 17250/55000, batch loss = 0.04\n",
      "epoch 7, step 17500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.48\n",
      "epoch 7, step 17750/55000, batch loss = 0.06\n",
      "epoch 7, step 18000/55000, batch loss = 0.07\n",
      "epoch 7, step 18250/55000, batch loss = 0.07\n",
      "epoch 7, step 18500/55000, batch loss = 0.05\n",
      "epoch 7, step 18750/55000, batch loss = 0.05\n",
      "epoch 7, step 19000/55000, batch loss = 0.06\n",
      "epoch 7, step 19250/55000, batch loss = 0.06\n",
      "epoch 7, step 19500/55000, batch loss = 0.05\n",
      "epoch 7, step 19750/55000, batch loss = 0.04\n",
      "epoch 7, step 20000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.49\n",
      "epoch 7, step 20250/55000, batch loss = 0.06\n",
      "epoch 7, step 20500/55000, batch loss = 0.04\n",
      "epoch 7, step 20750/55000, batch loss = 0.05\n",
      "epoch 7, step 21000/55000, batch loss = 0.04\n",
      "epoch 7, step 21250/55000, batch loss = 0.04\n",
      "epoch 7, step 21500/55000, batch loss = 0.04\n",
      "epoch 7, step 21750/55000, batch loss = 0.04\n",
      "epoch 7, step 22000/55000, batch loss = 0.06\n",
      "epoch 7, step 22250/55000, batch loss = 0.13\n",
      "epoch 7, step 22500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.50\n",
      "epoch 7, step 22750/55000, batch loss = 0.04\n",
      "epoch 7, step 23000/55000, batch loss = 0.05\n",
      "epoch 7, step 23250/55000, batch loss = 0.05\n",
      "epoch 7, step 23500/55000, batch loss = 0.06\n",
      "epoch 7, step 23750/55000, batch loss = 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, step 24000/55000, batch loss = 0.04\n",
      "epoch 7, step 24250/55000, batch loss = 0.06\n",
      "epoch 7, step 24500/55000, batch loss = 0.15\n",
      "epoch 7, step 24750/55000, batch loss = 0.04\n",
      "epoch 7, step 25000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.49\n",
      "epoch 7, step 25250/55000, batch loss = 0.07\n",
      "epoch 7, step 25500/55000, batch loss = 0.05\n",
      "epoch 7, step 25750/55000, batch loss = 0.04\n",
      "epoch 7, step 26000/55000, batch loss = 0.05\n",
      "epoch 7, step 26250/55000, batch loss = 0.06\n",
      "epoch 7, step 26500/55000, batch loss = 0.05\n",
      "epoch 7, step 26750/55000, batch loss = 0.05\n",
      "epoch 7, step 27000/55000, batch loss = 0.08\n",
      "epoch 7, step 27250/55000, batch loss = 0.04\n",
      "epoch 7, step 27500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.48\n",
      "epoch 7, step 27750/55000, batch loss = 0.09\n",
      "epoch 7, step 28000/55000, batch loss = 0.06\n",
      "epoch 7, step 28250/55000, batch loss = 0.05\n",
      "epoch 7, step 28500/55000, batch loss = 0.05\n",
      "epoch 7, step 28750/55000, batch loss = 0.05\n",
      "epoch 7, step 29000/55000, batch loss = 0.04\n",
      "epoch 7, step 29250/55000, batch loss = 0.05\n",
      "epoch 7, step 29500/55000, batch loss = 0.11\n",
      "epoch 7, step 29750/55000, batch loss = 0.04\n",
      "epoch 7, step 30000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.47\n",
      "epoch 7, step 30250/55000, batch loss = 0.04\n",
      "epoch 7, step 30500/55000, batch loss = 0.06\n",
      "epoch 7, step 30750/55000, batch loss = 0.04\n",
      "epoch 7, step 31000/55000, batch loss = 0.05\n",
      "epoch 7, step 31250/55000, batch loss = 0.04\n",
      "epoch 7, step 31500/55000, batch loss = 0.07\n",
      "epoch 7, step 31750/55000, batch loss = 0.13\n",
      "epoch 7, step 32000/55000, batch loss = 0.04\n",
      "epoch 7, step 32250/55000, batch loss = 0.05\n",
      "epoch 7, step 32500/55000, batch loss = 0.06\n",
      "Train accuracy = 99.47\n",
      "epoch 7, step 32750/55000, batch loss = 0.05\n",
      "epoch 7, step 33000/55000, batch loss = 0.04\n",
      "epoch 7, step 33250/55000, batch loss = 0.06\n",
      "epoch 7, step 33500/55000, batch loss = 0.04\n",
      "epoch 7, step 33750/55000, batch loss = 0.04\n",
      "epoch 7, step 34000/55000, batch loss = 0.05\n",
      "epoch 7, step 34250/55000, batch loss = 0.10\n",
      "epoch 7, step 34500/55000, batch loss = 0.06\n",
      "epoch 7, step 34750/55000, batch loss = 0.06\n",
      "epoch 7, step 35000/55000, batch loss = 0.07\n",
      "Train accuracy = 99.46\n",
      "epoch 7, step 35250/55000, batch loss = 0.04\n",
      "epoch 7, step 35500/55000, batch loss = 0.05\n",
      "epoch 7, step 35750/55000, batch loss = 0.04\n",
      "epoch 7, step 36000/55000, batch loss = 0.11\n",
      "epoch 7, step 36250/55000, batch loss = 0.10\n",
      "epoch 7, step 36500/55000, batch loss = 0.06\n",
      "epoch 7, step 36750/55000, batch loss = 0.04\n",
      "epoch 7, step 37000/55000, batch loss = 0.04\n",
      "epoch 7, step 37250/55000, batch loss = 0.05\n",
      "epoch 7, step 37500/55000, batch loss = 0.16\n",
      "Train accuracy = 99.46\n",
      "epoch 7, step 37750/55000, batch loss = 0.09\n",
      "epoch 7, step 38000/55000, batch loss = 0.05\n",
      "epoch 7, step 38250/55000, batch loss = 0.05\n",
      "epoch 7, step 38500/55000, batch loss = 0.08\n",
      "epoch 7, step 38750/55000, batch loss = 0.05\n",
      "epoch 7, step 39000/55000, batch loss = 0.05\n",
      "epoch 7, step 39250/55000, batch loss = 0.04\n",
      "epoch 7, step 39500/55000, batch loss = 0.05\n",
      "epoch 7, step 39750/55000, batch loss = 0.08\n",
      "epoch 7, step 40000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.47\n",
      "epoch 7, step 40250/55000, batch loss = 0.05\n",
      "epoch 7, step 40500/55000, batch loss = 0.05\n",
      "epoch 7, step 40750/55000, batch loss = 0.05\n",
      "epoch 7, step 41000/55000, batch loss = 0.05\n",
      "epoch 7, step 41250/55000, batch loss = 0.07\n",
      "epoch 7, step 41500/55000, batch loss = 0.04\n",
      "epoch 7, step 41750/55000, batch loss = 0.07\n",
      "epoch 7, step 42000/55000, batch loss = 0.04\n",
      "epoch 7, step 42250/55000, batch loss = 0.04\n",
      "epoch 7, step 42500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.47\n",
      "epoch 7, step 42750/55000, batch loss = 0.08\n",
      "epoch 7, step 43000/55000, batch loss = 0.04\n",
      "epoch 7, step 43250/55000, batch loss = 0.09\n",
      "epoch 7, step 43500/55000, batch loss = 0.05\n",
      "epoch 7, step 43750/55000, batch loss = 0.16\n",
      "epoch 7, step 44000/55000, batch loss = 0.05\n",
      "epoch 7, step 44250/55000, batch loss = 0.06\n",
      "epoch 7, step 44500/55000, batch loss = 0.04\n",
      "epoch 7, step 44750/55000, batch loss = 0.04\n",
      "epoch 7, step 45000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.47\n",
      "epoch 7, step 45250/55000, batch loss = 0.06\n",
      "epoch 7, step 45500/55000, batch loss = 0.06\n",
      "epoch 7, step 45750/55000, batch loss = 0.05\n",
      "epoch 7, step 46000/55000, batch loss = 0.05\n",
      "epoch 7, step 46250/55000, batch loss = 0.05\n",
      "epoch 7, step 46500/55000, batch loss = 0.08\n",
      "epoch 7, step 46750/55000, batch loss = 0.04\n",
      "epoch 7, step 47000/55000, batch loss = 0.04\n",
      "epoch 7, step 47250/55000, batch loss = 0.07\n",
      "epoch 7, step 47500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.47\n",
      "epoch 7, step 47750/55000, batch loss = 0.04\n",
      "epoch 7, step 48000/55000, batch loss = 0.04\n",
      "epoch 7, step 48250/55000, batch loss = 0.06\n",
      "epoch 7, step 48500/55000, batch loss = 0.05\n",
      "epoch 7, step 48750/55000, batch loss = 0.05\n",
      "epoch 7, step 49000/55000, batch loss = 0.08\n",
      "epoch 7, step 49250/55000, batch loss = 0.05\n",
      "epoch 7, step 49500/55000, batch loss = 0.04\n",
      "epoch 7, step 49750/55000, batch loss = 0.11\n",
      "epoch 7, step 50000/55000, batch loss = 0.07\n",
      "Train accuracy = 99.48\n",
      "epoch 7, step 50250/55000, batch loss = 0.04\n",
      "epoch 7, step 50500/55000, batch loss = 0.08\n",
      "epoch 7, step 50750/55000, batch loss = 0.04\n",
      "epoch 7, step 51000/55000, batch loss = 0.05\n",
      "epoch 7, step 51250/55000, batch loss = 0.04\n",
      "epoch 7, step 51500/55000, batch loss = 0.07\n",
      "epoch 7, step 51750/55000, batch loss = 0.04\n",
      "epoch 7, step 52000/55000, batch loss = 0.07\n",
      "epoch 7, step 52250/55000, batch loss = 0.06\n",
      "epoch 7, step 52500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.46\n",
      "epoch 7, step 52750/55000, batch loss = 0.05\n",
      "epoch 7, step 53000/55000, batch loss = 0.07\n",
      "epoch 7, step 53250/55000, batch loss = 0.04\n",
      "epoch 7, step 53500/55000, batch loss = 0.04\n",
      "epoch 7, step 53750/55000, batch loss = 0.06\n",
      "epoch 7, step 54000/55000, batch loss = 0.05\n",
      "epoch 7, step 54250/55000, batch loss = 0.05\n",
      "epoch 7, step 54500/55000, batch loss = 0.09\n",
      "epoch 7, step 54750/55000, batch loss = 0.05\n",
      "Train accuracy = 99.46\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.08\n",
      "Validation avg loss = 0.07\n",
      "\n",
      "epoch 8, step 0/55000, batch loss = 0.05\n",
      "epoch 8, step 250/55000, batch loss = 0.16\n",
      "epoch 8, step 500/55000, batch loss = 0.06\n",
      "epoch 8, step 750/55000, batch loss = 0.04\n",
      "epoch 8, step 1000/55000, batch loss = 0.06\n",
      "epoch 8, step 1250/55000, batch loss = 0.07\n",
      "epoch 8, step 1500/55000, batch loss = 0.04\n",
      "epoch 8, step 1750/55000, batch loss = 0.06\n",
      "epoch 8, step 2000/55000, batch loss = 0.04\n",
      "epoch 8, step 2250/55000, batch loss = 0.05\n",
      "epoch 8, step 2500/55000, batch loss = 0.06\n",
      "Train accuracy = 99.29\n",
      "epoch 8, step 2750/55000, batch loss = 0.04\n",
      "epoch 8, step 3000/55000, batch loss = 0.04\n",
      "epoch 8, step 3250/55000, batch loss = 0.05\n",
      "epoch 8, step 3500/55000, batch loss = 0.13\n",
      "epoch 8, step 3750/55000, batch loss = 0.09\n",
      "epoch 8, step 4000/55000, batch loss = 0.06\n",
      "epoch 8, step 4250/55000, batch loss = 0.08\n",
      "epoch 8, step 4500/55000, batch loss = 0.05\n",
      "epoch 8, step 4750/55000, batch loss = 0.04\n",
      "epoch 8, step 5000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.29\n",
      "epoch 8, step 5250/55000, batch loss = 0.08\n",
      "epoch 8, step 5500/55000, batch loss = 0.07\n",
      "epoch 8, step 5750/55000, batch loss = 0.12\n",
      "epoch 8, step 6000/55000, batch loss = 0.07\n",
      "epoch 8, step 6250/55000, batch loss = 0.04\n",
      "epoch 8, step 6500/55000, batch loss = 0.04\n",
      "epoch 8, step 6750/55000, batch loss = 0.05\n",
      "epoch 8, step 7000/55000, batch loss = 0.06\n",
      "epoch 8, step 7250/55000, batch loss = 0.04\n",
      "epoch 8, step 7500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.39\n",
      "epoch 8, step 7750/55000, batch loss = 0.05\n",
      "epoch 8, step 8000/55000, batch loss = 0.04\n",
      "epoch 8, step 8250/55000, batch loss = 0.05\n",
      "epoch 8, step 8500/55000, batch loss = 0.05\n",
      "epoch 8, step 8750/55000, batch loss = 0.06\n",
      "epoch 8, step 9000/55000, batch loss = 0.08\n",
      "epoch 8, step 9250/55000, batch loss = 0.05\n",
      "epoch 8, step 9500/55000, batch loss = 0.05\n",
      "epoch 8, step 9750/55000, batch loss = 0.05\n",
      "epoch 8, step 10000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.38\n",
      "epoch 8, step 10250/55000, batch loss = 0.04\n",
      "epoch 8, step 10500/55000, batch loss = 0.08\n",
      "epoch 8, step 10750/55000, batch loss = 0.08\n",
      "epoch 8, step 11000/55000, batch loss = 0.04\n",
      "epoch 8, step 11250/55000, batch loss = 0.04\n",
      "epoch 8, step 11500/55000, batch loss = 0.05\n",
      "epoch 8, step 11750/55000, batch loss = 0.05\n",
      "epoch 8, step 12000/55000, batch loss = 0.04\n",
      "epoch 8, step 12250/55000, batch loss = 0.05\n",
      "epoch 8, step 12500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, step 12750/55000, batch loss = 0.04\n",
      "epoch 8, step 13000/55000, batch loss = 0.06\n",
      "epoch 8, step 13250/55000, batch loss = 0.04\n",
      "epoch 8, step 13500/55000, batch loss = 0.05\n",
      "epoch 8, step 13750/55000, batch loss = 0.06\n",
      "epoch 8, step 14000/55000, batch loss = 0.06\n",
      "epoch 8, step 14250/55000, batch loss = 0.05\n",
      "epoch 8, step 14500/55000, batch loss = 0.06\n",
      "epoch 8, step 14750/55000, batch loss = 0.05\n",
      "epoch 8, step 15000/55000, batch loss = 0.15\n",
      "Train accuracy = 99.40\n",
      "epoch 8, step 15250/55000, batch loss = 0.04\n",
      "epoch 8, step 15500/55000, batch loss = 0.19\n",
      "epoch 8, step 15750/55000, batch loss = 0.04\n",
      "epoch 8, step 16000/55000, batch loss = 0.04\n",
      "epoch 8, step 16250/55000, batch loss = 0.06\n",
      "epoch 8, step 16500/55000, batch loss = 0.06\n",
      "epoch 8, step 16750/55000, batch loss = 0.07\n",
      "epoch 8, step 17000/55000, batch loss = 0.06\n",
      "epoch 8, step 17250/55000, batch loss = 0.09\n",
      "epoch 8, step 17500/55000, batch loss = 0.08\n",
      "Train accuracy = 99.42\n",
      "epoch 8, step 17750/55000, batch loss = 0.08\n",
      "epoch 8, step 18000/55000, batch loss = 0.05\n",
      "epoch 8, step 18250/55000, batch loss = 0.05\n",
      "epoch 8, step 18500/55000, batch loss = 0.06\n",
      "epoch 8, step 18750/55000, batch loss = 0.04\n",
      "epoch 8, step 19000/55000, batch loss = 0.04\n",
      "epoch 8, step 19250/55000, batch loss = 0.06\n",
      "epoch 8, step 19500/55000, batch loss = 0.04\n",
      "epoch 8, step 19750/55000, batch loss = 0.06\n",
      "epoch 8, step 20000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.43\n",
      "epoch 8, step 20250/55000, batch loss = 0.05\n",
      "epoch 8, step 20500/55000, batch loss = 0.04\n",
      "epoch 8, step 20750/55000, batch loss = 0.05\n",
      "epoch 8, step 21000/55000, batch loss = 0.04\n",
      "epoch 8, step 21250/55000, batch loss = 0.06\n",
      "epoch 8, step 21500/55000, batch loss = 0.05\n",
      "epoch 8, step 21750/55000, batch loss = 0.04\n",
      "epoch 8, step 22000/55000, batch loss = 0.04\n",
      "epoch 8, step 22250/55000, batch loss = 0.05\n",
      "epoch 8, step 22500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.43\n",
      "epoch 8, step 22750/55000, batch loss = 0.04\n",
      "epoch 8, step 23000/55000, batch loss = 0.05\n",
      "epoch 8, step 23250/55000, batch loss = 0.05\n",
      "epoch 8, step 23500/55000, batch loss = 0.14\n",
      "epoch 8, step 23750/55000, batch loss = 0.04\n",
      "epoch 8, step 24000/55000, batch loss = 0.04\n",
      "epoch 8, step 24250/55000, batch loss = 0.04\n",
      "epoch 8, step 24500/55000, batch loss = 0.04\n",
      "epoch 8, step 24750/55000, batch loss = 0.04\n",
      "epoch 8, step 25000/55000, batch loss = 0.09\n",
      "Train accuracy = 99.45\n",
      "epoch 8, step 25250/55000, batch loss = 0.04\n",
      "epoch 8, step 25500/55000, batch loss = 0.05\n",
      "epoch 8, step 25750/55000, batch loss = 0.07\n",
      "epoch 8, step 26000/55000, batch loss = 0.07\n",
      "epoch 8, step 26250/55000, batch loss = 0.05\n",
      "epoch 8, step 26500/55000, batch loss = 0.04\n",
      "epoch 8, step 26750/55000, batch loss = 0.04\n",
      "epoch 8, step 27000/55000, batch loss = 0.05\n",
      "epoch 8, step 27250/55000, batch loss = 0.04\n",
      "epoch 8, step 27500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.44\n",
      "epoch 8, step 27750/55000, batch loss = 0.05\n",
      "epoch 8, step 28000/55000, batch loss = 0.06\n",
      "epoch 8, step 28250/55000, batch loss = 0.06\n",
      "epoch 8, step 28500/55000, batch loss = 0.04\n",
      "epoch 8, step 28750/55000, batch loss = 0.05\n",
      "epoch 8, step 29000/55000, batch loss = 0.09\n",
      "epoch 8, step 29250/55000, batch loss = 0.07\n",
      "epoch 8, step 29500/55000, batch loss = 0.04\n",
      "epoch 8, step 29750/55000, batch loss = 0.05\n",
      "epoch 8, step 30000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.46\n",
      "epoch 8, step 30250/55000, batch loss = 0.08\n",
      "epoch 8, step 30500/55000, batch loss = 0.05\n",
      "epoch 8, step 30750/55000, batch loss = 0.10\n",
      "epoch 8, step 31000/55000, batch loss = 0.05\n",
      "epoch 8, step 31250/55000, batch loss = 0.04\n",
      "epoch 8, step 31500/55000, batch loss = 0.05\n",
      "epoch 8, step 31750/55000, batch loss = 0.07\n",
      "epoch 8, step 32000/55000, batch loss = 0.05\n",
      "epoch 8, step 32250/55000, batch loss = 0.06\n",
      "epoch 8, step 32500/55000, batch loss = 0.06\n",
      "Train accuracy = 99.47\n",
      "epoch 8, step 32750/55000, batch loss = 0.04\n",
      "epoch 8, step 33000/55000, batch loss = 0.04\n",
      "epoch 8, step 33250/55000, batch loss = 0.06\n",
      "epoch 8, step 33500/55000, batch loss = 0.06\n",
      "epoch 8, step 33750/55000, batch loss = 0.05\n",
      "epoch 8, step 34000/55000, batch loss = 0.04\n",
      "epoch 8, step 34250/55000, batch loss = 0.05\n",
      "epoch 8, step 34500/55000, batch loss = 0.07\n",
      "epoch 8, step 34750/55000, batch loss = 0.05\n",
      "epoch 8, step 35000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.47\n",
      "epoch 8, step 35250/55000, batch loss = 0.06\n",
      "epoch 8, step 35500/55000, batch loss = 0.05\n",
      "epoch 8, step 35750/55000, batch loss = 0.05\n",
      "epoch 8, step 36000/55000, batch loss = 0.05\n",
      "epoch 8, step 36250/55000, batch loss = 0.04\n",
      "epoch 8, step 36500/55000, batch loss = 0.05\n",
      "epoch 8, step 36750/55000, batch loss = 0.08\n",
      "epoch 8, step 37000/55000, batch loss = 0.06\n",
      "epoch 8, step 37250/55000, batch loss = 0.05\n",
      "epoch 8, step 37500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.46\n",
      "epoch 8, step 37750/55000, batch loss = 0.05\n",
      "epoch 8, step 38000/55000, batch loss = 0.04\n",
      "epoch 8, step 38250/55000, batch loss = 0.06\n",
      "epoch 8, step 38500/55000, batch loss = 0.05\n",
      "epoch 8, step 38750/55000, batch loss = 0.05\n",
      "epoch 8, step 39000/55000, batch loss = 0.10\n",
      "epoch 8, step 39250/55000, batch loss = 0.04\n",
      "epoch 8, step 39500/55000, batch loss = 0.07\n",
      "epoch 8, step 39750/55000, batch loss = 0.14\n",
      "epoch 8, step 40000/55000, batch loss = 0.04\n",
      "Train accuracy = 99.49\n",
      "epoch 8, step 40250/55000, batch loss = 0.13\n",
      "epoch 8, step 40500/55000, batch loss = 0.05\n",
      "epoch 8, step 40750/55000, batch loss = 0.05\n",
      "epoch 8, step 41000/55000, batch loss = 0.04\n",
      "epoch 8, step 41250/55000, batch loss = 0.04\n",
      "epoch 8, step 41500/55000, batch loss = 0.04\n",
      "epoch 8, step 41750/55000, batch loss = 0.05\n",
      "epoch 8, step 42000/55000, batch loss = 0.04\n",
      "epoch 8, step 42250/55000, batch loss = 0.04\n",
      "epoch 8, step 42500/55000, batch loss = 0.08\n",
      "Train accuracy = 99.48\n",
      "epoch 8, step 42750/55000, batch loss = 0.04\n",
      "epoch 8, step 43000/55000, batch loss = 0.11\n",
      "epoch 8, step 43250/55000, batch loss = 0.06\n",
      "epoch 8, step 43500/55000, batch loss = 0.16\n",
      "epoch 8, step 43750/55000, batch loss = 0.06\n",
      "epoch 8, step 44000/55000, batch loss = 0.05\n",
      "epoch 8, step 44250/55000, batch loss = 0.04\n",
      "epoch 8, step 44500/55000, batch loss = 0.05\n",
      "epoch 8, step 44750/55000, batch loss = 0.04\n",
      "epoch 8, step 45000/55000, batch loss = 0.05\n",
      "Train accuracy = 99.48\n",
      "epoch 8, step 45250/55000, batch loss = 0.07\n",
      "epoch 8, step 45500/55000, batch loss = 0.05\n",
      "epoch 8, step 45750/55000, batch loss = 0.05\n",
      "epoch 8, step 46000/55000, batch loss = 0.05\n",
      "epoch 8, step 46250/55000, batch loss = 0.06\n",
      "epoch 8, step 46500/55000, batch loss = 0.04\n",
      "epoch 8, step 46750/55000, batch loss = 0.06\n",
      "epoch 8, step 47000/55000, batch loss = 0.04\n",
      "epoch 8, step 47250/55000, batch loss = 0.04\n",
      "epoch 8, step 47500/55000, batch loss = 0.05\n",
      "Train accuracy = 99.48\n",
      "epoch 8, step 47750/55000, batch loss = 0.05\n",
      "epoch 8, step 48000/55000, batch loss = 0.04\n",
      "epoch 8, step 48250/55000, batch loss = 0.04\n",
      "epoch 8, step 48500/55000, batch loss = 0.05\n",
      "epoch 8, step 48750/55000, batch loss = 0.08\n",
      "epoch 8, step 49000/55000, batch loss = 0.04\n",
      "epoch 8, step 49250/55000, batch loss = 0.10\n",
      "epoch 8, step 49500/55000, batch loss = 0.07\n",
      "epoch 8, step 49750/55000, batch loss = 0.12\n",
      "epoch 8, step 50000/55000, batch loss = 0.07\n",
      "Train accuracy = 99.47\n",
      "epoch 8, step 50250/55000, batch loss = 0.04\n",
      "epoch 8, step 50500/55000, batch loss = 0.06\n",
      "epoch 8, step 50750/55000, batch loss = 0.21\n",
      "epoch 8, step 51000/55000, batch loss = 0.04\n",
      "epoch 8, step 51250/55000, batch loss = 0.04\n",
      "epoch 8, step 51500/55000, batch loss = 0.05\n",
      "epoch 8, step 51750/55000, batch loss = 0.05\n",
      "epoch 8, step 52000/55000, batch loss = 0.04\n",
      "epoch 8, step 52250/55000, batch loss = 0.06\n",
      "epoch 8, step 52500/55000, batch loss = 0.04\n",
      "Train accuracy = 99.46\n",
      "epoch 8, step 52750/55000, batch loss = 0.05\n",
      "epoch 8, step 53000/55000, batch loss = 0.05\n",
      "epoch 8, step 53250/55000, batch loss = 0.06\n",
      "epoch 8, step 53500/55000, batch loss = 0.05\n",
      "epoch 8, step 53750/55000, batch loss = 0.04\n",
      "epoch 8, step 54000/55000, batch loss = 0.09\n",
      "epoch 8, step 54250/55000, batch loss = 0.06\n",
      "epoch 8, step 54500/55000, batch loss = 0.06\n",
      "epoch 8, step 54750/55000, batch loss = 0.06\n",
      "Train accuracy = 99.46\n",
      "\n",
      "Running evaluation:  Validation\n",
      "Validation accuracy = 99.08\n",
      "Validation avg loss = 0.07\n",
      "\n",
      "\n",
      "Running evaluation:  Test\n",
      "Test accuracy = 99.09\n",
      "Test avg loss = 0.07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "train_tf(session, train_x, train_y, valid_x, valid_y, config)\n",
    "evaluate_tf(session, \"Test\", test_x, test_y, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. zadatak - Klasifikacija na CIFAR-10 skupu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_image(img, path, mean, std):\n",
    "    img = img.copy()\n",
    "    img *= std\n",
    "    img += mean\n",
    "    img = img.astype(np.uint8)\n",
    "    ski.io.imsave(path, img)\n",
    "\n",
    "def show_image(img, mean, std):\n",
    "    img = img.copy()\n",
    "    img *= std\n",
    "    img += mean\n",
    "    img = img.astype(np.uint8)\n",
    "    ski.io.imshow(img)\n",
    "    ski.io.show()\n",
    "\n",
    "def shuffle_data(data_x, data_y):\n",
    "    indices = np.arange(data_x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    shuffled_data_x = np.ascontiguousarray(data_x[indices])\n",
    "    shuffled_data_y = np.ascontiguousarray(data_y[indices])\n",
    "    return shuffled_data_x, shuffled_data_y\n",
    "\n",
    "def unpickle(file):\n",
    "    print(file)\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pickle.load(fo, encoding='latin1')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "def get_label_names(blob):\n",
    "    label_dict = unpickle(blob)['label_names']\n",
    "    return np.array(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'C:\\\\Users\\\\Korisnik\\\\Desktop\\\\cifar-10-batches-py\\\\'\n",
    "SAVE_DIR = 'C:\\\\Users\\\\Korisnik\\\\Desktop\\\\du_lab2\\\\Deep-Learning\\\\2_lab\\\\zad4_images\\\\'\n",
    "\n",
    "config = {}\n",
    "config['max_epochs'] = 40\n",
    "config['batch_size'] = 50\n",
    "config['save_dir'] = SAVE_DIR\n",
    "config['weight_decay'] = 1e-4\n",
    "lr_initial = 0.01\n",
    "config['lr_policy'] = {e:{'lr':(0.9**e)*lr_initial} for e in range(1, config['max_epochs']+1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Korisnik\\Desktop\\cifar-10-batches-py\\data_batch_1\n",
      "C:\\Users\\Korisnik\\Desktop\\cifar-10-batches-py\\data_batch_2\n",
      "C:\\Users\\Korisnik\\Desktop\\cifar-10-batches-py\\data_batch_3\n",
      "C:\\Users\\Korisnik\\Desktop\\cifar-10-batches-py\\data_batch_4\n",
      "C:\\Users\\Korisnik\\Desktop\\cifar-10-batches-py\\data_batch_5\n",
      "C:\\Users\\Korisnik\\Desktop\\cifar-10-batches-py\\test_batch\n",
      "(45000, 32, 32, 3)\n",
      "C:\\Users\\Korisnik\\Desktop\\cifar-10-batches-py\\batches.meta\n",
      "['airplane' 'automobile' 'bird' 'cat' 'deer' 'dog' 'frog' 'horse' 'ship'\n",
      " 'truck']\n"
     ]
    }
   ],
   "source": [
    "img_height, img_width, num_channels = 32, 32, 3\n",
    "train_x = np.ndarray((0, img_height * img_width * num_channels), dtype=np.float32)\n",
    "train_y = []\n",
    "for i in range(1, 6):\n",
    "    subset = unpickle(os.path.join(DATA_DIR, 'data_batch_%d' % i))\n",
    "    train_x = np.vstack((train_x, subset['data']))\n",
    "    train_y += subset['labels']\n",
    "    \n",
    "train_x = train_x.reshape((-1, num_channels, img_height, img_width)).transpose(0,2,3,1)\n",
    "train_y = np.array(train_y, dtype=np.int32)\n",
    "\n",
    "subset = unpickle(os.path.join(DATA_DIR, 'test_batch'))\n",
    "test_x = subset['data'].reshape((-1, num_channels, img_height, img_width)).transpose(0,2,3,1).astype(np.float32)\n",
    "test_y = np.array(subset['labels'], dtype=np.int32)\n",
    "\n",
    "valid_size = 5000\n",
    "train_x, train_y = shuffle_data(train_x, train_y)\n",
    "valid_x = train_x[:valid_size, ...]\n",
    "valid_y = train_y[:valid_size, ...]\n",
    "train_x = train_x[valid_size:, ...]\n",
    "train_y = train_y[valid_size:, ...]\n",
    "data_mean = train_x.mean((0,1,2))\n",
    "data_std = train_x.std((0,1,2))\n",
    "\n",
    "train_x = (train_x - data_mean) / data_std\n",
    "valid_x = (valid_x - data_mean) / data_std\n",
    "test_x = (test_x - data_mean) / data_std\n",
    "print(train_x.shape)\n",
    "\n",
    "weight_decay = config['weight_decay']\n",
    "n_classes = 10\n",
    "\n",
    "class_names = get_label_names(os.path.join(DATA_DIR, 'batches.meta'))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l2_loss(weights):\n",
    "    regularizers = 0;\n",
    "    for w in weights:\n",
    "        regularizers += tf.nn.l2_loss(w)\n",
    "    return regularizers\n",
    "        \n",
    "\n",
    "def conv2d(x, W, b, activation=tf.nn.relu, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return activation(x)\n",
    "\n",
    "def maxpool2d(x, k=2, stride=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "def fc(x, W, b, activation=None):\n",
    "    x = tf.reshape(x, [-1, W.get_shape().as_list()[0]])\n",
    "    if activation :\n",
    "        return activation(tf.matmul(x, W) +  b)    \n",
    "    return tf.matmul(x, W) +  b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import xavier_initializer_conv2d as xavier_conv2d\n",
    "from tensorflow.contrib.layers import xavier_initializer as xavier\n",
    "tf.reset_default_graph()\n",
    "\n",
    "weights = {\n",
    "    'conv1': tf.get_variable('w_conv1', [5, 5, 3, 16], initializer=xavier_conv2d()),\n",
    "    'conv2': tf.get_variable('w_conv2', [5, 5, 16, 32], initializer=xavier_conv2d()),\n",
    "    \n",
    "    'fc3': tf.get_variable('w_fc3', [8*8*32, 256], initializer=xavier()),\n",
    "    'fc4': tf.get_variable('w_fc4', [256, 128], initializer=xavier()),\n",
    "    'fc5': tf.get_variable('w_fc5', [128, n_classes], initializer=xavier())\n",
    "    \n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'conv1': tf.Variable(tf.zeros([16]), name='b_conv1'),\n",
    "    'conv2': tf.Variable(tf.zeros([32]), name='b_conv2'),\n",
    "    \n",
    "    'fc3': tf.Variable(tf.zeros([256]), name='b_fc3'),\n",
    "    'fc4': tf.Variable(tf.zeros([128]), name='b_fc4'),\n",
    "    'fc5': tf.Variable(tf.zeros([n_classes]), name='b_fc5')\n",
    "}\n",
    "\n",
    "#conv(16,5) -> pool(3,2) -> conv(32,5) -> pool(3,2) -> fc(256) -> fc(128) -> fc(10)\n",
    "def convnet(x, weights, biases):\n",
    "    x = tf.reshape(x, shape=[-1, img_height, img_width, num_channels])\n",
    "    net = conv2d(x, weights['conv1'], biases['conv1'], tf.nn.relu)\n",
    "    net = maxpool2d(net, k=3, stride=2)\n",
    "    \n",
    "    net = conv2d(net, weights['conv2'], biases['conv2'], tf.nn.relu)\n",
    "    net = maxpool2d(net, k=3, stride=2)\n",
    "    \n",
    "    net = fc(net, weights['fc3'],  biases['fc3'], tf.nn.relu)\n",
    "    net = fc(net, weights['fc4'],  biases['fc4'], tf.nn.relu)\n",
    "    net = fc(net, weights['fc5'],  biases['fc5'])\n",
    "    return net\n",
    "\n",
    "\n",
    "# Graph\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "Y_ = tf.placeholder(tf.int32, [None,])\n",
    "logits = convnet(X, weights, biases)\n",
    "\n",
    "# loss\n",
    "regularizers = l2_loss(weights.values())\n",
    "loss_per_sample = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y_)\n",
    "data_loss = tf.reduce_mean(loss_per_sample)\n",
    "loss = data_loss + weight_decay*regularizers\n",
    "\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(0.01, global_step, 900, 0.9, staircase=True)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_cifar(session, train_x, train_y, valid_x, valid_y, config, plot_data={}):\n",
    "    plot_data['train_loss'] = []\n",
    "    plot_data['valid_loss'] = []\n",
    "    plot_data['train_acc'] = []\n",
    "    plot_data['valid_acc'] = []\n",
    "    plot_data['lr'] = []\n",
    "    \n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    batch_size = config['batch_size']\n",
    "    max_epochs = config['max_epochs']\n",
    "    save_dir = config['save_dir']\n",
    "    num_examples = train_x.shape[0]\n",
    "    assert num_examples % batch_size == 0\n",
    "    num_batches = num_examples // batch_size\n",
    "    \n",
    "    for epoch_num in range(1, max_epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "        train_x, train_y = shuffle_data(train_x, train_y)\n",
    "    \n",
    "        for step in range(num_batches):\n",
    "            offset = step * batch_size \n",
    "\n",
    "            batch_x = train_x[offset:(offset + batch_size), ...]\n",
    "            batch_y = train_y[offset:(offset + batch_size), ...]\n",
    "\n",
    "            feed_dict = {X: batch_x, Y_: batch_y}\n",
    "            start_time = time.time()\n",
    "            ret_val = session.run([train_step, loss, logits], feed_dict=feed_dict)\n",
    "            _, loss_val, logits_val = ret_val\n",
    "            duration = time.time() - start_time\n",
    "\n",
    "            if (step+1) % 50 == 0:\n",
    "                sec_per_batch = float(duration)\n",
    "                format_str = 'epoch %d, step %d / %d, loss = %.2f (%.3f sec/batch)'\n",
    "                print(format_str % (epoch_num, step+1, num_batches, loss_val, sec_per_batch))\n",
    "\n",
    "            if (step+1) % 100 == 0:\n",
    "                w = session.run(weights['conv1'])\n",
    "                draw_conv_filters(epoch_num, step+1, w, save_dir)\n",
    "\n",
    "        print('Train error:')\n",
    "        train_loss, train_acc = evaluate_cifar(session, train_x, train_y, config)\n",
    "        print('Validation error:')\n",
    "        valid_loss, valid_acc = evaluate_cifar(session, valid_x, valid_y, config)\n",
    "        print('Epoch time:', time.time() - epoch_start)\n",
    "        plot_data['train_loss'] += [train_loss]\n",
    "        plot_data['valid_loss'] += [valid_loss]\n",
    "        plot_data['train_acc'] += [train_acc]\n",
    "        plot_data['valid_acc'] += [valid_acc]\n",
    "        plot_data['lr'] += [session.run(learning_rate)]\n",
    "        plot_training_progress(plot_data, SAVE_DIR)\n",
    "        \n",
    "    return plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_cifar(session, x, y, config):\n",
    "    batch_size = config['batch_size']\n",
    "    num_examples = x.shape[0]\n",
    "    assert num_examples % batch_size == 0\n",
    "    num_batches = num_examples // batch_size\n",
    "    cnt_correct = 0\n",
    "    loss_avg = 0\n",
    "\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        batch_x = x[i*batch_size:(i+1)*batch_size, ...]\n",
    "        batch_y = y[i*batch_size:(i+1)*batch_size, ...]\n",
    "\n",
    "        data_dict = {X: batch_x, Y_: batch_y}\n",
    "        logits_val, loss_val = session.run([logits, loss] ,feed_dict=data_dict)\n",
    "\n",
    "        yp = np.argmax(logits_val, 1)\n",
    "        yt = batch_y\n",
    "        cnt_correct += (yp == yt).sum()\n",
    "\n",
    "        loss_avg += loss_val\n",
    "        \n",
    "    valid_acc = cnt_correct / num_examples * 100\n",
    "    loss_avg /= num_batches\n",
    "    \n",
    "    print(\" accuracy = %.2f\" % valid_acc)\n",
    "    print(\" avg loss = %.2f\\n\" % loss_avg)\n",
    "    return loss_avg, valid_acc\n",
    "\n",
    "def worst_samples(session, x, y, config):\n",
    "    batch_size = config['batch_size']\n",
    "    num_examples = x.shape[0]\n",
    "    num_batches = num_examples // batch_size\n",
    "\n",
    "    worst_samples = []\n",
    "    for i in range(num_batches):\n",
    "        batch_x = x[i*batch_size:(i+1)*batch_size, ...]\n",
    "        batch_y = y[i*batch_size:(i+1)*batch_size, ...]\n",
    "\n",
    "        data_dict = {X: batch_x, Y_: batch_y}\n",
    "        loss_vals, logits_val = session.run([loss_per_sample, logits] ,feed_dict=data_dict)\n",
    "        prediction = np.argmax(logits_val, 1)\n",
    "        loss_pairs = [(i*batch_size+id, loss, p) for id, (loss, p) in enumerate(zip(loss_vals, prediction))]\n",
    "        worst_samples = sorted(loss_pairs + worst_samples, key=lambda x: -x[1])[:20]\n",
    "    return worst_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_conv_filters(epoch, step, weights, save_dir):\n",
    "    w = weights.copy()\n",
    "    num_filters = w.shape[3]\n",
    "    num_channels = w.shape[2]\n",
    "    k = w.shape[0]\n",
    "    assert w.shape[0] == w.shape[1]\n",
    "    w = w.reshape(k, k, num_channels, num_filters)\n",
    "    w -= w.min()\n",
    "    w /= w.max()\n",
    "    border = 1\n",
    "    cols = 8\n",
    "    rows = math.ceil(num_filters / cols)\n",
    "    width = cols * k + (cols-1) * border\n",
    "    height = rows * k + (rows-1) * border\n",
    "    img = np.zeros([height, width, num_channels])\n",
    "    for i in range(num_filters):\n",
    "        r = int(i / cols) * (k + border)\n",
    "        c = int(i % cols) * (k + border)\n",
    "        img[r:r+k,c:c+k,:] = w[:,:,:,i]\n",
    "    filename = 'epoch_%02d_step_%06d.png' % (epoch, step)\n",
    "    ski.io.imsave(os.path.join(save_dir, filename), img)\n",
    "\n",
    "def plot_training_progress(data, save_dir=None):\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16,8))\n",
    "    linewidth = 2\n",
    "    legend_size = 10\n",
    "    train_color = 'm'\n",
    "    val_color = 'c'\n",
    "\n",
    "    num_points = len(data['train_loss'])\n",
    "    x_data = np.linspace(1, num_points, num_points)\n",
    "    ax1.set_title('Cross-entropy loss')\n",
    "    ax1.plot(x_data, data['train_loss'], marker='o', color=train_color,\n",
    "           linewidth=linewidth, linestyle='-', label='train')\n",
    "    ax1.plot(x_data, data['valid_loss'], marker='o', color=val_color,\n",
    "           linewidth=linewidth, linestyle='-', label='validation')\n",
    "    ax1.legend(loc='upper right', fontsize=legend_size)\n",
    "    ax2.set_title('Average class accuracy')\n",
    "    ax2.plot(x_data, data['train_acc'], marker='o', color=train_color,\n",
    "           linewidth=linewidth, linestyle='-', label='train')\n",
    "    ax2.plot(x_data, data['valid_acc'], marker='o', color=val_color,\n",
    "           linewidth=linewidth, linestyle='-', label='validation')\n",
    "    ax2.legend(loc='upper left', fontsize=legend_size)\n",
    "    ax3.set_title('Learning rate')\n",
    "    ax3.plot(x_data, data['lr'], marker='o', color=train_color,\n",
    "           linewidth=linewidth, linestyle='-', label='learning_rate')\n",
    "    ax3.legend(loc='upper left', fontsize=legend_size)\n",
    "    if save_dir is not None:\n",
    "        save_path = os.path.join(save_dir, 'training_plot.pdf')\n",
    "        print('Plotting in: ', save_path)\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 50 / 900, loss = 2.29 (0.007 sec/batch)\n",
      "epoch 1, step 100 / 900, loss = 2.04 (0.007 sec/batch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Korisnik\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 150 / 900, loss = 1.85 (0.006 sec/batch)\n",
      "epoch 1, step 200 / 900, loss = 1.93 (0.006 sec/batch)\n",
      "epoch 1, step 250 / 900, loss = 1.86 (0.007 sec/batch)\n",
      "epoch 1, step 300 / 900, loss = 1.71 (0.006 sec/batch)\n",
      "epoch 1, step 350 / 900, loss = 1.58 (0.005 sec/batch)\n",
      "epoch 1, step 400 / 900, loss = 1.53 (0.006 sec/batch)\n",
      "epoch 1, step 450 / 900, loss = 1.50 (0.006 sec/batch)\n",
      "epoch 1, step 500 / 900, loss = 1.44 (0.006 sec/batch)\n",
      "epoch 1, step 550 / 900, loss = 1.59 (0.006 sec/batch)\n",
      "epoch 1, step 600 / 900, loss = 1.71 (0.006 sec/batch)\n",
      "epoch 1, step 650 / 900, loss = 1.73 (0.006 sec/batch)\n",
      "epoch 1, step 700 / 900, loss = 1.40 (0.006 sec/batch)\n",
      "epoch 1, step 750 / 900, loss = 1.36 (0.006 sec/batch)\n",
      "epoch 1, step 800 / 900, loss = 1.52 (0.006 sec/batch)\n",
      "epoch 1, step 850 / 900, loss = 1.40 (0.006 sec/batch)\n",
      "epoch 1, step 900 / 900, loss = 1.54 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 51.10\n",
      " avg loss = 1.41\n",
      "\n",
      "Validation error:\n",
      " accuracy = 50.82\n",
      " avg loss = 1.42\n",
      "\n",
      "Epoch time: 8.228540658950806\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 2, step 50 / 900, loss = 1.55 (0.007 sec/batch)\n",
      "epoch 2, step 100 / 900, loss = 1.39 (0.006 sec/batch)\n",
      "epoch 2, step 150 / 900, loss = 1.30 (0.006 sec/batch)\n",
      "epoch 2, step 200 / 900, loss = 1.24 (0.006 sec/batch)\n",
      "epoch 2, step 250 / 900, loss = 1.42 (0.006 sec/batch)\n",
      "epoch 2, step 300 / 900, loss = 1.15 (0.006 sec/batch)\n",
      "epoch 2, step 350 / 900, loss = 1.63 (0.007 sec/batch)\n",
      "epoch 2, step 400 / 900, loss = 1.37 (0.006 sec/batch)\n",
      "epoch 2, step 450 / 900, loss = 1.51 (0.009 sec/batch)\n",
      "epoch 2, step 500 / 900, loss = 1.58 (0.008 sec/batch)\n",
      "epoch 2, step 550 / 900, loss = 1.33 (0.006 sec/batch)\n",
      "epoch 2, step 600 / 900, loss = 1.21 (0.006 sec/batch)\n",
      "epoch 2, step 650 / 900, loss = 1.12 (0.007 sec/batch)\n",
      "epoch 2, step 700 / 900, loss = 1.52 (0.006 sec/batch)\n",
      "epoch 2, step 750 / 900, loss = 1.17 (0.006 sec/batch)\n",
      "epoch 2, step 800 / 900, loss = 1.30 (0.007 sec/batch)\n",
      "epoch 2, step 850 / 900, loss = 1.14 (0.006 sec/batch)\n",
      "epoch 2, step 900 / 900, loss = 1.25 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 59.89\n",
      " avg loss = 1.17\n",
      "\n",
      "Validation error:\n",
      " accuracy = 58.14\n",
      " avg loss = 1.21\n",
      "\n",
      "Epoch time: 8.320021390914917\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 3, step 50 / 900, loss = 1.26 (0.006 sec/batch)\n",
      "epoch 3, step 100 / 900, loss = 1.34 (0.006 sec/batch)\n",
      "epoch 3, step 150 / 900, loss = 1.18 (0.006 sec/batch)\n",
      "epoch 3, step 200 / 900, loss = 1.23 (0.006 sec/batch)\n",
      "epoch 3, step 250 / 900, loss = 1.18 (0.008 sec/batch)\n",
      "epoch 3, step 300 / 900, loss = 1.02 (0.007 sec/batch)\n",
      "epoch 3, step 350 / 900, loss = 1.23 (0.007 sec/batch)\n",
      "epoch 3, step 400 / 900, loss = 1.10 (0.006 sec/batch)\n",
      "epoch 3, step 450 / 900, loss = 1.13 (0.006 sec/batch)\n",
      "epoch 3, step 500 / 900, loss = 1.14 (0.006 sec/batch)\n",
      "epoch 3, step 550 / 900, loss = 1.14 (0.006 sec/batch)\n",
      "epoch 3, step 600 / 900, loss = 1.04 (0.007 sec/batch)\n",
      "epoch 3, step 650 / 900, loss = 1.18 (0.007 sec/batch)\n",
      "epoch 3, step 700 / 900, loss = 0.94 (0.007 sec/batch)\n",
      "epoch 3, step 750 / 900, loss = 1.33 (0.007 sec/batch)\n",
      "epoch 3, step 800 / 900, loss = 1.13 (0.006 sec/batch)\n",
      "epoch 3, step 850 / 900, loss = 0.93 (0.008 sec/batch)\n",
      "epoch 3, step 900 / 900, loss = 0.96 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 64.85\n",
      " avg loss = 1.05\n",
      "\n",
      "Validation error:\n",
      " accuracy = 62.50\n",
      " avg loss = 1.10\n",
      "\n",
      "Epoch time: 8.412391185760498\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 4, step 50 / 900, loss = 1.19 (0.006 sec/batch)\n",
      "epoch 4, step 100 / 900, loss = 0.91 (0.006 sec/batch)\n",
      "epoch 4, step 150 / 900, loss = 1.03 (0.006 sec/batch)\n",
      "epoch 4, step 200 / 900, loss = 1.13 (0.006 sec/batch)\n",
      "epoch 4, step 250 / 900, loss = 1.12 (0.006 sec/batch)\n",
      "epoch 4, step 300 / 900, loss = 1.14 (0.006 sec/batch)\n",
      "epoch 4, step 350 / 900, loss = 0.86 (0.006 sec/batch)\n",
      "epoch 4, step 400 / 900, loss = 1.04 (0.006 sec/batch)\n",
      "epoch 4, step 450 / 900, loss = 1.24 (0.006 sec/batch)\n",
      "epoch 4, step 500 / 900, loss = 0.84 (0.008 sec/batch)\n",
      "epoch 4, step 550 / 900, loss = 1.01 (0.008 sec/batch)\n",
      "epoch 4, step 600 / 900, loss = 0.92 (0.007 sec/batch)\n",
      "epoch 4, step 650 / 900, loss = 1.05 (0.007 sec/batch)\n",
      "epoch 4, step 700 / 900, loss = 1.01 (0.007 sec/batch)\n",
      "epoch 4, step 750 / 900, loss = 1.05 (0.006 sec/batch)\n",
      "epoch 4, step 800 / 900, loss = 0.96 (0.006 sec/batch)\n",
      "epoch 4, step 850 / 900, loss = 0.84 (0.006 sec/batch)\n",
      "epoch 4, step 900 / 900, loss = 0.79 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 67.13\n",
      " avg loss = 0.98\n",
      "\n",
      "Validation error:\n",
      " accuracy = 63.78\n",
      " avg loss = 1.07\n",
      "\n",
      "Epoch time: 8.25957202911377\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 5, step 50 / 900, loss = 0.85 (0.008 sec/batch)\n",
      "epoch 5, step 100 / 900, loss = 0.91 (0.007 sec/batch)\n",
      "epoch 5, step 150 / 900, loss = 0.79 (0.007 sec/batch)\n",
      "epoch 5, step 200 / 900, loss = 1.33 (0.006 sec/batch)\n",
      "epoch 5, step 250 / 900, loss = 1.14 (0.007 sec/batch)\n",
      "epoch 5, step 300 / 900, loss = 0.88 (0.006 sec/batch)\n",
      "epoch 5, step 350 / 900, loss = 0.92 (0.007 sec/batch)\n",
      "epoch 5, step 400 / 900, loss = 0.89 (0.007 sec/batch)\n",
      "epoch 5, step 450 / 900, loss = 1.21 (0.006 sec/batch)\n",
      "epoch 5, step 500 / 900, loss = 0.98 (0.006 sec/batch)\n",
      "epoch 5, step 550 / 900, loss = 0.96 (0.006 sec/batch)\n",
      "epoch 5, step 600 / 900, loss = 0.86 (0.007 sec/batch)\n",
      "epoch 5, step 650 / 900, loss = 0.78 (0.006 sec/batch)\n",
      "epoch 5, step 700 / 900, loss = 0.94 (0.006 sec/batch)\n",
      "epoch 5, step 750 / 900, loss = 1.01 (0.005 sec/batch)\n",
      "epoch 5, step 800 / 900, loss = 1.06 (0.008 sec/batch)\n",
      "epoch 5, step 850 / 900, loss = 1.08 (0.007 sec/batch)\n",
      "epoch 5, step 900 / 900, loss = 1.43 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 69.66\n",
      " avg loss = 0.92\n",
      "\n",
      "Validation error:\n",
      " accuracy = 65.88\n",
      " avg loss = 1.02\n",
      "\n",
      "Epoch time: 8.383856058120728\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 6, step 50 / 900, loss = 0.68 (0.006 sec/batch)\n",
      "epoch 6, step 100 / 900, loss = 0.62 (0.006 sec/batch)\n",
      "epoch 6, step 150 / 900, loss = 0.89 (0.006 sec/batch)\n",
      "epoch 6, step 200 / 900, loss = 0.78 (0.007 sec/batch)\n",
      "epoch 6, step 250 / 900, loss = 0.86 (0.006 sec/batch)\n",
      "epoch 6, step 300 / 900, loss = 1.00 (0.006 sec/batch)\n",
      "epoch 6, step 350 / 900, loss = 1.01 (0.006 sec/batch)\n",
      "epoch 6, step 400 / 900, loss = 1.44 (0.007 sec/batch)\n",
      "epoch 6, step 450 / 900, loss = 0.80 (0.006 sec/batch)\n",
      "epoch 6, step 500 / 900, loss = 0.67 (0.007 sec/batch)\n",
      "epoch 6, step 550 / 900, loss = 0.85 (0.006 sec/batch)\n",
      "epoch 6, step 600 / 900, loss = 0.86 (0.006 sec/batch)\n",
      "epoch 6, step 650 / 900, loss = 0.80 (0.008 sec/batch)\n",
      "epoch 6, step 700 / 900, loss = 1.00 (0.006 sec/batch)\n",
      "epoch 6, step 750 / 900, loss = 0.73 (0.006 sec/batch)\n",
      "epoch 6, step 800 / 900, loss = 0.83 (0.006 sec/batch)\n",
      "epoch 6, step 850 / 900, loss = 0.80 (0.006 sec/batch)\n",
      "epoch 6, step 900 / 900, loss = 1.02 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 71.29\n",
      " avg loss = 0.86\n",
      "\n",
      "Validation error:\n",
      " accuracy = 66.96\n",
      " avg loss = 0.99\n",
      "\n",
      "Epoch time: 8.52667498588562\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 7, step 50 / 900, loss = 1.02 (0.006 sec/batch)\n",
      "epoch 7, step 100 / 900, loss = 0.64 (0.008 sec/batch)\n",
      "epoch 7, step 150 / 900, loss = 0.88 (0.007 sec/batch)\n",
      "epoch 7, step 200 / 900, loss = 1.03 (0.007 sec/batch)\n",
      "epoch 7, step 250 / 900, loss = 0.90 (0.008 sec/batch)\n",
      "epoch 7, step 300 / 900, loss = 0.78 (0.007 sec/batch)\n",
      "epoch 7, step 350 / 900, loss = 0.91 (0.007 sec/batch)\n",
      "epoch 7, step 400 / 900, loss = 0.79 (0.006 sec/batch)\n",
      "epoch 7, step 450 / 900, loss = 1.08 (0.007 sec/batch)\n",
      "epoch 7, step 500 / 900, loss = 0.72 (0.007 sec/batch)\n",
      "epoch 7, step 550 / 900, loss = 0.97 (0.006 sec/batch)\n",
      "epoch 7, step 600 / 900, loss = 0.90 (0.008 sec/batch)\n",
      "epoch 7, step 650 / 900, loss = 0.77 (0.007 sec/batch)\n",
      "epoch 7, step 700 / 900, loss = 0.83 (0.007 sec/batch)\n",
      "epoch 7, step 750 / 900, loss = 0.76 (0.006 sec/batch)\n",
      "epoch 7, step 800 / 900, loss = 0.75 (0.007 sec/batch)\n",
      "epoch 7, step 850 / 900, loss = 1.20 (0.006 sec/batch)\n",
      "epoch 7, step 900 / 900, loss = 1.04 (0.006 sec/batch)\n",
      "Train error:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy = 74.15\n",
      " avg loss = 0.79\n",
      "\n",
      "Validation error:\n",
      " accuracy = 67.98\n",
      " avg loss = 0.95\n",
      "\n",
      "Epoch time: 8.60514211654663\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 8, step 50 / 900, loss = 0.81 (0.006 sec/batch)\n",
      "epoch 8, step 100 / 900, loss = 0.97 (0.008 sec/batch)\n",
      "epoch 8, step 150 / 900, loss = 0.86 (0.007 sec/batch)\n",
      "epoch 8, step 200 / 900, loss = 1.08 (0.007 sec/batch)\n",
      "epoch 8, step 250 / 900, loss = 0.85 (0.006 sec/batch)\n",
      "epoch 8, step 300 / 900, loss = 0.90 (0.006 sec/batch)\n",
      "epoch 8, step 350 / 900, loss = 0.95 (0.006 sec/batch)\n",
      "epoch 8, step 400 / 900, loss = 0.70 (0.006 sec/batch)\n",
      "epoch 8, step 450 / 900, loss = 0.80 (0.008 sec/batch)\n",
      "epoch 8, step 500 / 900, loss = 0.89 (0.006 sec/batch)\n",
      "epoch 8, step 550 / 900, loss = 0.73 (0.009 sec/batch)\n",
      "epoch 8, step 600 / 900, loss = 0.82 (0.008 sec/batch)\n",
      "epoch 8, step 650 / 900, loss = 0.75 (0.008 sec/batch)\n",
      "epoch 8, step 700 / 900, loss = 0.61 (0.008 sec/batch)\n",
      "epoch 8, step 750 / 900, loss = 0.63 (0.006 sec/batch)\n",
      "epoch 8, step 800 / 900, loss = 0.80 (0.006 sec/batch)\n",
      "epoch 8, step 850 / 900, loss = 0.94 (0.005 sec/batch)\n",
      "epoch 8, step 900 / 900, loss = 0.75 (0.009 sec/batch)\n",
      "Train error:\n",
      " accuracy = 75.06\n",
      " avg loss = 0.77\n",
      "\n",
      "Validation error:\n",
      " accuracy = 69.02\n",
      " avg loss = 0.94\n",
      "\n",
      "Epoch time: 8.354280948638916\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 9, step 50 / 900, loss = 0.59 (0.007 sec/batch)\n",
      "epoch 9, step 100 / 900, loss = 0.84 (0.006 sec/batch)\n",
      "epoch 9, step 150 / 900, loss = 0.65 (0.006 sec/batch)\n",
      "epoch 9, step 200 / 900, loss = 0.56 (0.006 sec/batch)\n",
      "epoch 9, step 250 / 900, loss = 0.95 (0.006 sec/batch)\n",
      "epoch 9, step 300 / 900, loss = 0.70 (0.006 sec/batch)\n",
      "epoch 9, step 350 / 900, loss = 0.73 (0.006 sec/batch)\n",
      "epoch 9, step 400 / 900, loss = 0.74 (0.006 sec/batch)\n",
      "epoch 9, step 450 / 900, loss = 0.57 (0.006 sec/batch)\n",
      "epoch 9, step 500 / 900, loss = 1.00 (0.006 sec/batch)\n",
      "epoch 9, step 550 / 900, loss = 0.86 (0.006 sec/batch)\n",
      "epoch 9, step 600 / 900, loss = 0.77 (0.006 sec/batch)\n",
      "epoch 9, step 650 / 900, loss = 0.86 (0.006 sec/batch)\n",
      "epoch 9, step 700 / 900, loss = 1.05 (0.007 sec/batch)\n",
      "epoch 9, step 750 / 900, loss = 0.67 (0.006 sec/batch)\n",
      "epoch 9, step 800 / 900, loss = 0.75 (0.006 sec/batch)\n",
      "epoch 9, step 850 / 900, loss = 0.97 (0.007 sec/batch)\n",
      "epoch 9, step 900 / 900, loss = 0.79 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 73.38\n",
      " avg loss = 0.81\n",
      "\n",
      "Validation error:\n",
      " accuracy = 67.16\n",
      " avg loss = 1.00\n",
      "\n",
      "Epoch time: 8.273066997528076\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 10, step 50 / 900, loss = 0.88 (0.008 sec/batch)\n",
      "epoch 10, step 100 / 900, loss = 0.67 (0.008 sec/batch)\n",
      "epoch 10, step 150 / 900, loss = 0.56 (0.008 sec/batch)\n",
      "epoch 10, step 200 / 900, loss = 0.84 (0.006 sec/batch)\n",
      "epoch 10, step 250 / 900, loss = 0.76 (0.006 sec/batch)\n",
      "epoch 10, step 300 / 900, loss = 0.65 (0.006 sec/batch)\n",
      "epoch 10, step 350 / 900, loss = 0.84 (0.006 sec/batch)\n",
      "epoch 10, step 400 / 900, loss = 0.94 (0.006 sec/batch)\n",
      "epoch 10, step 450 / 900, loss = 0.80 (0.006 sec/batch)\n",
      "epoch 10, step 500 / 900, loss = 0.61 (0.007 sec/batch)\n",
      "epoch 10, step 550 / 900, loss = 0.83 (0.007 sec/batch)\n",
      "epoch 10, step 600 / 900, loss = 0.76 (0.007 sec/batch)\n",
      "epoch 10, step 650 / 900, loss = 1.05 (0.006 sec/batch)\n",
      "epoch 10, step 700 / 900, loss = 0.70 (0.006 sec/batch)\n",
      "epoch 10, step 750 / 900, loss = 0.70 (0.006 sec/batch)\n",
      "epoch 10, step 800 / 900, loss = 0.76 (0.006 sec/batch)\n",
      "epoch 10, step 850 / 900, loss = 0.71 (0.007 sec/batch)\n",
      "epoch 10, step 900 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 77.14\n",
      " avg loss = 0.70\n",
      "\n",
      "Validation error:\n",
      " accuracy = 69.98\n",
      " avg loss = 0.91\n",
      "\n",
      "Epoch time: 8.264557123184204\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 11, step 50 / 900, loss = 0.76 (0.007 sec/batch)\n",
      "epoch 11, step 100 / 900, loss = 0.54 (0.008 sec/batch)\n",
      "epoch 11, step 150 / 900, loss = 0.58 (0.008 sec/batch)\n",
      "epoch 11, step 200 / 900, loss = 0.86 (0.006 sec/batch)\n",
      "epoch 11, step 250 / 900, loss = 0.75 (0.006 sec/batch)\n",
      "epoch 11, step 300 / 900, loss = 0.71 (0.006 sec/batch)\n",
      "epoch 11, step 350 / 900, loss = 0.67 (0.006 sec/batch)\n",
      "epoch 11, step 400 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "epoch 11, step 450 / 900, loss = 0.49 (0.006 sec/batch)\n",
      "epoch 11, step 500 / 900, loss = 0.82 (0.005 sec/batch)\n",
      "epoch 11, step 550 / 900, loss = 0.47 (0.006 sec/batch)\n",
      "epoch 11, step 600 / 900, loss = 0.62 (0.006 sec/batch)\n",
      "epoch 11, step 650 / 900, loss = 0.92 (0.005 sec/batch)\n",
      "epoch 11, step 700 / 900, loss = 0.97 (0.006 sec/batch)\n",
      "epoch 11, step 750 / 900, loss = 0.89 (0.009 sec/batch)\n",
      "epoch 11, step 800 / 900, loss = 0.69 (0.006 sec/batch)\n",
      "epoch 11, step 850 / 900, loss = 0.75 (0.006 sec/batch)\n",
      "epoch 11, step 900 / 900, loss = 0.69 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 78.90\n",
      " avg loss = 0.66\n",
      "\n",
      "Validation error:\n",
      " accuracy = 70.46\n",
      " avg loss = 0.90\n",
      "\n",
      "Epoch time: 8.259509086608887\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 12, step 50 / 900, loss = 0.84 (0.008 sec/batch)\n",
      "epoch 12, step 100 / 900, loss = 0.78 (0.006 sec/batch)\n",
      "epoch 12, step 150 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 12, step 200 / 900, loss = 0.63 (0.008 sec/batch)\n",
      "epoch 12, step 250 / 900, loss = 0.69 (0.007 sec/batch)\n",
      "epoch 12, step 300 / 900, loss = 0.70 (0.006 sec/batch)\n",
      "epoch 12, step 350 / 900, loss = 0.75 (0.007 sec/batch)\n",
      "epoch 12, step 400 / 900, loss = 0.57 (0.006 sec/batch)\n",
      "epoch 12, step 450 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 12, step 500 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 12, step 550 / 900, loss = 0.92 (0.006 sec/batch)\n",
      "epoch 12, step 600 / 900, loss = 0.86 (0.006 sec/batch)\n",
      "epoch 12, step 650 / 900, loss = 0.86 (0.006 sec/batch)\n",
      "epoch 12, step 700 / 900, loss = 0.66 (0.006 sec/batch)\n",
      "epoch 12, step 750 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "epoch 12, step 800 / 900, loss = 0.67 (0.006 sec/batch)\n",
      "epoch 12, step 850 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 12, step 900 / 900, loss = 0.55 (0.005 sec/batch)\n",
      "Train error:\n",
      " accuracy = 79.12\n",
      " avg loss = 0.65\n",
      "\n",
      "Validation error:\n",
      " accuracy = 70.92\n",
      " avg loss = 0.90\n",
      "\n",
      "Epoch time: 8.259331464767456\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 13, step 50 / 900, loss = 0.48 (0.006 sec/batch)\n",
      "epoch 13, step 100 / 900, loss = 0.64 (0.006 sec/batch)\n",
      "epoch 13, step 150 / 900, loss = 0.56 (0.006 sec/batch)\n",
      "epoch 13, step 200 / 900, loss = 0.59 (0.006 sec/batch)\n",
      "epoch 13, step 250 / 900, loss = 0.70 (0.006 sec/batch)\n",
      "epoch 13, step 300 / 900, loss = 0.78 (0.007 sec/batch)\n",
      "epoch 13, step 350 / 900, loss = 0.73 (0.006 sec/batch)\n",
      "epoch 13, step 400 / 900, loss = 0.58 (0.007 sec/batch)\n",
      "epoch 13, step 450 / 900, loss = 0.63 (0.006 sec/batch)\n",
      "epoch 13, step 500 / 900, loss = 0.67 (0.006 sec/batch)\n",
      "epoch 13, step 550 / 900, loss = 0.79 (0.007 sec/batch)\n",
      "epoch 13, step 600 / 900, loss = 0.66 (0.006 sec/batch)\n",
      "epoch 13, step 650 / 900, loss = 0.73 (0.006 sec/batch)\n",
      "epoch 13, step 700 / 900, loss = 0.54 (0.006 sec/batch)\n",
      "epoch 13, step 750 / 900, loss = 0.70 (0.006 sec/batch)\n",
      "epoch 13, step 800 / 900, loss = 0.69 (0.006 sec/batch)\n",
      "epoch 13, step 850 / 900, loss = 0.57 (0.006 sec/batch)\n",
      "epoch 13, step 900 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 80.23\n",
      " avg loss = 0.62\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.32\n",
      " avg loss = 0.88\n",
      "\n",
      "Epoch time: 8.246513843536377\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 14, step 50 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 14, step 100 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 14, step 150 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 14, step 200 / 900, loss = 0.67 (0.006 sec/batch)\n",
      "epoch 14, step 250 / 900, loss = 0.76 (0.006 sec/batch)\n",
      "epoch 14, step 300 / 900, loss = 0.66 (0.006 sec/batch)\n",
      "epoch 14, step 350 / 900, loss = 0.58 (0.007 sec/batch)\n",
      "epoch 14, step 400 / 900, loss = 0.62 (0.007 sec/batch)\n",
      "epoch 14, step 450 / 900, loss = 0.63 (0.007 sec/batch)\n",
      "epoch 14, step 500 / 900, loss = 0.57 (0.006 sec/batch)\n",
      "epoch 14, step 550 / 900, loss = 0.54 (0.006 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, step 600 / 900, loss = 0.69 (0.006 sec/batch)\n",
      "epoch 14, step 650 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 14, step 700 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 14, step 750 / 900, loss = 0.43 (0.006 sec/batch)\n",
      "epoch 14, step 800 / 900, loss = 0.56 (0.006 sec/batch)\n",
      "epoch 14, step 850 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "epoch 14, step 900 / 900, loss = 0.64 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 80.85\n",
      " avg loss = 0.60\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.12\n",
      " avg loss = 0.89\n",
      "\n",
      "Epoch time: 8.260732412338257\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 15, step 50 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 15, step 100 / 900, loss = 0.82 (0.006 sec/batch)\n",
      "epoch 15, step 150 / 900, loss = 0.67 (0.006 sec/batch)\n",
      "epoch 15, step 200 / 900, loss = 0.78 (0.007 sec/batch)\n",
      "epoch 15, step 250 / 900, loss = 0.72 (0.006 sec/batch)\n",
      "epoch 15, step 300 / 900, loss = 0.42 (0.006 sec/batch)\n",
      "epoch 15, step 350 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 15, step 400 / 900, loss = 0.75 (0.008 sec/batch)\n",
      "epoch 15, step 450 / 900, loss = 0.69 (0.008 sec/batch)\n",
      "epoch 15, step 500 / 900, loss = 0.66 (0.007 sec/batch)\n",
      "epoch 15, step 550 / 900, loss = 0.71 (0.006 sec/batch)\n",
      "epoch 15, step 600 / 900, loss = 0.34 (0.006 sec/batch)\n",
      "epoch 15, step 650 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 15, step 700 / 900, loss = 0.57 (0.006 sec/batch)\n",
      "epoch 15, step 750 / 900, loss = 0.60 (0.006 sec/batch)\n",
      "epoch 15, step 800 / 900, loss = 0.42 (0.006 sec/batch)\n",
      "epoch 15, step 850 / 900, loss = 0.54 (0.006 sec/batch)\n",
      "epoch 15, step 900 / 900, loss = 0.74 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 81.87\n",
      " avg loss = 0.58\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.30\n",
      " avg loss = 0.89\n",
      "\n",
      "Epoch time: 8.229873180389404\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 16, step 50 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 16, step 100 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 16, step 150 / 900, loss = 0.36 (0.008 sec/batch)\n",
      "epoch 16, step 200 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 16, step 250 / 900, loss = 0.75 (0.009 sec/batch)\n",
      "epoch 16, step 300 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 16, step 350 / 900, loss = 0.31 (0.006 sec/batch)\n",
      "epoch 16, step 400 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 16, step 450 / 900, loss = 0.60 (0.006 sec/batch)\n",
      "epoch 16, step 500 / 900, loss = 0.81 (0.006 sec/batch)\n",
      "epoch 16, step 550 / 900, loss = 0.59 (0.006 sec/batch)\n",
      "epoch 16, step 600 / 900, loss = 0.49 (0.006 sec/batch)\n",
      "epoch 16, step 650 / 900, loss = 0.73 (0.006 sec/batch)\n",
      "epoch 16, step 700 / 900, loss = 0.68 (0.006 sec/batch)\n",
      "epoch 16, step 750 / 900, loss = 0.69 (0.007 sec/batch)\n",
      "epoch 16, step 800 / 900, loss = 0.81 (0.006 sec/batch)\n",
      "epoch 16, step 850 / 900, loss = 0.57 (0.006 sec/batch)\n",
      "epoch 16, step 900 / 900, loss = 0.45 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 82.17\n",
      " avg loss = 0.57\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.30\n",
      " avg loss = 0.89\n",
      "\n",
      "Epoch time: 8.264528512954712\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 17, step 50 / 900, loss = 0.69 (0.006 sec/batch)\n",
      "epoch 17, step 100 / 900, loss = 0.68 (0.006 sec/batch)\n",
      "epoch 17, step 150 / 900, loss = 0.58 (0.006 sec/batch)\n",
      "epoch 17, step 200 / 900, loss = 0.42 (0.005 sec/batch)\n",
      "epoch 17, step 250 / 900, loss = 0.31 (0.006 sec/batch)\n",
      "epoch 17, step 300 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 17, step 350 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "epoch 17, step 400 / 900, loss = 0.43 (0.006 sec/batch)\n",
      "epoch 17, step 450 / 900, loss = 0.59 (0.006 sec/batch)\n",
      "epoch 17, step 500 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "epoch 17, step 550 / 900, loss = 0.36 (0.007 sec/batch)\n",
      "epoch 17, step 600 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 17, step 650 / 900, loss = 0.52 (0.008 sec/batch)\n",
      "epoch 17, step 700 / 900, loss = 0.60 (0.009 sec/batch)\n",
      "epoch 17, step 750 / 900, loss = 0.59 (0.006 sec/batch)\n",
      "epoch 17, step 800 / 900, loss = 0.69 (0.007 sec/batch)\n",
      "epoch 17, step 850 / 900, loss = 0.71 (0.006 sec/batch)\n",
      "epoch 17, step 900 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 83.15\n",
      " avg loss = 0.54\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.76\n",
      " avg loss = 0.88\n",
      "\n",
      "Epoch time: 8.289650440216064\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 18, step 50 / 900, loss = 0.41 (0.008 sec/batch)\n",
      "epoch 18, step 100 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "epoch 18, step 150 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 18, step 200 / 900, loss = 0.33 (0.006 sec/batch)\n",
      "epoch 18, step 250 / 900, loss = 0.31 (0.006 sec/batch)\n",
      "epoch 18, step 300 / 900, loss = 0.59 (0.006 sec/batch)\n",
      "epoch 18, step 350 / 900, loss = 0.49 (0.006 sec/batch)\n",
      "epoch 18, step 400 / 900, loss = 0.43 (0.006 sec/batch)\n",
      "epoch 18, step 450 / 900, loss = 0.47 (0.006 sec/batch)\n",
      "epoch 18, step 500 / 900, loss = 0.54 (0.006 sec/batch)\n",
      "epoch 18, step 550 / 900, loss = 0.67 (0.006 sec/batch)\n",
      "epoch 18, step 600 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 18, step 650 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 18, step 700 / 900, loss = 0.67 (0.006 sec/batch)\n",
      "epoch 18, step 750 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 18, step 800 / 900, loss = 0.46 (0.008 sec/batch)\n",
      "epoch 18, step 850 / 900, loss = 0.47 (0.008 sec/batch)\n",
      "epoch 18, step 900 / 900, loss = 0.56 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 83.38\n",
      " avg loss = 0.53\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.32\n",
      " avg loss = 0.88\n",
      "\n",
      "Epoch time: 8.305020332336426\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 19, step 50 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 19, step 100 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 19, step 150 / 900, loss = 0.47 (0.006 sec/batch)\n",
      "epoch 19, step 200 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 19, step 250 / 900, loss = 0.64 (0.008 sec/batch)\n",
      "epoch 19, step 300 / 900, loss = 0.51 (0.008 sec/batch)\n",
      "epoch 19, step 350 / 900, loss = 0.37 (0.008 sec/batch)\n",
      "epoch 19, step 400 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "epoch 19, step 450 / 900, loss = 0.57 (0.008 sec/batch)\n",
      "epoch 19, step 500 / 900, loss = 0.58 (0.006 sec/batch)\n",
      "epoch 19, step 550 / 900, loss = 0.70 (0.006 sec/batch)\n",
      "epoch 19, step 600 / 900, loss = 0.55 (0.006 sec/batch)\n",
      "epoch 19, step 650 / 900, loss = 0.55 (0.007 sec/batch)\n",
      "epoch 19, step 700 / 900, loss = 0.66 (0.006 sec/batch)\n",
      "epoch 19, step 750 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 19, step 800 / 900, loss = 0.54 (0.006 sec/batch)\n",
      "epoch 19, step 850 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 19, step 900 / 900, loss = 0.63 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 82.76\n",
      " avg loss = 0.54\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.14\n",
      " avg loss = 0.91\n",
      "\n",
      "Epoch time: 8.259739875793457\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 20, step 50 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "epoch 20, step 100 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 20, step 150 / 900, loss = 0.40 (0.006 sec/batch)\n",
      "epoch 20, step 200 / 900, loss = 0.30 (0.007 sec/batch)\n",
      "epoch 20, step 250 / 900, loss = 0.54 (0.006 sec/batch)\n",
      "epoch 20, step 300 / 900, loss = 0.54 (0.006 sec/batch)\n",
      "epoch 20, step 350 / 900, loss = 0.41 (0.008 sec/batch)\n",
      "epoch 20, step 400 / 900, loss = 0.43 (0.008 sec/batch)\n",
      "epoch 20, step 450 / 900, loss = 0.60 (0.009 sec/batch)\n",
      "epoch 20, step 500 / 900, loss = 0.58 (0.006 sec/batch)\n",
      "epoch 20, step 550 / 900, loss = 0.34 (0.006 sec/batch)\n",
      "epoch 20, step 600 / 900, loss = 0.39 (0.008 sec/batch)\n",
      "epoch 20, step 650 / 900, loss = 0.68 (0.007 sec/batch)\n",
      "epoch 20, step 700 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "epoch 20, step 750 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 20, step 800 / 900, loss = 0.57 (0.006 sec/batch)\n",
      "epoch 20, step 850 / 900, loss = 0.58 (0.006 sec/batch)\n",
      "epoch 20, step 900 / 900, loss = 0.38 (0.005 sec/batch)\n",
      "Train error:\n",
      " accuracy = 84.18\n",
      " avg loss = 0.51\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.94\n",
      " avg loss = 0.89\n",
      "\n",
      "Epoch time: 8.285493850708008\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 21, step 50 / 900, loss = 0.59 (0.009 sec/batch)\n",
      "epoch 21, step 100 / 900, loss = 0.54 (0.008 sec/batch)\n",
      "epoch 21, step 150 / 900, loss = 0.43 (0.006 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, step 200 / 900, loss = 0.74 (0.006 sec/batch)\n",
      "epoch 21, step 250 / 900, loss = 0.62 (0.006 sec/batch)\n",
      "epoch 21, step 300 / 900, loss = 0.60 (0.006 sec/batch)\n",
      "epoch 21, step 350 / 900, loss = 0.63 (0.006 sec/batch)\n",
      "epoch 21, step 400 / 900, loss = 0.59 (0.007 sec/batch)\n",
      "epoch 21, step 450 / 900, loss = 0.29 (0.006 sec/batch)\n",
      "epoch 21, step 500 / 900, loss = 0.57 (0.008 sec/batch)\n",
      "epoch 21, step 550 / 900, loss = 0.78 (0.006 sec/batch)\n",
      "epoch 21, step 600 / 900, loss = 0.67 (0.007 sec/batch)\n",
      "epoch 21, step 650 / 900, loss = 0.43 (0.006 sec/batch)\n",
      "epoch 21, step 700 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "epoch 21, step 750 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "epoch 21, step 800 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "epoch 21, step 850 / 900, loss = 0.48 (0.006 sec/batch)\n",
      "epoch 21, step 900 / 900, loss = 0.52 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 84.60\n",
      " avg loss = 0.50\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.50\n",
      " avg loss = 0.89\n",
      "\n",
      "Epoch time: 8.437671661376953\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 22, step 50 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 22, step 100 / 900, loss = 0.74 (0.006 sec/batch)\n",
      "epoch 22, step 150 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 22, step 200 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 22, step 250 / 900, loss = 0.62 (0.007 sec/batch)\n",
      "epoch 22, step 300 / 900, loss = 0.69 (0.007 sec/batch)\n",
      "epoch 22, step 350 / 900, loss = 0.80 (0.006 sec/batch)\n",
      "epoch 22, step 400 / 900, loss = 0.54 (0.006 sec/batch)\n",
      "epoch 22, step 450 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 22, step 500 / 900, loss = 0.55 (0.006 sec/batch)\n",
      "epoch 22, step 550 / 900, loss = 0.57 (0.006 sec/batch)\n",
      "epoch 22, step 600 / 900, loss = 0.70 (0.006 sec/batch)\n",
      "epoch 22, step 650 / 900, loss = 0.55 (0.007 sec/batch)\n",
      "epoch 22, step 700 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 22, step 750 / 900, loss = 0.51 (0.008 sec/batch)\n",
      "epoch 22, step 800 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "epoch 22, step 850 / 900, loss = 0.41 (0.009 sec/batch)\n",
      "epoch 22, step 900 / 900, loss = 0.33 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 84.95\n",
      " avg loss = 0.49\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.66\n",
      " avg loss = 0.90\n",
      "\n",
      "Epoch time: 8.332533836364746\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 23, step 50 / 900, loss = 0.54 (0.006 sec/batch)\n",
      "epoch 23, step 100 / 900, loss = 0.57 (0.006 sec/batch)\n",
      "epoch 23, step 150 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 23, step 200 / 900, loss = 0.60 (0.006 sec/batch)\n",
      "epoch 23, step 250 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 23, step 300 / 900, loss = 0.54 (0.006 sec/batch)\n",
      "epoch 23, step 350 / 900, loss = 0.54 (0.008 sec/batch)\n",
      "epoch 23, step 400 / 900, loss = 0.48 (0.008 sec/batch)\n",
      "epoch 23, step 450 / 900, loss = 0.35 (0.008 sec/batch)\n",
      "epoch 23, step 500 / 900, loss = 0.40 (0.008 sec/batch)\n",
      "epoch 23, step 550 / 900, loss = 0.23 (0.007 sec/batch)\n",
      "epoch 23, step 600 / 900, loss = 0.55 (0.006 sec/batch)\n",
      "epoch 23, step 650 / 900, loss = 0.62 (0.006 sec/batch)\n",
      "epoch 23, step 700 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 23, step 750 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 23, step 800 / 900, loss = 0.39 (0.007 sec/batch)\n",
      "epoch 23, step 850 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 23, step 900 / 900, loss = 0.62 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 85.19\n",
      " avg loss = 0.48\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.64\n",
      " avg loss = 0.90\n",
      "\n",
      "Epoch time: 8.255624532699585\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 24, step 50 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 24, step 100 / 900, loss = 0.35 (0.007 sec/batch)\n",
      "epoch 24, step 150 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "epoch 24, step 200 / 900, loss = 0.57 (0.006 sec/batch)\n",
      "epoch 24, step 250 / 900, loss = 0.28 (0.006 sec/batch)\n",
      "epoch 24, step 300 / 900, loss = 0.40 (0.006 sec/batch)\n",
      "epoch 24, step 350 / 900, loss = 0.48 (0.006 sec/batch)\n",
      "epoch 24, step 400 / 900, loss = 0.64 (0.007 sec/batch)\n",
      "epoch 24, step 450 / 900, loss = 0.40 (0.006 sec/batch)\n",
      "epoch 24, step 500 / 900, loss = 0.40 (0.006 sec/batch)\n",
      "epoch 24, step 550 / 900, loss = 0.78 (0.006 sec/batch)\n",
      "epoch 24, step 600 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 24, step 650 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 24, step 700 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 24, step 750 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 24, step 800 / 900, loss = 0.60 (0.006 sec/batch)\n",
      "epoch 24, step 850 / 900, loss = 0.60 (0.006 sec/batch)\n",
      "epoch 24, step 900 / 900, loss = 0.67 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 85.46\n",
      " avg loss = 0.48\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.86\n",
      " avg loss = 0.90\n",
      "\n",
      "Epoch time: 8.261679887771606\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 25, step 50 / 900, loss = 0.59 (0.007 sec/batch)\n",
      "epoch 25, step 100 / 900, loss = 0.46 (0.010 sec/batch)\n",
      "epoch 25, step 150 / 900, loss = 0.41 (0.008 sec/batch)\n",
      "epoch 25, step 200 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "epoch 25, step 250 / 900, loss = 0.48 (0.008 sec/batch)\n",
      "epoch 25, step 300 / 900, loss = 0.62 (0.006 sec/batch)\n",
      "epoch 25, step 350 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 25, step 400 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 25, step 450 / 900, loss = 0.39 (0.007 sec/batch)\n",
      "epoch 25, step 500 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 25, step 550 / 900, loss = 0.42 (0.006 sec/batch)\n",
      "epoch 25, step 600 / 900, loss = 0.42 (0.006 sec/batch)\n",
      "epoch 25, step 650 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 25, step 700 / 900, loss = 0.71 (0.006 sec/batch)\n",
      "epoch 25, step 750 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 25, step 800 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 25, step 850 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "epoch 25, step 900 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 85.96\n",
      " avg loss = 0.46\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.98\n",
      " avg loss = 0.89\n",
      "\n",
      "Epoch time: 8.267149686813354\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 26, step 50 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 26, step 100 / 900, loss = 0.29 (0.006 sec/batch)\n",
      "epoch 26, step 150 / 900, loss = 0.61 (0.006 sec/batch)\n",
      "epoch 26, step 200 / 900, loss = 0.61 (0.006 sec/batch)\n",
      "epoch 26, step 250 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "epoch 26, step 300 / 900, loss = 0.45 (0.005 sec/batch)\n",
      "epoch 26, step 350 / 900, loss = 0.40 (0.006 sec/batch)\n",
      "epoch 26, step 400 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "epoch 26, step 450 / 900, loss = 0.64 (0.006 sec/batch)\n",
      "epoch 26, step 500 / 900, loss = 0.29 (0.008 sec/batch)\n",
      "epoch 26, step 550 / 900, loss = 0.38 (0.008 sec/batch)\n",
      "epoch 26, step 600 / 900, loss = 0.39 (0.008 sec/batch)\n",
      "epoch 26, step 650 / 900, loss = 0.36 (0.008 sec/batch)\n",
      "epoch 26, step 700 / 900, loss = 0.38 (0.008 sec/batch)\n",
      "epoch 26, step 750 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 26, step 800 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 26, step 850 / 900, loss = 0.67 (0.006 sec/batch)\n",
      "epoch 26, step 900 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.05\n",
      " avg loss = 0.46\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.68\n",
      " avg loss = 0.90\n",
      "\n",
      "Epoch time: 8.251080751419067\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 27, step 50 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 27, step 100 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 27, step 150 / 900, loss = 0.55 (0.007 sec/batch)\n",
      "epoch 27, step 200 / 900, loss = 0.33 (0.007 sec/batch)\n",
      "epoch 27, step 250 / 900, loss = 0.56 (0.006 sec/batch)\n",
      "epoch 27, step 300 / 900, loss = 0.43 (0.005 sec/batch)\n",
      "epoch 27, step 350 / 900, loss = 0.43 (0.006 sec/batch)\n",
      "epoch 27, step 400 / 900, loss = 0.39 (0.006 sec/batch)\n",
      "epoch 27, step 450 / 900, loss = 0.59 (0.006 sec/batch)\n",
      "epoch 27, step 500 / 900, loss = 0.67 (0.008 sec/batch)\n",
      "epoch 27, step 550 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 27, step 600 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 27, step 650 / 900, loss = 0.47 (0.005 sec/batch)\n",
      "epoch 27, step 700 / 900, loss = 0.32 (0.008 sec/batch)\n",
      "epoch 27, step 750 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 27, step 800 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 27, step 850 / 900, loss = 0.45 (0.006 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, step 900 / 900, loss = 0.75 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.19\n",
      " avg loss = 0.46\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.88\n",
      " avg loss = 0.90\n",
      "\n",
      "Epoch time: 8.270525455474854\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 28, step 50 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 28, step 100 / 900, loss = 0.33 (0.006 sec/batch)\n",
      "epoch 28, step 150 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 28, step 200 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 28, step 250 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "epoch 28, step 300 / 900, loss = 0.46 (0.007 sec/batch)\n",
      "epoch 28, step 350 / 900, loss = 0.49 (0.007 sec/batch)\n",
      "epoch 28, step 400 / 900, loss = 0.47 (0.008 sec/batch)\n",
      "epoch 28, step 450 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 28, step 500 / 900, loss = 0.49 (0.006 sec/batch)\n",
      "epoch 28, step 550 / 900, loss = 0.43 (0.006 sec/batch)\n",
      "epoch 28, step 600 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "epoch 28, step 650 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 28, step 700 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 28, step 750 / 900, loss = 0.32 (0.006 sec/batch)\n",
      "epoch 28, step 800 / 900, loss = 0.58 (0.007 sec/batch)\n",
      "epoch 28, step 850 / 900, loss = 0.59 (0.006 sec/batch)\n",
      "epoch 28, step 900 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.60\n",
      " avg loss = 0.45\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.74\n",
      " avg loss = 0.90\n",
      "\n",
      "Epoch time: 8.267243146896362\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 29, step 50 / 900, loss = 0.69 (0.006 sec/batch)\n",
      "epoch 29, step 100 / 900, loss = 0.54 (0.006 sec/batch)\n",
      "epoch 29, step 150 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 29, step 200 / 900, loss = 0.38 (0.007 sec/batch)\n",
      "epoch 29, step 250 / 900, loss = 0.34 (0.006 sec/batch)\n",
      "epoch 29, step 300 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 29, step 350 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 29, step 400 / 900, loss = 0.39 (0.006 sec/batch)\n",
      "epoch 29, step 450 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 29, step 500 / 900, loss = 0.42 (0.006 sec/batch)\n",
      "epoch 29, step 550 / 900, loss = 0.34 (0.008 sec/batch)\n",
      "epoch 29, step 600 / 900, loss = 0.27 (0.007 sec/batch)\n",
      "epoch 29, step 650 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 29, step 700 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 29, step 750 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 29, step 800 / 900, loss = 0.38 (0.007 sec/batch)\n",
      "epoch 29, step 850 / 900, loss = 0.60 (0.006 sec/batch)\n",
      "epoch 29, step 900 / 900, loss = 0.55 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.45\n",
      " avg loss = 0.45\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.72\n",
      " avg loss = 0.91\n",
      "\n",
      "Epoch time: 8.236117362976074\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 30, step 50 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 30, step 100 / 900, loss = 0.36 (0.006 sec/batch)\n",
      "epoch 30, step 150 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 30, step 200 / 900, loss = 0.42 (0.006 sec/batch)\n",
      "epoch 30, step 250 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 30, step 300 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 30, step 350 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 30, step 400 / 900, loss = 0.53 (0.008 sec/batch)\n",
      "epoch 30, step 450 / 900, loss = 0.35 (0.009 sec/batch)\n",
      "epoch 30, step 500 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "epoch 30, step 550 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 30, step 600 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 30, step 650 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 30, step 700 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 30, step 750 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 30, step 800 / 900, loss = 0.55 (0.005 sec/batch)\n",
      "epoch 30, step 850 / 900, loss = 0.48 (0.006 sec/batch)\n",
      "epoch 30, step 900 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.83\n",
      " avg loss = 0.44\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.86\n",
      " avg loss = 0.91\n",
      "\n",
      "Epoch time: 8.256052732467651\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 31, step 50 / 900, loss = 0.34 (0.006 sec/batch)\n",
      "epoch 31, step 100 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "epoch 31, step 150 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 31, step 200 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 31, step 250 / 900, loss = 0.43 (0.006 sec/batch)\n",
      "epoch 31, step 300 / 900, loss = 0.55 (0.006 sec/batch)\n",
      "epoch 31, step 350 / 900, loss = 0.56 (0.006 sec/batch)\n",
      "epoch 31, step 400 / 900, loss = 0.55 (0.006 sec/batch)\n",
      "epoch 31, step 450 / 900, loss = 0.31 (0.007 sec/batch)\n",
      "epoch 31, step 500 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 31, step 550 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 31, step 600 / 900, loss = 0.43 (0.008 sec/batch)\n",
      "epoch 31, step 650 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 31, step 700 / 900, loss = 0.42 (0.006 sec/batch)\n",
      "epoch 31, step 750 / 900, loss = 0.42 (0.006 sec/batch)\n",
      "epoch 31, step 800 / 900, loss = 0.40 (0.006 sec/batch)\n",
      "epoch 31, step 850 / 900, loss = 0.30 (0.006 sec/batch)\n",
      "epoch 31, step 900 / 900, loss = 0.49 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.98\n",
      " avg loss = 0.44\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.88\n",
      " avg loss = 0.91\n",
      "\n",
      "Epoch time: 8.273346900939941\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 32, step 50 / 900, loss = 0.34 (0.007 sec/batch)\n",
      "epoch 32, step 100 / 900, loss = 0.39 (0.007 sec/batch)\n",
      "epoch 32, step 150 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 32, step 200 / 900, loss = 0.73 (0.006 sec/batch)\n",
      "epoch 32, step 250 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 32, step 300 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 32, step 350 / 900, loss = 0.68 (0.006 sec/batch)\n",
      "epoch 32, step 400 / 900, loss = 0.39 (0.009 sec/batch)\n",
      "epoch 32, step 450 / 900, loss = 0.60 (0.008 sec/batch)\n",
      "epoch 32, step 500 / 900, loss = 0.59 (0.008 sec/batch)\n",
      "epoch 32, step 550 / 900, loss = 0.47 (0.008 sec/batch)\n",
      "epoch 32, step 600 / 900, loss = 0.38 (0.006 sec/batch)\n",
      "epoch 32, step 650 / 900, loss = 0.62 (0.006 sec/batch)\n",
      "epoch 32, step 700 / 900, loss = 0.24 (0.006 sec/batch)\n",
      "epoch 32, step 750 / 900, loss = 0.38 (0.006 sec/batch)\n",
      "epoch 32, step 800 / 900, loss = 0.25 (0.006 sec/batch)\n",
      "epoch 32, step 850 / 900, loss = 0.34 (0.006 sec/batch)\n",
      "epoch 32, step 900 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.98\n",
      " avg loss = 0.44\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.92\n",
      " avg loss = 0.91\n",
      "\n",
      "Epoch time: 8.24842643737793\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 33, step 50 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 33, step 100 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 33, step 150 / 900, loss = 0.32 (0.007 sec/batch)\n",
      "epoch 33, step 200 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 33, step 250 / 900, loss = 0.59 (0.007 sec/batch)\n",
      "epoch 33, step 300 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 33, step 350 / 900, loss = 0.47 (0.006 sec/batch)\n",
      "epoch 33, step 400 / 900, loss = 0.33 (0.005 sec/batch)\n",
      "epoch 33, step 450 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 33, step 500 / 900, loss = 0.55 (0.007 sec/batch)\n",
      "epoch 33, step 550 / 900, loss = 0.36 (0.006 sec/batch)\n",
      "epoch 33, step 600 / 900, loss = 0.33 (0.006 sec/batch)\n",
      "epoch 33, step 650 / 900, loss = 0.28 (0.008 sec/batch)\n",
      "epoch 33, step 700 / 900, loss = 0.48 (0.008 sec/batch)\n",
      "epoch 33, step 750 / 900, loss = 0.35 (0.006 sec/batch)\n",
      "epoch 33, step 800 / 900, loss = 0.32 (0.006 sec/batch)\n",
      "epoch 33, step 850 / 900, loss = 0.39 (0.005 sec/batch)\n",
      "epoch 33, step 900 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.14\n",
      " avg loss = 0.43\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.80\n",
      " avg loss = 0.91\n",
      "\n",
      "Epoch time: 8.285939931869507\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 34, step 50 / 900, loss = 0.32 (0.006 sec/batch)\n",
      "epoch 34, step 100 / 900, loss = 0.48 (0.006 sec/batch)\n",
      "epoch 34, step 150 / 900, loss = 0.34 (0.008 sec/batch)\n",
      "epoch 34, step 200 / 900, loss = 0.40 (0.006 sec/batch)\n",
      "epoch 34, step 250 / 900, loss = 0.40 (0.006 sec/batch)\n",
      "epoch 34, step 300 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 34, step 350 / 900, loss = 0.36 (0.006 sec/batch)\n",
      "epoch 34, step 400 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 34, step 450 / 900, loss = 0.35 (0.006 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, step 500 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 34, step 550 / 900, loss = 0.59 (0.006 sec/batch)\n",
      "epoch 34, step 600 / 900, loss = 0.33 (0.006 sec/batch)\n",
      "epoch 34, step 650 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 34, step 700 / 900, loss = 0.47 (0.006 sec/batch)\n",
      "epoch 34, step 750 / 900, loss = 0.69 (0.006 sec/batch)\n",
      "epoch 34, step 800 / 900, loss = 0.33 (0.006 sec/batch)\n",
      "epoch 34, step 850 / 900, loss = 0.18 (0.006 sec/batch)\n",
      "epoch 34, step 900 / 900, loss = 0.34 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.29\n",
      " avg loss = 0.43\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.94\n",
      " avg loss = 0.91\n",
      "\n",
      "Epoch time: 8.353089332580566\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 35, step 50 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 35, step 100 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "epoch 35, step 150 / 900, loss = 0.48 (0.006 sec/batch)\n",
      "epoch 35, step 200 / 900, loss = 0.33 (0.006 sec/batch)\n",
      "epoch 35, step 250 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 35, step 300 / 900, loss = 0.40 (0.008 sec/batch)\n",
      "epoch 35, step 350 / 900, loss = 0.48 (0.006 sec/batch)\n",
      "epoch 35, step 400 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "epoch 35, step 450 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 35, step 500 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "epoch 35, step 550 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 35, step 600 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 35, step 650 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 35, step 700 / 900, loss = 0.36 (0.008 sec/batch)\n",
      "epoch 35, step 750 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 35, step 800 / 900, loss = 0.49 (0.008 sec/batch)\n",
      "epoch 35, step 850 / 900, loss = 0.65 (0.008 sec/batch)\n",
      "epoch 35, step 900 / 900, loss = 0.50 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.36\n",
      " avg loss = 0.43\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.78\n",
      " avg loss = 0.91\n",
      "\n",
      "Epoch time: 8.326900482177734\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 36, step 50 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 36, step 100 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 36, step 150 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 36, step 200 / 900, loss = 0.34 (0.006 sec/batch)\n",
      "epoch 36, step 250 / 900, loss = 0.43 (0.006 sec/batch)\n",
      "epoch 36, step 300 / 900, loss = 0.69 (0.006 sec/batch)\n",
      "epoch 36, step 350 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 36, step 400 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 36, step 450 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "epoch 36, step 500 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 36, step 550 / 900, loss = 0.25 (0.006 sec/batch)\n",
      "epoch 36, step 600 / 900, loss = 0.27 (0.006 sec/batch)\n",
      "epoch 36, step 650 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 36, step 700 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "epoch 36, step 750 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 36, step 800 / 900, loss = 0.45 (0.008 sec/batch)\n",
      "epoch 36, step 850 / 900, loss = 0.41 (0.008 sec/batch)\n",
      "epoch 36, step 900 / 900, loss = 0.36 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.43\n",
      " avg loss = 0.43\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.80\n",
      " avg loss = 0.91\n",
      "\n",
      "Epoch time: 8.408028602600098\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 37, step 50 / 900, loss = 0.29 (0.006 sec/batch)\n",
      "epoch 37, step 100 / 900, loss = 0.28 (0.006 sec/batch)\n",
      "epoch 37, step 150 / 900, loss = 0.64 (0.006 sec/batch)\n",
      "epoch 37, step 200 / 900, loss = 0.28 (0.007 sec/batch)\n",
      "epoch 37, step 250 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 37, step 300 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 37, step 350 / 900, loss = 0.38 (0.006 sec/batch)\n",
      "epoch 37, step 400 / 900, loss = 0.67 (0.007 sec/batch)\n",
      "epoch 37, step 450 / 900, loss = 0.35 (0.006 sec/batch)\n",
      "epoch 37, step 500 / 900, loss = 0.64 (0.006 sec/batch)\n",
      "epoch 37, step 550 / 900, loss = 0.49 (0.006 sec/batch)\n",
      "epoch 37, step 600 / 900, loss = 0.56 (0.007 sec/batch)\n",
      "epoch 37, step 650 / 900, loss = 0.34 (0.007 sec/batch)\n",
      "epoch 37, step 700 / 900, loss = 0.24 (0.006 sec/batch)\n",
      "epoch 37, step 750 / 900, loss = 0.49 (0.006 sec/batch)\n",
      "epoch 37, step 800 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 37, step 850 / 900, loss = 0.48 (0.006 sec/batch)\n",
      "epoch 37, step 900 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.62\n",
      " avg loss = 0.42\n",
      "\n",
      "Validation error:\n",
      " accuracy = 72.02\n",
      " avg loss = 0.91\n",
      "\n",
      "Epoch time: 8.353128671646118\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 38, step 50 / 900, loss = 0.25 (0.006 sec/batch)\n",
      "epoch 38, step 100 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 38, step 150 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 38, step 200 / 900, loss = 0.43 (0.007 sec/batch)\n",
      "epoch 38, step 250 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 38, step 300 / 900, loss = 0.42 (0.006 sec/batch)\n",
      "epoch 38, step 350 / 900, loss = 0.38 (0.006 sec/batch)\n",
      "epoch 38, step 400 / 900, loss = 0.49 (0.006 sec/batch)\n",
      "epoch 38, step 450 / 900, loss = 0.34 (0.006 sec/batch)\n",
      "epoch 38, step 500 / 900, loss = 0.31 (0.006 sec/batch)\n",
      "epoch 38, step 550 / 900, loss = 0.59 (0.006 sec/batch)\n",
      "epoch 38, step 600 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 38, step 650 / 900, loss = 0.22 (0.006 sec/batch)\n",
      "epoch 38, step 700 / 900, loss = 0.59 (0.006 sec/batch)\n",
      "epoch 38, step 750 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "epoch 38, step 800 / 900, loss = 0.47 (0.006 sec/batch)\n",
      "epoch 38, step 850 / 900, loss = 0.38 (0.007 sec/batch)\n",
      "epoch 38, step 900 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.57\n",
      " avg loss = 0.42\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.72\n",
      " avg loss = 0.91\n",
      "\n",
      "Epoch time: 8.397081851959229\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 39, step 50 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "epoch 39, step 100 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 39, step 150 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 39, step 200 / 900, loss = 0.42 (0.009 sec/batch)\n",
      "epoch 39, step 250 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 39, step 300 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 39, step 350 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 39, step 400 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 39, step 450 / 900, loss = 0.32 (0.006 sec/batch)\n",
      "epoch 39, step 500 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 39, step 550 / 900, loss = 0.46 (0.008 sec/batch)\n",
      "epoch 39, step 600 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 39, step 650 / 900, loss = 0.30 (0.006 sec/batch)\n",
      "epoch 39, step 700 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 39, step 750 / 900, loss = 0.41 (0.008 sec/batch)\n",
      "epoch 39, step 800 / 900, loss = 0.40 (0.006 sec/batch)\n",
      "epoch 39, step 850 / 900, loss = 0.49 (0.006 sec/batch)\n",
      "epoch 39, step 900 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.69\n",
      " avg loss = 0.42\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.70\n",
      " avg loss = 0.91\n",
      "\n",
      "Epoch time: 8.440207719802856\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 40, step 50 / 900, loss = 0.36 (0.008 sec/batch)\n",
      "epoch 40, step 100 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 40, step 150 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 40, step 200 / 900, loss = 0.39 (0.006 sec/batch)\n",
      "epoch 40, step 250 / 900, loss = 0.54 (0.008 sec/batch)\n",
      "epoch 40, step 300 / 900, loss = 0.39 (0.006 sec/batch)\n",
      "epoch 40, step 350 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 40, step 400 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 40, step 450 / 900, loss = 0.52 (0.008 sec/batch)\n",
      "epoch 40, step 500 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 40, step 550 / 900, loss = 0.28 (0.006 sec/batch)\n",
      "epoch 40, step 600 / 900, loss = 0.43 (0.006 sec/batch)\n",
      "epoch 40, step 650 / 900, loss = 0.30 (0.006 sec/batch)\n",
      "epoch 40, step 700 / 900, loss = 0.48 (0.006 sec/batch)\n",
      "epoch 40, step 750 / 900, loss = 0.61 (0.006 sec/batch)\n",
      "epoch 40, step 800 / 900, loss = 0.34 (0.007 sec/batch)\n",
      "epoch 40, step 850 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "epoch 40, step 900 / 900, loss = 0.33 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.70\n",
      " avg loss = 0.42\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.92\n",
      " avg loss = 0.92\n",
      "\n",
      "Epoch time: 8.368254899978638\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "Total train time: 346.6922128200531\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "train_start = time.time()\n",
    "\n",
    "plot_data={}\n",
    "train_cifar(session, train_x, train_y, valid_x, valid_y, config, plot_data)\n",
    "\n",
    "print(\"Total train time:\", time.time() - train_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAHiCAYAAADcelBQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xl8XHW5+PHPM8lksjRb0zZNlyRN6Ub3vZWtXNDLoiCo\ngBQQBKqIoF7vVaQgqFThioiowK/IIlqqCAKKeMGlAQoBWqB0TVqavWmmSZp9mSQz398fZ5JOkplk\nkk4yWZ7369VXkznfOeeZk5N8z3O+mxhjUEoppZRSSimlRipbuANQSimllFJKKaVOhia2SimllFJK\nKaVGNE1slVJKKaWUUkqNaJrYKqWUUkoppZQa0TSxVUoppZRSSik1omliq5RSSimllFJqRNPEVik1\nKETkbhH5fbjjUEoppQaTiKwTkdJwx6HUWKeJrRrTRORKEdkpIg0iclRE/i4ip4c7roEQkUwRMSIS\nGe5YlFJKKRHJFpFqEXGEOxal1Oinia0as0Tkv4AHgR8DqUA68GvgogDlR3zCOBo+g1JKqeFPRDKB\nMwBDgHo1BMfQOi0MRCQi3DEo5Y8mtmpMEpFE4IfAzcaYPxtjGo0xbcaYl40x3/GWuVtEnhOR34tI\nHXCtiDhE5EERKfP+e7DjSbSITBCRl0WkRkSOi8ibImLzbvuuiBwRkXoRyRORc3qJbY2IvO3dz0ci\nss5nW7aI/EhE3vLu6zURmeDd/Ib3/xpvC/RaEbnWW/bnIlIF3C0iNhG5Q0SKROSYiDztPR++rb4b\nvJ/vqIj8t3fbZBFpEpEUn3iWiUiFiNiDOOcXicg+7+fKFpF5Ptv8nh8RWeVtUa8TEaeIPNDnD1cp\npdRwcA3wDvAU8KWOF0VktYiU+yZHInKJiOz2fm0TkdtE5LCIVInIsyIy3ruto466XkSKgX97X/+T\nd5+1IvKGiMz32XeKiPzVW4/sEJF7RGS7z/a5IvIPb72dJyKXBfpAIjJeRJ701o/VIvJigHId8deL\nyH4RucRn2yki8ro31koR+aP3dfHW1ce8se4RkQUB9n+diBzw7j9fRL7SbfvFIrLLu5/DInJeb/F7\n7xW2d9uHEZFTvF8/JSKPiMgrItIInC0iF4rIh95jlIjI3d3ef7qcuJcp8R5jpbcu9/3ZXyoiHwU6\n50r1hya2aqxaC0QDL/RR7mLgOSAJ2AJsBNYAS4DFwCrgDm/ZbwOlwESsFuDbASMic4CvAyuNMfHA\nfwKF/g4mIlOBvwH3AOOB/waeF5GJPsWuBK4DJgFR3jIAZ3r/TzLGjDPG5Hi/Xw3ke2PaBFzr/Xc2\nkAWMA37VLZSzgVnAp4Dvisi5xphyIBvwrfSvBv5gjGnz93l8PtdsYCvwTe/5eQX4q4hE9XF+fgH8\nwhiTAMwEnu3tOEoppYaNa7DqzS3Af4pIKoAx5l2gEfgPn7JXAs94v74F+CxwFjAFqMbqTeXrLGAe\nVn0B8HesOmsS8IH3mB1+7T3eZKwE2zfJjgP+4T32JOAK4GEROTXAZ/odEAvM95b/eYByh7FaqxOB\nHwC/F5E077YfAa8BycA04Jfe1z+FVY/P9r7vMqAqwP6PAZ8GErDuB34uIsu8n2kV8DTwP1j3Lmdy\nok4NNn5/rsS6h4gHtmOd02u8x7gQuElEPuuNIQPrZ/JLrDp/CbDLGLPD+5k+5bPfq73xKnXSNLFV\nY1UKUGmMae+jXI4x5kVjjMcY0wysB35ojDlmjKnAqrCu9pZtA9KADG/r75vGGAO4AQdwqojYjTGF\nxpjDAY53FfCKMeYV7zH/AewELvAp86Qx5qA3nmexKozelBljfmmMaff5DA8YY/KNMQ3A94ArpGuX\nrh94W7H3AE8CX/S+/ltvjB1dkb6IVVH25XLgb8aYf3iT4PuBGOAT9H5+2oBTRGSCMabBGPNOEMdS\nSikVRmLNVZEBPGuMeR8r0bvSp8hWvPWKiMRj1XFbvdu+Cmw0xpQaY1zA3cDnu9VRd3vrqGYAY8wT\nxph6n/KLRSTRW099DrjLGNNkjNmPVY91+DRQaIx50ltHfgg8D3zBz2dKA84HvmqMqfbW86/7+/zG\nmD8ZY8q89fgfgUNYD8LBqtcygCnGmBZjzHaf1+OBuYAYYw4YY44G2P/fjDGHjeV1rET5DO/m64En\nvPWtxxhzxBiT25/4A3jJGPOWd58txphsY8we7/e7sX5+Z3nLXgn80xiz1XucKmPMLu823/uI8VgP\nJ57pfjClBkITWzVWVQETpO/xOSXdvp8CFPl8X+R9DeCnwMfAa96uQbcBGGM+xmqpvBs4JiJ/EJEp\nAGJ1Ge74l45V2X3B23WnRkRqgNOxEuYO5T5fN2G1uJ7sZ4jEatH19x7fz/gSVgI6A/gkUGuMea+P\n4/c4pjHG4z3G1N7OD1YFPRvI9XYh+3QQx1JKKRVeXwJeM8ZUer9/Bp+WUu/3l4o1lOdS4ANjTEcd\nkQG84FMHHsB6AOq3jhKRCBG519vlto4TrZMTsFoLI+lap/l+nQGs7lbnrsdq3e1uOnDcGFPd14cX\nkWu8XYE79rnAGw/AdwAB3hNreM6XAYwx/8bqPfVrrLpws4gkBNj/+SLyjljdp2uwHgx07H861oOE\nAccfQJd7CbG6lG8TazhSLdYDib5iAPg98Blva/llwJuBEnil+ksTWzVW5QAurO5OvTHdvi/Dqgg7\npHtfw/u0+NvGmCysiTL+S7xjRY0xzxhjOp5gG+A+7+vjfP4VY1UcvzPGJPn8izPG3BvEZ+oea38+\nQzvg9HlteoDP2ILVSnwVVkt1MK21PY4pIuI9xhHvfgOdn0PGmC9idZm6D3jOWxkqpZQahkQkBith\nOUusca/lwLewWlEXA3hbTouwWhB9uyGDVQ+e360ejDbGHPEp41uvXYk1bOhcrC68mR2hABVY9ds0\nn/K+9VsJ8Hq3Y40zxtzk56OVAONFJKmPz58BPIY1xCbFGJME7PXGgzGm3BhzozFmCvAVrK7Pp3i3\nPWSMWQ6civVQ93/87N+B1ap8P5Dq3f8rHfv3xjmzn/E3YnVR7jiGv8S++73EM8BfgOnGmETg0SBi\nwPtzzMF6oNGf+wil+qSJrRqTjDG1wPeBX4vIZ0UkVkTs3qeg/9vLW7cCd4jIRLEmbfo+1tNHROTT\nYk0KIUAt1hNmj4jMEZH/8FZGLUAz4Amw/44nmf/pfQodLdb6eNMClPdV4d1vVh/ltgLfEpEZIjIO\na1boP5qu3bLv9J6T+Vjjd/7os+1prDG6FxF8hfQscKGInCPWRFPfxnqw8HZv50dErhKRid4W3hrv\nvgKdO6WUUuH3Waz671SsoTJLsMbDvok1JrPDM8A3sMaA/snn9UeBTd4EEW99e3Evx4vHqk+qsJKz\nH3dsMMa4gT9jTZwYKyJzu8XwMjBbRK723gPYxZrgaB7deFsV/46ViCZ7y57ZvRwQh5UEVnjjvw6r\nxRbv91/wqdOrvWU93uOu9taRjVj1ob/6Lgpr+E4F0C4i59N1zOrjwHXe+tYmIlNFZG4f8X8EzBeR\nJSISjdWDqi/xWC3ALWKN6/Xtar4FOFdELhORSLEm8PIdNvU0Vsv1Qqyfj1IhoYmtGrOMMT8D/gtr\n8qcKrCeMXwf8znLodQ/WmNfdwB6sSSru8W6bBfwTaMB6GvmwMWYbVgV0L1CJ1Y14Eta4Vn8xlWA9\neb7dJ6b/IYjfVWNME9bEDm95uz+tCVD0CayE9A2gAKvyvKVbmdexulX/C7jfGPOaz3HewqpsfbuO\n9RVbHlYr7y+xzsNngM8YY1rp/fycB+wTkQasiaSu6BhTpZRSalj6EtZcEMXe1slyY00++Ctgvc8Q\noI4xmf/26bIM1t/6v2AN66nHmll5dS/Hexqr9fcIsN9b3tfXsVpyy7Hqvq1YiTDGmHqspPAKrJ5F\n5Vi9gwKtu3s11ljYXKwJnL7ZvYC3NfpnWPcBTqzk7S2fIiuBd7312l+Abxhj8rEmgnoMK9ktwkrU\nf+pn//XArVgPjKuxEsq/+Gx/D++EUlgP2V/nRI8pv/EbYw5irRTxT6zxwF1mSA7ga8APvT+j7+Mz\nuaO3B9oFWA+xjwO7sCbc7PCCN6YXvPcuSoWEGBOo96JSaqwRa93BAsBueplYS0T+DTxjjPnNEIWm\nlFJKnTQRuQ+YbIz5Up+F1aARkcPAV4wx/wx3LGr00BZbpVS/iMhKYBlduycrpZRSw45Y69QuEssq\nrEkJ+1rqTw0iEfkcVhfsf4c7FjW69DUjrFJKdRKR32KNn/qGtzuUUkopNZzFY3U/noLVNfhnWDP8\nqzAQkWys8ddXe+fPUCpktCuyUkoppZRSSqkRTbsiK6WUUkoppZQa0TSxVUoppZRSSik1oo2oMbYT\nJkwwmZmZ4Q5DKaXUKPH+++9XGmMmhjuOkUzrZqWUUqE00Lp5RCW2mZmZ7Ny5M9xhKKWUGiVEJKi1\nmFVgWjcrpZQKpYHWzdoVWSmllFJKKaXUiKaJrVJKKaWUUkqpEU0TW6WUUkoppZRSI9qIGmOrlFJj\nQVtbG6WlpbS0tIQ7lFEjOjqaadOmYbfbwx3KmKDXcGjp9auUUn0bU4ntFqeTjfn5FLtcpDscbMrK\nYn1qarjDUkqpLkpLS4mPjyczMxMRCXc4I54xhqqqKkpLS5kxY0a4wxkT9BoOHb1+lVL94dziJH9j\nPq5iF450B1mbskhdP7B8J5h9hfJ4J2vMdEXe4nRy475cilwuDFDkcnHjvly2OJ3hDk0ppbpoaWkh\nJSVFE4IQERFSUlK09XAI6TUcOnr9KqXASiBzMnPItmWTk5mDc0vPHMa5xUnehjxcRS4w4Cpykbch\nr0fZAe/rxjzKHi+jvbadtuo2jvy/I+Td2PfxhsqgtNiKyBPAp4FjxpgFvZRbCeQAVxhjnhuMWDrc\ntucQzZGmy2vNNsNtew5pq61SatjRhCC09HwOPT3noaPnUqmRKxStnh1JpqfJA5xIINsb20k6I4nW\n8lZay1s5dMuhzjIdPE0eDn71IPXv12Nz2GjMa+T4y8cxbaZzX7nX5nLk0SPYx9tpr2mnvaadxn2N\n4O76WTzNHg7ecJCDNxwM+Hk9TR7yN+aHpdV2sLoiPwX8Cng6UAERiQDuA14bpBi6OBLR3q/XlVJq\nLKupqeGZZ57ha1/7Wr/ed8EFF/DMM8+QlJQ0SJEp1Te9fpVS/gTbbTZUXXD9JaS5N+TS9HETSWcm\n4Wn2cPzV45Q9WoZp9Uk0r8ul/JlyYjJicDe5qfhThd+E9dBXDgX1ud0Nbkp/Xhpwu2k31G2vC2pf\nABEJEYhNaK/xn0e5il1B7yuUBiWxNca8ISKZfRS7BXgeWDkYMXQ3yQnOyf5fV0qpkWwwxrfU1NTw\n8MMP90gM2tvbiYwMXHW88sorJ3VcNTaF+hrW61epsWegrZ5A0OUmXTkJd72bo48fJf/2fExLt1bP\nx45gT7TTVtlGW2UbzR83Q9d8FNNiKLq7iCKKAn4W02aofqWaaqr7/Nwxs2OImhxF1OQojv/9OO56\nd48ykcmRZNyRgcfloeD2goD7mv/CfCKTIolMimTPp/fQeqS1RxlHhoO1hWsByMnMsbohdy+T7ugz\n7sEQlsmjRGQqcAlwNkOU2H71xQjuvdaNK/rEa44W63WuGIoIlFIq9IKtqPvrtttu4/DhwyxZsgS7\n3U50dDTJycnk5uZy8OBBPvvZz1JSUkJLSwvf+MY32LBhAwCZmZns3LmThoYGzj//fE4//XTefvtt\npk6dyksvvURMTMzJf2g1qgzGNazXr1IjQ6geavn9O3JjHq1VrSSdkURbZRuHvhmgm+5NB6nfWQ9Y\nk7WVP1Hut9yBLx0g98u5nS2r3Zl2Q93rwbd6Jp6VSERMBMf/73jAMrN+NQtbrI3D3zlMe2XP1lFH\nhoPVeas7v+9+HgBssTZm/XJW53kt+39l/pPRDAcTPzux8/uZ9830u6+sTVmd32dtyuqzzFAK16zI\nDwLfNcZ4+ho3IiIbgA0A6enpAz7gTZ+ZjfuhAzx2DThTAYELX7VeV0qp4Spbsvv9Hk+ThwNXHeDA\nVQcCllln1vW6j3vvvZe9e/eya9cusrOzufDCC9m7d2/nrKxPPPEE48ePp7m5mZUrV/K5z32OlJSU\nLvs4dOgQW7du5bHHHuOyyy7j+eef56qrrur351EjWziuYb1+lRr++tOCGij5dTe5adjd4H9sabOH\nw9843Gcc7no3pQ8G7qZ7oiAYt8EWZ8PT6AlYbP4L87FPsGOfYGf3J3fjKvWfRC7NXgr00uqZ4WDq\nzVMBsEXZgkogO85Lbw8Lgk1Gg9lXMGWGUrgS2xXAH7xJ7QTgAhFpN8a82L2gMWYzsBlgxYoV/h+R\nBCF1fSpfBy64LZ/HT3fx+A0QvSwubCdeKaVGklWrVnVZauShhx7ihRdeAKCkpIRDhw71SAxmzJjB\nkiVLAFi+fDmFhYVDFq9SvvT6VWpo9dUS21bTxsf/9bH/caO3HMJ4DPYJdup21lHykxI8zT5jVK/L\npfThUtw1bppym3p09e0ublGcta936nocDyAyKZKMOzPA29ZW9KMi2qt7to5GTY1i9aHVRMRE9JqM\n+rZ6Zt3bdxIZTKLZnwQydX1qr/lNKPcVbJmhEpbE1hjTWbuIyFPAy/6S2lDrOPHFd+/lcSp5J6Vn\nv3GllBpO+mpZ7a1y7RgDEwpxcXGdX2dnZ/PPf/6TnJwcYmNjWbdund+lSByOE2NsIiIiaG5uDlk8\nauQYDtewXr9K9S1UEysFmjCp6tUqxAh179XRfDDw71N7dTu51+QG3G7aDPVvW12HiYC4hXE05zf7\nbUV1ZDhY+dFKv3GBt5vur2Z1iT9qUpTfcjPvm0lETAQQnlbPUCaQwykZDaXBWu5nK7AOmCAipcBd\ngB3AGPPoYByzP06bNYHo5kryY9s46nKR5gjPAGellDpZgzW+JT4+nvr6er/bamtrSU5OJjY2ltzc\nXN55552TOpYa2wbjGtbrV6n+OZmJlXKvz6VuRx1xC+Jor2qn6MdFPVpGTYvh2O+OdX4vDgGD3/Gq\nEfERpHwmhbbKNqpfCzx50rL3lhG3MI6I6IiASetAWj1D3QV3pLV6jmSDNSvyF/tR9trBiKE341cn\nsPDPsGMVbKup4Updx1YpNUIN1viWlJQUTjvtNBYsWEBMTAypPn8nzzvvPB599FHmzZvHnDlzWLNm\nzUkdS41tg3EN6/WrVP/k357vt1tw7vW5lDxQgrvejbvBTWt5K3TLRY3LcOQXR4I6zqyHZ5GwKoG4\nhXFU/KnCbzI6+5HZnb//vfXoSFiZ0Pl9qFs9NRkdmcSYAQ9bHXIrVqwwO3fuPOn9GGP42o1v8uhV\nHq4bN5EnVswPQXRKKRUaBw4cYN68eeEOY9Txd15F5H1jzIowhTQq+Kub9RoOPT2n6mT46z6ceHoi\n1f+upmZbDc7fnfz6l5Ovm0zk+EiOPn4Ud03PJWf8DS/ob7dmsJLfOZvnaFI5ig20bg7X5FFhJSKc\nxjgepY7smppwh6OUUkoNORH5FnADVvvLHuA64DbgRqDCW+x2Y4wu7qrUMBXMuFh/3YcPXH2gR8ur\nP/ZUO4v+toiIcRFEjIvggzUfBJzld+4TcwGIXxof9PCCUE50pNSYTGwB1qQnE9tYR0FcG6UtLUyL\nju77TUoppdQo4F1P/lbgVGNMs4g8y4lV3X9ujLk/fNEppWBgkzTl3ZBH/a56oqdH03y4mebDzVS/\nWo1p795/GBBIuSiF5P9Ixt3spuiHRT2S0VN+dgrxy+M7Xwtmlt9QJ6Pa5VcFa8wmtuPXJLLwA3h3\nDWTX1HDV5MnhDkkppZQaSpFAjIi0AbFAGZAZ1oiUUkDgyZxaK1oZt3gcLYUtfPwtP8vltHgovT+I\nNVm9Fr64sPPr6GnRIZlYqaOcJqNqqI3ZxDZ+VTxLH7cS238fr9bEViml1JhhjDkiIvcDxUAz8Jox\n5jUR+QRwi4hcA+wEvm2MCTwtqVJqQHprjW2raePjb/tf4/Xwtw4Htf+0r6QRMzOGmFNiOHTzIVqP\n9lzi0pHedVWQUE6spFQ4jNnE1p5kZ02Ng0dxsa1C62yllFJjh4gkAxcDM4Aa4E8ichXwCPAjrI6K\nPwJ+BnzZz/s3ABsA0tPThyhqpUYHv0vmXJdL8QPFtFe24yruOYbVV+LpiTgyHFT9tQp3nf9JmuY8\nOqfze0+TZ1CWhVNquLGFO4BwWj4lkbgGKDStFPtZnF0ppZQapc4FCowxFcaYNuDPwCeMMU5jjNsY\n4wEeA1b5e7MxZrMxZoUxZsXEiROHMGylhjfnFic5mTlk27LJyczBueXEbMMtpS1U/LmCg1872HOd\n1zZD4weNuIpd2KJtSJT43b8jw8HSN5dy6u9PZfbDs7HFdr2V95ewpq5PZc7mOTgyHCDexFdnFVaj\n0JhObJNXJbL4I+vrbTo7slJKDdi4ceMAKCsr4/Of/7zfMuvWraOvJdsefPBBmpqaOr+/4IILqNG/\nz4OhGFgjIrEiIsA5wAERSfMpcwmwNyzRDTG9flUodLTEuopcYE60xO5csZO3p77NO9PfYd/n9vlt\nZQVAYOX+lZxefzpzn5jbZ9Lan4Q1dX0qawvXss6zjrWFazWpVaPSmE5sE9YksGSX9fW2au2OrJQa\nmbY4nWTm5GDLziYzJ4ctzpNfj3CgpkyZwnPPPTfg93dPDF555RWSkpJCEZryYYx5F3gO+ABrqR8b\nsBn4XxHZIyK7gbOBbw1FPMPlGtbrV52M/I35fltiG95voLWslYjECJI/mUxEYoTf9zvSHcTNi8MW\naQs6adWEVakTxnRiG7cwjqUHrK4e2cf1iapSauTZ4nSyIS+PIpcLAxS5XGzIyzvpxOC2227j17/+\ndef3d999N/fccw/nnHMOy5YtY+HChbz00ks93ldYWMiCBQsAaG5u5oorrmDevHlccsklNDc3d5a7\n6aabWLFiBfPnz+euu+4C4KGHHqKsrIyzzz6bs88+G4DMzEwqKysBeOCBB1iwYAELFizgwQcf7Dze\nvHnzuPHGG5k/fz6f+tSnuhxHBWaMucsYM9cYs8AYc7UxxuX9f6ExZpEx5iJjzNHBjmMwrmG9flU4\n9DY2dlXuKk4/fjqLX1vM7F8H34VYk1algjdmJ48CsEXaWDo+nvi6OooSXBQ0NzMjJibcYSmlVCfJ\nzu73e5o8Hq46cICrDhwIWMasW9frPi6//HK++c1vcvPNNwPw7LPP8uqrr3LrrbeSkJBAZWUla9as\n4aKLLsLqydrTI488QmxsLAcOHGD37t0sW7asc9umTZsYP348brebc845h927d3PrrbfywAMPsG3b\nNiZMmNBlX++//z5PPvkk7777LsYYVq9ezVlnnUVycjKHDh1i69atPPbYY1x22WU8//zzXHXVVUGe\nLTXYwnEN6/Wr+qOv9WL74mn1UHBHgTXlmh+ODAexc2I7vw/1Oq9KKcuYbrEFSFqt42yVUqq7pUuX\ncuzYMcrKyvjoo49ITk5m8uTJ3H777SxatIhzzz2XI0eO4OylVe2NN97ovEFftGgRixYt6tz27LPP\nsmzZMpYuXcq+ffvYv39/r/Fs376dSy65hLi4OMaNG8ell17Km2++CcCMGTNYsmQJAMuXL6ewsPAk\nP70a6fT6VR16m8ypY3v3cbF5G/J6lAuk+XAzH57+ISU/LQEBsXd9UBJo9mFtjVUq9MZ0iy1A/Op4\nlmyF7WdYie2X09L6fpNSSg2RvlpWM3NyKHL17P6W4XBQuHbtSR37C1/4As899xzl5eVcfvnlbNmy\nhYqKCt5//33sdjuZmZm0DGBG+YKCAu6//3527NhBcnIy11577YD208HhOLEWY0REhHblHGbCdQ3r\n9av8LqtzfS4122uInhZNS3ELzqedeFp6rheb/738PpNN51YnB79yEHe9G0e6g1O3nkpLQYu2xCoV\nJmO+xdZ3Aqns6hqMCdCPRCmlhqFNWVnE2rr+KY+12diUdfLrE15++eX84Q9/4LnnnuMLX/gCtbW1\nTJo0CbvdzrZt2ygqKur1/WeeeSbPPPMMAHv37mX37t0A1NXVERcXR2JiIk6nk7///e+d74mPj6e+\nvr7Hvs444wxefPFFmpqaaGxs5IUXXuCMM8446c+owm+wrmG9flX+7X4mc3IZjj56lII7Cji6+WiP\npLaDq8TF7gt2U/ZYGa3OVqBr6+8b497gwJUHcNe7mfC5CazYtYLETyRqS6xSYTTmW2yjp0Uzx2Un\nobaN0kQXh5ubOSU2tu83KqXUMLA+1bpp2pifT7HLRbrDwaasrM7XT8b8+fOpr69n6tSppKWlsX79\nej7zmc+wcOFCVqxYwdy5c3t9/0033cR1113HvHnzmDdvHsuXLwdg8eLFLF26lLlz5zJ9+nROO+20\nzvds2LCB8847jylTprBt27bO15ctW8a1117LqlXWsqo33HADS5cu1W6bo8BgXcN6/Y5dnlYP5U+V\n9zqZ0/TvTCc6PZrCHxTSVtHmt8zxvx/n+N+Pc/ArB4mZFUNLQQumzWoA8TRaCfHkL09mzm/mBByr\nrZQaOjKSWihXrFhh+lpDbiD2XrqXmxdX8sZZsHn2bG6cMiXkx1BKqWAdOHCAefPmhTuMUcffeRWR\n940xK8IU0qjgr27Wazj09Jz2zdPmofy35RRvKqalMHD3cEeGg7WFVjf37t2VwRoXO/P+mYhdqHyh\nkup/VmNa/d8v++5LKRUaA62bx3yLLXi7I+dYie22mhpNbJVSSimlhrEuMxlPd5D8qWRq/lVDS4GV\n0MbOiyXpnCTKnyjvkbT6TubU1wzFU26YQntdO9uTtvud9bi3VmGl1NDSxBZIWJ3A0oetr7NrrHG2\n2qVEKaWUUmro9bX8To9JoYpdlP+mHICYOTFk3pXJpMsmIRFC4prEPidzSl2f2utY2MiESBzpDmvm\n5G4c6Q4/71BKhYMmtsC45ePIKIHkajia3MrB5mbm6DhbpZRSSqkh5W8m47wb82jY04BjmoPmvGaO\n/sb/pE+RKZGs2rcKiTjRONFX0hqsrE1Zfrss+1vKRykVHprYApHjIhm3MI7FuxrJPhu2VVdrYquU\nCivtORI+qai9AAAgAElEQVRaI2k+idFCr+HQGUvXb/7GnjMZe5o9lNxX0ud724+3d0lqQ6mvLstK\nqfAb88v9dEhYncDSD62vs2tqwhuMUmpMi46OpqqqakzdzA4mYwxVVVVER0eHO5QxQ6/h0BlL129L\naYvf7r4d0m5II+unWdgn2v1uH+xuwbqUj1LDm7bYeiWsSWDJXUcBHWerlAqvadOmUVpaSkVFRbhD\nGTWio6OZNm1auMMYM/QaDq3Rfv22VrZS/JNijvz6SMAyjgwHcx6bY32d5tBuwUqpHjSx9UpYncD0\nEkipAWdSGweamjg1Li7cYSmlxiC73c6MGTPCHYZSA6bXsPKn+6RQGXdm0FraSsnPSnDXuwGIXx1P\n40eNXcbQ9ncmY6XU2KSJrVfs3FgiEyJY/L6bf59jLfujia1SSiml1MnzNynUwRsOdm4ff954Zmya\nQfyy+D5nRYbQTQqllBo9NLH1EpuQsCqBpR9W8+9zrO7IN0+dGu6wlFJKKaVGvPzbe04KBSAOYfFr\ni0k6M6nzNU1alVIDoZNH+YhfHd9lAimPTnqhlFJKKdUn5xYnOZk5ZNuyycnMwbnFiTGGuh115H/P\nan31x7SaLkmtUkoNlLbY+khYncCUTRDfBJWxbUS+/jrpDgebsrJYn6pPDpVSSo0eIvIt4AbAAHuA\n64BY4I9AJlAIXGaMqQ5TiGqE8NfNOPfaXA7echB3tbvX9w72TMZKqbFjUFpsReQJETkmInsDbF8v\nIrtFZI+IvC0iiwcjjv5KWJ3Av86BRu/fWAMUuVxsyMtji9MZ1tiUUkqpUBGRqcCtwApjzAIgArgC\nuA34lzFmFvAv7/dK9crf2rOm3eCudhM1NYqpt0xl+sbp2GK73nbqTMZKqVAarK7ITwHn9bK9ADjL\nGLMQ+BGweZDi6JeoSVE8/lXwRHR9vcnjYWN+fniCUkoppQZHJBAjIpFYLbVlwMXAb73bfwt8Nkyx\nqRHC3eIOvPaswNritcx6aBYz75nJnM1zcGQ4QLzL92yeo2NplVIhMyhdkY0xb4hIZi/b3/b59h1g\n2CzO5kzx/3qxK/CC4UoppdRIYow5IiL3A8VAM/CaMeY1EUk1xhz1FisH/GYdIrIB2ACQnp4+FCGr\nYcYYQ8VzFRz+n8MByzjSHYhNOr/XSaGUUoNpOEwedT3w93AH0WFKm/9cP92hY0CUUkqNDiKSjNU6\nOwOYAsSJyFW+ZYwxBmtUTg/GmM3GmBXGmBUTJ04c9HjV8FK3s45dZ+5i/2X7cRW5iJoWhTikSxnt\nZqyUGmphnTxKRM7GSmxP76XMkD4Vvjt2Kl9vKMIVfeK1GJuNTVn6x1kppdSocS5QYIypABCRPwOf\nAJwikmaMOSoiacCxcAapws93TdmoKVFEZ0VT92YdAPaJdmbcM4O069M49odjfa49q5RSgylsia2I\nLAJ+A5xvjKkKVM4YsxnvGNwVK1YM+vo7X16ZQeHFRfzmWnBOtl47IyFBZ0VWSik1mhQDa0QkFqsr\n8jnATqAR+BJwr/f/l8IWoRp0vkmrv2S0fEs5B288iKfZmhiq9UgrrUdaIQKmf3s6GbdnEJlo3Upq\nN2OlVLiFJbEVkXTgz8DVxpiD4YghEJvDxoWHHJz7RRcFM+DLT8Dr1bUccbmYqt2RlVJKjQLGmHdF\n5DngA6Ad+BDrIfI44FkRuR4oAi4LX5RqMAVaoufIo0ew2W24Slw0f9zs971RqVHMvG/mUIarlFJ9\nGpTEVkS2AuuACSJSCtwF2AGMMY8C3wdSgIdFBKDdGLNiMGLpL+cWJ63FrQDMKICzsuH1dYbv/yOX\nxz89LFYlUkoppU6aMeYurPrZlwur9VaNcoGW6KnbXtfne1uPtg5WWEopNWCDNSvyF/vYfgPWovDD\nTv7GfEz7iR7PX/otvHEm/M5RzQ+11VYppZRSo4CrOPBqD4teXYRjuoPd/7kbV0nPco50vRdSSg0/\nw2FW5GGl+x/6GYVw1uvQZoefFBWFJyillFJKqRAp/VVpgPmurfVlx39qPHHz4sj6SRa22K63ijrb\nsVJquNLEtht/TyGveRrEA48dPUppS0sYolJKKaWUOjnGGAruLODjWz4GQOy9L9GTuj6VOZvn4Mhw\ngFhJ75zNc3SSKKXUsKSJbTdZm3o+nZx5zMZFLQm0GsNPiovDFJlSSiml1MB42j0c3HCQonuKIALm\nPDGHuU/O7TNpTV2fytrCtazzrGNt4VpNapVSw1ZY17Edjjr+YOffnt/ZLXnKTVPYdFYaf9mxg98c\nPcpt6elMj47ubTdKKaWUUsOCu9nNgSsPUPliJbYYG6c+eyoTPj0BQBNVpdSooS22fqSuT2Vt0Vqy\nfmp1x2nc08j8uDgumziRVmO4V1ttlVJKKTWMObc4ycnMIduWzfbk7VS+WElkciSL/7m4M6lVSqnR\nRBPbXqR9OQ1bjI3q16ppzG3k+5mZCPCbo0cp0bG2SimllBqGOtaodRW5wIBxGRCY/t3pJH4iMdzh\nKaXUoNDEthf28XZSr7a66Bz51RFOjYvj8kmTdKytUkoppYYtf2vUYqDskbLwBKSUUkNAE9s+TP36\nVADKnyqnvbadOzMytNVWKaWUUsNWoDVqe1u7VimlRjpNbPswbuE4ks5OwtPoofypck6Ni+OKSZNo\nM4Yfa6utUkoppYYZe6rd7+v+ljRUSqnRQhPbIEy9xWq1PfKrIxiP4c6MDAAeLSvDlp1NZk4OW5zO\ncIaolFJKKQWAfWLPxLb7GrVKKTXaaGIbhJTPpODIcND8cTPH/+84HzQ0EOHdZoAil4sNeXma3Cql\nlFIqrGrerKFpTxPiEBzTel+jVimlRhNNbINgi7Qx9WtWq23pQ6VszM/H3a1Mk8fDxvz8oQ9OKaWU\nUgowxlBwRwEA6d9NZ23JWtZ51rG2cK0mtUqpUU8T2yCl3eBd+ufVaopd/idfCPS6UkoppdRgq/5X\nNbVv1BKZHMn0/5oe7nCUUmpIaWIbJPt4e+fTzrTGCP9lRMhvbh7KsJRSSimlrNbajVZr7fTvTCcy\nMTLMESml1NDSxLYfOiaRuv4RD7HS9dQJ0GoMS3bu5Hfl5RhjwhChUkop1TcRmSMiu3z+1YnIN0Xk\nbhE54vP6BeGOVQWn6uUq6t+rxz7JzrRbpoU7HKWUGnKa2PbDuEXjSDwrkf/4m+HeoglkOBwIkOFw\n8MisWXxuwgTq3W6uyc3lygMHqGlrC3fISimlVA/GmDxjzBJjzBJgOdAEvODd/POObcaYV8IX5djj\n3OIkJzOHbFs2OZk5OLcENyml8RgK7vSOrf1eOhFx/nuWKaXUaKb9VPpp2q3TqH29llX31FOQuwax\nSee2DVOm8GR5ObceOsQfjh3j7dparklN5XdOJ8UuF+kOB5uyslifqhM4KKWUGjbOAQ4bY4pEpM/C\nanA4tzjJuzEPT7MHAFeRi7wNeQB9TvxU8XwFjR81EjU1iilfnTLosSql1HCkLbb9lHJRCo7pDpoP\nNXP81eNdtokIX05L48MVK1gZH0+xy8U9xcUUuVy6LJBSSqnh6gpgq8/3t4jIbhF5QkSSwxXUWNJ4\noJG8r5xIajt4mjzkb+x9xQXjNhR+vxCAzDsziYjW1lql1NikiW0/2SJtTL3ZGmt75KEjfsvMio3l\nraVLSYjoWbnoskBKKaWGCxGJAi4C/uR96REgC1gCHAV+FuB9G0Rkp4jsrKioGJJYR6Pad2rZ89k9\n7Dh1B55Gj98yruLeV1xwbnHSlNtE9IxoJl83eTDCVEqpEUG7Ig9A2g1p5N+Rz/H/O062LRtHuoOs\nTVldugrZbTbq3d1Xu7XoskBKKaWGifOBD4wxToCO/wFE5DHgZX9vMsZsBjYDrFixQmdL7INzi5P8\njfm4il04pjuYeNlE6t+rp/aNWgDEIdjsNtwNPe8bIpMiMcbgr5u4p81D4d2FAGTelYktStsrlFJj\nl/4FHIDj/3ccOqpxc2IcTPdJHtIdDr/vnxIVNcgRKqWUUkH5Ij7dkEUkzWfbJcDeIY9olHFucZK3\nIQ9Xkcu6Zyh2UXp/KbVv1BKRGEH699JZW7SW2Y/Oxhbb87asvbqdQ18/hKe9Z4tu+ZPltBS0EDMn\nhknrJw3Fx1FKqWFLE9sByN+YD90eqvobB7MpK4tYW89T3Oh2s7+xcTBDVEoppXolInHAJ4E/+7z8\nvyKyR0R2A2cD3wpLcKNI/sZ8PE09k9LIpEjWFq8l68dZRKVGkbo+lTmb5+DIcICAI8PBlJunIA6h\n7OEy9l68l/aG9s73u1vcFP2oCIAZP5yBLVJv6ZRSY5t2RR6AQONdur/eMfvxxvx8il0upjkcxNps\n5DU3c8aHH/LKokWsTkgY9HiVUkqp7owxjUBKt9euDlM4o1age4b22nYiE7rehqWuT+0xA3LqF1PZ\nc/Eejr9ynF1n7GLhywtxTHVw9P8dxVXqIm5RHBM/P3HQ4ldKqZFCE9sBcKQ7rC5Ffl7vbn1qapfl\nfZrdbi7fv5+/VlVxzq5dvLBgAZ8cP35Q41VKKaVUeERNjqL1aGuP1/3dM/iTeFoiy3KWsefCPTTs\nauC9Be9hc9hoc7YBkHxucpelB5VSaqzSfisDkLUpy+84mLQb0/yU7iomIoLn58/n6tRUGj0eLtyz\nhz8dOzYYYSqllFIqjDxtHiSqZ9Jpi7WRtSkr6P3EzoplWc4yYmbH4K5xdya1AGWPlvWY40MppcYi\nTWwHoPs4GNs46zSWP15OW3VbH++2Zkx+au5cvjltGm3GcNn+/aRs344tO5vMnBxd51YppZQaBYp/\nUoyryEXkhEgc00+MnZ2zeU6PLsd9safYe6xzC8GtdauUUmOBdkUeIN9xMO4WNx+e/iEN7zeQ+6Vc\nFry4oM9uQTYRHpg5k9KWFp6rrOR4uzUhRJHLxYa8PIAuXZiVUkopNXLUf1DfObnT/Gfnk3x28knv\n01Ua3BwfSik1Fg1Ki62IPCEix0TE7zIBYnlIRD4Wkd0ismww4hgqEdERzH9uPpHJkVT9tYri+4qD\nep+IsKO+vsfrTR4PG/P16atSSik1EnlcHnK/lItpN0y9dWpIkloIPC432PG6Sik1mg1WV+SngPN6\n2X4+MMv7bwPwyCDFMWRiMmOY97t5ABTcUUD1tuqg3lfs8v+Utcjl4gM/Se9Q2uJ0kpmTo12klVJK\nqX4ovLuQxr2NxMyKIesnwY+l7Yu/OT76O15XKaVGq0FJbI0xbwDHeylyMfC0sbwDJHVbFH5ESrkw\nhfSN6eCB/Vfsx3Wk765B6Y7AT1mXv/8+V+7fT35zcyjDDMoWp5MNeXkUuVwYTnSR1uRWKaWUCqz2\nnVqK/7cYbDD3qblExEaEbN/+1rodyHhdpdToNZYbpsI1edRUoMTn+1LvayPejB/MIOmcJNqOtbHv\n8n142npO9OBrU1YWsbauP4YYm40LkpOJEmHrsWPMfe89vnHoEI8eOTJkF+rG/HyaPF1j1y7SSiml\nVGDuJje5X8oFD0z/7+kkfiIx5MdIXZ/K2sK1rPOsY23hWk1qh5nhmlQEE1coYw/HeQjlZxyO+wq2\nzFA3TA2na37YTx4lIhuwuiuTnp4e5mj6JhHCqVtPZefSndS9VUf+bfmc8rNTApbvmCBqY34+xS4X\n6Q4Hm7KyWJ+aSlFLC98vKOB3TicPHTnS5X2DPclUoC7SgV5XSimlxrqCjQU0H2wm9tRYMn+QGe5w\nFNZNt797rME61oa8vM6GgZO9Vwsm9mDLdI/rxrw8KlpbWZeURE17Oy9VVvJwWRmtxnSWuSEvjzaP\nh2vT0vp1zP6ch8H8jN2PGeg8NLa3c/HEibR5PLQZw/MVFdxZWEhLP/flW8ZtDNVtbfy2vJyNBQW4\nfM7rjXl5YAzrJ08+qdg3ePdzXkoKJS0tlLhc3HLokN+Gqe8cPszlEycS6W1MC/b3IpQ/66Egxnui\nQ75jkUzgZWPMAj/b/h+QbYzZ6v0+D1hnjDna2z5XrFhhdu7cOQjRhl5tTi27ztyFaTdEToikvaod\nR7qDrE1Z/X66uruhgdUffND5C+Yrw+GgcO3aUIUNgDGGhO3baXC7h+R4SikVLiLyvjFmRbjjGMlG\nUt08mGper2HX2bvABsvfXU788vhwhzTmbSkv54aDB7vcP8XabGyeMyfkN91uY0h7+20q2nou+xgf\nEcGTc+fyiYQE0rxD0PqbMPiL3V+ZGJuNOzMyWDRuXGey84vSUhr93EMGa0Z0NHNjY5kTG0ttezvP\nOJ2diRqAQ4QrJ01iWnQ0ZS4XW44d83vPGiXCJ5OTGW+3k2K3U9LSwl+qqmjrtq9bp07lk+PHYxNh\n2/Hj3F9a2uV4USJcOmECGdHRHG9v53hbGy9XVXUp00G8580DNJ/EOejYV1pUFEmRkRxubvZ7vEhg\nXGQkNd7VTnozNSqKSVFRHGhq8nu+4iMiuD4tDbcxPFle7ve+XIBgMzm7CLNiYoi12djV2Ei7T/zR\nItyRkcFnJkwgQgQb8EpVFXf4JPgd+/hkcjLxERGUuFy8W1dHz6hOPl8YaN0crsT2QuDrwAXAauAh\nY8yqvvY50irP/Vfv59jvj3V5zRZrG9B4GFt2tt8LVwDPunUDjtGfB0pK+Pbhwz1jAJ6eO7fzCZNS\nSo10mtievJFWN4eac4uT/O/l4yqxejSlXJLCwj8vDHNUQy+ULaMDbcW7fOJEPmxoYHttLW/W1vJS\nZSX+UplxERE8MmsWn0hMZEZ0NM8cOzbg2J2trTx+9Ciby8ooCqJXW2Z0NGl2OzsbGrokdFEiXJyS\nwtToaCpaW3m+stJvshMBTHE4iBChtKWFvtOn3i2MiyMpMpI3a2tPck8j20S7HbsIUTYbhS0tIdln\nUpAJ7slKiIhgusPB9OhottfU0BDguvGXgA6Wk81PBlo3D0pXZBHZCqwDJohIKXAXYAcwxjwKvIKV\n1H4MNAHXDUYc4Vb7Rs8/Eh0Lqfc3sU13OPz+wYwSoaSlhenR0QOO09fzFRX8tzep/fqUKfy1qopi\nl8u6QIEoW7iGZSullFLDi3OLk7wNeXiaTtxIVr9ajXOLc0yNfQ22O2JQCWt5OTcePNjZutbRJba0\npYULU1IA+FtVFXcXFXXpKnrNgQN8+cABWoOIt8Ht5urcXAASbDYaPZ7Om35/XUX9xT/JbicrOrpL\nghoJfhPNxIgIViUk8E5dHYUtLX4Tp1Zj+FNlZZ+xu4GSIBLoTyUndyY7vywtpcpPgpXhcLB75UoA\nMnNy/N5npjsc/N+iReQ1NZHb1MT3CgoCHvP7GRlMcTi4s6DAb8t1qt3O5jlzqGpr43h7e+f9pj/n\nJifjNoZtNTUBy2yaMYMUu53xkZF8/dAhjvk55nSHg30rVxIhwtz33vN77rq3LgY6F9MdDt5eupSa\n9nbO/egjnH6ONyUqio9WrCDZbidCpNd9vbl0KRWtrVy4Z4/f2JMiI/l+RgYRItxdWEi1n5/hdIeD\nYp/Ye2vp/+yECRxsamLZ++/32E+HBXFxeIzBbQx5vUxe+7u5c5keHc2V+/dT1trzt663yXEH06C1\n2A6GkfZUONuW7b9/gMA6z7p+7cvfhdohOTKSzbNn8/lJkwYUZ4d3ams5+6OPaPF4+MmMGdyWkdG5\nbXNZGV85eJBpDge5q1YRFxG6WR6VUipctMX25I20ujmUcjJycBX3vGl1ZDhYWzg6hu0Eahnd19TE\njro6dtTX82R5eZfWxw42YPG4cUx1OGhsb2d7XV2XcnYRzkhIID4ykvLWVpxtbSfdWjYrJobTExM5\nIzGROwoK/N50J0VGcmZiIm/X1VHpJ6HokOFwMDkqitSoKOr9xN/h4pQUbpo6lYrWVr5y8GDA7sNu\nY9jX2MjiXn5f7p85k4l2O/9z+LDfZGdqVBRvLVuGxxhO//BDv5+ve6I20G7N/rptB0rUfI8Zyn0F\nUybUn3E47ivY43WU7e0BUrDnNJQ/6/4aVi22yuJId+Aq8lPhTe//Uwx/k0x9Nz2dV44f5+WqKr6w\nfz/XHT/OQ6ecwrjI/v9Y85ubuWjvXlo8Hm5MS+O73Sbquj4tjc1lZbzf0MCPi4rYlKVr5imllBq7\nPG0ev0ktEPD1kcZfS+w1Bw5w3YEDBE4HT/AAHzY08GFDg9/tbcbw7350gZ0fGwvAvqYmv9sFOLh6\ndef3UTab35vuX82axfrUVIwxRLz+esAxikUuV5/di6dGRfHiwhNdz0UkYFIRIcKicePICNALL8Ph\n4NvTp3eW9Rf7fTNnkuHtpfe/M2f6LdP9Hq23iUr7Uwas1Tz6OmYo9xVMmVB/xuG4r2CP11G2t6Qy\n2HMayp/1UNEW20Hkr4sSwMTLJzL/D/NDcgxjDI+UlfHtw4dp8XiYZLdjA5xtbUFfXMfb2vjEBx+Q\n19zMfyYn89eFC7H76XL8Tm0taz/8kCgR9q5cySxvBaOUUiOVttievJFWN4dCW3Ub+y/bT/U/q/1u\nHykttv5adq6YNIm9jY1sr63lO4cP++0pBpAVHc3K+HhWJiTw0+Jiv90yp0ZF8ecFCyhzubhk376A\ncTw3fz6To6KYHBXF2bt29dldNNgWp0CfMZjWq+kOB9lLllgtya2tXBog/oGMJexPa18oZgwOteEw\nnjpcidNoEapZkQfLsJs8ajCMxMrTucVJ/sZ8XMUuIlMiaa+0+sfPf34+Ey+dGLLj7Gts5PyPPqKk\nW5eUvroDuDwePvXRR7xRW8uiuDjeXLqUhF5afL+cm8uT5eWcP348f1u4EBEJ2WdQSqmhNlYTWxGZ\nA/zR56Us4PvA097XM4FC4DJjjP/szWsk1s0no+lQE3s+s4fmvGZs8TZMq8G4TtxLDXSSyKHmL7my\nYc1K29zHvWH3ZC6YRC0cXUqDEcpus/09riZrSvk30LpZZwIaZL4LqZ9ecTpZ91rN9weuOkDdjrqQ\nHWd+XJzfJLPJ4+HGvDx+UVrKRw0NeLyV1Rank4ycHKLfeIM3amtJiojgbwsX9prUAvwkK4vEiAj+\n7u0CrZRSauQxxuQZY5YYY5YAy7EmcnwBuA34lzFmFvAv7/fKqzq7mg9Wf0BzXjNxC+NYtWcVcx+f\niyPDAWK11A6XpHaL00lmTg627Gwyc3LY4nQC0Ox2s626mpu7jQUFq+twszFkOBysnzSJ8QHuCbpP\nDLM+NZXNc+aQ4XAgWMle98RwU1YWsd16gwXqUtrXvoIpE6xg9xVs/P05buHatXjWraNw7VpNapUK\nAW2xHWLGGPJuzKP88XLsqXaWv7uc6IzQzGgcaEkgX+MjI8mKjuajxsYuEyBEi/CbuXOD+sP6UGkp\n3/j4Y2ZER7N/5UqidSIppdQINVZbbH2JyKeAu4wxp/muKy8iaVhrzs/p7f2joW4ORtlvyjh00yFM\nuyHl0ynMe2YekfHDc6oSf62QdhFmREdT2NJCay/3fr6tsaGeGGakt1KO9PiVGil08qgRQkSY/chs\nWgpaqPl3DXs+vYel25cSmXjyP4pASwKlREZyYUoK22pqKHG5OO5nEocWY9iYnx/UH+ivTZnCY0eP\nsrexkZ+WlHBnZuZJx66UUipsrgC2er9ONcYc9X5dDozZu3bfoUQR4yJw11sLwkz79jRm3jcTiRi+\nQ3E25uf3aI1tM4aDzc0IsDgujvyWFurdPVe29G2NDfXEMH1NajPcjfT4lRrttCtyGNjsNuY/N5/Y\nubE07m1k3+X78LT7n5yhPwJ1k/nFrFn8dt48itas4bDPbIHdFQexLhpApHdGQYAfFxdT2Ms6V0op\npYYvEYkCLgL+1H2bsbp0+W3aE5ENIrJTRHZWVFQMcpRDr2PyR1eRCwydSe3kGyZzyv2nDOukFgLX\n5wJUnXYau1au5JHZs4PuGqxdZpVSI4EmtmFiT7az8G8LsU+wU/1qNW8lv0W2LZuczBycW5wD2mdf\n40REhKyYGDICLJrcn8WUz0pK4ouTJtHi8fDtXhbYVkqNPIHG5oX7mOGIaww4H/jAGNNxMp3eLsh4\n/z/m703GmM3GmBXGmBUTJ4ZuIsThIn9jfo8VDQCq/9HrPFrDxrgAQ4TSHQ6S7XYgtONUlVJqONCu\nyGEUkxXDlJunUPSDItwN1tNgV5GLvA15AAOafCKYbjLBrl/Vl5/OnMlfKiv5c2UlqW+9RUU/lhhS\nSgUvlNPy91XG37qVG/Ksv0kDWYIh2DJ9HbM/cal++SInuiED/AX4EnCv9/+XwhFUuIVrfdpQjOHc\nVl3tt4txoNZY/f1RSo0WOnlUmOVk5lhdnboZ7DXwQjUBwhX79vHHbt3QTmZiCWUZyRNUjIXYQ7nu\nXn8TTQi83qG/cr845RT+IzmZqrY2/nTsGL84cqTLxDGRIpyZkMC06GiaPR5erqqi2c+6lXE2Gxum\nTCEpMpLkyEj2NzbyZHk5Lp99OUT4+tSpfCIxEZfHQ3ZNDU+Vl3c5nl2Ei1NSmB8XhxtoN4aHjxyh\nzs+NeJQIs2JiqHO7KXW5/PaJHehSGx3G8uRRIhIHFANZxpha72spwLNAOlCEtdzP8d72Mxrr5u0T\nt3cuz+drMOvmUEzUVNvezqIdOyh2ubg0JYX3GxpG5N9ipdTYpuvYjlDZtmz/I5gE1nnWDXE0/ZeR\nk+N3LM90h4Pift5sjuSEKJS2OJ3cmJfXJbkYKQ8LwjGDZigSSI83ufrvw4e7JGpR3kTtwpQUYm02\n4iIi+Gd1NRsLCrr8fGJsNh465RQumzQJAzzrdPKNw4d7lNk0Ywbnjx9PmzG0GcPLlZX8uLi4yzE7\nEr/MmBhq2tt5xunsMQlMR2yLx41DAJsIH9TX9zrT6WjVfT3Nfr9/DCe2oTLa6uamg03sWLSjy9q0\nMPjr0057+22OdFuLHvr38Oa63FyeKi9nRXw8by9dit2mI86UUiOPJrYjVKAWW/tkO6cdPS0MEfVP\nb0sMrUtK4rzx4zlv/Hj2NjSwsaDgpFulgjVSk2Rnayuz333Xb+vVRLudgjVriPOOnQrlZzzZ5LDN\n45+HDnkAACAASURBVKGwpYXTP/yQY21tPd6X7nBQ5HNjFmzC2j3BjxbhjowMLp4wgSibjVeqqrjd\nT5LZkUC2ehPIv1ZWcm+3BDICmBMTQytQ3MfyFyNdusNBit3Oh35mRO/w5Jw5xEREcMuhQ1T4+RmO\nj4zk9owMatrbqW5r49dlZQH3dcmECUSJ9OjN4ev7GRlEiBApwk9LSqhp79k6lmq384/Fi0mIjOT0\nDz+k1M9DNG2xDb/RVDe7m9x8sOYDGvc0Er8qntbyVlwlLhzpDrI2ZQ1KUnu8rY2fFBdzf0mJ3+3B\nPrx5saKCS/btI9pm44Ply5kXFxfaQJVSaohoYjtCdcy82H2SCts4G8t3LCdu7vCumDJzcvwuMdSX\nCGBRXByxEREcb28nr6kJf/NCp0VFcWTtWkSCn4FyJCbJhc3N/LSkhCfKy2nx0zrXIdpm49zkZFLt\ndp45diyoVt3e4m9xu3m0rIzb8vN7tFRen5bGGYmJRIhgA96qreWRsrIu5WxYy0kdb2+nZyre1ZqE\nBJaMG4fL42Gr00mL7zrKNhtfTUtjssNBXlMTeU1NvFNX5/eaCIezk5JodLtpdLvZ19QUsFy896GD\nv/FtHWbHxGAXwW6zsauXRPPerCwSIyK4s6CASj9J32S7nRcXLsQYgwe4dO9enH4SUt/EL9Dvq2+Z\nYH9/gtlXMGWCPWaof687aGJ78kZL3WyMIffaXJxPO4mZHcPyHcuJTBi8qUia3G5+UVrKfcXF1Pby\nN6P7g0F/jrW2smDHDira2njwlFP4xrRpoQ5XKaWGjCa2I5jvWnmO6Q4ikyJp3N2IY7qDpW8vJfr/\ns3fn8VFX9/7HX5+ZJJOEYIAAIQIBopiIIosIoq2XXmtdbutSbWtLW/W2Umu1e6vWtva2pdVWb5db\nW4tLtbe0tnWptNdrrb2X258aREB2CEtIIAGSEAjZyGSZ8/tjJhiSmawzmUzyfj4ePJg5c77f72e+\ngTn5zNmmpMY7xIgi/bL5ozPOYGxyMi8dPcpThw/3mPR056y0NG6YMIHrJ0xgXkYGv62sjJioNQcC\nTF+zhkNhhnNNTE7mjfnzmeLzkRQantVd0lfX2soj5eV8o6TklGQuzePh0T4mkJHqfPr009na2Mjv\nKipO3qM0jyfsHMcUsx57FTO9Xr6am0tSqCdsY10dT1dV0dIpGZ2ckkJjIEB1mISpP4zg8POK5uZT\n7lWszEpPp9k59nSz1dRZaWmkeDykmLEhQgJpwLYLLiA3NZVz1q7tVRIWzYQumolmNJPD/iz4NJDr\n9eWa0f6SSYntwA2XtvngowfZtWwXnjQP89+YT8bsjKidu+O/3ak+H5eOHctLR4+ebKsuGzuWSzIz\n+f7+/V2mHswfNYrX5s8nNcJKx845rtu6lReqq/nnMWP425w5ePrwZbCIyFCjxHYYaWtoY9Nlm6gt\nrCX97HTm/b95JGclxzusiHr6ZTPScGUDVs+dS1ZyMpdv2hR2bpEHTum1G5+URE1bG62d5iTOz8ig\nrq2NXSdOnPJaOElm5Pp8pJpRdOLEKUm3h2BPWH0gEHY4cDsvcNm4cZw3ahTnZWRwoKmJ75SW9vmX\n/I7n+0h2Nnfl5rKxvj5iMnDpmDH8pbqaW3ft6vY99laSWbf368aJE2lzjoBzPHvkSNg6Bpy45BJ8\nHk+3X3ScmZ7Oxvr6breH+tzkyeSnp5Ofns7Hd+zocb7ZcEggo5Vo9rbeYA9hH+rTApTYDtxwaJvr\nNtSx4aINOL+j4NcFTPrYpKidu7vP/vMzMrg/L493jxt3sm77/5fs5GRqW1tpdI7Lxo7lT+eeS3qY\n5PbJQ4e4paiI07xetoS+qBMRSWRKbIeZlqMtvHXJWzRua2T0otHMeWUOSRmJuTvTQJKKR2bO5PTU\nVJ6tquL5I0c4HCbR6cgAb4RkzWdGVnIyB3s4R7tUj6fbYcG9kWTGVJ+P5kCAQ83NYYfWZni9bFmw\ngOlpaSfLekoGIt3TTK+X2ydPptU5Wp3jR2VlYeMy4ODixUxMSSFvzZqoJYcDiT2Ww1OHcgI51BO/\n4U6J7cAletvccqyF9eevp2lfEznLcsj/ZX5Uzx9pkcXxSUlUXHxxt72rm+vruWzTJipbWrgkM5O/\nzJ7N6KS3fxcobWpi9ptvUtfWxlMFBXx8UvQSchGReFFiOwz5y/1suHgD/lI/Yy8fy+xVs/GkJN4K\nh9FKKtqcI/n//i/iYlXrzj+fs9PTef7IkW6v19TWRqnfz9lr10bsST5y8cWMTUpiRoSk7/SUFP5j\n5kw219ezuaGB5yP0ZvZGf1Z1jeY8yGgnh9GKvb2uEkiJJSW2A5fIbbMLOLZeu5XqP1eTMT+Dea/N\nw5safshvf6w5fpzFb70V9rXefvYXNTZy6caNlDc3s3D0aF467zzGJicTcI5LN21idU0N140fz7Pn\nnNOn9ShERIYqJbbDVOOuRt56x1u0VLUwevFomstjv0JjLEQrqYhWr2FvzzXQBDInJYX/N28ePjMW\nR3lV12jNg+ztufpSLxqxiwwGJbYDl4ht88m1LUK7EliasXDbQtJmpPVwZO9sqa/n6/v2saq6OmKd\nvnz27ztxgn/etImSpiZyfT4CcLI9Ge3xsPfCC5mQkhKN0EVE4k6J7TBWt76ODRdvGPQ99YaiaK6M\nOpQX0okmJZEikSmxHbhEa5vD7UZgPqPg8YJ+tacdP2NzUlKY5vOxpq4OB4zyeHj3mDG8XFMz4L3J\ny5qauGD9eg53Wv3cZ8bjBQX6XBeRYUOJ7TD3WvZrtFR23crDN83H4pL+7+GYiOKxf2u0zqUkU2Ro\nUWI7cInWNkfaP74/7WmkhaG8wGcmT+Zr06aRnZIStc/+qYWFMdnPWURkKFFiO8yt9qwm0oTQJYEl\ngxyNiMjwoMR24BKtbY5me5pbWMiBMInm5JQUyi66qF/xdae7XQb6ulaDiMhQ1d+2OfFWIhqhfLm+\nPpWLiIjIqVybw5Ma/lefvrSnrYEAvygvD5vUAr1efb+vcn3hY4xULiIykiixTRB5y/PwpHf6cRlM\n/+b0uMQjIiKSaPZ+dS+BE103XvOke8hbntfj8c45/nLkCLPXreP23bsj1otVork8L490z6m/C6R7\nPCzP6zl2EZHhToltgshemk3+inx803xgYEkGDo79/RiJNJxcREQkHsofKafs38uwJGPqvVNPtqe+\nab6wCzGurKhgemEhntWrmV5YyPKSEt69aRPv27qVnY2NnJGaymcnTx7URHNpdjYr8vOZ5vNhBOfW\nxnoBQhGRRKE5tgmqYXsDGxZtoK2+jTN+dAZTPz813iGJiCQczbEduERom4++fJTNV22GNsh/Ip+c\nW3K6rR9pUSiAsUlJfHPaNG6fPJkUj0eLAoqIRFl/2+akWAQjsTdq1igKnixg2w3b2PvlvYyeN5ox\n/zQm3mGJiIgMKQ3bGtj2gW3QBrn35PaY1ALcW1wcNqkd7fWyZ9EixiUnnyxbmp2tRFZEZAjQUOQE\nNuH6CUy9ayq0wbYPbqOprCmq569YWUHh9EJWe1ZTOL2QipUVUT2/iIhILDVXNLP5XzbTVtvGhBsm\nMOO7M3p13P4Ii0LVt7WdktSKiMjQEbPE1syuMLMiM9tjZneHeT3TzP5sZpvMbJuZ3RKrWIazGd+d\nwdh3j6WlsoVtN2wj4O/6DXN/tG9g7y/1gwN/qZ+iZUVKbkVEhgkzG2Nmz5jZTjPbYWaLzexbZlZu\nZhtDf66Kd5z91Xaija3XbsVf6mf0wtEU/LoA81ivjs1KCj+gTasPi4gMXTFJbM3MCzwMXAnMAj5s\nZrM6VfsMsN05NwdYAjxkZimxiGc48yR5OPt3Z+Ob5qPujTp2fzbyKo19UXxvMYHGU5PkQGOA4nuL\no3J+ERGJu58ALznnCoA5wI5Q+Y+cc3NDf16MX3h913Gk0WvjX6N2TS2+XB/nvnAu3jRvr87x8tGj\nHG1t7VKu1YdFRIa2WPXYLgT2OOeKnXPNwNPANZ3qOGC0mRmQARwFurYk0qOU8Smc+9y5eFI9HFpx\niFezXh3w8GH//vDDsCKVi4hI4jCzTOAS4HEA51yzc64mvlENTOeRRu1fzp7+6dPxTepdT+ua48e5\nbutWAsAVY8eSq9WHRUQSRqwWj5oMHOjwvAxY1KnOz4BVwEFgNPAh51x0xtGOQKPnjyb749kcWnGI\n1qPB7wfahw8DXbYx6E7V81URX+vLBvYiIjJkzQCqgF+Z2RxgPfC50Gt3mtnHgXXAl5xzx+IUY5+E\nG2kEcPCRg0y7e1qPx29raOCqLVtoDAT4WHY2TxYU4LHeDV0WEZH4i+fiUZcDG4HTgbnAz8zstM6V\nzGyZma0zs3VVVZETLoGjfz3apawvw4ddwFHybyVse/+2YH96p1FblmK92sBeRESGvCRgPvAL59w8\noAG4G/gFkEewXT4EPBTu4KHYNg9kpFHJiRO8Z9MmjrW28r6sLB7Pz1dSKyKSYGKV2JYDHTdWnRIq\n6+gW4DkXtAfYBxR0PpFzboVzboFzbsGECRNiFO7wELFRL/UTaOm+M7y1rpVt12+j5FslYJD3gzwK\nnioIbmAf4h3jZcKH9DMQERkGyoAy59wboefPAPOdcxXOubbQCKpHCU4t6mIots2RRhT1NNKoormZ\nyzZv5mBzM5dkZvL7WbNI9mjTCBGRRBOrT+43gZlmNiO0INSNBIcdd7QfuBTAzLKBfEArEw1Ad433\n2vy1HHzsIIHmrgnuib0n2LB4A0f+dARvppfZ/zWb3K/kMmnpJBaXLOaSlktIOzON1spWKn9XGcu3\nICIig8A5dxg4YGb5oaJLge1m1nGT1+uArYMeXD/lLc/rMtLIk+4JO9JoZUUF0wsL8axezdTCQvac\nOMG8jAxWzZ5Nmrd3i0yJiMjQEpM5ts65VjO7A/grwWbmCefcNjO7LfT6I8B3gCfNbAtgwF3OuSOx\niGekyFueR9GyolPmGFmKkTQuiaZ9Tey6dRel3y1l2j3TsFSj5L6SYC+vAQFIL0jn3BfOJf2s9FPO\n60nykHtvLkW3FFH63VKyP5KNeTVES0Qkwd0JrAx9AV1McCTVT81sLsEJKSXAp+IXXt+Mu2Lc208s\n+GVv3vK8LmtMrKyoYFlREY2BYFvZ4hwG3JqTQ2aEbX5ERGToi9kneGiLgBc7lT3S4fFB4D2xuv5I\n1N54F99bjH+//2SjPvHGiVT+oZLS75TSuKORXbftCiazLnRgaD7tlC9N6ZLUdjx36XdKObHrBJW/\nryT7I1oZUkQkkTnnNgILOhV/LB6xREPFbyqgLZjgnvff50Wsd29x8cmktp0DHti/n09PnhzjKEVE\nJFY0iWSYyV6azeKSxSwJLGFxyWKylwZ7V7M/nM0FWy9g1u9nYcn2dlLbrg1Kv1sa8byeZA/TvhZc\nVbL0u6W4ts4nEBERiQ/nHIceOwRAzq053dbd7w+/HkWkchERSQxKbEcQ8xgTPzgR1xo+Ke1p5cjs\nj2Xjm+ajcUcjVc8OjVUwRUREat+opWFrA8kTk8l6b1bYOnWtrXx6164u3+u2y/VpOzsRkUSmxHYE\n6u/KkZ4UD9PuCfbalny7BBdQr62IiMRfe2/tpJsm4Unp+qvNy0ePcu6bb/LIwYN4gOROW/mkezws\nz9N2diIiiUyJ7QiUtzwPT/qpP/pIK0d2NunmSfim+mjc1siR57XWl4iIxFdrXSuVTwdX7M/5xKnD\nkGtaWvjEzp1cvnkz+/1+zs/IYOOCBfyqoIBpPh8GTPP5WJGfz9JsrR0hIpLItPzfCBRpkanOK0eG\n4/F5yL07l92f2U3Jt0sYf914zKMVkkVEJD4qf19JoCFA5jszeX5MHfcWbmK/38/45GRaAgFq2tpI\nMePfpk/ny1OnkuTxMDsjQ4msiMgwo8R2hMpemt2rRDacSf86idLlpTRsbuDIqiNMuHZClKMTERHp\nnfZhyIWfS+crHbbxqWppAeCM1FT+PHs2Z48aFbcYRUQk9jQUWfrMm+ol9+5cAEq/XYpzmmsrIiKD\nr35LPXVv1OHN9PJAztEu2/hAcJ9aJbUiIsOfElvpl5xP5pAyKYX6t+qp/q/qeIcjIiIjUHtvbfbS\nbA40h1/Z/4C28RERGRGU2Eq/eNO8TP3qVEC9tiIiMvjamtqo+M8KIPhla6TterSNj4jIyKDEVvrt\n9E+dTvLEZOrerOP1Sa+z2rOawumFVKysiHdoIiIyzB15/gitx1rJmJ/B6HmjuTs3t0sdbeMjIjJy\nKLGVfvOmexlz6RgAWipbwIG/1E/RsiIltyIiElOHHg0OQ865NbjFT2Vosag0j0fb+IiIjEBaFVkG\npPbV2i5lgcYAxfcW93vVZRERke407mmk5n9r8KR5yP5wNk1tbTxcXg7Af82ezbvGjo1zhCIiMtjU\nYysD4i8LvyiHf78W6xARkdg4/MRhACZ8cAJJmUn8rrKSypYW5mZksGTMmDhHJyIi8aDEVgbElxt+\nUQ7fFC3WISIi0RdoDXD4V8HENueTOTjn+PeyMgC+OGUKZhbP8EREJE6U2MqA5C3Pw5Pe9Z+Rc44T\ne0/EISIRERnOjv7XUZoPN5NekE7mxZm8cuwYWxsayElJ4UMTJ8Y7PBERiRMltjIg2UuzyV+Rj2+a\nDwxSclJInpRMc1kz6xesp/ol7XErIjIUmdkYM3vGzHaa2Q4zW2xm48zsb2a2O/T3kJus2r53bc4n\nczCzk721d06eTIpHv9aIiIxUagFkwLKXZrO4ZDFLAku46OBFLNq5iKyrs2itaWXLVVso/Z72uRUR\nGYJ+ArzknCsA5gA7gLuBvzvnZgJ/Dz0fEipWVvD6lNep/kvwC1NPuodtDQ28dPQo6R4Pnzr99DhH\nKCIi8aTEVqIuKTOJc58/l+nfng7Avnv3sX7hegpzC7XXrYjIEGBmmcAlwOMAzrlm51wNcA3wVKja\nU8C18YnwVBUrKyhaVkRzefPJsr1f3sv3V+8G4OZJkxiXnByv8EREZAhQYisxYR5j+jemM/vPs7E0\no35dPf4Dfu11KyIyNMwAqoBfmdlbZvaYmY0Csp1zh0J1DgNDYt+24nuLCTQGTimrTgnwx5QaDPjc\nlCnxCUxERIYMJbYSU1n/kkXy2K7fogcaA+y+czf1m+txgeAw5YqVFRROV6+uiMggSALmA79wzs0D\nGug07NgF55CEnUdiZsvMbJ2Zrauqqop5sOG2kFt1NTQnw/uysjgrPT3mMYiIyNCWFO8AZPhrPtQc\ntrz1WCvr5qzDm+kldXoqjdsbcS3B36Hae3UhOIdXRESiqgwoc869EXr+DMHEtsLMcpxzh8wsB6gM\nd7BzbgWwAmDBggUxX0TBl+vDX/p2ctucDH8KDZL+4tSpsb68iIgkAPXYSsxF2uvWM8qDb5qPtuNt\nNGxqOJnUtgs0Bii+t3gwQhQRGVGcc4eBA2aWHyq6FNgOrAJuCpXdBLwQh/C6yFueB963n//tMqgZ\nC+c1p3JJZmb8AhMRkSFDia3EXLi9bj3pHvJ/mc/iksVcuP/CiMf6S/24Nq2oLCISA3cCK81sMzAX\n+B5wP3CZme0G3h16HnfZS7NJGhscZOYMnv2IAfDVOTMws3iGJiIiQ4QSW4m5znvd+qb5yF+Rf3KI\ncerU1OBrEaybt45jfz82WOGKiIwIzrmNzrkFzrnznHPXOueOOeeqnXOXOudmOufe7Zw7Gu84AZor\nmmk90opnlAd/5Wz2TXZMTknhAxMmxDs0EREZIjTHVgZF9tLsbufK5i3Po2hZ0SmrXlqK4RntoWFL\nA5vevYms92VxxoNnUPdmHcX3FuPf78eX6yNveZ7m4YqIDGO1a2oBOG3haSwvLwPgzilTSPHo+3kR\nEQlSYitDQnti2jlhHX/9eMp+VMb+7+2n+s/VVP+lGvMarlWLTImIjBTHC4/zyqXw6JdrqTwWwICx\nXm+Px4mIyMihxFaGjEi9utPumcakWyax7+v7OPz44ZNJbbv2RaaU2IqIDE9PNxzhwS+DPzU4qscB\nX9i7l1FJSSzN1me/iIjEcI6tmV1hZkVmtsfM7o5QZ4mZbTSzbWb2f7GKRRKfb5KPgscKIMIaIf5S\nP3Ub6ghuu6g9cUVEhotAa4D/eMcJ/KmnljcGAtxbrJXzRUQkKCY9tmbmBR4GLiO4V96bZrbKObe9\nQ50xwM+BK5xz+81sYixikeGl816GHa0/fz2+aT7SCtI4vvo4zq/hyiIiia5hSwOVEdaI2u8P3x6I\niMjIE6se24XAHudcsXOuGXgauKZTnY8Azznn9gM458JuAi/SUbitg8xnjLl0DCk5KfhL/dT8teZk\nUttOe+KKiCSm2sJaJkb4DSHXF3lFfRERGVlildhOBg50eF4WKuvoLGCsma02s/Vm9vEYxSLDSLit\ngwoeL2DuK3NZXLaYeYXzIh7r369v9kVEEk3tmlo+8RhYpy3N0z0eluflxScoEREZcuK5eFQScD5w\nKZAGFJrZGufcro6VzGwZsAwgNzd30IOUoSfSIlPmMTIvzMQ3LcJwZQfbPrSNad+YRsa5GYMQqYiI\nDFRtYS2zGsFZ8Nt4R7CndnlenhaOEhGRk2LVY1sOTO3wfEqorKMy4K/OuQbn3BHgH8Cczidyzq0I\nbSC/YII2YpdeCDtcOcnAC1V/qGLd7HVs+8A26rfUa5EpEZEhrPlIMyf2nGDD4uDKgddPmEBgyRJK\nFi9WUisiIqeIVWL7JjDTzGaYWQpwI7CqU50XgHeYWZKZpQOLgB0xikdGkLDDlZ8s4MKSC5l8x2TM\nZ1Q9U8W689ax46Ydwd5d9/YiU0puRUSGhto1tQBseldwz9p3jx0bz3BERGQIi8lQZOdcq5ndAfwV\n8AJPOOe2mdltodcfcc7tMLOXgM1AAHjMObc1FvHIyBNpuPLM/5hJ7t257H9gP+X/UQ5tp74eaAyw\n9669pxxbsbKC4nuL8e/348v1kbc8T6sri4gMgto1tbR5YN3M4P61SmxFRCSSmM2xdc69CLzYqeyR\nTs9/CPwwVjGIhOOb7GPmT2dS/rPy4GStTprLmymcWshpF56GpRhVz1Zp6yARkTioLaxlz5lwPCXA\njNRU8tLS4h2SiIgMUbEaiiwy5PlyI2wTYeAv81P1TBWVv63U1kEiInHg2hx1a+tYf37wuXprRUSk\nO0psZcQKt8iUJ91Dwa8LuGD7BeQ/nh/xWH+pn9b61liHKCIyYjVsa6Ctvo23Lg5+TiuxFRGR7iix\nlREr3CJT+SvymfTRSYw6exQ5/5oTfC2CNVPXUPy1YvyHo78/rlZrFpGRrrawFn8KbM4Pzq/95zFj\n4hyRiIgMZfHcx1Yk7iItMtUub3keRcuKCDQGTpaZz/Dl+mja3cT+7+/nwEMHmPTxSaSelcrBhw8O\neJGpipUVp1xT83pFZCSqXVPL1nOhOQnmZmQwPiUl3iGJiMgQph5bkW6E3Tro8QIu3HUh816bx/hr\nx+NaHIceO8S+r+47deugW4s49OtDp5wvUk+sc47mqmZqXq1h92d3n5JIg+b1ikj0mVmJmW0xs41m\nti5U9i0zKw+VbTSzq+IV3/HC42yYH3ysYcgiItIT9diK9CBSr27mRZlkPp9JY1Ej6xasI1DfKRk9\nEaDopiJKvllC2ow0AoEAdYV1uJa3V1jecdMO9n1rH61HW2k92v2cXf/+6A95FpER713OuSOdyn7k\nnHswLtGEtBxt4UTRCdZ/Mfhcia2IiPREia3IAKXnpxNoCER83V/qD/bkhtMGTXuaAPCO9pKen07D\n9oYuPbYAHp+Huo11jJ47Oipxi4gMVbVv1FI7GnadCSlmvCMzM94hiYjIEKehyCJREGnrIF+uj4VF\nCznvpfMiH2yw+OBi3nH8HZz/5vnkr8jvslozQKApwPr569l5y06aypqiFbqIjFwOeMXM1pvZsg7l\nd5rZZjN7wszCdpWa2TIzW2dm66qqqqIeWO2aWt6aB84DF2VmMsrrjfo1RERkeFFiKxIFkbYOyvte\nHulnpTPu8nERV1j25frw5fgwMyD8vN6Zj8xkyhemYEnG4ScPs/astWy+djOFuVo5WUT67R3OubnA\nlcBnzOwS4BdAHjAXOAQ8FO5A59wK59wC59yCCRMmRD2w2sJaza8VEZE+0VBkkShon4NbfG9xxFWR\nw62w7En3kLc8L+z5ws3rnfyZyRTfU0zVH6s4+sLRk+VaOVlE+so5Vx76u9LMngcWOuf+0f66mT0K\n/GXQ4wo4at+oZf3Hg8+V2IqISG8osRWJkp62DupN8tuTtDPSOOcP5/DapNdoqWg55bVAY4CiTxbR\nVNpE5sWZjF44Gm+al4qVFQO6pogMP2Y2CvA45+pCj98DfNvMcpxz7cu5XwdsHezYGnc0Up7WRvkU\nyPR6OT8jY7BDEBGRBKTEVmQQ9ZT89lZLZUvY8kBTgH337gPAkoP77fpL/bjWt1diDtezq+RXZMTJ\nBp4PTYFIAn7rnHvJzP7TzOYSnH9bAnxqsAOrXVPL+vODj981dixJHs2aEhGRnimxFUlA7QlrZ0nj\nk8i+MZvjrx6nflM9TXu7LjIVaAyw69O7CLQEyJiTQf3menbf/vbeuRrWLDL8OeeKgTlhyj8Wh3BO\nof1rRUSkP5TYiiSgSPN1Z/545slktPV4K6+OfTXY79JJW10bRbcURTx/oDFA8deKuyS26tkVkVir\neeM4G74dfHzpmDHxDUZERBKGEluRBNSb+bpJmUkRe3a9Y7yMe8846jfVc6LoRNhr+Pf72fiujYw6\nbxSjZo/CX+7nwAMHCJzovmdXya+I9Ffr8Va2nThBzViYnJJCfnp6vEMSEZEEocRWJEH1Zr5upJ7d\ns3521sljC3ML8R/omvwC1KyuoWZ1TcTzBxoD7PrMLlprWkmemEz9pnrKHioj0KRhzSLSd7Vra1nf\nYRhy+zZoIiIiPVFiKzKM9Wobou+HT35n3D+D9DPTadjcQP2WeipXVoa9RtvxNnbfsTtiDIHGbtbz\npwAAIABJREFUAHu/ule9uiLSI+1fKyIi/aXEVmSYG+g2RFlXZgFw/NXj4Yc1Z3rJ/nA2zVXNHHn2\nSNhrNB9sZs2MNYy5dAyeVA+Hnzjc45BmUAIsMtJUrz3Ops8EH1+qxFZERPpAia2IDGxY88MdhjVP\nLwyb/OKBppImDj9+OOy5A40Bdn9+N8njk0kak0TS2CSO/c8x9n5pb4+rNSv5FRkeXMBRWFNLUxrM\nSk4jx+eLd0giIpJAlNiKSK/0alhzpOT3l2cxatYojr1yjOK7isOev/VIK5uv2NxtDIHGAEXLiqhb\nV0fyhGROFJ+g4jcVOH/3+/RC7xJgJcki8XNi9wnWntUGwLsnjotzNCIikmiU2IpIrw10WPPo+aMp\n/3l52F5dT7qHzIsyaa1ppeVYS9g9eCGY3Jb9uCxiDO3Jb2NRI+lnp5N+djr1b9Wz+47u9+qtWFlx\nSlKuha9EBlfH/Wsv0zBkERHpIyW2IhJVPSW/kXp181fkn3JcpGHNSVlJTLtnGs1VzRx44EDYawQa\nA5R+p7TbOAONAYpuLaJiZQWuzVHzjxpck+tSZ/fnd5N+djppZ6SRlBn8yIxm7696iUWCytfXsONa\n8Dr4J+1fKyIifaTEVkQGVW+GNEPkBHjmT2aerFv5dGXE5Pf0T51O447G4J+djWFjCZwIcPS/j3Yb\nb+uRVtafv/7keb1jvPhL/BAcMYm/1M/OT+ykubKZnFtzSMpI6nXvb1/qKfmV4e7/jtYQ8MIiRjE6\nSb+eiIhI36jlEJFB15vFqgYyp7dj8gtQOK0Q//6uCXDyhGQKflWAJRk7Pr6DlsqWLnU8aR7Szkjj\nxN4TtFa30lrd2qWO8zv2fnEve7+4F0+6h4A/cDLxbdfeQ1z5x0poA9fqqFldc3LP3471dt+5G0s2\nUrJTOL72OKX3lUZtFWklyTLUVKysoPieYl67Nvh/9KJjqXGOSEREEpESWxEZsgY6p7dd3vfCJ8Bn\n/uhMsv4luJ3Rmf9+ZrdDpJ1zNB9qpnBKIZw6Yvkk89kpx3cWOBGg+oXqHt9367FWtn9oe+TztC+i\ntb6O5InJpExIoWF7A+U/Lz85nNpf6qfo1iICgQA5H8sBot9DrCHZMlAd/022z6+d8f2jVDRW6Ocv\nIiJ9Ys5F+A1tCFqwYIFbt25dvMMQkQQUrSQs0txf3zQfF+67kLbaNtbOWkvzweYudZLGJ5G/Ih9L\nMizJ2HnzzrC9xN4ML2MvG0tzRTO1r9cO8J0DHvD4PMHe4TAf+Z5UD+OuGIcn3YP/oJ/aV2txrW9X\ntBRj8h2TGX/1eLyZXpLGJHH05aPs/cLebudKd06kw9Xpa71oJ79mtt45t2BAJxnhBtI2F04v5L/O\n9PPLZXBkIhCAu+6Ha3b5WFyyOLqBiohIQuhv26zEVkSkD3qThEUzoetuEa3cu3JpqWqhpaqFw0+G\n3yN4sFmSkT4rHU+Kh/ot9Se3YurIk+5h/NXjsSQDL1Q9U0WgoWtPtzfTy9QvTcWSjYbNDVQ9U4Vr\ncaecp/M97XO8SmwHbCBt89ffvZoHvwz+DqOPfU3w5Qfhu68siU6AIiKSUPrbNsdsKLKZXQH8BPAC\njznn7o9Q7wKgELjROfdMrOIREYmG3gx/7u0Q6WjOIz72v8ci9iQv2rMI53esLViLvyzMXOOJyZz1\ni7Noa2xj58d2Rnzvme/IpPV4K601rfgPdD0PBOcON2xuiHgOCA6lrny6sts6AG3H2yj5Zkm35ym+\nt1hDVhPYY7edmtRC8Pljt8F34xOSiIgkqJgktmbmBR4GLgPKgDfNbJVzbnuYeg8AL8ciDhGRWOjt\n4le9SbiiNo84QgKctzwPT5IHkiDv/ghzjf/9TCa8fwIA+76+L2KCPO//zTv5PFJPckpOCrNfnI1r\ndmy5egstFV2HWieNT2LmT2bi2hyuzbH3S3tpPdp1US5vppcpd04h0BKIuLVTuEXBpHfMrASoI7jU\nWatzboGZjQN+D0wHSoAPOueOxSqGyqy+lYuIiEQSqx7bhcAe51wxgJk9DVwDdF4N5U7gWeCCGMUh\nIpLworWK9EB6iPOW551yvUj1zvjhGYyeOxqAMx8KvyDXzB/PJPsjb1/Tk+wJW++sh8/qcWsnX66v\n2/siPXqXc+5Ih+d3A393zt1vZneHnt8Vq4vnpvoo9Xf9ueam6ucqIiJ9E6vEdjLQ8ev1MmBRxwpm\nNhm4DngXSmxFRAYsGj3J0RxGPRhDsjsn3DJg1wBLQo+fAlYTw8R2eV4ey4qKaAy8/XNN93hYnqef\nq4iI9E08t/v5MXCXcy5gZhErmdkyYBlAbm7uIIUmIjJyRWsYdTTP1dskWfrEAa+YWRvwS+fcCiDb\nOXco9PphIKY3eGl28PT3Fhez3+8n1+djeV7eyXIREZHeilViWw5M7fB8SqisowXA06GkdjxwlZm1\nOuf+1LFSqKFdAcGVF2MUr4iIDHG9TZKl197hnCs3s4nA38zslJXDnHPOzMK2u9H80nlpdrYSWRER\nGTBPjM77JjDTzGaYWQpwI7CqYwXn3Azn3HTn3HTgGeD2zkmtiIiIxIZzrjz0dyXwPMH1MSrMLAcg\n9HfY5audcyuccwuccwsmTJgwWCGLiIhEFJPE1jnXCtwB/BXYAfzBObfNzG4zs9ticU0RERHpHTMb\nZWaj2x8D7wG2EvwS+qZQtZuAF+IToYiISN/EbI6tc+5F4MVOZY9EqHtzrOIQERGRLrKB50PTgZKA\n3zrnXjKzN4E/mNkngFLgg3GMUUREpNfiuXiUiIiIxEFoO745YcqrgUsHPyIREZGBMecSZz0mM6si\n+A1yd8YDR3qoM1QlcuyQ2PEr9vhI5NghseNX7EHTnHOaJDoAapuHvESOX7HHRyLHDokdv2IP6lfb\nnFCJbW+Y2Trn3IJ4x9EfiRw7JHb8ij0+Ejl2SOz4FbsMpkT+mSVy7JDY8Sv2+Ejk2CGx41fsAxOr\nVZFFREREREREBoUSWxEREREREUlowzGxXRHvAAYgkWOHxI5fscdHIscOiR2/YpfBlMg/s0SOHRI7\nfsUeH4kcOyR2/Ip9AIbdHFsREREREREZWYZjj62IiIiIiIiMIMMmsTWzK8ysyMz2mNnd8Y6nr8ys\nxMy2mNlGM1sX73i6Y2ZPmFmlmW3tUDbOzP5mZrtDf4+NZ4zdiRD/t8ysPHT/N5rZVfGMMRIzm2pm\n/2tm281sm5l9LlQ+5O9/N7EP+XtvZqlmttbMNoVi/7dQeSLc90ixD/n73s7MvGb2lpn9JfR8yN93\nCVLbPHjUNsdHIrfLoLY5XtQ2xyim4TAU2cy8wC7gMqAMeBP4sHNue1wD6wMzKwEWOOeG/N5VZnYJ\nUA/82jl3bqjsB8BR59z9oV9exjrn7opnnJFEiP9bQL1z7sF4xtYTM8sBcpxzG8xsNLAeuBa4mSF+\n/7uJ/YMM8XtvZgaMcs7Vm1ky8CrwOeD9DP37Hin2Kxji972dmX0RWACc5px7byJ93oxkapsHl9rm\n+EjkdhnUNseL2ubYGC49tguBPc65YudcM/A0cE2cYxq2nHP/AI52Kr4GeCr0+CmCH4pDUoT4E4Jz\n7pBzbkPocR2wA5hMAtz/bmIf8lxQfehpcuiPIzHue6TYE4KZTQH+BXisQ/GQv+8CqG0eVGqb4yOR\n22VQ2xwvaptjY7gktpOBAx2el5Eg/yk7cMArZrbezJbFO5h+yHbOHQo9PgxkxzOYfrrTzDaHhkMN\nuWErnZnZdGAe8AYJdv87xQ4JcO9DQ242ApXA35xzCXPfI8QOCXDfgR8DXwUCHcoS4r6L2uYhYDj8\nX0mEzykgsdtlUNs82NQ2R99wSWyHg3c45+YCVwKfCQ3JSUguOL49Yb51CvkFkAfMBQ4BD8U3nO6Z\nWQbwLPB551xtx9eG+v0PE3tC3HvnXFvo/+gUYKGZndvp9SF73yPEPuTvu5m9F6h0zq2PVGco33cZ\nFtQ2x9eQ/5xql8jtMqhtjge1zdE3XBLbcmBqh+dTQmUJwzlXHvq7Enie4BCuRFIRmqfRPl+jMs7x\n9IlzriL0ARMAHmUI3//QXIxngZXOuedCxQlx/8PFnkj3HsA5VwP8L8F5MAlx39t1jD1B7vvFwNWh\neY5PA/9sZr8hwe77CKa2Of4S+v9KgnxOJXS7DGqb401tc/QMl8T2TWCmmc0wsxTgRmBVnGPqNTMb\nFZqwj5mNAt4DbO3+qCFnFXBT6PFNwAtxjKXP2v8jhlzHEL3/ocUGHgd2OOf+vcNLQ/7+R4o9Ee69\nmU0wszGhx2kEF8PZSWLc97CxJ8J9d87d45yb4pybTvBz/X+ccx8lAe67AGqbh4KE/r+SCJ9Tidwu\ng9rmeFHbHBtJg33BWHDOtZrZHcBfAS/whHNuW5zD6ots4PngZwtJwG+dcy/FN6TIzOx3wBJgvJmV\nAfcB9wN/MLNPAKUEV9MbkiLEv8TM5hIcNlECfCpuAXbvYuBjwJbQvAyAr5EY9z9S7B9OgHufAzxl\nwVVePcAfnHN/MbNChv59jxT7fybAfY8kEf69j3hqmweX2ua4SeR2GdQ2x4va5hgYFtv9iIiIiIiI\nyMg1XIYii4iIiIiIyAilxFZEREREREQSmhJbERERERERSWhKbEVERERERCShKbEVERERERGRhKbE\nVkRERERERBKaElsRERERERFJaEpsRRKYmf23md0U7zhEREREROJJia1IP5hZiZm9O95xOOeudM49\nFe84AMxstZl9Mt5xiIiIiMjIo8RWZIgys6R4x9BuKMUiIiIiItKZEluRKDOz95rZRjOrMbPXzey8\nDq/dbWZ7zazOzLab2XUdXrvZzF4zsx+ZWTXwrVDZq2b2oJkdM7N9ZnZlh2NO9pL2ou4MM/tH6Nqv\nmNnDZvabCO9hiZmVmdldZnYY+JWZjTWzv5hZVej8fzGzKaH6y4F3Aj8zs3oz+1movMDM/mZmR82s\nyMw+GN27LSIiIiKixFYkqsxsHvAE8CkgC/glsMrMfKEqewkmgJnAvwG/MbOcDqdYBBQD2cDyDmVF\nwHjgB8DjZmYRQuiu7m+BtaG4vgV8rIe3MwkYB0wDlhH8vPhV6HkucAL4GYBz7l7g/wF3OOcynHN3\nmNko4G+h604EbgR+bmazeriuiIiIiEifKLEVia5lwC+dc28459pC81/9wIUAzrk/OucOOucCzrnf\nA7uBhR2OP+ic+w/nXKtz7kSorNQ596hzrg14CsghmPiGE7aumeUCFwDfdM41O+deBVb18F4CwH3O\nOb9z7oRzrto596xzrtE5V0cw8f6nbo5/L1DinPtV6P28BTwLfKCH64qIiIiI9InmzYlE1zTgJjO7\ns0NZCnA6gJl9HPgiMD30WgbB3tV2B8Kc83D7A+dcY6gDNiPC9SPVHQ8cdc41drrW1G7eS5Vzrqn9\niZmlAz8CrgDGhopHm5k3lEh3Ng1YZGY1HcqSgP/s5poiIiIiIn2mxFYkug4Ay51zyzu/YGbTgEeB\nS4FC51ybmW0EOg4rdjGK6xAwzszSOyS33SW14WL5EpAPLHLOHTazucBbvB1/5/oHgP9zzl02gLhF\nRERERHqkocgi/ZdsZqkd/iQRTFxvM7NFFjTKzP7FzEYDowgmf1UAZnYLcO5gBOqcKwXWEVyQKsXM\nFgPv6+NpRhOcV1tjZuOA+zq9XgHkdXj+F+AsM/uYmSWH/lxgZmf3822IiIiIiISlxFak/14kmOi1\n//mWc24dcCvBRZWOAXuAmwGcc9uBh4BCgkngbOC1QYx3KbAYqAa+C/ye4Pzf3voxkAYcAdYAL3V6\n/SfADaEVk38amof7HoKLRh0kOEz6AcCHiIiIiEgUmXOxGvkoIkOZmf0e2Omc69zzKiIiIiKSUNRj\nKzJChIYBn2FmHjO7ArgG+FO84xIRERERGSgltiIjxyRgNVAP/BT4dGgLHhEZAczsCTOrNLOtEV43\nM/upme0xs81mNn+wYxQREekvDUUWEREZAczsEoJfbP3aOddl4Tozuwq4E7gKWAT8xDm3aHCjFBER\n6R/12IqIiIwAzrl/AEe7qXINwaTXOefWAGPMLGdwohMRERkYJbYiIiICMJng/tPtykJlIiIiQ15S\nvAPoi/Hjx7vp06fHOwwRERkm1q9ff8Q5NyHecSQaM1sGLAMYNWrU+QUFBXGOSEREhov+ts0JldhO\nnz6ddevWxTsMEREZJsysNN4xDCHlwNQOz6eEyrpwzq0AVgAsWLDAqW0WEZFo6W/brKHIIiIiArAK\n+HhodeQLgePOuUPxDkpERKQ3EqrHVkRERPrHzH4HLAHGm1kZcB+QDOCcewR4keCKyHuARuCW+EQq\nIiLSd0psRURERgDn3Id7eN0BnxmkcERERKIq4RPblpYWysrKaGpqincoEpKamsqUKVNITk6Odygi\nIiIiIjICJHxiW1ZWxujRo5k+fTpm1m3dluoW/OV+XLPDUgzfZB/JWUq+osk5R3V1NWVlZcyYMSPe\n4YiIiIiIyAiQ8ItHNTU1kZWV1auktqm0CdfsAHDNjqbSJlqqWwYjzBHDzMjKylIPuoiIiIiIDJqE\nT2yBHpNaAH+5HwKdCgOhcomq3vw8REREREREomVYJLa90d5T29tyERERERERSQwjJrG1lPC9iJHK\n+yIjI2PA5+jJqlWruP/++2N+nXD+9Kc/sX379rhcW0REREREpCcjJrH1TfaBB6r/u5ot79vC+oXr\n2fK+LRwvPB7v0E5qa2uL+NrVV1/N3XffHZdrK7EVEREREZGhbMQktslZydS+Wcv+7+2n+XAzOGg+\n3MzeL+ylYmVF1K7zwx/+kAsuuIDzzjuP++6772T5tddey/nnn88555zDihUrTpZnZGTwpS99iTlz\n5lBYWMj06dO57777mD9/PrNnz2bnzp0APPnkk9xxxx0A3HzzzXz2s5/loosuIi8vj2eeeQaAQCDA\n7bffTkFBAZdddhlXXXXVydfCmT59OnfddRfz58/nj3/8I48++igXXHABc+bM4frrr6exsZHXX3+d\nVatW8ZWvfIW5c+eyd+9e9u7dyxVXXMH555/PO9/5zpMxioiIiIiIxEPCb/fT0Wpb3edjAicC7Pjo\nDnZ8dEfEOkvckl6d6+WXX2b37t2sXbsW5xxXX301//jHP7jkkkt44oknGDduHCdOnOCCCy7g+uuv\nJysri4aGBhYtWsRDDz108jzjx49nw4YN/PznP+fBBx/kscce63KtQ4cO8eqrr7Jz506uvvpqbrjh\nBp577jlKSkrYvn07lZWVnH322fzrv/5rtzFnZWWxYcMGAKqrq7n11lsB+PrXv87jjz/OnXfeydVX\nX8173/tebrjhBgAuvfRSHnnkEWbOnMkbb7zB7bffzv/8z//06h6JiIiIiIhE27BKbOPt5Zdf5uWX\nX2bevHkA1NfXs3v3bi655BJ++tOf8vzzzwNw4MABdu/eTVZWFl6vl+uvv/6U87z//e8H4Pzzz+e5\n554Le61rr70Wj8fDrFmzqKgI9ji/+uqrfOADH8Dj8TBp0iTe9a539Rjzhz70oZOPt27dyte//nVq\namqor6/n8ssv71K/vr6e119/nQ984AMny/x+rSwtIiIiIiLxM6wS2556VgunF+Iv7ZqEpeSksLh8\n8YC3qXHOcc899/CpT33qlPLVq1fzyiuvUFhYSHp6OkuWLDm5z2tqaiper/eU+j6fDwCv10tra2vY\na7XXab9uf40aNerk45tvvpk//elPzJkzhyeffJLVq1d3qR8IBBgzZgwbN27s9zVFRERERESiacTM\nsQXIW56HJ/3Ut+xJ9XD6p0+n9Wj4BLIvLr/8cp544gnq6+sBKC8vp7KykuPHjzN27FjS09PZuXMn\na9asGfC1wrn44ot59tlnCQQCVFRUhE1Mu1NXV0dOTg4tLS2sXLnyZPno0aOpq6sD4LTTTmPGjBn8\n8Y9/BIJJ9aZNm6L2HkRERERERPpqRCW22UuzyV+Rj2+aDwx803yc8aMzyLoyC/9B/4B6PgHe8573\n8JGPfITFixcze/ZsbrjhBurq6rjiiitobW3l7LPP5u677+bCCy+M0js61fXXX8+UKVOYNWsWH/3o\nR5k/fz6ZmZm9Pv473/kOixYt4uKLL6agoOBk+Y033sgPf/hD5s2bx969e1m5ciWPP/44c+bM4Zxz\nzuGFF16IxdsRERERERHpFRtoMjeYFixY4NatW3dK2Y4dOzj77LP7fU4XcDRsa8D5Hb7pPlLGpww0\nzLiqr68nIyOD6upqFi5cyGuvvcakSZMGPY6B/lxERAaDma13zi2IdxyJLFzbLCIi0l/9bZuH1Rzb\n/jCP4TvdR9O+JpoPNpM8LhnzDGyubTy9973vpaamhubmZr7xjW/EJakVEREREREZTCM+sQVIGpeE\n55CHQFOAliMtpExM3F7bcPNqr7vuOvbt23dK2QMPPBB21WMREREREZFEo8QWMDNSJqfQtLeJ5kPN\nJGclY97E7bXtrH2bIRERERERkeFoWCweFY15wkljkvCke3Atjuaq5ihENXIl0rxtERERERFJfAmf\n2KamplJdXT3gZMrM8E0O7g3bfLgZ16bkrD+cc1RXV5OamhrvUEREREREZIRI+KHIU6ZMoaysjKqq\nqqicr7mumYA/ABWAA/MaSWOT8I7yRuX8I0FqaipTpkyJdxgiIiIiIjJCJHxim5yczIwZM6J2vr0r\n93Jg+YFTyjzpHvJX5JO9NDtq1xEREREREZHo6NVQZDO7wsyKzGyPmd0d5nUzs5+GXt9sZvN7OtbM\n5prZGjPbaGbrzGxhdN7SwFT+prJLWaAxQPG9xXGIRkRERERERHrSY2JrZl7gYeBKYBbwYTOb1ana\nlcDM0J9lwC96cewPgH9zzs0Fvhl6Hnf+/f4+lYuIiIiIiEh89abHdiGwxzlX7JxrBp4GrulU5xrg\n1y5oDTDGzHJ6ONYBp4UeZwIHB/heosKX6+tTuYiIiIiIiMRXbxLbyUDHSadlobLe1Onu2M8DPzSz\nA8CDwD3hLm5my0JDlddFa4Go7uQtz8OTfuptMZ+Rtzwv5tcWERERERGRvovndj+fBr7gnJsKfAF4\nPFwl59wK59wC59yCCRMmxDyo7KXZ5K/Ixzft7R7alJwUJn54YsyvLSIiIiIiIn3Xm8S2HJja4fmU\nUFlv6nR37E3Ac6HHfyQ4bHlIyF6azeKSxbyz/p2kTE7BX+Ln8FOH4x2WiIiIiIiIhNGbxPZNYKaZ\nzTCzFOBGYFWnOquAj4dWR74QOO6cO9TDsQeBfwo9/mdg9wDfS9R5R3nJuz84BHnf1/bRWtca54hE\nRERERESksx4TW+dcK3AH8FdgB/AH59w2M7vNzG4LVXsRKAb2AI8Ct3d3bOiYW4GHzGwT8D2CqykP\nOdkfyea0C0+j+XAz+7+3P97hiIiIiIiISCfmnIt3DL22YMECt27dukG/bu3aWjYs2oClGAu3LyTt\njLRBj0FERKLPzNY75xbEO45EFq+2WUREhqf+ts3xXDwqYZy28DSyP5aNa3bs/creeIcjIiIiIiIi\nHSix7aW87+fhGeXhyPNHOPa/x+IdjoiISJ+Z2RVmVmRme8zs7jCvZ5rZn81sk5ltM7Nb4hGniIhI\nXymx7SXfZB/T7pkGwJ7P7yHQGohzRCIiIr1nZl7gYeBKYBbwYTOb1anaZ4Dtzrk5wBKCa2GkDGqg\nIiIi/aDEtg+mfHEKvmk+GjY3cOixQ/EOR0REpC8WAnucc8XOuWbgaeCaTnUcMNrMDMgAjgLaEkBE\nRIY8JbZ94E3zcsaDZwBQ8o0SWmpa4hyRiIhIr00GDnR4XhYq6+hnwNkEt+TbAnzOOachSiIiMuQp\nse2jCddPIPOSTFqOtFD67dJ4hyMiIhJNlwMbgdOBucDPzOy0zpXMbJmZrTOzdVVVVYMdo4iISBdK\nbPvIzDjzx2cCUPajMlZ7VlM4vZCKlRVxjkxERKRb5cDUDs+nhMo6ugV4zgXtAfYBBZ1P5Jxb4Zxb\n4JxbMGHChJgFLCIi0ltKbPuhcXsjJIWeOPCX+ilaVqTkVkREhrI3gZlmNiO0INSNwKpOdfYDlwKY\nWTaQDxQPapQiIiL9oMS2H4rvLe6ylEagMRAsFxERGYKcc63AHcBfgR3AH5xz28zsNjO7LVTtO8BF\nZrYF+Dtwl3PuSHwiFhER6b2knqtIZ/79/j6Vi4iIDAXOuReBFzuVPdLh8UHgPYMdl4iIyECpx7Yf\nfLm+PpWLiIiIiIhI7Cix7Ye85Xl40rveukk3T4pDNCIiIiIiIiObEtt+yF6aTf6KfHzTfGDgPc0L\nQNUzVQSatd2fiIiIiIjIYFJi20/ZS7NZXLKYJYElXHT4ItLOTKNxWyP7H9gf79BERERERERGFCW2\nUeBN83LWirMAKP1uKQ07GuIckYiIiIiIyMihxDZKxr5rLDmfzME1O3Yt24ULuHiHJCIiIiIiMiIo\nsY2ivB/kkZydzPFXj3NwxcF4hyMiIiIiIjIiKLGNouSxycz82UwAir9ajL9c+9qKiIiIiIjEmhLb\nKJtw/QSyrs6ira6NXZ/ZhXMakiwiIiIiIhJLSmyjzMyY+fBMvKO9VL9QzZHnjsQ7JBERERERkWFN\niW0MpE5JJe+BPAB237GblmMtcY5IRERERERk+FJiGyOnf+p0Trv4NJoPN1OYW8hqz2oKpxdSsbIi\n3qGJiIiIiIgMK0psY8Q8RtbVWQAE6gPgwF/qp2hZkZJbERERERGRKFJiG0MHf951y59AY4Die4vj\nEI2IiIiIiMjwpMQ2hvz7w2/3E6lcRERERERE+k6JbQz5cn19KhcREREREZG+U2IbQ3nL8/Ckd73F\nU744JQ7RiIiIiIiIDE9KbGMoe2k2+Svy8U3zgYEnLXi7q5+vxrW5OEcnIiIiIiIyPCixjbHspdks\nLlnMksASLiy5kOSJydSsruHAQwfiHZqIiIiIiMiwoMR2EKVMTKHgyQIA9n19H3Xr6+JORT20AAAg\nAElEQVQckYiIiIiISOJTYjvIsq7MYvKdk3Etju1Lt9PW0BbvkERERERERBJarxJbM7vCzIrMbI+Z\n3R3mdTOzn4Ze32xm83tzrJndaWY7zWybmf1g4G8nMeQ9kEf6OemcKDrBni/tiXc4IiIiIiIiCa3H\nxNbMvMDDwJXALODDZjarU7UrgZmhP8v+f3v3HmV3WR56/PvsmcnOFRJIGEJuw0gIIBf1RFBrT7Es\nKlBWUy3Hg6aCqCtFBT09riNWjrfVk1NaradeoRGpl6LUVtDURlHbRkodLgGBEJKQGHIlmSTknoGd\nmdnv+WPvhCHZe2ZPZjJ775nvZ62szP793nfPs9+5/PYz7/t7XuD2vvpGxFuAecBFKaVXA58fjBdU\nDxrGNHDed88jRgVb/3YrO3+0s9ohSZIkSVLdqmTG9mJgbUppXUrpEHAPhYS0p3nAt1PBQ8DEiJja\nR98PALellHIAKaXtg/B66sb4C8fTelsrAKvet4rc1lyVI5IkSZKk+lRJYjsN6FnCd3PxWCVteut7\nNvDbEfFwRPwyIl7fn8CHg+kfmc6kyyfR9UIXD7c+zNLMUtpa2mi/u73aoUmSJElS3ahm8ahG4BTg\nDcD/Ar4fEXF0o4hYEBHLImLZjh07hjrGEyoywal/cCoA+ZfykCC3IcfqBatNbiVJkiSpQpUktluA\nGT0eTy8eq6RNb303A/cWly8/AuSByUd/8pTSopTS3JTS3ClTplQQbn3Z9Plj97PNd+RZd+u6KkQj\nSZIkSfWnksT2UWB2RJwZEaOAa4HFR7VZDFxXrI78BmBvSmlrH31/CLwFICLOBkYBI66KUm5j6Xtr\nyx2XJEmSJL1SY18NUkpdEXETcD/QANyVUloRETcWz98BLAGuAtYCHcANvfUtPvVdwF0R8TRwCLg+\npZQG9dXVgezMLLkNxyax2RnZKkQjSZIkSfWnz8QWIKW0hELy2vPYHT0+TsCHKu1bPH4I+OP+BDsc\ntS5sZfWC1eQ78q84Pu4146oUkSRJkiTVl2oWjxLQPL+ZOYvmkJ2VhYCm05ogYNfiXey4d3gVy5Ik\nVVdEXBERqyNibUR8vEybSyPiiYhYERG/HOoYJUk6HhXN2OrEap7fTPP85iOPN31hE7/56G9Ydf0q\nxp43lnHnOHsrSRqYiGgAvgpcTqGA46MRsTil9EyPNhOBrwFXpJQ2RsRp1YlWkqT+cca2Bk3/0+lM\n+e9T6D7QzYq3raBrX1e1Q5Ik1b+LgbUppXXF24HuAeYd1eZdFHYs2AiQUto+xDFKknRcTGxrUERw\nzjfOYdz54+hY1cGq96xiBNbVkiQNrmlAzz3mNheP9XQ2MCkilkbEYxFx3ZBFJ0nSAJjY1qiGcQ28\n+t5X03ByAzvv28nGv9xY7ZAkScNfI/BfgN8H3gp8srgl3ytExIKIWBYRy3bssB6EJKn6TGxr2NjZ\nYzn3788F4Llbn2PXz3ZVOSJJUh3bAszo8Xh68VhPm4H7U0oHU0o7gQeAi45+opTSopTS3JTS3ClT\nppywgCVJqpSJbY2bfPVkZn16FuRh+duX86vpv2JpZiltLW20391e7fAkSfXjUWB2RJwZEaOAa4HF\nR7X5EfDmiGiMiLHAJcDKIY5TkqR+M7GtAy2famHcReNIBxOHthyCBLkNOVYvWG1yK0mqSEqpC7gJ\nuJ9Csvr9lNKKiLgxIm4stlkJ/BR4CngEuDOl9HS1YpYkqVJu91MHIhN0vXBsZeR8R551t657xVZB\nkiSVk1JaAiw56tgdRz3+HPC5oYxLkqSBcsa2TuS25Eof31j6uCRJkiSNFCa2dSI7M9uv45IkSZI0\nUpjY1onWha1kxh775ZpyjdUoJUmSJI1sJrZ1onl+M3MWzSE7KwsBDSc3APD87c+zb9m+KkcnSZIk\nSdVjYltHmuc388b1b+TS/KW8efebab6umXxHnuVXL+fF9S9WOzxJkiRJqgoT2zoVEcz5+hwmXjaR\nzvZOll+5nM5dndUOS5IkSZKGnIltHcuMynD+D85n3Pnj6FjVwdNve5p8Ll/tsCRJkiRpSJnY1rnG\nkxu5YMkFjJo2ir0P7GXl9StJ+VTtsCRJkiRpyJjYDgOjZ4zmwn+5kIYJDez4hx08OOlBlmaW0tbS\nRvvd7dUOT5IkSZJOKBPbYWL8ReM544NnANC9rxsS5DbkWL1gtcmtJEmSpGHNxHYY2X7P9mOO5Tvy\nrLt1XRWikSRJkqShYWI7jOQ25vp1XJIkSZKGAxPbYSQ7M1vyeNPkpiGORJIkSZKGjontMNK6sJXM\n2GO/pJ0vdPLCkheqEJEkSZIknXgmtsNI8/xm5iyaQ3ZWFqIwgzvxrRMhD0+//Wl2/XxXtUOUJEmS\npEHXWO0ANLia5zfTPL/5yOOUEms+tIbnb3+ep+c9zQVLLmDSpZOqGKEkSZIkDS5nbIe5iGD2V2Zz\n+vtOJ/9inuVXL2fvf+6tdliSJEmSNGicsR0BIhPMWTSHdCjR/p12nrryKaZ/dDrb/m4buY05sjOz\ntC5sfcVMryRJkiTVCxPbESIywTl/dw6pM7H9nu1s+MyGI+dyG3KsXrAawORWkiRJUt1xKfIIEg3B\nOd8+h8yYY7/s+Y48625dV4WoJEmSJGlgTGxHmExThvxL+ZLnchtzQxyNJEmSJA2cie0IlJ2Z7ddx\nSZIkSaplJrYjUOvCVjJjj/3Sn3rVqVWIRpIkSZIGpqLENiKuiIjVEbE2Ij5e4nxExJeK55+KiNf1\no+9HIyJFxOSBvRRVqnl+M3MWzSE7KwsBDSc1APD87c+z+SubqxydJEmSJPVPn1WRI6IB+CpwObAZ\neDQiFqeUnunR7EpgdvHfJcDtwCV99Y2IGcDvARsH7yWpEs3zm19RAXnjX21k3S3rWHvzWrpe6GLW\np2YREVWMUJIkSZIqU8mM7cXA2pTSupTSIeAeYN5RbeYB304FDwETI2JqBX3/H/AxIA30hWhgZn5s\nJnPunAMZWP+Z9az98FpS3i+LJEmSpNpXyT6204BNPR5vpjAr21ebab31jYh5wJaU0pPODNaGqe+b\nSuOkRp555zNs+coW9j22j0NbDpHblCM7M0vrwlb3uZUkSZJUc6pSPCoixgKfAD5VQdsFEbEsIpbt\n2LHjxAc3wk15+xQuXHIhkQ32t+0vbAGUILchx+oFq2m/u73aIUqSJEnSK1SS2G4BZvR4PL14rJI2\n5Y6/CjgTeDIi1hePPx4Rpx/9yVNKi1JKc1NKc6dMmVJBuBqoSZdNonHSsZP5+Y48625dV4WIJEmS\nJKm8ShLbR4HZEXFmRIwCrgUWH9VmMXBdsTryG4C9KaWt5fqmlJanlE5LKbWklFooLFF+XUpp22C9\nMA1MZ3tnyeO5jbkhjkSSJEmSetfnPbYppa6IuAm4H2gA7koprYiIG4vn7wCWAFcBa4EO4Ibe+p6Q\nV6JBlZ2ZJbfh2CS2aXJTFaKRJEmSpPIqusc2pbQkpXR2SulVKaWFxWN3FJNaitWQP1Q8f0FKaVlv\nfUs8f0tKaedgvCANjtaFrWTGHvvt0bmjk42f20hKVkyWpHrT197yPdq9PiK6IuKaoYxPkqTjVZXi\nUap9zfObmbNoDtlZWYjCDO7kP5oMwLqPrWP1e1eTz+WrHKUkqVI99pa/EjgPeGdEnFem3V8CPxva\nCCVJOn6VbPejEap5fvMx2/vs+MEOVl63km3f3EbHmg7Ov/d8Rp02qkoRSpL64cje8gARcXhv+WeO\nancz8APg9UMbniRJx88ZW/XLlD+awmsffC3Z6Vn2/ec+Hrv4MTb8xQbaWtpYmllKW0ubWwJJUm0q\nt+f8ERExDXgbcPsQxiVJ0oCZ2KrfJrx2Aq975HVMuGQCuQ05nvvEc4VCU+53K0n17m+AW1JKvd5r\n4h7zkqRaY2Kr45KdmuU1S19TssCU+91KUk2qZF/6ucA9xT3mrwG+FhF/ePQTuce8JKnWeI+tjlvD\n6AbyL5b+o7773UpSzTmytzyFhPZa4F09G6SUzjz8cUR8E/hxSumHQxmkJEnHwxlbDUh2Zrbk8aYp\n7ncrSbUkpdQFHN5bfiXw/cP70h/em16SpHplYqsBKbvf7fZOnvvMc6Ru97uVpFrR1770R7V9T0rp\nn4Y+SkmS+s/EVgNSar/bU99+KgRs+OwGnrz8SXLbXJYsSZIk6cTxHlsNWKn9bnf/626emf8Me/59\nD8suWsbp7z2d7d/bTm5jjuzMLK0LW4/pI0mSJEnHwxlbnRCTLpvE3CfmMvF3J9K5vZNNt21ySyBJ\nkiRJJ4SJrU6Y7OlZLvrZRTSc3HDMObcEkiRJkjRYTGx1QkVD0L2vu+Q5twSSJEmSNBhMbHXCldsS\nKJPN8NLGl4Y4GkmSJEnDjYmtTrhyWwLlX8rz6PmPsvUbW0nJbYEkSZIkHR8TW51wx2wJNCvL7K/O\nZvLbJtO9v5vV71/N8quWs+nLm2hraWNpZiltLW0Wl5IkSZJUEbf70ZAotSXQGR84g+3f286am9aw\n66e72PXTXUfOHa6cfLivJEmSJJXjjK2qJiJoflczr1/xejJjSixVtnKyJEmSpAqY2KrqslOz5F/K\nlzxn5WRJkiRJfTGxVU0oVzk5GoM9D+wZ4mgkSZIk1RMTW9WEkpWTA1Jn4onfeYKV163kUPuh6gQn\nSZIkqaZZPEo14XCBqHW3riO3MUd2ZpaWT7fw0oaX2HjbRtq/087OxTtpXdhKw0kNPPfJ5460a13Y\naoEpSZIkaQQzsVXNKFU5GeD0d5/OmpvXsOsnu1hz0xoIoLjtrdWTJUmSJLkUWTVvzKvGcMG/XMCr\n7301NHAkqT3M6smSJEnSyGZiq7oQEUx52xQoXTzZ6smSJEnSCGZiq7pSrnoyAZu/spn8oTKZryRJ\nkqRhy8RWdaVk9eQMkIe1N6/l0Vc/yvZ/3M62u7fR1tLG0sxS2lraaL+7vSrxSpIkSTrxLB6lulKq\nevKZC8+kcXwjv7nlN7y4+kWeecczR5JdsMCUJEmSNNyZ2KrulKuefMrvn8K2b2zj2Q8+e8y9uIcL\nTJnYSpIkScOPS5E1bGQaM5zxJ2ccUzX5MAtMSZIkScOTia2GnbIFphI8ddVT7G3bO7QBSZIkSTqh\nKkpsI+KKiFgdEWsj4uMlzkdEfKl4/qmIeF1ffSPicxGxqtj+voiYODgvSSNdqQJT0RgwCnb9ZBe/\nftOvefLyJ9nzwB7a7263yJQkSZJU5/pMbCOiAfgqcCVwHvDOiDjvqGZXArOL/xYAt1fQ9+fA+Sml\nC4FngT8b8KuRKNyDO2fRHLKzshCQnZXlnG+ew5u2vImZt86kYUIDu3+xmyd+5wlWXreS3IYcpJeL\nTJncSpIkSfWlkuJRFwNrU0rrACLiHmAe8EyPNvOAb6eUEvBQREyMiKlAS7m+KaWf9ej/EHDNQF+M\ndFi5AlOt/6eVGR+dwZYvbWH9Z9dbZEqSJEkaBipZijwN2NTj8ebisUraVNIX4L3ATyqIRRqwpklN\ntHy6pez53IYcnXs6hy4gSZIkSQNS9eJREXEr0AXcXeb8gohYFhHLduzYMbTBaVgrW2QKaJvexpoP\nr+HF37zofbiSJElSjasksd0CzOjxeHrxWCVteu0bEe8BrgbmF5cxHyOltCilNDelNHfKlCkVhCtV\npmSRqWww5rwx5A/m2fLlLTx81sOsvN77cCVJkqRaVkli+ygwOyLOjIhRwLXA4qPaLAauK1ZHfgOw\nN6W0tbe+EXEF8DHgD1JKHYP0eqSKlSwy9Y1zuGTFJcx9ci6n33B6oWH3K/sdvg9XkiRJUm3os3hU\nSqkrIm4C7gcagLtSSisi4sbi+TuAJcBVwFqgA7iht77Fp/4KkAV+HhEAD6WUbhzMFyf1pVyRqfEX\njuecu85h2ze3QYm1BLkNOfY9uo8JcydQ/P6VJEmSVCWVVEUmpbSEQvLa89gdPT5OwIcq7Vs8fla/\nIpWqIDszW1iGXMLjFz/O+NeMZ+qCqTS/q5kXfvwC625dR25jjuzMLK0LW62uLKmmFFdLfZHCH5vv\nTCnddtT5+cAtQAD7gQ+klJ4c8kAlSeqnqhePkmpZqftwM6MzTLpyEo2nNnLgiQOs+eAaHpzyoPfi\nSqppFe5L/xzwOymlC4A/BxYNbZSSJB0fE1upF6Xuw51z5xwuWnIRb9ryJs793rlMfMtE6MR7cSXV\nuiP70qeUDgGH95Y/IqX0q5TS7uLDhygUfZQkqeZVtBRZGsnK3YebyWZovraZ5mubWZpZWvZe3C13\nbOG0/3YaTac20X53u8uVJVVLqb3lL+ml/fsos8d8RCwAFgDMnDlzsOKTJOm4mdhKg6C3e3HXfGAN\naz+8lrEXjKXj6Q7SoUIGfHi5MmByK6mmRMRbKCS2by51PqW0iOIy5blz55bcrk+SpKHkUmRpEJS8\nF3dMhqk3TmXS700idScOPn7wSFJ7mMuVJQ2hSvalJyIuBO4E5qWUXhii2CRJGhATW2kQlLwX9+tz\nmHP7HC66/yLeuOWNZfvmNuTY8YMddB98+Sbd9rvbaWtpY2lmKW0tbRahkjQY+tyXPiJmAvcC704p\nPVuFGCVJOi4uRZYGSbl7cQGyp2fJziq/XHnFNSvIjMlwyhWn0NTcRPu32sm/mAdcsixpcFS4L/2n\ngFOBrxX36O5KKc2tVsySJFXKxFYaIq0LW1m9YDX5jvyRY5nRGU79w1PJrc+x76F97LxvZ8m+h5cs\nm9hKGogK9qV/P/D+oY5LkqSBMrGVhsjhpLRcVeTclhw77tvB2pvXluyf25Bj99LdnPxbJ5Npylhh\nWZIkSSoysZWGUK/LladlmX7TdDZ9flPZJctPvuVJGk5qYOw5YznwxAErLEuSJElYPEqqOaUqLEc2\nOOWqUxh73li693Wz/5H9pSss/5kVliVJkjTyOGMr1Zi+liy/uP5FHj7z4ZJ9c5ty/Pq3f83EyyYy\n6bJJnHTJSez4xx0uWZYkSdKwZmIr1aDeliyPaRnTa4XlvQ/uZe+De9nw2Q3QBHQDxXpVLlmWJEnS\ncORSZKkOlVqunBmbYfai2Zz/w/OZdvM0xp43Fjo5ktQelu/I8+yHnmXXz3bRta8LcN9cSZIk1Tdn\nbKU61Ndy5cnzJgOwNLMU0rH9u/d289Rbn4IMZGdkObTlEKnLQlSSJEmqTya2Up3qbbnyYdmZpZcs\nN0xoYOx5Yznw2IGS5/MdeZ696VlGTR3FhLkTaDyp8KvCLYYkSZJUi0xspWGsdWErqxesJt/x8nrk\nzNgMZ99+Ns3zm+nu6OY/xv9H6VndPd08edmTEDD2nLE0Tm5k/0P7SZ3O7EqSJKm2eI+tNIw1z29m\nzqI5ZGdlISA7K8ucRXOOJKINYxvIzsyW7NswoYEJF08gmoKOlR3s+499R5Law/IdedbcvIY9v9xD\n555OwPt1JUmSNPScsZWGub6WLPc1q5vP5Tnw1AEev/jxkv27dnfxxKVPANA4uZGu3V2FSsyUn9V1\nSbMkSZIGk4mtNML1VYgqk81w0utPKrvFUGZ8hnHnjuPg8oN07ew65ny+I8+q965i9y92M+78cRza\nfogtX95C/sVCIu2SZkmSJA2Uia2kigpRlZvZnXNHYWlzvivPA6MeKHm/bjqU2PbNbWWfO9+RZ+2f\nrmXCxRMYfeZoMo2FuySc2ZUkSVIlTGwlVaTPmd3GTNkqzE3NTbR8uoWDTx/k+a89X/L5O3d08sjZ\njxBNwZizxpAZm+Hgkwf73IbI5FeSJEkmtpIqdrz3657112cd6ffCv7xQeknz6AxNU5rIbcrRsbKj\n5PPnO/KsumEVO+7bwZhXjaHzhU7a/76dlOu7UrMJsCRJ0vBlYitp0PQ1qwu9LGkuVmvuPthNx5oO\nHnvtYyU/R+pM7PzBzrIx5DvyrL5xNS+tf4nRLaMZ3TKa/b/ez7pb1h35nM7+SpIkDS8mtpIGVV+z\nun0lvw3jGpjwmglli1U1nd7EWV84ixfXvsj6T60v+TnyB/I897+f6zXOfEeeNR9eQ+PERrIzsux9\naC+/+dPf9Jn8ggmwJElSrTGxlTTkBlKs6qzPn0XzOwt9t35ja8nkt/GURqa+fyovrX+Jl9a/xP5H\n9pf8HF27ulh+9fKyMRzepzczOsOoM0Yxauoo9vxyD2s+uMbZX0mSpBpiYiupJg1kWfPsL81+Rbu2\nlrbS9/WOy3Dym04mt7n8fb1du7tYcc2KXmPNd+RZc9MaUj4xqnkU+x/bz4Y/31DRlkYmwJIkSQNn\nYiupZg10WfNhZe/r/ds5R9q2zWojt/HY5LdhfAMTL5vIoecPkXs+x6Eth0rG0rWni1XXrSoba74j\nz+oFq9n7q700TWli1JRRHFx1kK1f39pn8atKk1+TZEmSNFJFSiU2naxRc+fOTcuWLat2GJLqUF9J\nX/vd7b0WtTqsbAI8oYFTrz6VQ+2H2PNvewYWbAOMv3A8Tac20XWgiwPLDhzZ9gggssGMj83gtHec\nRtOkJhonNbLjvh08u+DZPuOvJPkdSQlyRDyWUppb7TjqmddmSdJgOt5rs4mtJBVVmvT1lQCXW/rc\nOLmRlk+20Lmjk0M7DrH1b7ee2BcEZMZnmHbjNBonNnLw2YPsuGcH6dDLv/czozO86guv4vQbTieT\nzbD9u9srSvBhcJPkaiXTJrYD57VZkjSYTGwlaYgM2uxvmQR41BmjOP+H59O1q4unrniqbBxjzx1L\n1+4uOnd3HlnOPBDRFKTuBPljz2XGZZj63qk0TGigYXwDB1cdmyTH6ODMPz+T5nc2kxmXYefinaz5\nwJqKZpErGa8Tkfya2A6c12ZJ0mAysZWkGnKiZ3+zs7K8cf0bjzxum9lGblPpCtEzPzaTrr1dbPyL\njWXjjaYgdQ7N9SCywcTfnkhmbIaGsQ3s/Oed5A8em003ntLIWV88i4YxDex9aC9bvrzlFQl8uZnk\nfsViYjtgXpslSYPpeK/NFRWPiogrgC8CDcCdKaXbjjofxfNXAR3Ae1JKj/fWNyJOAf4BaAHWA+9I\nKe3u7wuQpFpUyZZGA6n83Lqw9RXP1foXfVeIbv9ue69Jcj6X5+GzHia3uXSCPOuTs+g+0E33/m42\n/dWmsq9r1NRRdB/spntfd8nzKZfY/Yu+f9137epi1bt7L8i17tZ1w/b+X0mSVLk+E9uIaAC+ClwO\nbAYejYjFKaVnejS7Ephd/HcJcDtwSR99Pw78a0rptoj4ePHxLYP30iSp9g1W5efBSJIz2Qytt1W2\nhdL2f9je50xyuUJbTc1NnPudc8l35Onu6GbNTWvo2tV1TLvMuAyT500m/2KenfftLDk+pZ5fkiSN\nPJXM2F4MrE0prQOIiHuAeUDPxHYe8O1UWNf8UERMjIipFGZjy/WdB1xa7P8tYCkmtpJ0jEpmfytp\nV0nyO9AtlHrOJLf+39Jtzvrrszjl8lNefrI8fW/HVG5J9sxsr2MiSZJGhkoS22lAzzVnmynMyvbV\nZloffZtTSodLgm4DXEsmSSdYpUukB2MZ9VDONkuSpJGtontsT7SUUoqIklVLImIBsABg5syZQxqX\nJKm8wUqSK2lXaZIsSZJGpkoS2y3AjB6PpxePVdKmqZe+7RExNaW0tbhseXupT55SWgQsgkLlxQri\nlSQNQ5UmyZIkaeTJVNDmUWB2RJwZEaOAa4HFR7VZDFwXBW8A9haXGffWdzFwffHj64EfDfC1SJKk\nXkTEFRGxOiLWFgs3Hn0+IuJLxfNPRcTrqhGnJEn91eeMbUqpKyJuAu6nsGXPXSmlFRFxY/H8HcAS\nClv9rKWw3c8NvfUtPvVtwPcj4n3ABuAdg/rKJEnSEQPZ5WCoY5Ukqb8qusc2pbSEQvLa89gdPT5O\nwIcq7Vs8/gJwWX+ClSRJx+24dznoUexRkqSaVMlSZEmSVP/K7WDQ3zaSJNWcmqiKXKnHHntsZ0Rs\n6KPZZGDnUMRzAtRz7FDf8Rt7ddRz7FDf8Rt7waxBep4RpeeOBUAuIp6uZjzDQD3/PNYKx3DgHMPB\n4TgO3Jzj6VRXiW1KaUpfbSJiWUpp7lDEM9jqOXao7/iNvTrqOXao7/iNfUQayC4Hr9BzxwK/HgPn\nGA6cYzhwjuHgcBwHLiKWHU8/lyJLkjQyDGSXA0mSalpdzdhKkqTjM5BdDiRJqnXDMbFdVO0ABqCe\nY4f6jt/Yq6OeY4f6jt/YR6CB7HLQC78eA+cYDpxjOHCO4eBwHAfuuMYwCtcwSZIkSZLqk/fYSpIk\nSZLq2rBJbCPiiohYHRFrI+Lj1Y6nvyJifUQsj4gnjrcS2FCJiLsiYnvP7R0i4pSI+HlErCn+P6ma\nMfamTPyfiYgtxfF/IiKuqmaM5UTEjIj494h4JiJWRMRHisdrfvx7ib3mxz4iRkfEIxHxZDH2zxaP\n18O4l4u95sf9sIhoiIhfR8SPi49rftyHo76us8WCU18qnn8qIl5XjThrWQVjOL84dssj4lcRcVE1\n4qxllb7fi4jXR0RXRFwzlPHVg0rGMCIuLV4bVkTEL4c6xlpXwc/yyRHxzz2uvdYrOEqp9+NHne/3\nNWVYLEWOiAbgWeByCpvJPwq8M6X0TFUD64eIWA/MTSnV/L5XEfFfgQPAt1NK5xeP/RWwK6V0W/EH\nfFJK6ZZqxllOmfg/AxxIKX2+mrH1JSKmAlNTSo9HxATgMeAPgfdQ4+PfS+zvoMbHPiICGJdSOhAR\nTcCDwEeAt1P7414u9iuo8XE/LCL+JzAXOCmldHU9/b4ZLiq5zhb/OHIzheJTlwBfTCldUoVwa1KF\nY/gmYGVKaXdEXAl8xjF8WaXv94rtfg68RKFI2j8Nday1qsLvw4nAr4ArUkobI+K0lNL2qgRcgyoc\nw08AJ6eUbomIKcBq4PSU0qFqxFyLSr0fP+p8v68pw2XG9mJgbUppXfEb5h5gXpVjGrZSSg8Au446\nPA/4VvHjb1FIWGpSmfjrQkppa0rp8eLH+4GVwDTqYPx7ib3mpYIDxYdNxX+J+g9Ppv4AAAR4SURB\nVBj3crHXhYiYDvw+cGePwzU/7sNQJdfZeRTeoKSU0kPAxOIftFTQ5ximlH6VUtpdfPgQhX2E9bJK\n3+/dDPwAMBk7ViVj+C7g3pTSRgCT2mNUMoYJmFD84/J4Cu87u4Y2zNpWwfvxfl9ThktiOw3Y1OPx\nZurkDXMPCfhFRDwWEQuqHcxxaO6x1+E2oLmawRynm4tLHe6qh6WNEdECvBZ4mDob/6NihzoY++Jy\n2CcovFH6eUqpbsa9TOxQB+MO/A3wMSDf41hdjPswU8l1djhci0+k/o7P+4CfnNCI6k+fYxgR04C3\nAbcPYVz1pJLvw7OBSRGxtPi+9Lohi64+VDKGXwHOBZ4HlgMfSSnlUX/0+5oyXBLb4eDNKaXXAFcC\nHypOz9el4nYRdTMjVHQ70Aq8BtgK/HV1w+ldRIyn8Nfo/5FS2tfzXK2Pf4nY62LsU0rdxZ/R6cDF\nEXH+UedrdtzLxF7z4x4RVwPbU0qPlWtTy+MuHa+IeAuFxNYl9v33N8AtJhED0gj8FwqrZd4KfDIi\nzq5uSHXnrcATwBkUrrNfiYiTqhvS8DdcEtstwIwej6cXj9WNlNKW4v/bgfsoLHOoJ+2HlwcU/6+r\nZSsppfbim/888HVqePyL90n+ALg7pXRv8XBdjH+p2Otp7AFSSnuAf6dwj2pdjPthPWOvk3H/LeAP\nijUI7gF+NyL+njob92Gikuts3V+LT7CKxiciLqSw9H5eSumFIYqtXlQyhnOBe4q/N64BvhYR3q7w\nskrGcDNwf0rpYLH2ywOAhcxeVskY3kBhOXdKKa0FngPOGaL4hot+X1OGS2L7KDA7Is6MiFHAtcDi\nKsdUsYgYVyymQ0SMA34PKFkhrIYtBq4vfnw98KMqxtJvR63Zfxs1Ov7FezW+QaG4yBd6nKr58S8X\nez2MfURMKRbTICLGUCgYsYr6GPeSsdfDuKeU/iylND2l1ELh9/q/pZT+mDoY92GokuvsYuC6YiXL\nNwB7eywZVwVjGBEzgXuBd6eUnq1CjLWuzzFMKZ2ZUmop/t74J+CDKaUfDn2oNauSn+UfAW+OiMaI\nGEuhcM/KIY6zllUyhhuBywAiohmYA6wb0ijrX7+vKY1DE9eJlVLqioibgPuBBgoV8FZUOaz+aAbu\nK7zvpxH4bkrpp9UNqbyI+B5wKTA5IjYDnwZuA74fEe8DNlCodFuTysR/aUS8hsKSxvXAn1QtwN79\nFvBuYHnxnkmAT1Af418u9nfWwdhPBb5VrISYAb6fUvpxRLRR++NeLvbv1MG4l1MP3+/DSrnrbETc\nWDx/B7CEQvXKtUAHhRkLFVU4hp8CTqUwywjQlVKaW62Ya02FY6heVDKGKaWVEfFT4CkK9Q3uTCnV\n3B8/q6XC78M/B74ZEcuBoLA8vuZ3PhlKZd6PN8HxX1OGxXY/kiRJkqSRa7gsRZYkSZIkjVAmtpIk\nSZKkumZiK0mSJEmqaya2kiRJkqS6ZmIrSZIkSaprJraSJEmSpLpmYitJkiRJqmsmtpIkSZKkuvb/\nAf4bXfqsvMj6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f89a1a390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_progress(plot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOP 20 worst samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17e88596a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: airplane\n",
      "Predictions: ['horse' 'cat' 'dog'] [  9.99739468e-01   9.74641371e-05   8.75552141e-05]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSSjYiEgSCjYikoSCjYgkoWAjIkn8f+e0E0lbrqeIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f89d0e940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: cat\n",
      "Predictions: ['frog' 'bird' 'deer'] [  9.99967933e-01   2.01723269e-05   6.18917466e-06]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKXogt15lAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17eea197668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: automobile\n",
      "Predictions: ['cat' 'bird' 'airplane'] [ 0.36930302  0.27390957  0.19647795]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3WtsnOd1J/D/4dw4HA45vEoUdaGoixVb1sVhHMdxEse3\n2K4T223XsQsEXjSAukA3SIB+2KAFttlvwaJJkQ+7KZSNUWeROvE2duK4Qb2240uNdW1LiqKLdZco\niRTv9yE5vAzPfuAoUBydMyOJekjT/x8gSJzDZ+bhOy+P3pnnzHlEVUFEdL2VLfYEiOijgcmGiIJg\nsiGiIJhsiCgIJhsiCoLJhoiCYLIhoiCYbIgoCCYbIgoiGvLBypMJTVdXmPHs6IQZi8TEve9o1P9R\npMweH4vH/Psu8+NTUzkz5jwsACCfn3Pj8XjCjU/kJs2Y5v3q8Pxc3o1HIvYxlSI/VyLhz3sqN2XG\nKiqS7thYwn+u55yfe3rKPscAoDxpn58AMOs8X6r+c5mI+edRzjmPAGDOufu8FwQwOz3jxlMVNWas\nMm3HAODk8ff7VbXB/SZcY7IRkfsBfA9ABMD/UtVve9+frq7AI1/5vBn/95f32mNXlrtzqW2odeOx\nlH3yr1zlH6eGqiY3fubUCTOWLJIkh4bG3Pi6NRvc+G+OHDZjM2P2LzQAjIyPu/HaavuYRuL+RfH6\njWvd+Kljp83YLTtvdseu3lDnxrOj9i9W+8kD7tgtN+904wOjdnLP5/xE1rJyhRs/euq4G5+wHxpj\n404QwGDnBTf+iZ1/asZu/+x/cMd+8Z6tZ91vKLjql1EiEgHwPwA8AOBGAE+IyI1Xe39EtLxdy3s2\ntwI4qaqnVXUawE8APLww0yKi5eZakk0zgPOXfN1RuO33iMguEdkjIntyE/5lPREtX9d9NUpVd6tq\nm6q2lVf4bxoS0fJ1LcmmE8CaS75eXbiNiOgPXEuyeQ/AJhFZLyJxAI8DeGFhpkVEy81VL32r6qyI\n/GcAL2F+6fspVbXXYQHkclM4dvSkGZ+BXR/Rsm29O59y9WsYKjNpM7a+9Q/eavo9mVS9G5+cHTBj\nUxOz7tjR9l43PjjqrypOjU6bsek5v7YiXu6/rM3NOHUf4/bjAsCJw358Nm/X+LSftZfFAeBs7yk3\nfsNme+l8TatfStB+ssuNDwx1mLG1zZv9sSN+qcHUXNyNz6l9zGTcr5maLPJ8VWfs34FkpV97VKpr\nqrNR1V8B+NWCzISIljV+XIGIgmCyIaIgmGyIKAgmGyIKgsmGiIII2mKioiKBHbfYy4MHIvanXre2\nrnTvu6NvxI3ftMVeDhX4n8w+cGiPGx/oH7Xvu8z/tHp5tf8URKeKtIGYspcl61fay/0AMDrsH7N4\nuT13qa5yx1YmK914JmUv846MDbpj62r8c6H9zBk7OOEfz46uHjeeaciYsUTCP4/GR+zzBACikYgb\nL6u0SxU6Tpw3YwDQtHK1G1+33v69jMf8lh+l4pUNEQXBZENEQTDZEFEQTDZEFASTDREFwWRDREEw\n2RBREEHrbOLxGNa1NJrxqoxdA1FX7XfUP9/V7cZjzlYvM/msOzZV47eYGBmy6yN6u+yWBADQtNbf\nJiM9W2SLmmPnzFhyyq+taN6wyY3nZu02rr3DfiuGvi4/rnXVZqyixq/rmJr0ty3pvmDX6aRj/vY2\n69f7NTwrGuzzd3Cw3x3b32u3IgGAuiK7fFQ5rR5uuHGLOzbq/9hIVdp1U9msXx9UKl7ZEFEQTDZE\nFASTDREFwWRDREEw2RBREEw2RBQEkw0RBRG0zmZuTjE5Zm9tUpNuMWOdQxPufeu0/6NM5extNNJF\ndurc2upvIxNXu+9LRZm/hUZ2zP+5KjN2XQcAIHfUDB096tf4bBG7NwsASMz+v6gpc5M7tqbC70kz\nC7t2Iz/tb0Ez1Of/XOpsnzMW9Wt0WrfUuvFoyt4yaMrfqQVTM/7/7TURf8uUP3vgCTPWVOmfJ92n\nj7jx8Yg9+TNZ//koFa9siCgIJhsiCoLJhoiCYLIhoiCYbIgoCCYbIgoi6NI3BEDcXnocy9rLbw0Z\nf5uLjZ/4ZJGHtj9j393nt0NIVNjLnQBwrv2gGWuqX+OOra7ztzyZOuH/fxBN260aUll/7Oomv22H\nRu1j3jfotx1IlPutMzBjt5GYnfTLASYG/GX1ickxe15OmwYAOHvW38pl8xa7DGJlvd+eIjdst+wA\nAIn6JRj19RvMWGLU38qlMe2fZ+XldolG2QJdklxTshGRdgBjAPIAZlW1bSEmRUTLz0Jc2XxeVf2u\nQUT0kcf3bIgoiGtNNgrgFRHZKyK7LvcNIrJLRPaIyJ7x7OQ1PhwRfVhd68uoO1S1U0QaAbwsIkdV\n9c1Lv0FVdwPYDQDN6xqKdEIlouXqmq5sVLWz8HcvgOcB3LoQkyKi5eeqk42IpEQkffHfAO4DcGih\nJkZEy8u1vIxaAeB5Ebl4P/+kqv/qDZiZnkXX+SEzvv1j9tYi+Qn//Z7BHru2AgAGuvrM2DRG3LHx\nqrQbn8na9REneo+5Yzev/YQbL4vb29sAwGMPPmDGzrdfcMdq2q85iaXs7T2GR/3jLUWKM3ROzFhU\n/Xl59SYA0Dtqt93IVPv1JuPD/nlWlrd/ZbLj9rkNANOac+PJIq1OTv7f583Yiy+96I69cbtfh9a2\ntdWMbWnya8VKddXJRlVPA9i+ILMgomWPS99EFASTDREFwWRDREEw2RBREEw2RBQEkw0RBRG0n00+\nn8fIiF2fURa1p3O82/9g+coGvzdLfUODGRub9T9FMTbi17p0nrV7iTSssh8XAKojft1HfyzrxvMz\n9rYl0SI/V++w35MGTm1TeUWRepUJf97Na9aasf7uTndsf7+/Z0om0WzGyvN+r5yOvm43vu/dPWYs\nvcLfBiaZ9OuH+s4Ou/Ffvv6KGYsVeewLg3E3/tJ79vY4ke5X3bGl4pUNEQXBZENEQTDZEFEQTDZE\nFASTDREFwWRDREEEXfoWCCJOfsvO2EvMqZT/8ftszm950HOu3b7vxow7dnTAX8ZtWrXajDXWr3DH\nZir99hUjQ/5S7f79+8xYPJlyx6aq7CViAOibtLceqa6yt5ABgEiRFhPlcfv5rKr2t4FR9Zf0R/rt\nVg/5ItvbbNjit6/IR+wtTyor/KXt6Iy/JVBjzC+TSKyy73940N+O6OTpN9z49s/cZcZ+edo/B0vF\nKxsiCoLJhoiCYLIhoiCYbIgoCCYbIgqCyYaIgmCyIaIggtbZzE5PY7DDbh+wb9auYbj3vs+79322\nw9+2ZK5szozF4n7NSP+A3UICAJrW1Jux5hr/o//qzAsAcmP2FjQAEIkkzVhj80Z3bEfPOTc+NG7X\ns9Rk7G1eAKAi5begmJywazeqqv3nQ/P2eQIAc7MzZuzMMf88aSjzfyVidfZjJ2r953pj/VY3Prb3\nfTc+OHTcjF0Q+2cGgEyrXz90bsKuU8s7rV+uBK9siCgIJhsiCoLJhoiCYLIhoiCYbIgoCCYbIgqC\nyYaIgii6gC4iTwF4CECvqm4t3FYL4KcAWgC0A3hMVe0mIgUqgrmInd+mpiNmLDs+6N73qlV2rQsA\nzM7Y9REH3z/ojp2Lihv3tqDBtN0TBgAOnj7txsvL7GMCAFPO8ezttbfnAIDT5/14sqrRDkb8rUGi\ncT9e7mxrUgZ/65wyv50NyuN235iGplXu2NFuv6bq5tX2MRnp8/seDXWedONdXX58Z9snzVhn51F3\n7FjC/1UfGLd7H23YuN0d+wp+7sYvKuXK5h8B3P+B274J4FVV3QTg1cLXRESmoslGVd8E8MHLiocB\nPF3499MAHlngeRHRMnO179msUNWLfQi7Afi9L4noI++a3yDW+Yaw5qtoEdklIntEZM/0lL1VLBEt\nb1ebbHpEpAkACn/3Wt+oqrtVtU1V2+JF3qQiouXrapPNCwCeLPz7SQC/WJjpENFyVTTZiMgzAN4G\ncIOIdIjIVwF8G8C9InICwD2Fr4mITEVf16jqE0bo7it+sFgMdStXmvH1a+0aiFSRPXmqqta48QsV\no2Ysnfb3Keo4e9aNl83Y+/1UNvh9X+68s82NXzjm10/sP2THaxv8mpKqSv+YzojzHtus//5bMu3v\n86Vqjy+L+Psr1RTpGwO163Qa6/z+QRND/W58csgu8onn/V8nifl1OMNpf5+vjz/0BTP2//7hjDv2\n+IF2N/6pz95hxmqSfq1XqVhBTERBMNkQURBMNkQUBJMNEQXBZENEQTDZEFEQQUt6k8k4tt5sL1Ef\nOmgv4zZv8ltITA/4W540N9pL7qeO+Evbk+P2sjkAdPR0mbEV1S3u2DUV/pYnIyN+i4pIKmPGZtRf\n5l1X5y/5v330lBnbuHmzOxbq94GYyeXM2GzUX1avr7V/ZgDQOXtbk3Hxj8matWvd+NSkPe901l/a\nPlXlb0HTsq7Vja/O261Odm5occeeH/CXr9fV1JmxNw+9544tFa9siCgIJhsiCoLJhoiCYLIhoiCY\nbIgoCCYbIgqCyYaIgghaZxONxFGXaTHjuRm7zubY4XPufQsG3PjwmNlMEAODw+7YjVs+5sanx+26\njuZ1fj1Kbsqvo+nq63HjcLY9qc/4LQu0SJuIoX67dmk2N+7fN/x6lpkZ+5jFi9QHVVYk3Xis0W75\nMaD24wJAQvz2FrP93Wase9rf8md02K/D+fJ9f+TGExn7XBk4528J9PlPP+zGD3fa4/u6LrhjS8Ur\nGyIKgsmGiIJgsiGiIJhsiCgIJhsiCoLJhoiCYLIhoiCC1tnk87MYGbHrXfJzcTM2POjXKLSs8bcl\nOXHE7knTdWHQHRuP+jm5sXadHav2tx3pPf6+G++40OnGMxm7D8lkzq8pOXym3Y3Hna1cRgb82qQb\ntvlb1AzH7HqWpF+uUvSk1Yj9HRs2+XVPo0WOSfe0fR5VxvyZPbz5Fje+vdYfH62yz6XWtTvdsd11\nfm1S13vtZixf5DwqFa9siCgIJhsiCoLJhoiCYLIhoiCYbIgoCCYbIgoi6NJ3JCqoqrGXPG+/bYcZ\niyb9pe366kY33t7RYcayk/52Kgd/47e3ePxPP23GOs61u2N7O/z77huZdOMNFXb8TKddZgAA2azf\nlqOy3j4ua9bZy/0AEBX//7FY3C5ziEb9bUdikSL/R0YSZigR9U/5A/v3ufGqOrt9xUN33OaObUz4\nz+WxPr8E4+O99vMxu8H+3QGAw3v3uvGzJ9vN2OSY306kVEWvbETkKRHpFZFDl9z2LRHpFJH9hT8P\nLshsiGjZKuVl1D8CuP8yt/+9qu4o/PnVwk6LiJaboslGVd8E4F/fEREVcS1vEH9NRA4UXmaZ+7iK\nyC4R2SMie8ZGJ67h4Yjow+xqk833AbQC2AGgC8B3rG9U1d2q2qaqbekq/01eIlq+rirZqGqPquZV\ndQ7ADwDcurDTIqLl5qqSjYg0XfLlowAOWd9LRASUUGcjIs8AuBNAvYh0APhbAHeKyA4ACqAdwF+U\n8mDj45N4d+9hM14m5fbYCX/Lk/ycv/3HyKTdoqJlS6t/33n/vre1rjVjU1n/4/nne/xWDbm8vVUL\nABw9dMqM6dyIOzZeY9e6AMD5CfuYZar92qRipTCZSvu5jkbtOhkAmCtSK1NbYY9/4xc/d8dKzJ4X\nAGzbusmMrWmud8deOHrcjcdj6sbfOGrX6Rw659dM9fX6NVfeOa467Y4tVdFko6pPXObmHy7IoxPR\nRwY/rkBEQTDZEFEQTDZEFASTDREFwWRDREEw2RBREEH72WRS1Xj44w+Y8YnxnBnr7fXrUarrU258\neNTZgiNp99gBgPs2bnfjCSdlz1X4dRs9Q36vkHS539slF7fjf3TvF9yx627ytzXpG7A/fyt5+7kC\ngGjU348lXmYf87wWGZvw63BOvW/Xcs2W+f+/furez7nxiZ4eM9bZNeaO7Z3x591zrN+Nd62y77+n\nz+7XBADjWX9u+Rm7ji2X8/vwlIpXNkQUBJMNEQXBZENEQTDZEFEQTDZEFASTDREFEXTpe1bnMDBt\ntwb9+bP/YsaKtZCIp6rceDpht0SYgf/R/h07trrxqrT9MyWKbEFT5mxpAgDnO7vdePNqZwubyrQ7\nNpH2l+XbNtxixn79y9fdsTUrW9z4hNM6Q4psA4Mpu/UFAJw8a2+P87m77nbHql9pgOmIvTwdLXIO\n1jjL/QDQJX7bjqHu82bs/MnT7tiBC11u3Fsazzu/s1eCVzZEFASTDREFwWRDREEw2RBREEw2RBQE\nkw0RBcFkQ0RBBK2ziUaiqM+sNOMVFXZNysikv9Y/mvW3ehkYcloiRPwanvoL/kf/J3IXzFg84hdu\n3HPLFje+s7XOje8/esyMHT5y0h07POa37egfsOtZpkb9bWLWr/N/Lo3Y9UW1RdpqvFBkO5b7H/2y\nGZOEX/ck0347hdqWDWYsX+afR3N5v51IZ9aPH3h3nxnr7er0H3va344lD3vuN9T4LT/6/F+P3+GV\nDREFwWRDREEw2RBREEw2RBQEkw0RBcFkQ0RBMNkQURBF62xEZA2AHwFYAUAB7FbV74lILYCfAmgB\n0A7gMVUd8u4rNz6Jo+/sN+O3b99mxiJRPy9GitRmxGL2NhqJuL8NTDLlx197/W0zls3NuGNffOOA\nG7/j5hvc+H96/FEzFk36825cu86N9/XZtTQ9w36NTke7v7VIJmHX2Tzz7Ivu2M3bb3PjVRmnr0x+\n1h0bcWq9ACBenjRj9XG/1uvYjN+vprPziBuH2j2AajK17tDRrF8XlZkcMGMp8XsulaqUK5tZAH+l\nqjcCuA3AX4rIjQC+CeBVVd0E4NXC10REl1U02ahql6ruK/x7DMARAM0AHgbwdOHbngbwyPWaJBF9\n+F3RezYi0gJgJ4B3AKxQ1Yu9Brsx/zLrcmN2icgeEdkzPr4wO+sR0YdPyclGRCoB/AzAN1T19/ay\nVVUFLt/IV1V3q2qbqralUvbrXSJa3kpKNiISw3yi+bGqPle4uUdEmgrxJgC912eKRLQcFE02IiIA\nfgjgiKp+95LQCwCeLPz7SQC/WPjpEdFyIfOvgJxvELkDwL8BOAj87nPof435922eBbAWwFnML30P\nevdVkUrqlo/ZH9EfHbCX3/rH/BYTUmRLlGjSXvrOT/qtAW5qbXHjd99ut1OYGHCrAdB+YdSNn3ba\nPADAdM5ebv3qw/e5Y0d67dYYADAzad/3UM7e+gMAmhqa3fjRcz1mLJa225AAwCN/8gU3PjpoH9NM\n42XfWvydOfFLKBoy9nl0bN+77th3u+ylawA4csgvg+hsP2XGJou0YJFJv33FbSvtJf/RGb9C5qXD\nh/aqapv7TSihzkZV3wJgNbTwN+EhIipgBTERBcFkQ0RBMNkQURBMNkQUBJMNEQXBZENEQQTdyqWp\nvhZ/8+d/ZsZnL/+JBwBFOwNAitRHqLl6D0xOOdu8AEgW+ZhFXW2DGRsZ9VsxbJvya3zSc35txtig\nXZtUlvTbJWTSds0TAMw5LQ26xvz6n4izVQsAJJytdW7/5HZ37Axiblzm7JNFyvxtSRqrqv37nrCf\nz1+/ecgdu/LGHW58sL/Ljeeydm2T5v2tWm5I+9cVK536o9XJenfsS4f9n/siXtkQURBMNkQUBJMN\nEQXBZENEQTDZEFEQTDZEFASTDREFEbTOpndgGN/7p+fNeC5n99yYmPG3RInFy914RYW9jUaRXWKw\nrqnJjd98k93PZnjA71dzvtfu6wIAFVG/LiRVYfdXiab8mpGNGz/mxgd77e1Ycgm/1mVqxK/DSVXa\nc0vWZNyxVckidTYxu14r4WwhAwA1Mb/m6un/85IZa23x65bOD3W68cbmFjcei9t1U2M9fe7YVLnf\nz6YMdk1Vc8b/3SoVr2yIKAgmGyIKgsmGiIJgsiGiIJhsiCgIJhsiCiLo0nc6VYE7b7nFjI86200M\nF2lpkJ/1t6SZcdpXTBdp45As0qohHrXbW0xM2NuhAMDxs35bgUSRZygZt5eBJ3Kn3bESrXXjx44f\nNGMnOv2l1oj4x/RP7n3AjFVVpd2xUuT5QqrRDK1I+Qf0mR/9gxvfe8TerWjj+o3u2KFhd6cjpFL+\n8yH1dhsISdglEACQ6zzixpGzSzROdJzxx5aIVzZEFASTDREFwWRDREEw2RBREEw2RBQEkw0RBcFk\nQ0RBBK2zARQasbfZqHI+yl5VY7eIAIBEwv8YfLnTWiBR7m/Vkk5XufEVDfZWLpvXrnPHfu52f9sS\nifstEVTtFhQR8f8vqajyf66H7rrVjA0Nd7tjZ5ytcwAgP23PLRIpMjbvb39zY2uNGRs6c8Id++s9\nfhuIO++614wdP7LfHbum1j+HLxTZZiY2bddUJcv986Q/57domZqwa5fGy/2WHqUqemUjImtE5DUR\neV9EDovI1wu3f0tEOkVkf+HPgwsyIyJalkq5spkF8Fequk9E0gD2isjLhdjfq+rfXb/pEdFyUTTZ\nqGoXgK7Cv8dE5AiA5us9MSJaXq7oDWIRaQGwE8A7hZu+JiIHROQpEbnsC2UR2SUie0Rkz/ik33KR\niJavkpONiFQC+BmAb6jqKIDvA2gFsAPzVz7fudw4Vd2tqm2q2pZKLkwvUyL68Ckp2YhIDPOJ5seq\n+hwAqGqPquZVdQ7ADwDYSxdE9JFXymqUAPghgCOq+t1Lbr90y4FHARxa+OkR0XJRymrUpwF8BcBB\nEblYSPDXAJ4QkR0AFEA7gL8odkdjEzm8tfeoGR8c7jdjA0P+lih59fNmfs6uzYjF/cOwpnmVG7/j\nVrtW5uRpezsUADh42u8VUl/n93bx+uWki7xsralNufG77/iiGfuXN/7VHTs8NuLGd7RsNmP33f5p\nd+wt2/y+MRMDA2bs337j19l85c93ufHJUbuPT3faP97ZEfv8BoB4tV/vNZ20e9ZMdvi9cnqm/Nqk\nwUk7lkza/ZquRCmrUW8Bl63Q+tWCzICIPhL4cQUiCoLJhoiCYLIhoiCYbIgoCCYbIgqCyYaIggja\nz6ahNoNdj3/JjKvTfyU/O+3ed1nE77kx6+wbBfH7iCQTfv1DTV29Gbttu18f1DvQ68bLivSkyU3b\ndTYq/l5aibhfF9JQnzFjj3/Rfh4BYO/+t914XXqlGdvQ6NcW9V7we870jNm9WdbftMMdq0W2pBrt\ns/sxVVb4ezd19Nj7ogFAMu6fK8NOLUzXhbPu2Cnxa2X6puxzpSlv/8xXglc2RBQEkw0RBcFkQ0RB\nMNkQURBMNkQUBJMNEQURdOm7b3AI//Mnz5nx8dyEGctm7RgARKP+jxKP2cuSCWebFwBoXb/Wjd+y\nbasZG+wbdsd29ftL31XVfhuI+ky1GavL+Fu1VKT8coHJmSEzVltvb18DAA/dY7enAADN2e0WRkb8\npe0LY0VaZ6xeb8Yms/7z8fprr7vxHTvs53rot35bjcGsv/TdnHLWtgHIuL0EnZ30x0bL/GX5C5P2\nfaed2JXglQ0RBcFkQ0RBMNkQURBMNkQUBJMNEQXBZENEQTDZEFEQQetsqirTeOAznzHjQ872H6Nj\nY+59T4zbrRYAIDc1Y8am8nYMAGrTtW68wmlBcSZ73h179NQ5Nx4vss1MKmnXCNVUV7pjVzT6tTID\nQ3ZNSt+wv3XIjm2fcuNtq+xj+txLb7ljv/Tlx914LGK3U3j9nffcsY0Ndt0SAMic3YphbMLfXnok\n559nTVP+OX7PJz5uxrIzfpuUwT57CxoAGJ2wt7/py/q/W6XilQ0RBcFkQ0RBMNkQURBMNkQUBJMN\nEQXBZENEQTDZEFEQRetsRKQcwJsAEoXv/2dV/VsRqQXwUwAtANoBPKaqdgMUAMlkDDd+bJUZj0ft\nvjH5/Jw7z2LxaNSuvZgt82sUEokKN15dVWfGbt68zh37+JfuduPTTn0QAMSdXjxlRbbvqEz7W6ZM\nTNp1I8X6C004W8wAwOqmFjPWNur32YlE/fhbb7xmxmTW36slUeVv2zM5afekyTs1OEDxc3RkzO9J\ns33TajP2z6/79UPVtX5vo8pae9uevn6/v1CpSrmymQJwl6puB7ADwP0ichuAbwJ4VVU3AXi18DUR\n0WUVTTY6L1v4Mlb4owAeBvB04fanATxyXWZIRMtCSe/ZiEhERPYD6AXwsqq+A2CFqnYVvqUbwApj\n7C4R2SMie0ZH/baIRLR8lZRsVDWvqjsArAZwq4hs/UBcgcvvb6uqu1W1TVXbqqr8frpEtHxd0WqU\nqg4DeA3A/QB6RKQJAAp/+527iegjrWiyEZEGEckU/p0EcC+AowBeAPBk4dueBPCL6zVJIvrwK6XF\nRBOAp0Ukgvnk9KyqvigibwN4VkS+CuAsgMeK3ZFIGSJxexuOikq7JUKZ0zYAAHI5f6nVW92WiJ9z\npUhKjiXtucUT/rYjMfGXQ2em/QePx+yl77j4S/oi/lJrwnnVW5b3j3dluf/YQ92HzdjsRJcZA4C3\n3+5w4xUpe/k6lfDPo0lnuR8AYjH7+Zyd8Y+JwD8ms7P++PPn7DYRTU12SQkAjOb890uHeuytdYpM\nu2RFk42qHgCw8zK3DwDwi0SIiApYQUxEQTDZEFEQTDZEFASTDREFwWRDREEw2RBREDL/SYNADybS\nh/manIvqATgL/Itmqc4LWLpz47yu3FKd25XOa52q+vsCIXCy+YMHF9mjqm2LNgHDUp0XsHTnxnld\nuaU6t+s1L76MIqIgmGyIKIjFTja7F/nxLUt1XsDSnRvndeWW6tyuy7wW9T0bIvroWOwrGyL6iGCy\nIaIgFiXZiMj9InJMRE6KyJLalUFE2kXkoIjsF5E9iziPp0SkV0QOXXJbrYi8LCInCn/XLKG5fUtE\nOgvHbb+IPLgI81ojIq+JyPsiclhEvl64fVGPmzOvpXDMykXkXRH5bWFu/61w+4Ifs+Dv2RSacB3H\nfMe/DgDvAXhCVd8POhGDiLQDaFPVRS22EpHPAsgC+JGqbi3c9t8BDKrqtwtJukZV/8sSmdu3AGRV\n9e9Cz+eSeTUBaFLVfSKSBrAX87t+/Ecs4nFz5vUYFv+YCYCUqmZFJAbgLQBfB/DHWOBjthhXNrcC\nOKmqp1XPd6cPAAAB0ElEQVR1GsBPML8tDF1CVd8EMPiBm5fE9jnG3Badqnap6r7Cv8cAHAHQjEU+\nbs68Fl3IrZoWI9k0Azh/ydcdWCIHvkABvCIie0Vk12JP5gNK2j5nEX1NRA4UXmYtyku8i0SkBfMd\nJkvediiED8wLWALH7Fq2aroSfIP4D91R2LbmAQB/WXjJsOR42+csku8DaMX8rqldAL6zWBMRkUoA\nPwPwDVUdvTS2mMftMvNaEsfsWrZquhKLkWw6Aay55OvVhduWBFXtLPzdC+B5zL/sWyqW7PY5qtpT\nOGnnAPwAi3TcCu87/AzAj1X1ucLNi37cLjevpXLMLrreWzUtRrJ5D8AmEVkvInEAj2N+W5hFJyKp\nwht4EJEUgPsAHPJHBbVkt8+5eGIWPIpFOG6FNzt/COCIqn73ktCiHjdrXkvkmIXbqklVg/8B8CDm\nV6ROAfibxZiDMa9WAL8t/Dm8mHMD8AzmL61nMP++1lcB1AF4FcAJAK8AqF1Cc/vfAA4COFA4UZsW\nYV53YP5y/wCA/YU/Dy72cXPmtRSO2TYAvynM4RCA/1q4fcGPGT+uQERB8A1iIgqCyYaIgmCyIaIg\nmGyIKAgmGyIKgsmGiIJgsiGiIP4/aN56M6AIyJ4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f890d8a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: horse\n",
      "Predictions: ['bird' 'cat' 'frog'] [ 0.80542415  0.15984803  0.02156841]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17eea1bc630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: ship\n",
      "Predictions: ['horse' 'truck' 'automobile'] [ 0.54567158  0.44412461  0.00595216]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKNmISBJKNiKSxP8H+Plwhd9kWG8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17eea197cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: ship\n",
      "Predictions: ['horse' 'deer' 'cat'] [  9.80924249e-01   1.85880158e-02   2.54482380e-04]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAKMN4ZbRCaNeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17e889f0780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: dog\n",
      "Predictions: ['airplane' 'ship' 'bird'] [ 0.96621758  0.01631741  0.01473842]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f88fe7358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: bird\n",
      "Predictions: ['dog' 'cat' 'horse'] [ 0.47077549  0.19616599  0.19369781]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHtRJREFUeJzt3WuMnOd1H/D/mfteudxd3kmJoiRblhWLQlnFSIwijWtD\nFgrYTgEh+hCogAEFqGvYQD7USIHa7SejiB3kQ2GAroUohevYqO3aKIQGtmpENpqqXsu6U5YoiSJ3\neV+Se7/MzHv6YUcFLfP8nyF3+cxq9f8BBJdz9pl59p13D9+Z58x5zN0hInKzlXo9ARF5b1CyEZEs\nlGxEJAslGxHJQslGRLJQshGRLJRsRCQLJRsRyULJRkSyqOR8sKGhAd8xPhLGe1XMvN4qagcZv86f\nyS31HfE3pIaa8e8wcg/rfarWc8yTh2TTSsw8eUjib6DnYFdu/KiePHX6orvvSH3fupKNmT0A4K8A\nlAH8Z3f/Cvv+HeMj+A9f+ldh/GZ+dKIoijDWbrfp2NS82m123y061kr84rKdiDs5SSqlMh1bLVdp\nvGzx+PgnXpM6+dkxc+f3XrbUBTlJwPzpwLrSaCJ5J//ncP58uceTL7DCx/JHBjw+F9rkdwcAPvuF\nL72VuntgHS+jzKwM4D8B+ASAuwE8bGZ33+j9icjWtp73bO4HcNzd33D3VQB/C+CTGzMtEdlq1pNs\n9gE4ddW/Jzu3/QYze9TMJsxsYnZuYR0PJyLvZjd9Ncrdj7r7EXc/Mjw0cLMfTkQ2qfUkmykAB676\n9/7ObSIiv2U9yeYXAO40s9vMrAbgjwH8aGOmJSJbzQ0vfbt7y8z+NYC/w9rS92Pu/hIfZSiX44fk\nS8zrWxY3slyaqjcpitRjx0vnqftOLpeS5eeUWpn/X1Iv88cukQVuL2p0bLvgp1Ybzfi+y4lSBONL\nsfy5Th3PRKkBPUfTBQHr4Yjnbs6fj2RZCXm+SiX+fHRrXXU27v4EgCc2ZCYisqXp4woikoWSjYhk\noWQjIlko2YhIFko2IpJF1hYTMKNLj+zTvuxT22tjU8uKbJmXL4daakmTPHZq6Tu9GMr/P6D3nvyU\ncarFBBu6mrjrZf7Y7Lgk5uWeWJ4mw63EPx1tiXMBHv/KWCn1XPOPnBeJ84xXhvAzyRK/P+12/HyW\nE6UG3dKVjYhkoWQjIlko2YhIFko2IpKFko2IZKFkIyJZKNmISBZZ62wMQMnIQ7L1/MRaf5HoyM/q\nOlJdHgrnH7Fn41MbZKTqbNjuCQAAsvuCVfjuCe1Eu4WCbeVS4nU2hcUtJADASEsDI7UsAOBNfkza\nrbiWplzn8y6VGjTOWjEURaJlR5kf71bBa4DYWVg2fiaRzi5rPK6LsoIfs27pykZEslCyEZEslGxE\nJAslGxHJQslGRLJQshGRLJRsRCSLvP1sYGCVJ2wLjlKiVwgbCyT63SSKXTxRw1AqkcOY6rOTvO9E\njxTyc7cTT+9yix+zcrUvjlX28HklamUqFteUlHyRji2152jc2NY67LkC0GzxLVFmpuN6rnaL19EM\nDMbHEwBqg9tpHKTeyxJ1aM2VWRqvluPx1cbGXJPoykZEslCyEZEslGxEJAslGxHJQslGRLJQshGR\nLDIvfQPG8htZBrbEEnFKux2P91K60QMPsyXJRBsH0rIAAIrUkn45Xqptl/v5fVd4O4WiFI+fXRyl\nYy+c5Vu5nJ18LoztHeftKQ4d4MvTjTrZLoj8TABw7vQ8jb/68kwYu+OO++jY2cv8vhdal2l8fOeu\nMFZqLdGxUyeP0/idd8TL7nv2bqNju7WuZGNmJwDMYa3VRsvdj2zEpERk69mIK5t/6u4XN+B+RGQL\n03s2IpLFepONA/iJmf3SzB691jeY2aNmNmFmE7Oz/DWriGxd630Z9RF3nzKznQB+bGavuPtTV3+D\nux8FcBQAbj90y/re5RWRd611Xdm4+1Tn7/MAfgDg/o2YlIhsPTecbMxswMyG3v4awMcBvLhRExOR\nrWU9L6N2AfiBre1jUgHwX939f7IBBkPF4u1FCovrVdx43QbbYgMAilL8uC0kPp6fqHVZLbXCmDuv\nZVlaGaLxgXHeymFk184wNrPA21OcP3WFxqfPxa0eFld4XcfyCt/+49x0/Fy/ceIkHTs5yets7v3Q\nwTBW7+Njz0xO0fixV+L42YuJuqWlaRp/88wbNH47qeO5becgHTs6ymuXbj0Q19ksLia2SerSDScb\nd38DwL0bMgsR2fK09C0iWSjZiEgWSjYikoWSjYhkoWQjIlko2YhIFnn72ZihXInrXbxNtslwvtZf\nFLympFyJt9EYHBqhYy8lPtK11IxrSsp9fHuOUoP3ChnZt5/GR3cOh7HTvz5Hxx57i9d1tJfiY7r7\nwD46dlsf37Zk94HdYezsGy/TsW++9jyNz03EfWEaNX6eTJI6GgA4dyFucPDKW7w+aPdIXI8FAPtv\nifvVAMC2ofjTPo0Gr2u6/dAOGh8ciGNLC7xGp1u6shGRLJRsRCQLJRsRyULJRkSyULIRkSyUbEQk\ni6xL3wbASvHSo5Hla3eeF5uIl9QBoH80Xqod3f8+OvbK63GrBQBokFX56VneVuDFl16h8b2X+ZLm\n3oO3hLHL87xcYHA8bk8BAIN98bYnA9t4uUCpxtstjPTFj33wjoN07P7bP0DjJ9+Il6BPvPICHTs1\nNUvj8wtxW465+dN07D0f4OUCf/QvPkzjS/Nxe4xLZ07RsTPzvH5jZiZeVh8d5cvm3dKVjYhkoWQj\nIlko2YhIFko2IpKFko2IZKFkIyJZKNmISBZZ62wcjlY7/rh64fH2Hu1EXmyC13UsNuJagQv1uN0B\nAMxXeY3CxM/+Vxz7+X+nY6dOvEXjhz70CRq/53f/MIz1j/JamFof3/6jf1vcJqJvJHHq1HiNT/9I\nXDMyNszbU4wf4G05Dtz1wTBWlHjd0rFn/o7GV5bjuikrrdCxtxzYS+ODDd6CYnEmbhmyZ29iK6M2\nv+/ZK5fC2N5dfDuhbunKRkSyULIRkSyUbEQkCyUbEclCyUZEslCyEZEslGxEJItknY2ZPQbgnwM4\n7+73dG4bBfAdAAcBnADwkLvH+2d0uDuabL2/IHU2xrfgWCl4P5vzF+IaiMHBuJcHAEzP8jqbv3/y\niTB24lc/pWP3jfPtO84e59utlCvjYezDH41rcABgfHyUxgvMhbFaNX6uAGBge53GWTuc8V38uV5a\n4P9HrnhcczU0zk/51dZ5Gm+tkFqXPbw/0M6RMRqfPH6cxm+5La4HGxnhWwadnuTncKsZ/14ukx4+\n16ObK5u/BvDAO277IoAn3f1OAE92/i0iEkomG3d/CsA7yws/CeDxztePA/jUBs9LRLaYG33PZpe7\nn+l8fRYAfy0gIu95636D2N0dQPimh5k9amYTZjYxO5fYx1ZEtqwbTTbnzGwPAHT+Dt9Vc/ej7n7E\n3Y8MD/EP/onI1nWjyeZHAB7pfP0IgB9uzHREZKtKJhsz+zaAfwDwfjObNLPPAPgKgI+Z2WsA/lnn\n3yIioWSdjbs/HIQ+ev0PZ0Apzm9Gcl+5wuto2s7rOorl+EedfO5NOvaZn/2Mxmem49qM8R2307HD\nQ/tpvKgO0Pjq5bgG4uTLr9GxHzh8F43v2R/3jVkpeH+UoQp/yTxYj5/PZpP3wllY5D1pFlfimqpm\nK+6nBADe5j1pylgKY7cl+uwM1vlj18F/7vZS/NinZhP7Xc3yvc/qFs9t+vxZOrZbqiAWkSyUbEQk\nCyUbEclCyUZEslCyEZEslGxEJIvMW7kAhcftHEqIWwtUyomtKlp8ae+tY0+HsYmn+Uf7T73F495a\nCGOlCl+6XiniLU0AoEbuGwDas/Gy5K+fSXw8pDVDw6uzZFm+WqZjbYkv8w5a3BqjDn5MSuQcAoCC\nbBc0Mx1vWQKkl77vOBh/DPC+u/bRsePDNIwdY7xFxSppwTI/z5/r5WX+cy2T8+z0WT62W7qyEZEs\nlGxEJAslGxHJQslGRLJQshGRLJRsRCQLJRsRySJrnQ0AtEmJhFtcu1HhpRUYqS3TeG0l3hKlPfMC\nHbt3JFHXQToDtNtxWwAAWJh7hcbnFnm9SkFaaxSJNg8zF1+l8WO/ird6GR/jW4fs23+Axi/e/b4w\ndusHeduNZoP/H3l68mIY8+U4BgC/93t30/jhW+O6qQ8eupWOrTX4FjXV/ngLGgBorcRtPcqkdQsA\nlKv8HG6S2qWzidqkbunKRkSyULIRkSyUbEQkCyUbEclCyUZEslCyEZEslGxEJIu8dTYGlMtxLY1Z\nXIdQsGIWAPUKr2E4fO/BMLZn1xAdu7rKa11aZHsQ9jMBwIULvO7jf//sGRp/880TYawNvr3N3AKv\nw7l0OT4u56Z4TcjJ13n90KuvHgtjt7/Gt7+pj/B+N5dn4rqQemuajv1H995G47sH4lqXkdEROnZ+\nlfcmahW8FqZEfndSqon+Q02yM8/cAu8V1S1d2YhIFko2IpKFko2IZKFkIyJZKNmISBZKNiKSRdal\nb4PRpW+2vO2J7TtSBvqrYezQ7Tvo2HZi2Z2tbpcSS9+rq3tpfGpyisaPvx63ifAS34Ij0ZUAZSPf\n4PyYrK7y+567HC9fr17hW6KcO8FbY0xOPhfGdgyTNV4A43fxMohmPV7eboKfo4uteCsWALh07hSN\ns+ejldiCBsYf28mye63GSw26lbyyMbPHzOy8mb141W1fNrMpM3u28+fBDZmNiGxZ3byM+msAD1zj\n9r9098OdP09s7LREZKtJJht3fwrAxrTqEpH3rPW8Qfw5M3u+8zIr7BFpZo+a2YSZTczOzq3j4UTk\n3exGk83XARwCcBjAGQBfjb7R3Y+6+xF3PzI8zN98E5Gt64aSjbufc/e2uxcAvgHg/o2dlohsNTeU\nbMxsz1X//DSAF6PvFREBuqizMbNvA/gDAONmNgngSwD+wMwOA3AAJwD86U2c49vzWFe81YrrK4o2\nr0FIbZNRInFP1Oj01fppfLB/nMbd46fwlgN8O5Vmk/9c7XbcosLAj7cbb0tQtrgQZ6SxjY49c4Gv\nV1x68/kwdvA+fkx2ju6kcVj8fJ46fYYPrfFft8Ulvu3PMmn1UDhvg9Loi+vMAKB/IK6lGR3hW+t0\nK5ls3P3ha9z8zQ15dBF5z9DHFUQkCyUbEclCyUZEslCyEZEslGxEJAslGxHJIu9WLvDkliwR1gcH\nSG/1UpA2JmXj/TrqVb4lCqs5cfB5lYzfd2uVx+u1uL/Kxz/2MTr2+GvHafy5Z+PtWGpVXrex0uR1\nNpXacBibm+H1Jq2lZRq//da4Tuf9h3j/oJ3jozQOi8/D+Vlee1Qz/utWrfBj2q7G52m90UfHOngd\nztJifMwvT/PthrqlKxsRyULJRkSyULIRkSyUbEQkCyUbEclCyUZEssi89M2xNhF8UTHdYqJEVs7L\niTsvlRLbyNBtTfjYNluTB7C6ypfOK+X4KRwZadCxR/7x+2i81ZwNY6PDvPVFK/FzzyzHXRubvOMH\nBgYHaPyWA7eEsdFR3r6i3uD3bWT5emWRLy/3k6VrAGiM82M6efp0GJuZmaFjR7bzLpkDg4NhrFrl\nZSfd0pWNiGShZCMiWSjZiEgWSjYikoWSjYhkoWQjIlko2YhIFpnrbIy2inCPazMSlS6wUuLj/dW4\n5qREHhcAWq1425E1cS1MmdTBAECzyetsWomak1I5/rnm5vl2x/f/Lq+z2bd3LIwNN3grhtklXnPy\n97+Kt2O5cpHXhGwb520ixsbi+qBag7dxKCfaiZQs/v+5f5Cfg0WbH5OREf5zn78Yn0sz8/yx55f4\nOTzWiOtsxsZ47VG3dGUjIlko2YhIFko2IpKFko2IZKFkIyJZKNmISBZKNiKSRbLOxswOAPgbALuw\nVu5y1N3/ysxGAXwHwEEAJwA85O6X+X0BpVKc3250mxeAb6cCACXS0KZo8TqbZotvLVImKbucaJZT\nFDzfF857oKAU10csJ8qDKnXep2TbaLzdSrXgp87Zk+dp/PxlUnPCmg8BqFX481Uh51i9wY+nka1a\nUiq8RAeXLsX1PwDQmubn2WpzJY4l6rFslZ+HszPx9jiry3xe3ermyqYF4M/c/W4AHwbwWTO7G8AX\nATzp7ncCeLLzbxGRa0omG3c/4+7PdL6eA3AMwD4AnwTweOfbHgfwqZs1SRF597uu92zM7CCA+wA8\nDWCXu5/phM5i7WXWtcY8amYTZjYxMzu/jqmKyLtZ18nGzAYBfA/AF9z9N158+tqHmq75Qtrdj7r7\nEXc/sm04fn9BRLa2rpKNmVWxlmi+5e7f79x8zsz2dOJ7APB3BEXkPS2ZbGxt24JvAjjm7l+7KvQj\nAI90vn4EwA83fnoislV002Li9wH8CYAXzOzZzm1/DuArAL5rZp8B8BaAh27OFDeIxcul5TJfSq2V\neFsCI/ed2mIm1RrDEtt/NJ08hSW+Fuslft+TZ0+GsePH4hgAHH8jXkoFgNXq+8PY8DC/SK6X+GNv\n3xb/3Jb4/7WZ2DrHybY9s4n3JOdm+RLyAni8aMXnSmuFr33XKvw8W16Kxy8tLNCx3UomG3f/OeJt\nmz66IbMQkS1PFcQikoWSjYhkoWQjIlko2YhIFko2IpKFko2IZJF5K5ceKpHtVhI1COVEm4eClOkU\n7cQmNIk6nEbfCI/37wxjSyvxNi8A8H+efpXG33zj9fi+ebcEFO39ND5Q3xbGrPkaHbtnN++dsW/3\nvjA2s8i3zllZ4XHWBmX64gwdOzfH61UaDV4X1d8Xb6lSr/G6pnZiyyB2HnrqHO6SrmxEJAslGxHJ\nQslGRLJQshGRLJRsRCQLJRsRyULJRkSyyFxnY8n+LjdqrTNprNUm/T4S23eUE31fUMTjLdErp1rn\nvXLGxnfQ+M7xuJ7l1WOn6dh6Hy+WGeyP27g2anGdDAB4c4jG56Ynw1jfwJt07K7fGaXxRl9fGDt/\n5QId21xapPF6Lb7vRiOOAcCVK7zfTSpercV1OLfuj2uLAODMGX4uzC+SOp0iUaPTJV3ZiEgWSjYi\nkoWSjYhkoWQjIlko2YhIFko2IpJF9hYTpVKc39jydWppOxknO3SwVXEAKBlf+jaLlyTPnj1Lx56a\n5EuSly/P0fhAfzOM7d0zTsfW63HLAgA4fzZeJi5afIl4oC/ROmMk3q5l/wG+c2qtxksVZldJq4dS\nfLwA4PLFSzQ+0D8cxuo1fjy3bYvHAsD0lcs03mrHrTVGtvFl9+YKL0VwsqXQ6god2jVd2YhIFko2\nIpKFko2IZKFkIyJZKNmISBZKNiKShZKNiGSRtc7GzFCqxPnNSOpL19nwx24XpO7D+GFotXhOnrkS\n18I8/9wrdOyLLz1L4wsrfIuO22/7nTB28BZerzKZqPEZJsMHG7xuo13w+qJbb4vrXca283oVK/PC\nqBWLW2cMDvN6lLk5XsOz2ozri0olPnYo8dgt8FYOfX1xO5JWa4mOrdV43dPISPxkLyxtzDVJ8l7M\n7ICZ/dTMXjazl8zs853bv2xmU2b2bOfPgxsyIxHZkrq5smkB+DN3f8bMhgD80sx+3In9pbv/xc2b\nnohsFclk4+5nAJzpfD1nZscA8LZgIiLvcF0vxszsIID7ADzduelzZva8mT1mZtuDMY+a2YSZTczM\nJPZsFZEtq+tkY2aDAL4H4AvuPgvg6wAOATiMtSufr15rnLsfdfcj7n4k9UE0Edm6uko2ZlbFWqL5\nlrt/HwDc/Zy7t929APANAPffvGmKyLtdN6tRBuCbAI65+9euun3PVd/2aQAvbvz0RGSr6GY16vcB\n/AmAF8zs7aKQPwfwsJkdBuAATgD4024ezcZInQ3pOVM0eW1FareJksd1BiXng9sLvHdLcyXuQ7Jj\nlG/Vctf7dtP47Azvr7J3LK7DKa0cp2P38XY3WGnH9S4N401Oqsafr5G+uM5m13iizqbCT9v5xSth\nrGjxepOdY3ybmCY5D1NbubQTjZNabV6ns0xqri5M83qsWpX3ZCo8nlu5TH4xr0M3q1E/B3CtZ+iJ\nDZmBiLwn6OMKIpKFko2IZKFkIyJZKNmISBZKNiKShZKNiGSRd9+oisHG4lqCohmv5zeX+Fr/yhJv\naFO1ON4Hft/1Ms/JI/NxbHWRjx0e5nU2C1f6aby9En/erJro+1If4B8fefXkuTBWgB/v9x/kRTzn\np+P6oR07eA3PcD8/JgszcU3JQJ3Xwswu872bxsdGwtj27dvo2HKF1/hcfuZlGi/acW3SSsHPM0vU\nypTJvlGGxMZqXdKVjYhkoWQjIlko2YhIFko2IpKFko2IZKFkIyJZZF36djiaZAluaTX+mPxCk3+E\nvnCeNwfK8XJone0hA6BZxEuOADC3OBPG2sUqHQvw+x7bwZdqF2bjdff5ubjVAgCUnbc02L073t5j\nbjbevgYATs9coPFVj5e3T1/g28CsJlo1zM3ELUGKfr4E3GzxdiOzc/HPfe78GTq2r79B4xWyzREA\nsJ1iEtUZaJNlcwAoV+I7bzZT53B3dGUjIlko2YhIFko2IpKFko2IZKFkIyJZKNmISBZKNiKSRdY6\nmwIFFtpxvczMSlzDsLjMt1PpLw/ReKUS16sszvCakYVzvO3A0nJcZ1Or87YCrTaPV2q8PqI+EI9v\ngW/fUakmWmsgrjnxYb5FzWqxRONs25OW83lduHCRxkeGxsLY0jKv11pp8uNt5fh4sxocALgyy+ue\nGn38HG404l/XVovXHq2u8t+fgVq8fU6ttjFpQlc2IpKFko2IZKFkIyJZKNmISBZKNiKShZKNiGSh\nZCMiWSQX0M2sAeApAPXO9/83d/+SmY0C+A6AgwBOAHjI3WlBSuGOlXZcf8FicF7/MJDYJqM9E/d9\nuXzyNB072s97yvRti+Op2oulpQUat0S/G9Zrx6r86XWyvQ0ADDbiWppqNVE/RLYGAYDV5fjnriaa\ns1QrdRofGorrVU5NTdGx05emaXzXrh1hzBLzrpQSfZPafAubWi3uh1Ot8bqnZpPXPbXpY+fbymUF\nwB+6+70ADgN4wMw+DOCLAJ509zsBPNn5t4jINSWTja95+7Kg2vnjAD4J4PHO7Y8D+NRNmaGIbAld\nvWdjZmUzexbAeQA/dvenAexy97f7IJ4FsCsY+6iZTZjZxPxlsnWkiGxpXSUbd2+7+2EA+wHcb2b3\nvCPuwLX3Y3X3o+5+xN2PDG6Pe9qKyNZ2XatR7n4FwE8BPADgnJntAYDO3+c3fnoislUkk42Z7TCz\nkc7XfQA+BuAVAD8C8Ejn2x4B8MObNUkReffr5rPjewA8bmZlrCWn77r7/zCzfwDwXTP7DIC3ADyU\nuqOiaGNxMV4Kbq/Gy28N50up9QW+bLg0NRvGhlt8S5N9I9tpfGYmXi6dnedbg5SqiXxvfG7LK/Gy\nZAE+tlbvp/GhevyydyRx5pTqfFl9djae2+IibwPR18dLEVrtuEVFk8QAYDXRYmJuIV6ybyW2mKmy\nvVgABO9E/H9m8dyLIjG2xH/udhGfp5XUOdqlZLJx9+cB3HeN26cBfHRDZiEiW54qiEUkCyUbEclC\nyUZEslCyEZEslGxEJAslGxHJwtY+aZDpwcwuYK0m523jAPi+HL2xWecFbN65aV7Xb7PO7Xrndau7\nx703OrImm996cLMJdz/SswkENuu8gM07N83r+m3Wud2seelllIhkoWQjIln0Otkc7fHjRzbrvIDN\nOzfN6/pt1rndlHn19D0bEXnv6PWVjYi8RyjZiEgWPUk2ZvaAmf3azI6b2abalcHMTpjZC2b2rJlN\n9HAej5nZeTN78arbRs3sx2b2Wudv3mgn79y+bGZTneP2rJk92IN5HTCzn5rZy2b2kpl9vnN7T48b\nmddmOGYNM/u/ZvZcZ27/vnP7hh+z7O/ZdJpwvYq1jn+TAH4B4GF3fznrRAJmdgLAEXfvabGVmf0T\nAPMA/sbd7+nc9h8BXHL3r3SS9HZ3/zebZG5fBjDv7n+Rez5XzWsPgD3u/oyZDQH4JdZ2/fiX6OFx\nI/N6CL0/ZgZgwN3nzawK4OcAPg/gj7DBx6wXVzb3Azju7m+4+yqAv8XatjByFXd/CsCld9y8KbbP\nCebWc+5+xt2f6Xw9B+AYgH3o8XEj8+q5nFs19SLZ7ANw6qp/T2KTHPgOB/ATM/ulmT3a68m8Q1fb\n5/TQ58zs+c7LrJ68xHubmR3EWofJrrcdyuEd8wI2wTFbz1ZN10NvEP+2j3S2rfkEgM92XjJsOmz7\nnB75OoBDWNs19QyAr/ZqImY2COB7AL7g7r/RfLqXx+0a89oUx2w9WzVdj14kmykAB6769/7ObZuC\nu091/j4P4AdYe9m3WWza7XPc/VznpC0AfAM9Om6d9x2+B+Bb7v79zs09P27XmtdmOWZvu9lbNfUi\n2fwCwJ1mdpuZ1QD8Mda2hek5MxvovIEHMxsA8HEAL/JRWW3a7XPePjE7Po0eHLfOm53fBHDM3b92\nVainxy2a1yY5Zvm2anL37H8APIi1FanXAfzbXswhmNchAM91/rzUy7kB+DbWLq2bWHtf6zMAxgA8\nCeA1AD8BMLqJ5vZfALwA4PnOibqnB/P6CNYu958H8Gznz4O9Pm5kXpvhmH0IwK86c3gRwL/r3L7h\nx0wfVxCRLPQGsYhkoWQjIlko2YhIFko2IpKFko2IZKFkIyJZKNmISBb/D1Su+BAXSsmcAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17ee9f142e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: frog\n",
      "Predictions: ['horse' 'bird' 'dog'] [ 0.87164414  0.10383365  0.01343391]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCQLJRsRyULJRkSyULIRkSz+D2opgdyzgsqVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17e886b0668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: airplane\n",
      "Predictions: ['truck' 'cat' 'automobile'] [ 0.98806775  0.00313511  0.00250824]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17eee6822b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: deer\n",
      "Predictions: ['dog' 'frog' 'horse'] [ 0.98990017  0.00438304  0.00317229]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17eea1ac518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: ship\n",
      "Predictions: ['automobile' 'bird' 'cat'] [ 0.81574732  0.13052218  0.04060157]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noWQjIkko2YhIEko2IpLE/wPHQfjqNm0vFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f89383e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: dog\n",
      "Predictions: ['deer' 'bird' 'airplane'] [ 0.67643625  0.16384377  0.14045107]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f893047b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: truck\n",
      "Predictions: ['ship' 'cat' 'airplane'] [  9.98607337e-01   9.56409203e-04   1.60390948e-04]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nj4vSadQ1t8EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f89c58048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: deer\n",
      "Predictions: ['cat' 'dog' 'horse'] [ 0.76926351  0.11822023  0.08392049]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCSUbEUni/wPDm95yjNvOIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17e886b8550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: automobile\n",
      "Predictions: ['truck' 'horse' 'dog'] [  9.84286904e-01   1.51919518e-02   3.53193784e-04]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17e88a4c1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: truck\n",
      "Predictions: ['bird' 'dog' 'horse'] [  9.98521388e-01   6.92658476e-04   2.98972009e-04]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f89bad908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: automobile\n",
      "Predictions: ['truck' 'cat' 'horse'] [ 0.9849745   0.0131389   0.00147518]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyYaIomCyIaIomGyIKAomGyKK4v8DdePeKRKkW20AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f88febcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: ship\n",
      "Predictions: ['airplane' 'truck' 'deer'] [ 0.98544532  0.00985646  0.00249108]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+d3PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17e889e7ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: deer\n",
      "Predictions: ['automobile' 'truck' 'horse'] [ 0.99187875  0.00626307  0.00136699]\n"
     ]
    }
   ],
   "source": [
    "worst = worst_samples(session, test_x, test_y, config)\n",
    "\n",
    "for sample_id, l, predicted in worst:\n",
    "    show_image(test_x[sample_id], data_mean, data_std)\n",
    "    probas = session.run(tf.nn.softmax(logits), feed_dict={X: np.array([test_x[sample_id]])})\n",
    "    probas = probas[0]\n",
    "    predictions  = np.argsort(-probas)\n",
    "\n",
    "    print(\"Correct class:\", class_names[test_y[sample_id]])\n",
    "    print(\"Predictions:\", class_names[predictions[:3]], probas[predictions[:3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS task - Multiclass hinge loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_class_hinge_loss(logits, label, n_classes, delta=10):\n",
    "    label_oh = tf.one_hot(label, depth=n_classes, dtype=tf.float32)\n",
    "    mask = 1-label_oh\n",
    "    \n",
    "    correct_logits = tf.diag(tf.reduce_sum(label_oh * logits, 1))\n",
    "    correct_logits_mat = tf.matmul(correct_logits, tf.ones_like(logits))\n",
    "    \n",
    "    errors = tf.nn.relu(logits - correct_logits_mat + delta)\n",
    "    return errors * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Graph\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "Y_ = tf.placeholder(tf.int32, [None,])\n",
    "logits = convnet(X, weights, biases)\n",
    "\n",
    "# loss\n",
    "regularizers = l2_loss(weights.values())\n",
    "loss_per_sample = multi_class_hinge_loss(logits, Y_, n_classes)\n",
    "data_loss = tf.reduce_mean(loss_per_sample)\n",
    "loss = data_loss + weight_decay*regularizers\n",
    "\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(0.01, global_step, 900, 0.9, staircase=True)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 50 / 900, loss = 7.51 (0.007 sec/batch)\n",
      "epoch 1, step 100 / 900, loss = 6.23 (0.006 sec/batch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Korisnik\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 150 / 900, loss = 4.86 (0.006 sec/batch)\n",
      "epoch 1, step 200 / 900, loss = 4.44 (0.006 sec/batch)\n",
      "epoch 1, step 250 / 900, loss = 4.82 (0.008 sec/batch)\n",
      "epoch 1, step 300 / 900, loss = 4.16 (0.007 sec/batch)\n",
      "epoch 1, step 350 / 900, loss = 4.65 (0.008 sec/batch)\n",
      "epoch 1, step 400 / 900, loss = 3.61 (0.009 sec/batch)\n",
      "epoch 1, step 450 / 900, loss = 3.45 (0.007 sec/batch)\n",
      "epoch 1, step 500 / 900, loss = 3.54 (0.007 sec/batch)\n",
      "epoch 1, step 550 / 900, loss = 3.37 (0.008 sec/batch)\n",
      "epoch 1, step 600 / 900, loss = 2.82 (0.008 sec/batch)\n",
      "epoch 1, step 650 / 900, loss = 2.56 (0.007 sec/batch)\n",
      "epoch 1, step 700 / 900, loss = 3.11 (0.007 sec/batch)\n",
      "epoch 1, step 750 / 900, loss = 2.81 (0.006 sec/batch)\n",
      "epoch 1, step 800 / 900, loss = 4.42 (0.007 sec/batch)\n",
      "epoch 1, step 850 / 900, loss = 3.11 (0.007 sec/batch)\n",
      "epoch 1, step 900 / 900, loss = 3.24 (0.009 sec/batch)\n",
      "Train error:\n",
      " accuracy = 50.23\n",
      " avg loss = 2.92\n",
      "\n",
      "Validation error:\n",
      " accuracy = 48.92\n",
      " avg loss = 2.98\n",
      "\n",
      "Epoch time: 9.073502540588379\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 2, step 50 / 900, loss = 3.44 (0.006 sec/batch)\n",
      "epoch 2, step 100 / 900, loss = 3.18 (0.007 sec/batch)\n",
      "epoch 2, step 150 / 900, loss = 3.85 (0.007 sec/batch)\n",
      "epoch 2, step 200 / 900, loss = 3.59 (0.007 sec/batch)\n",
      "epoch 2, step 250 / 900, loss = 2.79 (0.007 sec/batch)\n",
      "epoch 2, step 300 / 900, loss = 2.77 (0.009 sec/batch)\n",
      "epoch 2, step 350 / 900, loss = 2.38 (0.007 sec/batch)\n",
      "epoch 2, step 400 / 900, loss = 2.29 (0.006 sec/batch)\n",
      "epoch 2, step 450 / 900, loss = 3.38 (0.007 sec/batch)\n",
      "epoch 2, step 500 / 900, loss = 3.47 (0.007 sec/batch)\n",
      "epoch 2, step 550 / 900, loss = 1.90 (0.007 sec/batch)\n",
      "epoch 2, step 600 / 900, loss = 2.09 (0.006 sec/batch)\n",
      "epoch 2, step 650 / 900, loss = 2.46 (0.007 sec/batch)\n",
      "epoch 2, step 700 / 900, loss = 2.80 (0.007 sec/batch)\n",
      "epoch 2, step 750 / 900, loss = 2.90 (0.008 sec/batch)\n",
      "epoch 2, step 800 / 900, loss = 2.76 (0.007 sec/batch)\n",
      "epoch 2, step 850 / 900, loss = 3.19 (0.007 sec/batch)\n",
      "epoch 2, step 900 / 900, loss = 2.35 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 57.97\n",
      " avg loss = 2.31\n",
      "\n",
      "Validation error:\n",
      " accuracy = 57.36\n",
      " avg loss = 2.46\n",
      "\n",
      "Epoch time: 9.08277678489685\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 3, step 50 / 900, loss = 2.63 (0.008 sec/batch)\n",
      "epoch 3, step 100 / 900, loss = 2.53 (0.007 sec/batch)\n",
      "epoch 3, step 150 / 900, loss = 1.81 (0.007 sec/batch)\n",
      "epoch 3, step 200 / 900, loss = 1.65 (0.007 sec/batch)\n",
      "epoch 3, step 250 / 900, loss = 3.04 (0.008 sec/batch)\n",
      "epoch 3, step 300 / 900, loss = 2.80 (0.007 sec/batch)\n",
      "epoch 3, step 350 / 900, loss = 3.05 (0.007 sec/batch)\n",
      "epoch 3, step 400 / 900, loss = 1.98 (0.009 sec/batch)\n",
      "epoch 3, step 450 / 900, loss = 2.69 (0.007 sec/batch)\n",
      "epoch 3, step 500 / 900, loss = 2.24 (0.009 sec/batch)\n",
      "epoch 3, step 550 / 900, loss = 2.21 (0.007 sec/batch)\n",
      "epoch 3, step 600 / 900, loss = 2.51 (0.009 sec/batch)\n",
      "epoch 3, step 650 / 900, loss = 1.92 (0.007 sec/batch)\n",
      "epoch 3, step 700 / 900, loss = 2.15 (0.007 sec/batch)\n",
      "epoch 3, step 750 / 900, loss = 1.92 (0.008 sec/batch)\n",
      "epoch 3, step 800 / 900, loss = 1.73 (0.009 sec/batch)\n",
      "epoch 3, step 850 / 900, loss = 1.50 (0.007 sec/batch)\n",
      "epoch 3, step 900 / 900, loss = 1.23 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 62.55\n",
      " avg loss = 1.96\n",
      "\n",
      "Validation error:\n",
      " accuracy = 60.68\n",
      " avg loss = 2.16\n",
      "\n",
      "Epoch time: 9.118268251419067\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 4, step 50 / 900, loss = 1.63 (0.007 sec/batch)\n",
      "epoch 4, step 100 / 900, loss = 2.26 (0.008 sec/batch)\n",
      "epoch 4, step 150 / 900, loss = 1.99 (0.007 sec/batch)\n",
      "epoch 4, step 200 / 900, loss = 2.12 (0.007 sec/batch)\n",
      "epoch 4, step 250 / 900, loss = 1.77 (0.007 sec/batch)\n",
      "epoch 4, step 300 / 900, loss = 1.92 (0.007 sec/batch)\n",
      "epoch 4, step 350 / 900, loss = 2.34 (0.007 sec/batch)\n",
      "epoch 4, step 400 / 900, loss = 2.37 (0.007 sec/batch)\n",
      "epoch 4, step 450 / 900, loss = 1.43 (0.009 sec/batch)\n",
      "epoch 4, step 500 / 900, loss = 1.45 (0.007 sec/batch)\n",
      "epoch 4, step 550 / 900, loss = 1.85 (0.006 sec/batch)\n",
      "epoch 4, step 600 / 900, loss = 1.70 (0.006 sec/batch)\n",
      "epoch 4, step 650 / 900, loss = 2.88 (0.007 sec/batch)\n",
      "epoch 4, step 700 / 900, loss = 2.01 (0.009 sec/batch)\n",
      "epoch 4, step 750 / 900, loss = 1.82 (0.006 sec/batch)\n",
      "epoch 4, step 800 / 900, loss = 1.64 (0.007 sec/batch)\n",
      "epoch 4, step 850 / 900, loss = 1.27 (0.007 sec/batch)\n",
      "epoch 4, step 900 / 900, loss = 1.93 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 65.03\n",
      " avg loss = 1.76\n",
      "\n",
      "Validation error:\n",
      " accuracy = 62.18\n",
      " avg loss = 2.05\n",
      "\n",
      "Epoch time: 9.131751298904419\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 5, step 50 / 900, loss = 1.93 (0.010 sec/batch)\n",
      "epoch 5, step 100 / 900, loss = 1.73 (0.007 sec/batch)\n",
      "epoch 5, step 150 / 900, loss = 1.16 (0.007 sec/batch)\n",
      "epoch 5, step 200 / 900, loss = 1.52 (0.006 sec/batch)\n",
      "epoch 5, step 250 / 900, loss = 1.77 (0.008 sec/batch)\n",
      "epoch 5, step 300 / 900, loss = 1.65 (0.007 sec/batch)\n",
      "epoch 5, step 350 / 900, loss = 2.20 (0.007 sec/batch)\n",
      "epoch 5, step 400 / 900, loss = 1.46 (0.007 sec/batch)\n",
      "epoch 5, step 450 / 900, loss = 1.62 (0.007 sec/batch)\n",
      "epoch 5, step 500 / 900, loss = 1.54 (0.009 sec/batch)\n",
      "epoch 5, step 550 / 900, loss = 1.42 (0.007 sec/batch)\n",
      "epoch 5, step 600 / 900, loss = 1.71 (0.007 sec/batch)\n",
      "epoch 5, step 650 / 900, loss = 2.33 (0.006 sec/batch)\n",
      "epoch 5, step 700 / 900, loss = 1.21 (0.009 sec/batch)\n",
      "epoch 5, step 750 / 900, loss = 0.95 (0.007 sec/batch)\n",
      "epoch 5, step 800 / 900, loss = 2.19 (0.007 sec/batch)\n",
      "epoch 5, step 850 / 900, loss = 2.04 (0.007 sec/batch)\n",
      "epoch 5, step 900 / 900, loss = 1.22 (0.009 sec/batch)\n",
      "Train error:\n",
      " accuracy = 67.93\n",
      " avg loss = 1.58\n",
      "\n",
      "Validation error:\n",
      " accuracy = 65.20\n",
      " avg loss = 1.89\n",
      "\n",
      "Epoch time: 9.094632863998413\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 6, step 50 / 900, loss = 1.98 (0.006 sec/batch)\n",
      "epoch 6, step 100 / 900, loss = 1.48 (0.006 sec/batch)\n",
      "epoch 6, step 150 / 900, loss = 1.04 (0.007 sec/batch)\n",
      "epoch 6, step 200 / 900, loss = 1.09 (0.007 sec/batch)\n",
      "epoch 6, step 250 / 900, loss = 1.02 (0.006 sec/batch)\n",
      "epoch 6, step 300 / 900, loss = 1.35 (0.007 sec/batch)\n",
      "epoch 6, step 350 / 900, loss = 1.70 (0.007 sec/batch)\n",
      "epoch 6, step 400 / 900, loss = 1.67 (0.007 sec/batch)\n",
      "epoch 6, step 450 / 900, loss = 1.55 (0.007 sec/batch)\n",
      "epoch 6, step 500 / 900, loss = 0.95 (0.007 sec/batch)\n",
      "epoch 6, step 550 / 900, loss = 1.09 (0.007 sec/batch)\n",
      "epoch 6, step 600 / 900, loss = 0.97 (0.007 sec/batch)\n",
      "epoch 6, step 650 / 900, loss = 1.12 (0.007 sec/batch)\n",
      "epoch 6, step 700 / 900, loss = 1.03 (0.007 sec/batch)\n",
      "epoch 6, step 750 / 900, loss = 2.15 (0.007 sec/batch)\n",
      "epoch 6, step 800 / 900, loss = 2.03 (0.008 sec/batch)\n",
      "epoch 6, step 850 / 900, loss = 1.67 (0.007 sec/batch)\n",
      "epoch 6, step 900 / 900, loss = 1.66 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 68.76\n",
      " avg loss = 1.50\n",
      "\n",
      "Validation error:\n",
      " accuracy = 65.40\n",
      " avg loss = 1.90\n",
      "\n",
      "Epoch time: 9.130816221237183\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 7, step 50 / 900, loss = 1.37 (0.006 sec/batch)\n",
      "epoch 7, step 100 / 900, loss = 1.64 (0.007 sec/batch)\n",
      "epoch 7, step 150 / 900, loss = 1.55 (0.006 sec/batch)\n",
      "epoch 7, step 200 / 900, loss = 1.11 (0.007 sec/batch)\n",
      "epoch 7, step 250 / 900, loss = 1.07 (0.007 sec/batch)\n",
      "epoch 7, step 300 / 900, loss = 0.67 (0.009 sec/batch)\n",
      "epoch 7, step 350 / 900, loss = 1.38 (0.008 sec/batch)\n",
      "epoch 7, step 400 / 900, loss = 1.53 (0.007 sec/batch)\n",
      "epoch 7, step 450 / 900, loss = 0.81 (0.007 sec/batch)\n",
      "epoch 7, step 500 / 900, loss = 1.28 (0.007 sec/batch)\n",
      "epoch 7, step 550 / 900, loss = 1.69 (0.006 sec/batch)\n",
      "epoch 7, step 600 / 900, loss = 1.09 (0.007 sec/batch)\n",
      "epoch 7, step 650 / 900, loss = 1.61 (0.007 sec/batch)\n",
      "epoch 7, step 700 / 900, loss = 1.89 (0.007 sec/batch)\n",
      "epoch 7, step 750 / 900, loss = 1.29 (0.007 sec/batch)\n",
      "epoch 7, step 800 / 900, loss = 1.26 (0.006 sec/batch)\n",
      "epoch 7, step 850 / 900, loss = 1.34 (0.006 sec/batch)\n",
      "epoch 7, step 900 / 900, loss = 1.82 (0.007 sec/batch)\n",
      "Train error:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy = 72.02\n",
      " avg loss = 1.31\n",
      "\n",
      "Validation error:\n",
      " accuracy = 67.40\n",
      " avg loss = 1.72\n",
      "\n",
      "Epoch time: 9.067446231842041\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 8, step 50 / 900, loss = 1.05 (0.009 sec/batch)\n",
      "epoch 8, step 100 / 900, loss = 1.60 (0.009 sec/batch)\n",
      "epoch 8, step 150 / 900, loss = 0.85 (0.007 sec/batch)\n",
      "epoch 8, step 200 / 900, loss = 1.44 (0.007 sec/batch)\n",
      "epoch 8, step 250 / 900, loss = 1.64 (0.007 sec/batch)\n",
      "epoch 8, step 300 / 900, loss = 1.91 (0.007 sec/batch)\n",
      "epoch 8, step 350 / 900, loss = 0.67 (0.007 sec/batch)\n",
      "epoch 8, step 400 / 900, loss = 1.88 (0.006 sec/batch)\n",
      "epoch 8, step 450 / 900, loss = 1.30 (0.009 sec/batch)\n",
      "epoch 8, step 500 / 900, loss = 1.71 (0.009 sec/batch)\n",
      "epoch 8, step 550 / 900, loss = 1.36 (0.007 sec/batch)\n",
      "epoch 8, step 600 / 900, loss = 2.08 (0.007 sec/batch)\n",
      "epoch 8, step 650 / 900, loss = 1.00 (0.007 sec/batch)\n",
      "epoch 8, step 700 / 900, loss = 1.22 (0.007 sec/batch)\n",
      "epoch 8, step 750 / 900, loss = 1.90 (0.008 sec/batch)\n",
      "epoch 8, step 800 / 900, loss = 1.53 (0.007 sec/batch)\n",
      "epoch 8, step 850 / 900, loss = 1.09 (0.007 sec/batch)\n",
      "epoch 8, step 900 / 900, loss = 2.21 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 73.29\n",
      " avg loss = 1.23\n",
      "\n",
      "Validation error:\n",
      " accuracy = 68.42\n",
      " avg loss = 1.70\n",
      "\n",
      "Epoch time: 9.059067726135254\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 9, step 50 / 900, loss = 0.72 (0.007 sec/batch)\n",
      "epoch 9, step 100 / 900, loss = 0.76 (0.007 sec/batch)\n",
      "epoch 9, step 150 / 900, loss = 1.14 (0.007 sec/batch)\n",
      "epoch 9, step 200 / 900, loss = 1.03 (0.007 sec/batch)\n",
      "epoch 9, step 250 / 900, loss = 1.42 (0.009 sec/batch)\n",
      "epoch 9, step 300 / 900, loss = 1.21 (0.008 sec/batch)\n",
      "epoch 9, step 350 / 900, loss = 1.58 (0.010 sec/batch)\n",
      "epoch 9, step 400 / 900, loss = 0.93 (0.007 sec/batch)\n",
      "epoch 9, step 450 / 900, loss = 1.28 (0.007 sec/batch)\n",
      "epoch 9, step 500 / 900, loss = 1.02 (0.006 sec/batch)\n",
      "epoch 9, step 550 / 900, loss = 1.21 (0.007 sec/batch)\n",
      "epoch 9, step 600 / 900, loss = 1.06 (0.007 sec/batch)\n",
      "epoch 9, step 650 / 900, loss = 1.42 (0.007 sec/batch)\n",
      "epoch 9, step 700 / 900, loss = 0.95 (0.007 sec/batch)\n",
      "epoch 9, step 750 / 900, loss = 1.46 (0.007 sec/batch)\n",
      "epoch 9, step 800 / 900, loss = 1.15 (0.007 sec/batch)\n",
      "epoch 9, step 850 / 900, loss = 1.38 (0.007 sec/batch)\n",
      "epoch 9, step 900 / 900, loss = 1.48 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 74.71\n",
      " avg loss = 1.12\n",
      "\n",
      "Validation error:\n",
      " accuracy = 68.66\n",
      " avg loss = 1.64\n",
      "\n",
      "Epoch time: 9.096686363220215\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 10, step 50 / 900, loss = 0.89 (0.007 sec/batch)\n",
      "epoch 10, step 100 / 900, loss = 1.34 (0.007 sec/batch)\n",
      "epoch 10, step 150 / 900, loss = 0.92 (0.007 sec/batch)\n",
      "epoch 10, step 200 / 900, loss = 1.13 (0.007 sec/batch)\n",
      "epoch 10, step 250 / 900, loss = 0.83 (0.006 sec/batch)\n",
      "epoch 10, step 300 / 900, loss = 1.50 (0.006 sec/batch)\n",
      "epoch 10, step 350 / 900, loss = 0.83 (0.007 sec/batch)\n",
      "epoch 10, step 400 / 900, loss = 1.08 (0.007 sec/batch)\n",
      "epoch 10, step 450 / 900, loss = 1.08 (0.007 sec/batch)\n",
      "epoch 10, step 500 / 900, loss = 0.80 (0.009 sec/batch)\n",
      "epoch 10, step 550 / 900, loss = 1.27 (0.007 sec/batch)\n",
      "epoch 10, step 600 / 900, loss = 1.20 (0.006 sec/batch)\n",
      "epoch 10, step 650 / 900, loss = 0.76 (0.009 sec/batch)\n",
      "epoch 10, step 700 / 900, loss = 0.90 (0.007 sec/batch)\n",
      "epoch 10, step 750 / 900, loss = 1.33 (0.007 sec/batch)\n",
      "epoch 10, step 800 / 900, loss = 1.41 (0.006 sec/batch)\n",
      "epoch 10, step 850 / 900, loss = 0.84 (0.008 sec/batch)\n",
      "epoch 10, step 900 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 76.33\n",
      " avg loss = 1.05\n",
      "\n",
      "Validation error:\n",
      " accuracy = 70.22\n",
      " avg loss = 1.61\n",
      "\n",
      "Epoch time: 9.07310152053833\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 11, step 50 / 900, loss = 0.86 (0.009 sec/batch)\n",
      "epoch 11, step 100 / 900, loss = 1.08 (0.008 sec/batch)\n",
      "epoch 11, step 150 / 900, loss = 1.45 (0.007 sec/batch)\n",
      "epoch 11, step 200 / 900, loss = 1.08 (0.007 sec/batch)\n",
      "epoch 11, step 250 / 900, loss = 0.58 (0.007 sec/batch)\n",
      "epoch 11, step 300 / 900, loss = 0.83 (0.006 sec/batch)\n",
      "epoch 11, step 350 / 900, loss = 1.11 (0.006 sec/batch)\n",
      "epoch 11, step 400 / 900, loss = 0.90 (0.007 sec/batch)\n",
      "epoch 11, step 450 / 900, loss = 1.33 (0.007 sec/batch)\n",
      "epoch 11, step 500 / 900, loss = 1.16 (0.007 sec/batch)\n",
      "epoch 11, step 550 / 900, loss = 1.12 (0.006 sec/batch)\n",
      "epoch 11, step 600 / 900, loss = 0.79 (0.008 sec/batch)\n",
      "epoch 11, step 650 / 900, loss = 0.87 (0.007 sec/batch)\n",
      "epoch 11, step 700 / 900, loss = 1.38 (0.007 sec/batch)\n",
      "epoch 11, step 750 / 900, loss = 1.41 (0.007 sec/batch)\n",
      "epoch 11, step 800 / 900, loss = 0.94 (0.007 sec/batch)\n",
      "epoch 11, step 850 / 900, loss = 1.08 (0.006 sec/batch)\n",
      "epoch 11, step 900 / 900, loss = 0.92 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 77.24\n",
      " avg loss = 0.98\n",
      "\n",
      "Validation error:\n",
      " accuracy = 70.38\n",
      " avg loss = 1.59\n",
      "\n",
      "Epoch time: 9.034096240997314\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 12, step 50 / 900, loss = 0.85 (0.006 sec/batch)\n",
      "epoch 12, step 100 / 900, loss = 0.80 (0.007 sec/batch)\n",
      "epoch 12, step 150 / 900, loss = 0.70 (0.007 sec/batch)\n",
      "epoch 12, step 200 / 900, loss = 1.28 (0.007 sec/batch)\n",
      "epoch 12, step 250 / 900, loss = 1.04 (0.008 sec/batch)\n",
      "epoch 12, step 300 / 900, loss = 0.77 (0.006 sec/batch)\n",
      "epoch 12, step 350 / 900, loss = 0.75 (0.006 sec/batch)\n",
      "epoch 12, step 400 / 900, loss = 0.95 (0.008 sec/batch)\n",
      "epoch 12, step 450 / 900, loss = 1.00 (0.007 sec/batch)\n",
      "epoch 12, step 500 / 900, loss = 1.09 (0.007 sec/batch)\n",
      "epoch 12, step 550 / 900, loss = 0.72 (0.009 sec/batch)\n",
      "epoch 12, step 600 / 900, loss = 0.67 (0.009 sec/batch)\n",
      "epoch 12, step 650 / 900, loss = 0.82 (0.006 sec/batch)\n",
      "epoch 12, step 700 / 900, loss = 0.85 (0.007 sec/batch)\n",
      "epoch 12, step 750 / 900, loss = 2.10 (0.007 sec/batch)\n",
      "epoch 12, step 800 / 900, loss = 1.05 (0.006 sec/batch)\n",
      "epoch 12, step 850 / 900, loss = 1.20 (0.007 sec/batch)\n",
      "epoch 12, step 900 / 900, loss = 1.63 (0.009 sec/batch)\n",
      "Train error:\n",
      " accuracy = 75.64\n",
      " avg loss = 1.04\n",
      "\n",
      "Validation error:\n",
      " accuracy = 68.92\n",
      " avg loss = 1.67\n",
      "\n",
      "Epoch time: 9.014873266220093\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 13, step 50 / 900, loss = 0.84 (0.007 sec/batch)\n",
      "epoch 13, step 100 / 900, loss = 0.83 (0.007 sec/batch)\n",
      "epoch 13, step 150 / 900, loss = 0.72 (0.007 sec/batch)\n",
      "epoch 13, step 200 / 900, loss = 0.71 (0.007 sec/batch)\n",
      "epoch 13, step 250 / 900, loss = 0.78 (0.007 sec/batch)\n",
      "epoch 13, step 300 / 900, loss = 0.86 (0.008 sec/batch)\n",
      "epoch 13, step 350 / 900, loss = 1.15 (0.007 sec/batch)\n",
      "epoch 13, step 400 / 900, loss = 1.34 (0.007 sec/batch)\n",
      "epoch 13, step 450 / 900, loss = 0.89 (0.009 sec/batch)\n",
      "epoch 13, step 500 / 900, loss = 0.97 (0.006 sec/batch)\n",
      "epoch 13, step 550 / 900, loss = 0.74 (0.007 sec/batch)\n",
      "epoch 13, step 600 / 900, loss = 1.42 (0.007 sec/batch)\n",
      "epoch 13, step 650 / 900, loss = 1.37 (0.009 sec/batch)\n",
      "epoch 13, step 700 / 900, loss = 0.66 (0.006 sec/batch)\n",
      "epoch 13, step 750 / 900, loss = 1.48 (0.007 sec/batch)\n",
      "epoch 13, step 800 / 900, loss = 1.06 (0.006 sec/batch)\n",
      "epoch 13, step 850 / 900, loss = 1.32 (0.008 sec/batch)\n",
      "epoch 13, step 900 / 900, loss = 0.74 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 78.93\n",
      " avg loss = 0.87\n",
      "\n",
      "Validation error:\n",
      " accuracy = 70.86\n",
      " avg loss = 1.55\n",
      "\n",
      "Epoch time: 9.094472408294678\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 14, step 50 / 900, loss = 0.62 (0.009 sec/batch)\n",
      "epoch 14, step 100 / 900, loss = 0.94 (0.009 sec/batch)\n",
      "epoch 14, step 150 / 900, loss = 0.85 (0.007 sec/batch)\n",
      "epoch 14, step 200 / 900, loss = 1.36 (0.010 sec/batch)\n",
      "epoch 14, step 250 / 900, loss = 0.32 (0.007 sec/batch)\n",
      "epoch 14, step 300 / 900, loss = 0.78 (0.007 sec/batch)\n",
      "epoch 14, step 350 / 900, loss = 0.98 (0.007 sec/batch)\n",
      "epoch 14, step 400 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 14, step 450 / 900, loss = 0.94 (0.007 sec/batch)\n",
      "epoch 14, step 500 / 900, loss = 0.73 (0.007 sec/batch)\n",
      "epoch 14, step 550 / 900, loss = 0.83 (0.007 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, step 600 / 900, loss = 0.66 (0.008 sec/batch)\n",
      "epoch 14, step 650 / 900, loss = 0.92 (0.007 sec/batch)\n",
      "epoch 14, step 700 / 900, loss = 0.82 (0.008 sec/batch)\n",
      "epoch 14, step 750 / 900, loss = 0.69 (0.006 sec/batch)\n",
      "epoch 14, step 800 / 900, loss = 0.67 (0.007 sec/batch)\n",
      "epoch 14, step 850 / 900, loss = 0.66 (0.007 sec/batch)\n",
      "epoch 14, step 900 / 900, loss = 0.80 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 79.63\n",
      " avg loss = 0.84\n",
      "\n",
      "Validation error:\n",
      " accuracy = 70.74\n",
      " avg loss = 1.55\n",
      "\n",
      "Epoch time: 9.249760389328003\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 15, step 50 / 900, loss = 1.07 (0.007 sec/batch)\n",
      "epoch 15, step 100 / 900, loss = 1.18 (0.007 sec/batch)\n",
      "epoch 15, step 150 / 900, loss = 0.68 (0.007 sec/batch)\n",
      "epoch 15, step 200 / 900, loss = 1.01 (0.006 sec/batch)\n",
      "epoch 15, step 250 / 900, loss = 0.65 (0.007 sec/batch)\n",
      "epoch 15, step 300 / 900, loss = 0.66 (0.007 sec/batch)\n",
      "epoch 15, step 350 / 900, loss = 0.66 (0.006 sec/batch)\n",
      "epoch 15, step 400 / 900, loss = 0.67 (0.007 sec/batch)\n",
      "epoch 15, step 450 / 900, loss = 0.78 (0.007 sec/batch)\n",
      "epoch 15, step 500 / 900, loss = 0.40 (0.009 sec/batch)\n",
      "epoch 15, step 550 / 900, loss = 1.74 (0.009 sec/batch)\n",
      "epoch 15, step 600 / 900, loss = 1.02 (0.007 sec/batch)\n",
      "epoch 15, step 650 / 900, loss = 0.74 (0.007 sec/batch)\n",
      "epoch 15, step 700 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 15, step 750 / 900, loss = 1.02 (0.008 sec/batch)\n",
      "epoch 15, step 800 / 900, loss = 1.01 (0.007 sec/batch)\n",
      "epoch 15, step 850 / 900, loss = 0.88 (0.007 sec/batch)\n",
      "epoch 15, step 900 / 900, loss = 0.54 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 80.51\n",
      " avg loss = 0.79\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.04\n",
      " avg loss = 1.53\n",
      "\n",
      "Epoch time: 9.048942565917969\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 16, step 50 / 900, loss = 0.88 (0.007 sec/batch)\n",
      "epoch 16, step 100 / 900, loss = 0.77 (0.006 sec/batch)\n",
      "epoch 16, step 150 / 900, loss = 1.08 (0.006 sec/batch)\n",
      "epoch 16, step 200 / 900, loss = 0.36 (0.006 sec/batch)\n",
      "epoch 16, step 250 / 900, loss = 0.84 (0.006 sec/batch)\n",
      "epoch 16, step 300 / 900, loss = 0.56 (0.007 sec/batch)\n",
      "epoch 16, step 350 / 900, loss = 0.79 (0.009 sec/batch)\n",
      "epoch 16, step 400 / 900, loss = 1.03 (0.007 sec/batch)\n",
      "epoch 16, step 450 / 900, loss = 0.67 (0.007 sec/batch)\n",
      "epoch 16, step 500 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 16, step 550 / 900, loss = 0.62 (0.007 sec/batch)\n",
      "epoch 16, step 600 / 900, loss = 0.80 (0.007 sec/batch)\n",
      "epoch 16, step 650 / 900, loss = 0.93 (0.009 sec/batch)\n",
      "epoch 16, step 700 / 900, loss = 0.62 (0.009 sec/batch)\n",
      "epoch 16, step 750 / 900, loss = 0.83 (0.007 sec/batch)\n",
      "epoch 16, step 800 / 900, loss = 1.10 (0.006 sec/batch)\n",
      "epoch 16, step 850 / 900, loss = 0.55 (0.009 sec/batch)\n",
      "epoch 16, step 900 / 900, loss = 0.60 (0.009 sec/batch)\n",
      "Train error:\n",
      " accuracy = 81.11\n",
      " avg loss = 0.75\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.00\n",
      " avg loss = 1.54\n",
      "\n",
      "Epoch time: 9.067134141921997\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 17, step 50 / 900, loss = 0.60 (0.008 sec/batch)\n",
      "epoch 17, step 100 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 17, step 150 / 900, loss = 0.56 (0.006 sec/batch)\n",
      "epoch 17, step 200 / 900, loss = 0.55 (0.006 sec/batch)\n",
      "epoch 17, step 250 / 900, loss = 0.99 (0.007 sec/batch)\n",
      "epoch 17, step 300 / 900, loss = 0.65 (0.007 sec/batch)\n",
      "epoch 17, step 350 / 900, loss = 0.90 (0.007 sec/batch)\n",
      "epoch 17, step 400 / 900, loss = 0.73 (0.007 sec/batch)\n",
      "epoch 17, step 450 / 900, loss = 0.90 (0.008 sec/batch)\n",
      "epoch 17, step 500 / 900, loss = 0.78 (0.007 sec/batch)\n",
      "epoch 17, step 550 / 900, loss = 0.79 (0.007 sec/batch)\n",
      "epoch 17, step 600 / 900, loss = 0.84 (0.007 sec/batch)\n",
      "epoch 17, step 650 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 17, step 700 / 900, loss = 0.40 (0.006 sec/batch)\n",
      "epoch 17, step 750 / 900, loss = 0.94 (0.006 sec/batch)\n",
      "epoch 17, step 800 / 900, loss = 0.87 (0.007 sec/batch)\n",
      "epoch 17, step 850 / 900, loss = 0.77 (0.008 sec/batch)\n",
      "epoch 17, step 900 / 900, loss = 0.65 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 81.86\n",
      " avg loss = 0.72\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.60\n",
      " avg loss = 1.52\n",
      "\n",
      "Epoch time: 9.062285900115967\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 18, step 50 / 900, loss = 0.55 (0.006 sec/batch)\n",
      "epoch 18, step 100 / 900, loss = 0.90 (0.008 sec/batch)\n",
      "epoch 18, step 150 / 900, loss = 0.64 (0.007 sec/batch)\n",
      "epoch 18, step 200 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 18, step 250 / 900, loss = 0.80 (0.006 sec/batch)\n",
      "epoch 18, step 300 / 900, loss = 1.13 (0.007 sec/batch)\n",
      "epoch 18, step 350 / 900, loss = 0.56 (0.006 sec/batch)\n",
      "epoch 18, step 400 / 900, loss = 0.95 (0.007 sec/batch)\n",
      "epoch 18, step 450 / 900, loss = 0.90 (0.007 sec/batch)\n",
      "epoch 18, step 500 / 900, loss = 1.06 (0.006 sec/batch)\n",
      "epoch 18, step 550 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "epoch 18, step 600 / 900, loss = 1.19 (0.007 sec/batch)\n",
      "epoch 18, step 650 / 900, loss = 0.68 (0.007 sec/batch)\n",
      "epoch 18, step 700 / 900, loss = 0.61 (0.007 sec/batch)\n",
      "epoch 18, step 750 / 900, loss = 0.82 (0.007 sec/batch)\n",
      "epoch 18, step 800 / 900, loss = 0.93 (0.007 sec/batch)\n",
      "epoch 18, step 850 / 900, loss = 0.94 (0.009 sec/batch)\n",
      "epoch 18, step 900 / 900, loss = 0.62 (0.009 sec/batch)\n",
      "Train error:\n",
      " accuracy = 82.24\n",
      " avg loss = 0.70\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.28\n",
      " avg loss = 1.53\n",
      "\n",
      "Epoch time: 9.083269119262695\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 19, step 50 / 900, loss = 0.75 (0.009 sec/batch)\n",
      "epoch 19, step 100 / 900, loss = 0.64 (0.007 sec/batch)\n",
      "epoch 19, step 150 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "epoch 19, step 200 / 900, loss = 0.59 (0.006 sec/batch)\n",
      "epoch 19, step 250 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 19, step 300 / 900, loss = 0.61 (0.007 sec/batch)\n",
      "epoch 19, step 350 / 900, loss = 0.59 (0.007 sec/batch)\n",
      "epoch 19, step 400 / 900, loss = 0.75 (0.007 sec/batch)\n",
      "epoch 19, step 450 / 900, loss = 0.67 (0.006 sec/batch)\n",
      "epoch 19, step 500 / 900, loss = 1.10 (0.007 sec/batch)\n",
      "epoch 19, step 550 / 900, loss = 0.71 (0.007 sec/batch)\n",
      "epoch 19, step 600 / 900, loss = 0.66 (0.007 sec/batch)\n",
      "epoch 19, step 650 / 900, loss = 1.05 (0.006 sec/batch)\n",
      "epoch 19, step 700 / 900, loss = 0.60 (0.006 sec/batch)\n",
      "epoch 19, step 750 / 900, loss = 0.69 (0.007 sec/batch)\n",
      "epoch 19, step 800 / 900, loss = 0.64 (0.007 sec/batch)\n",
      "epoch 19, step 850 / 900, loss = 0.70 (0.007 sec/batch)\n",
      "epoch 19, step 900 / 900, loss = 0.65 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 82.84\n",
      " avg loss = 0.67\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.86\n",
      " avg loss = 1.52\n",
      "\n",
      "Epoch time: 9.063470125198364\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 20, step 50 / 900, loss = 0.76 (0.007 sec/batch)\n",
      "epoch 20, step 100 / 900, loss = 0.54 (0.008 sec/batch)\n",
      "epoch 20, step 150 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 20, step 200 / 900, loss = 0.83 (0.007 sec/batch)\n",
      "epoch 20, step 250 / 900, loss = 0.70 (0.008 sec/batch)\n",
      "epoch 20, step 300 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 20, step 350 / 900, loss = 0.58 (0.007 sec/batch)\n",
      "epoch 20, step 400 / 900, loss = 0.86 (0.007 sec/batch)\n",
      "epoch 20, step 450 / 900, loss = 0.72 (0.006 sec/batch)\n",
      "epoch 20, step 500 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 20, step 550 / 900, loss = 0.42 (0.006 sec/batch)\n",
      "epoch 20, step 600 / 900, loss = 0.82 (0.006 sec/batch)\n",
      "epoch 20, step 650 / 900, loss = 0.66 (0.007 sec/batch)\n",
      "epoch 20, step 700 / 900, loss = 0.84 (0.007 sec/batch)\n",
      "epoch 20, step 750 / 900, loss = 0.55 (0.007 sec/batch)\n",
      "epoch 20, step 800 / 900, loss = 0.62 (0.007 sec/batch)\n",
      "epoch 20, step 850 / 900, loss = 0.22 (0.007 sec/batch)\n",
      "epoch 20, step 900 / 900, loss = 0.39 (0.009 sec/batch)\n",
      "Train error:\n",
      " accuracy = 82.94\n",
      " avg loss = 0.66\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.68\n",
      " avg loss = 1.52\n",
      "\n",
      "Epoch time: 9.026525497436523\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 21, step 50 / 900, loss = 0.65 (0.007 sec/batch)\n",
      "epoch 21, step 100 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 21, step 150 / 900, loss = 0.88 (0.007 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, step 200 / 900, loss = 0.65 (0.009 sec/batch)\n",
      "epoch 21, step 250 / 900, loss = 0.57 (0.008 sec/batch)\n",
      "epoch 21, step 300 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 21, step 350 / 900, loss = 0.91 (0.007 sec/batch)\n",
      "epoch 21, step 400 / 900, loss = 0.28 (0.008 sec/batch)\n",
      "epoch 21, step 450 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "epoch 21, step 500 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 21, step 550 / 900, loss = 0.46 (0.007 sec/batch)\n",
      "epoch 21, step 600 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 21, step 650 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 21, step 700 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 21, step 750 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 21, step 800 / 900, loss = 0.66 (0.007 sec/batch)\n",
      "epoch 21, step 850 / 900, loss = 0.59 (0.007 sec/batch)\n",
      "epoch 21, step 900 / 900, loss = 0.68 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 83.66\n",
      " avg loss = 0.63\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.74\n",
      " avg loss = 1.51\n",
      "\n",
      "Epoch time: 9.025930404663086\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 22, step 50 / 900, loss = 0.57 (0.008 sec/batch)\n",
      "epoch 22, step 100 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 22, step 150 / 900, loss = 0.65 (0.007 sec/batch)\n",
      "epoch 22, step 200 / 900, loss = 0.72 (0.007 sec/batch)\n",
      "epoch 22, step 250 / 900, loss = 0.83 (0.007 sec/batch)\n",
      "epoch 22, step 300 / 900, loss = 0.45 (0.009 sec/batch)\n",
      "epoch 22, step 350 / 900, loss = 0.35 (0.009 sec/batch)\n",
      "epoch 22, step 400 / 900, loss = 0.46 (0.007 sec/batch)\n",
      "epoch 22, step 450 / 900, loss = 1.07 (0.007 sec/batch)\n",
      "epoch 22, step 500 / 900, loss = 0.68 (0.006 sec/batch)\n",
      "epoch 22, step 550 / 900, loss = 1.18 (0.007 sec/batch)\n",
      "epoch 22, step 600 / 900, loss = 0.76 (0.007 sec/batch)\n",
      "epoch 22, step 650 / 900, loss = 0.74 (0.007 sec/batch)\n",
      "epoch 22, step 700 / 900, loss = 0.63 (0.006 sec/batch)\n",
      "epoch 22, step 750 / 900, loss = 0.69 (0.010 sec/batch)\n",
      "epoch 22, step 800 / 900, loss = 0.74 (0.007 sec/batch)\n",
      "epoch 22, step 850 / 900, loss = 0.72 (0.006 sec/batch)\n",
      "epoch 22, step 900 / 900, loss = 0.62 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 83.98\n",
      " avg loss = 0.62\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.82\n",
      " avg loss = 1.51\n",
      "\n",
      "Epoch time: 9.034543752670288\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 23, step 50 / 900, loss = 1.06 (0.008 sec/batch)\n",
      "epoch 23, step 100 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "epoch 23, step 150 / 900, loss = 0.68 (0.006 sec/batch)\n",
      "epoch 23, step 200 / 900, loss = 0.83 (0.007 sec/batch)\n",
      "epoch 23, step 250 / 900, loss = 0.49 (0.008 sec/batch)\n",
      "epoch 23, step 300 / 900, loss = 0.71 (0.007 sec/batch)\n",
      "epoch 23, step 350 / 900, loss = 0.70 (0.007 sec/batch)\n",
      "epoch 23, step 400 / 900, loss = 0.70 (0.007 sec/batch)\n",
      "epoch 23, step 450 / 900, loss = 0.38 (0.007 sec/batch)\n",
      "epoch 23, step 500 / 900, loss = 0.63 (0.007 sec/batch)\n",
      "epoch 23, step 550 / 900, loss = 0.79 (0.007 sec/batch)\n",
      "epoch 23, step 600 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "epoch 23, step 650 / 900, loss = 0.77 (0.007 sec/batch)\n",
      "epoch 23, step 700 / 900, loss = 0.74 (0.007 sec/batch)\n",
      "epoch 23, step 750 / 900, loss = 0.43 (0.007 sec/batch)\n",
      "epoch 23, step 800 / 900, loss = 0.63 (0.007 sec/batch)\n",
      "epoch 23, step 850 / 900, loss = 0.77 (0.006 sec/batch)\n",
      "epoch 23, step 900 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 84.18\n",
      " avg loss = 0.60\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.20\n",
      " avg loss = 1.52\n",
      "\n",
      "Epoch time: 9.008318185806274\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 24, step 50 / 900, loss = 0.98 (0.007 sec/batch)\n",
      "epoch 24, step 100 / 900, loss = 0.58 (0.006 sec/batch)\n",
      "epoch 24, step 150 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 24, step 200 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 24, step 250 / 900, loss = 0.58 (0.009 sec/batch)\n",
      "epoch 24, step 300 / 900, loss = 0.36 (0.007 sec/batch)\n",
      "epoch 24, step 350 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 24, step 400 / 900, loss = 0.38 (0.007 sec/batch)\n",
      "epoch 24, step 450 / 900, loss = 1.06 (0.007 sec/batch)\n",
      "epoch 24, step 500 / 900, loss = 0.73 (0.007 sec/batch)\n",
      "epoch 24, step 550 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 24, step 600 / 900, loss = 0.59 (0.006 sec/batch)\n",
      "epoch 24, step 650 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 24, step 700 / 900, loss = 0.32 (0.009 sec/batch)\n",
      "epoch 24, step 750 / 900, loss = 0.33 (0.007 sec/batch)\n",
      "epoch 24, step 800 / 900, loss = 0.62 (0.007 sec/batch)\n",
      "epoch 24, step 850 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 24, step 900 / 900, loss = 1.00 (0.009 sec/batch)\n",
      "Train error:\n",
      " accuracy = 84.40\n",
      " avg loss = 0.59\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.58\n",
      " avg loss = 1.53\n",
      "\n",
      "Epoch time: 9.046659708023071\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 25, step 50 / 900, loss = 0.35 (0.008 sec/batch)\n",
      "epoch 25, step 100 / 900, loss = 0.49 (0.007 sec/batch)\n",
      "epoch 25, step 150 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 25, step 200 / 900, loss = 0.51 (0.009 sec/batch)\n",
      "epoch 25, step 250 / 900, loss = 0.65 (0.007 sec/batch)\n",
      "epoch 25, step 300 / 900, loss = 1.27 (0.006 sec/batch)\n",
      "epoch 25, step 350 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 25, step 400 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "epoch 25, step 450 / 900, loss = 0.71 (0.007 sec/batch)\n",
      "epoch 25, step 500 / 900, loss = 0.32 (0.009 sec/batch)\n",
      "epoch 25, step 550 / 900, loss = 0.47 (0.009 sec/batch)\n",
      "epoch 25, step 600 / 900, loss = 0.90 (0.007 sec/batch)\n",
      "epoch 25, step 650 / 900, loss = 0.78 (0.006 sec/batch)\n",
      "epoch 25, step 700 / 900, loss = 0.35 (0.007 sec/batch)\n",
      "epoch 25, step 750 / 900, loss = 0.63 (0.007 sec/batch)\n",
      "epoch 25, step 800 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 25, step 850 / 900, loss = 0.64 (0.009 sec/batch)\n",
      "epoch 25, step 900 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 84.73\n",
      " avg loss = 0.58\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.64\n",
      " avg loss = 1.53\n",
      "\n",
      "Epoch time: 9.034089803695679\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 26, step 50 / 900, loss = 0.65 (0.007 sec/batch)\n",
      "epoch 26, step 100 / 900, loss = 0.85 (0.006 sec/batch)\n",
      "epoch 26, step 150 / 900, loss = 0.53 (0.009 sec/batch)\n",
      "epoch 26, step 200 / 900, loss = 0.46 (0.007 sec/batch)\n",
      "epoch 26, step 250 / 900, loss = 0.66 (0.007 sec/batch)\n",
      "epoch 26, step 300 / 900, loss = 0.58 (0.006 sec/batch)\n",
      "epoch 26, step 350 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 26, step 400 / 900, loss = 0.74 (0.007 sec/batch)\n",
      "epoch 26, step 450 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 26, step 500 / 900, loss = 0.55 (0.006 sec/batch)\n",
      "epoch 26, step 550 / 900, loss = 0.73 (0.009 sec/batch)\n",
      "epoch 26, step 600 / 900, loss = 0.36 (0.009 sec/batch)\n",
      "epoch 26, step 650 / 900, loss = 1.27 (0.007 sec/batch)\n",
      "epoch 26, step 700 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 26, step 750 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 26, step 800 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 26, step 850 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 26, step 900 / 900, loss = 0.56 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 85.01\n",
      " avg loss = 0.57\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.46\n",
      " avg loss = 1.52\n",
      "\n",
      "Epoch time: 9.025359630584717\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 27, step 50 / 900, loss = 0.77 (0.006 sec/batch)\n",
      "epoch 27, step 100 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 27, step 150 / 900, loss = 0.58 (0.006 sec/batch)\n",
      "epoch 27, step 200 / 900, loss = 0.56 (0.007 sec/batch)\n",
      "epoch 27, step 250 / 900, loss = 0.66 (0.007 sec/batch)\n",
      "epoch 27, step 300 / 900, loss = 0.70 (0.006 sec/batch)\n",
      "epoch 27, step 350 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "epoch 27, step 400 / 900, loss = 0.31 (0.007 sec/batch)\n",
      "epoch 27, step 450 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 27, step 500 / 900, loss = 0.73 (0.007 sec/batch)\n",
      "epoch 27, step 550 / 900, loss = 1.00 (0.009 sec/batch)\n",
      "epoch 27, step 600 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "epoch 27, step 650 / 900, loss = 0.69 (0.007 sec/batch)\n",
      "epoch 27, step 700 / 900, loss = 0.56 (0.008 sec/batch)\n",
      "epoch 27, step 750 / 900, loss = 0.74 (0.007 sec/batch)\n",
      "epoch 27, step 800 / 900, loss = 0.77 (0.006 sec/batch)\n",
      "epoch 27, step 850 / 900, loss = 0.68 (0.007 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, step 900 / 900, loss = 0.64 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 85.08\n",
      " avg loss = 0.57\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.58\n",
      " avg loss = 1.53\n",
      "\n",
      "Epoch time: 9.036214828491211\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 28, step 50 / 900, loss = 0.67 (0.006 sec/batch)\n",
      "epoch 28, step 100 / 900, loss = 0.71 (0.007 sec/batch)\n",
      "epoch 28, step 150 / 900, loss = 0.36 (0.008 sec/batch)\n",
      "epoch 28, step 200 / 900, loss = 0.79 (0.007 sec/batch)\n",
      "epoch 28, step 250 / 900, loss = 0.65 (0.006 sec/batch)\n",
      "epoch 28, step 300 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 28, step 350 / 900, loss = 0.28 (0.007 sec/batch)\n",
      "epoch 28, step 400 / 900, loss = 0.34 (0.010 sec/batch)\n",
      "epoch 28, step 450 / 900, loss = 0.75 (0.007 sec/batch)\n",
      "epoch 28, step 500 / 900, loss = 0.54 (0.006 sec/batch)\n",
      "epoch 28, step 550 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 28, step 600 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 28, step 650 / 900, loss = 0.35 (0.007 sec/batch)\n",
      "epoch 28, step 700 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 28, step 750 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 28, step 800 / 900, loss = 0.54 (0.009 sec/batch)\n",
      "epoch 28, step 850 / 900, loss = 0.92 (0.008 sec/batch)\n",
      "epoch 28, step 900 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 85.28\n",
      " avg loss = 0.56\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.20\n",
      " avg loss = 1.54\n",
      "\n",
      "Epoch time: 9.052425622940063\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 29, step 50 / 900, loss = 0.93 (0.007 sec/batch)\n",
      "epoch 29, step 100 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 29, step 150 / 900, loss = 0.36 (0.007 sec/batch)\n",
      "epoch 29, step 200 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 29, step 250 / 900, loss = 0.55 (0.008 sec/batch)\n",
      "epoch 29, step 300 / 900, loss = 0.52 (0.008 sec/batch)\n",
      "epoch 29, step 350 / 900, loss = 0.39 (0.007 sec/batch)\n",
      "epoch 29, step 400 / 900, loss = 0.58 (0.007 sec/batch)\n",
      "epoch 29, step 450 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 29, step 500 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 29, step 550 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 29, step 600 / 900, loss = 0.51 (0.008 sec/batch)\n",
      "epoch 29, step 650 / 900, loss = 0.70 (0.007 sec/batch)\n",
      "epoch 29, step 700 / 900, loss = 0.55 (0.007 sec/batch)\n",
      "epoch 29, step 750 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "epoch 29, step 800 / 900, loss = 0.66 (0.009 sec/batch)\n",
      "epoch 29, step 850 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "epoch 29, step 900 / 900, loss = 0.26 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 85.58\n",
      " avg loss = 0.55\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.82\n",
      " avg loss = 1.52\n",
      "\n",
      "Epoch time: 9.026522397994995\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 30, step 50 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 30, step 100 / 900, loss = 0.56 (0.007 sec/batch)\n",
      "epoch 30, step 150 / 900, loss = 0.73 (0.006 sec/batch)\n",
      "epoch 30, step 200 / 900, loss = 0.52 (0.008 sec/batch)\n",
      "epoch 30, step 250 / 900, loss = 0.82 (0.007 sec/batch)\n",
      "epoch 30, step 300 / 900, loss = 0.68 (0.007 sec/batch)\n",
      "epoch 30, step 350 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "epoch 30, step 400 / 900, loss = 0.28 (0.006 sec/batch)\n",
      "epoch 30, step 450 / 900, loss = 0.22 (0.006 sec/batch)\n",
      "epoch 30, step 500 / 900, loss = 0.51 (0.009 sec/batch)\n",
      "epoch 30, step 550 / 900, loss = 0.59 (0.009 sec/batch)\n",
      "epoch 30, step 600 / 900, loss = 0.61 (0.007 sec/batch)\n",
      "epoch 30, step 650 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 30, step 700 / 900, loss = 0.31 (0.007 sec/batch)\n",
      "epoch 30, step 750 / 900, loss = 0.73 (0.009 sec/batch)\n",
      "epoch 30, step 800 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 30, step 850 / 900, loss = 0.49 (0.007 sec/batch)\n",
      "epoch 30, step 900 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 85.76\n",
      " avg loss = 0.54\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.44\n",
      " avg loss = 1.52\n",
      "\n",
      "Epoch time: 9.102189779281616\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 31, step 50 / 900, loss = 0.67 (0.007 sec/batch)\n",
      "epoch 31, step 100 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "epoch 31, step 150 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 31, step 200 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "epoch 31, step 250 / 900, loss = 0.58 (0.006 sec/batch)\n",
      "epoch 31, step 300 / 900, loss = 0.66 (0.007 sec/batch)\n",
      "epoch 31, step 350 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 31, step 400 / 900, loss = 0.45 (0.008 sec/batch)\n",
      "epoch 31, step 450 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "epoch 31, step 500 / 900, loss = 0.29 (0.007 sec/batch)\n",
      "epoch 31, step 550 / 900, loss = 0.53 (0.009 sec/batch)\n",
      "epoch 31, step 600 / 900, loss = 0.70 (0.009 sec/batch)\n",
      "epoch 31, step 650 / 900, loss = 0.64 (0.007 sec/batch)\n",
      "epoch 31, step 700 / 900, loss = 0.48 (0.009 sec/batch)\n",
      "epoch 31, step 750 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "epoch 31, step 800 / 900, loss = 0.77 (0.007 sec/batch)\n",
      "epoch 31, step 850 / 900, loss = 0.75 (0.007 sec/batch)\n",
      "epoch 31, step 900 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 85.82\n",
      " avg loss = 0.54\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.78\n",
      " avg loss = 1.53\n",
      "\n",
      "Epoch time: 9.194083452224731\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 32, step 50 / 900, loss = 0.49 (0.007 sec/batch)\n",
      "epoch 32, step 100 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 32, step 150 / 900, loss = 0.33 (0.007 sec/batch)\n",
      "epoch 32, step 200 / 900, loss = 0.58 (0.007 sec/batch)\n",
      "epoch 32, step 250 / 900, loss = 0.28 (0.007 sec/batch)\n",
      "epoch 32, step 300 / 900, loss = 0.47 (0.010 sec/batch)\n",
      "epoch 32, step 350 / 900, loss = 0.36 (0.007 sec/batch)\n",
      "epoch 32, step 400 / 900, loss = 0.65 (0.007 sec/batch)\n",
      "epoch 32, step 450 / 900, loss = 0.47 (0.009 sec/batch)\n",
      "epoch 32, step 500 / 900, loss = 0.43 (0.007 sec/batch)\n",
      "epoch 32, step 550 / 900, loss = 0.74 (0.008 sec/batch)\n",
      "epoch 32, step 600 / 900, loss = 0.64 (0.006 sec/batch)\n",
      "epoch 32, step 650 / 900, loss = 0.46 (0.007 sec/batch)\n",
      "epoch 32, step 700 / 900, loss = 0.68 (0.006 sec/batch)\n",
      "epoch 32, step 750 / 900, loss = 0.57 (0.008 sec/batch)\n",
      "epoch 32, step 800 / 900, loss = 0.39 (0.006 sec/batch)\n",
      "epoch 32, step 850 / 900, loss = 0.49 (0.007 sec/batch)\n",
      "epoch 32, step 900 / 900, loss = 0.83 (0.010 sec/batch)\n",
      "Train error:\n",
      " accuracy = 85.91\n",
      " avg loss = 0.53\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.80\n",
      " avg loss = 1.53\n",
      "\n",
      "Epoch time: 9.232450485229492\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 33, step 50 / 900, loss = 0.41 (0.010 sec/batch)\n",
      "epoch 33, step 100 / 900, loss = 0.33 (0.007 sec/batch)\n",
      "epoch 33, step 150 / 900, loss = 0.55 (0.007 sec/batch)\n",
      "epoch 33, step 200 / 900, loss = 0.64 (0.008 sec/batch)\n",
      "epoch 33, step 250 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 33, step 300 / 900, loss = 0.65 (0.007 sec/batch)\n",
      "epoch 33, step 350 / 900, loss = 0.55 (0.008 sec/batch)\n",
      "epoch 33, step 400 / 900, loss = 0.43 (0.007 sec/batch)\n",
      "epoch 33, step 450 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 33, step 500 / 900, loss = 0.38 (0.007 sec/batch)\n",
      "epoch 33, step 550 / 900, loss = 0.26 (0.006 sec/batch)\n",
      "epoch 33, step 600 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "epoch 33, step 650 / 900, loss = 0.67 (0.007 sec/batch)\n",
      "epoch 33, step 700 / 900, loss = 0.57 (0.008 sec/batch)\n",
      "epoch 33, step 750 / 900, loss = 0.66 (0.007 sec/batch)\n",
      "epoch 33, step 800 / 900, loss = 0.71 (0.007 sec/batch)\n",
      "epoch 33, step 850 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 33, step 900 / 900, loss = 0.16 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.07\n",
      " avg loss = 0.52\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.68\n",
      " avg loss = 1.53\n",
      "\n",
      "Epoch time: 9.303394794464111\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 34, step 50 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 34, step 100 / 900, loss = 0.58 (0.009 sec/batch)\n",
      "epoch 34, step 150 / 900, loss = 0.56 (0.009 sec/batch)\n",
      "epoch 34, step 200 / 900, loss = 0.85 (0.007 sec/batch)\n",
      "epoch 34, step 250 / 900, loss = 0.46 (0.009 sec/batch)\n",
      "epoch 34, step 300 / 900, loss = 0.27 (0.009 sec/batch)\n",
      "epoch 34, step 350 / 900, loss = 0.36 (0.009 sec/batch)\n",
      "epoch 34, step 400 / 900, loss = 0.36 (0.008 sec/batch)\n",
      "epoch 34, step 450 / 900, loss = 0.75 (0.009 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, step 500 / 900, loss = 0.37 (0.009 sec/batch)\n",
      "epoch 34, step 550 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 34, step 600 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 34, step 650 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 34, step 700 / 900, loss = 0.28 (0.008 sec/batch)\n",
      "epoch 34, step 750 / 900, loss = 0.64 (0.007 sec/batch)\n",
      "epoch 34, step 800 / 900, loss = 0.56 (0.007 sec/batch)\n",
      "epoch 34, step 850 / 900, loss = 0.81 (0.008 sec/batch)\n",
      "epoch 34, step 900 / 900, loss = 0.34 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.17\n",
      " avg loss = 0.52\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.80\n",
      " avg loss = 1.52\n",
      "\n",
      "Epoch time: 9.538930177688599\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 35, step 50 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 35, step 100 / 900, loss = 0.26 (0.007 sec/batch)\n",
      "epoch 35, step 150 / 900, loss = 0.46 (0.008 sec/batch)\n",
      "epoch 35, step 200 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 35, step 250 / 900, loss = 0.49 (0.009 sec/batch)\n",
      "epoch 35, step 300 / 900, loss = 0.89 (0.007 sec/batch)\n",
      "epoch 35, step 350 / 900, loss = 0.28 (0.007 sec/batch)\n",
      "epoch 35, step 400 / 900, loss = 0.24 (0.008 sec/batch)\n",
      "epoch 35, step 450 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "epoch 35, step 500 / 900, loss = 0.46 (0.007 sec/batch)\n",
      "epoch 35, step 550 / 900, loss = 0.31 (0.007 sec/batch)\n",
      "epoch 35, step 600 / 900, loss = 0.45 (0.008 sec/batch)\n",
      "epoch 35, step 650 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 35, step 700 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 35, step 750 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "epoch 35, step 800 / 900, loss = 0.32 (0.007 sec/batch)\n",
      "epoch 35, step 850 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 35, step 900 / 900, loss = 0.42 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.24\n",
      " avg loss = 0.51\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.80\n",
      " avg loss = 1.53\n",
      "\n",
      "Epoch time: 9.280953645706177\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 36, step 50 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "epoch 36, step 100 / 900, loss = 0.38 (0.007 sec/batch)\n",
      "epoch 36, step 150 / 900, loss = 0.44 (0.008 sec/batch)\n",
      "epoch 36, step 200 / 900, loss = 0.59 (0.006 sec/batch)\n",
      "epoch 36, step 250 / 900, loss = 0.43 (0.007 sec/batch)\n",
      "epoch 36, step 300 / 900, loss = 0.26 (0.006 sec/batch)\n",
      "epoch 36, step 350 / 900, loss = 0.58 (0.007 sec/batch)\n",
      "epoch 36, step 400 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "epoch 36, step 450 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 36, step 500 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 36, step 550 / 900, loss = 0.33 (0.007 sec/batch)\n",
      "epoch 36, step 600 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "epoch 36, step 650 / 900, loss = 0.58 (0.007 sec/batch)\n",
      "epoch 36, step 700 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 36, step 750 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "epoch 36, step 800 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 36, step 850 / 900, loss = 0.59 (0.008 sec/batch)\n",
      "epoch 36, step 900 / 900, loss = 0.59 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.35\n",
      " avg loss = 0.51\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.56\n",
      " avg loss = 1.53\n",
      "\n",
      "Epoch time: 9.242517709732056\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 37, step 50 / 900, loss = 0.64 (0.006 sec/batch)\n",
      "epoch 37, step 100 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 37, step 150 / 900, loss = 0.60 (0.008 sec/batch)\n",
      "epoch 37, step 200 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 37, step 250 / 900, loss = 0.28 (0.006 sec/batch)\n",
      "epoch 37, step 300 / 900, loss = 0.67 (0.007 sec/batch)\n",
      "epoch 37, step 350 / 900, loss = 0.49 (0.009 sec/batch)\n",
      "epoch 37, step 400 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 37, step 450 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 37, step 500 / 900, loss = 0.55 (0.008 sec/batch)\n",
      "epoch 37, step 550 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "epoch 37, step 600 / 900, loss = 0.36 (0.007 sec/batch)\n",
      "epoch 37, step 650 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "epoch 37, step 700 / 900, loss = 0.74 (0.007 sec/batch)\n",
      "epoch 37, step 750 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 37, step 800 / 900, loss = 0.39 (0.007 sec/batch)\n",
      "epoch 37, step 850 / 900, loss = 0.77 (0.006 sec/batch)\n",
      "epoch 37, step 900 / 900, loss = 0.69 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.42\n",
      " avg loss = 0.51\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.60\n",
      " avg loss = 1.53\n",
      "\n",
      "Epoch time: 9.202286720275879\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 38, step 50 / 900, loss = 0.70 (0.007 sec/batch)\n",
      "epoch 38, step 100 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 38, step 150 / 900, loss = 0.27 (0.007 sec/batch)\n",
      "epoch 38, step 200 / 900, loss = 0.67 (0.006 sec/batch)\n",
      "epoch 38, step 250 / 900, loss = 0.82 (0.007 sec/batch)\n",
      "epoch 38, step 300 / 900, loss = 0.44 (0.009 sec/batch)\n",
      "epoch 38, step 350 / 900, loss = 0.59 (0.007 sec/batch)\n",
      "epoch 38, step 400 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 38, step 450 / 900, loss = 0.49 (0.008 sec/batch)\n",
      "epoch 38, step 500 / 900, loss = 0.64 (0.007 sec/batch)\n",
      "epoch 38, step 550 / 900, loss = 0.55 (0.007 sec/batch)\n",
      "epoch 38, step 600 / 900, loss = 0.39 (0.007 sec/batch)\n",
      "epoch 38, step 650 / 900, loss = 0.35 (0.008 sec/batch)\n",
      "epoch 38, step 700 / 900, loss = 0.43 (0.007 sec/batch)\n",
      "epoch 38, step 750 / 900, loss = 0.43 (0.007 sec/batch)\n",
      "epoch 38, step 800 / 900, loss = 0.62 (0.006 sec/batch)\n",
      "epoch 38, step 850 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "epoch 38, step 900 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.50\n",
      " avg loss = 0.50\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.62\n",
      " avg loss = 1.53\n",
      "\n",
      "Epoch time: 9.121679306030273\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 39, step 50 / 900, loss = 0.22 (0.007 sec/batch)\n",
      "epoch 39, step 100 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 39, step 150 / 900, loss = 0.31 (0.009 sec/batch)\n",
      "epoch 39, step 200 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 39, step 250 / 900, loss = 0.63 (0.007 sec/batch)\n",
      "epoch 39, step 300 / 900, loss = 0.30 (0.006 sec/batch)\n",
      "epoch 39, step 350 / 900, loss = 0.59 (0.007 sec/batch)\n",
      "epoch 39, step 400 / 900, loss = 0.73 (0.008 sec/batch)\n",
      "epoch 39, step 450 / 900, loss = 0.31 (0.006 sec/batch)\n",
      "epoch 39, step 500 / 900, loss = 0.47 (0.008 sec/batch)\n",
      "epoch 39, step 550 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 39, step 600 / 900, loss = 0.47 (0.009 sec/batch)\n",
      "epoch 39, step 650 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 39, step 700 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 39, step 750 / 900, loss = 0.27 (0.007 sec/batch)\n",
      "epoch 39, step 800 / 900, loss = 0.76 (0.006 sec/batch)\n",
      "epoch 39, step 850 / 900, loss = 0.24 (0.007 sec/batch)\n",
      "epoch 39, step 900 / 900, loss = 0.43 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.48\n",
      " avg loss = 0.50\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.50\n",
      " avg loss = 1.53\n",
      "\n",
      "Epoch time: 9.080658435821533\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 40, step 50 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 40, step 100 / 900, loss = 0.34 (0.007 sec/batch)\n",
      "epoch 40, step 150 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "epoch 40, step 200 / 900, loss = 0.73 (0.009 sec/batch)\n",
      "epoch 40, step 250 / 900, loss = 0.55 (0.006 sec/batch)\n",
      "epoch 40, step 300 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 40, step 350 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "epoch 40, step 400 / 900, loss = 0.53 (0.009 sec/batch)\n",
      "epoch 40, step 450 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 40, step 500 / 900, loss = 0.42 (0.006 sec/batch)\n",
      "epoch 40, step 550 / 900, loss = 0.35 (0.007 sec/batch)\n",
      "epoch 40, step 600 / 900, loss = 0.29 (0.008 sec/batch)\n",
      "epoch 40, step 650 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 40, step 700 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "epoch 40, step 750 / 900, loss = 0.61 (0.007 sec/batch)\n",
      "epoch 40, step 800 / 900, loss = 0.66 (0.009 sec/batch)\n",
      "epoch 40, step 850 / 900, loss = 0.46 (0.007 sec/batch)\n",
      "epoch 40, step 900 / 900, loss = 0.65 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.59\n",
      " avg loss = 0.50\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.60\n",
      " avg loss = 1.54\n",
      "\n",
      "Epoch time: 9.159557104110718\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "Total train time: 378.35075664520264\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "train_start = time.time()\n",
    "\n",
    "plot_data={}\n",
    "train_cifar(session, train_x, train_y, valid_x, valid_y, config, plot_data)\n",
    "\n",
    "print(\"Total train time:\", time.time() - train_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAHiCAYAAADcelBQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f89ead278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_progress(plot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "Y_ = tf.placeholder(tf.int32, [None,])\n",
    "logits = convnet(X, weights, biases)\n",
    "\n",
    "# loss\n",
    "regularizers = l2_loss(weights.values())\n",
    "loss_per_sample = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y_)\n",
    "data_loss = tf.reduce_mean(loss_per_sample)\n",
    "loss = data_loss + weight_decay*regularizers\n",
    "\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(0.01, global_step, 900, 0.9, staircase=True)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 50 / 900, loss = 2.28 (0.006 sec/batch)\n",
      "epoch 1, step 100 / 900, loss = 1.71 (0.007 sec/batch)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Korisnik\\Anaconda3\\lib\\site-packages\\skimage\\util\\dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 150 / 900, loss = 1.97 (0.008 sec/batch)\n",
      "epoch 1, step 200 / 900, loss = 1.77 (0.007 sec/batch)\n",
      "epoch 1, step 250 / 900, loss = 1.66 (0.007 sec/batch)\n",
      "epoch 1, step 300 / 900, loss = 1.56 (0.006 sec/batch)\n",
      "epoch 1, step 350 / 900, loss = 1.55 (0.006 sec/batch)\n",
      "epoch 1, step 400 / 900, loss = 1.78 (0.006 sec/batch)\n",
      "epoch 1, step 450 / 900, loss = 1.55 (0.006 sec/batch)\n",
      "epoch 1, step 500 / 900, loss = 1.40 (0.009 sec/batch)\n",
      "epoch 1, step 550 / 900, loss = 1.33 (0.007 sec/batch)\n",
      "epoch 1, step 600 / 900, loss = 1.31 (0.006 sec/batch)\n",
      "epoch 1, step 650 / 900, loss = 1.39 (0.006 sec/batch)\n",
      "epoch 1, step 700 / 900, loss = 1.24 (0.008 sec/batch)\n",
      "epoch 1, step 750 / 900, loss = 1.41 (0.007 sec/batch)\n",
      "epoch 1, step 800 / 900, loss = 1.26 (0.008 sec/batch)\n",
      "epoch 1, step 850 / 900, loss = 1.49 (0.007 sec/batch)\n",
      "epoch 1, step 900 / 900, loss = 1.35 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 56.42\n",
      " avg loss = 1.26\n",
      "\n",
      "Validation error:\n",
      " accuracy = 55.68\n",
      " avg loss = 1.29\n",
      "\n",
      "Epoch time: 9.518801927566528\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 2, step 50 / 900, loss = 1.38 (0.007 sec/batch)\n",
      "epoch 2, step 100 / 900, loss = 1.31 (0.008 sec/batch)\n",
      "epoch 2, step 150 / 900, loss = 1.31 (0.006 sec/batch)\n",
      "epoch 2, step 200 / 900, loss = 1.18 (0.009 sec/batch)\n",
      "epoch 2, step 250 / 900, loss = 1.36 (0.006 sec/batch)\n",
      "epoch 2, step 300 / 900, loss = 1.48 (0.006 sec/batch)\n",
      "epoch 2, step 350 / 900, loss = 1.21 (0.008 sec/batch)\n",
      "epoch 2, step 400 / 900, loss = 1.33 (0.007 sec/batch)\n",
      "epoch 2, step 450 / 900, loss = 0.90 (0.008 sec/batch)\n",
      "epoch 2, step 500 / 900, loss = 0.91 (0.010 sec/batch)\n",
      "epoch 2, step 550 / 900, loss = 1.10 (0.006 sec/batch)\n",
      "epoch 2, step 600 / 900, loss = 1.09 (0.007 sec/batch)\n",
      "epoch 2, step 650 / 900, loss = 1.09 (0.007 sec/batch)\n",
      "epoch 2, step 700 / 900, loss = 1.27 (0.006 sec/batch)\n",
      "epoch 2, step 750 / 900, loss = 0.87 (0.008 sec/batch)\n",
      "epoch 2, step 800 / 900, loss = 1.28 (0.007 sec/batch)\n",
      "epoch 2, step 850 / 900, loss = 1.08 (0.007 sec/batch)\n",
      "epoch 2, step 900 / 900, loss = 1.26 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 64.81\n",
      " avg loss = 1.05\n",
      "\n",
      "Validation error:\n",
      " accuracy = 62.28\n",
      " avg loss = 1.12\n",
      "\n",
      "Epoch time: 9.453373670578003\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 3, step 50 / 900, loss = 0.94 (0.009 sec/batch)\n",
      "epoch 3, step 100 / 900, loss = 1.08 (0.008 sec/batch)\n",
      "epoch 3, step 150 / 900, loss = 0.94 (0.008 sec/batch)\n",
      "epoch 3, step 200 / 900, loss = 1.14 (0.007 sec/batch)\n",
      "epoch 3, step 250 / 900, loss = 0.98 (0.009 sec/batch)\n",
      "epoch 3, step 300 / 900, loss = 0.82 (0.010 sec/batch)\n",
      "epoch 3, step 350 / 900, loss = 1.19 (0.009 sec/batch)\n",
      "epoch 3, step 400 / 900, loss = 1.08 (0.006 sec/batch)\n",
      "epoch 3, step 450 / 900, loss = 1.31 (0.008 sec/batch)\n",
      "epoch 3, step 500 / 900, loss = 1.07 (0.007 sec/batch)\n",
      "epoch 3, step 550 / 900, loss = 0.64 (0.007 sec/batch)\n",
      "epoch 3, step 600 / 900, loss = 1.14 (0.007 sec/batch)\n",
      "epoch 3, step 650 / 900, loss = 1.26 (0.007 sec/batch)\n",
      "epoch 3, step 700 / 900, loss = 1.06 (0.009 sec/batch)\n",
      "epoch 3, step 750 / 900, loss = 0.93 (0.007 sec/batch)\n",
      "epoch 3, step 800 / 900, loss = 0.67 (0.007 sec/batch)\n",
      "epoch 3, step 850 / 900, loss = 1.08 (0.007 sec/batch)\n",
      "epoch 3, step 900 / 900, loss = 1.09 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 68.45\n",
      " avg loss = 0.94\n",
      "\n",
      "Validation error:\n",
      " accuracy = 64.54\n",
      " avg loss = 1.05\n",
      "\n",
      "Epoch time: 9.603414535522461\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 4, step 50 / 900, loss = 1.28 (0.009 sec/batch)\n",
      "epoch 4, step 100 / 900, loss = 0.91 (0.007 sec/batch)\n",
      "epoch 4, step 150 / 900, loss = 0.76 (0.011 sec/batch)\n",
      "epoch 4, step 200 / 900, loss = 1.21 (0.006 sec/batch)\n",
      "epoch 4, step 250 / 900, loss = 0.94 (0.011 sec/batch)\n",
      "epoch 4, step 300 / 900, loss = 1.01 (0.007 sec/batch)\n",
      "epoch 4, step 350 / 900, loss = 0.69 (0.007 sec/batch)\n",
      "epoch 4, step 400 / 900, loss = 0.95 (0.007 sec/batch)\n",
      "epoch 4, step 450 / 900, loss = 0.99 (0.007 sec/batch)\n",
      "epoch 4, step 500 / 900, loss = 0.93 (0.006 sec/batch)\n",
      "epoch 4, step 550 / 900, loss = 1.11 (0.008 sec/batch)\n",
      "epoch 4, step 600 / 900, loss = 1.01 (0.007 sec/batch)\n",
      "epoch 4, step 650 / 900, loss = 1.16 (0.008 sec/batch)\n",
      "epoch 4, step 700 / 900, loss = 1.02 (0.007 sec/batch)\n",
      "epoch 4, step 750 / 900, loss = 0.93 (0.007 sec/batch)\n",
      "epoch 4, step 800 / 900, loss = 1.00 (0.006 sec/batch)\n",
      "epoch 4, step 850 / 900, loss = 0.83 (0.010 sec/batch)\n",
      "epoch 4, step 900 / 900, loss = 1.05 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 69.73\n",
      " avg loss = 0.90\n",
      "\n",
      "Validation error:\n",
      " accuracy = 64.64\n",
      " avg loss = 1.05\n",
      "\n",
      "Epoch time: 9.545189619064331\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 5, step 50 / 900, loss = 1.17 (0.010 sec/batch)\n",
      "epoch 5, step 100 / 900, loss = 0.69 (0.007 sec/batch)\n",
      "epoch 5, step 150 / 900, loss = 0.81 (0.008 sec/batch)\n",
      "epoch 5, step 200 / 900, loss = 0.98 (0.006 sec/batch)\n",
      "epoch 5, step 250 / 900, loss = 0.78 (0.008 sec/batch)\n",
      "epoch 5, step 300 / 900, loss = 0.71 (0.007 sec/batch)\n",
      "epoch 5, step 350 / 900, loss = 0.74 (0.007 sec/batch)\n",
      "epoch 5, step 400 / 900, loss = 0.80 (0.007 sec/batch)\n",
      "epoch 5, step 450 / 900, loss = 0.79 (0.007 sec/batch)\n",
      "epoch 5, step 500 / 900, loss = 0.84 (0.007 sec/batch)\n",
      "epoch 5, step 550 / 900, loss = 1.01 (0.009 sec/batch)\n",
      "epoch 5, step 600 / 900, loss = 0.78 (0.008 sec/batch)\n",
      "epoch 5, step 650 / 900, loss = 0.70 (0.007 sec/batch)\n",
      "epoch 5, step 700 / 900, loss = 0.96 (0.007 sec/batch)\n",
      "epoch 5, step 750 / 900, loss = 0.67 (0.007 sec/batch)\n",
      "epoch 5, step 800 / 900, loss = 0.85 (0.007 sec/batch)\n",
      "epoch 5, step 850 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "epoch 5, step 900 / 900, loss = 0.96 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 73.85\n",
      " avg loss = 0.80\n",
      "\n",
      "Validation error:\n",
      " accuracy = 67.32\n",
      " avg loss = 0.96\n",
      "\n",
      "Epoch time: 9.55604100227356\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 6, step 50 / 900, loss = 0.63 (0.007 sec/batch)\n",
      "epoch 6, step 100 / 900, loss = 0.88 (0.008 sec/batch)\n",
      "epoch 6, step 150 / 900, loss = 0.98 (0.007 sec/batch)\n",
      "epoch 6, step 200 / 900, loss = 0.71 (0.006 sec/batch)\n",
      "epoch 6, step 250 / 900, loss = 0.74 (0.008 sec/batch)\n",
      "epoch 6, step 300 / 900, loss = 0.51 (0.008 sec/batch)\n",
      "epoch 6, step 350 / 900, loss = 0.99 (0.007 sec/batch)\n",
      "epoch 6, step 400 / 900, loss = 1.03 (0.006 sec/batch)\n",
      "epoch 6, step 450 / 900, loss = 1.03 (0.006 sec/batch)\n",
      "epoch 6, step 500 / 900, loss = 0.68 (0.006 sec/batch)\n",
      "epoch 6, step 550 / 900, loss = 0.84 (0.013 sec/batch)\n",
      "epoch 6, step 600 / 900, loss = 0.65 (0.009 sec/batch)\n",
      "epoch 6, step 650 / 900, loss = 0.90 (0.007 sec/batch)\n",
      "epoch 6, step 700 / 900, loss = 0.72 (0.008 sec/batch)\n",
      "epoch 6, step 750 / 900, loss = 0.61 (0.009 sec/batch)\n",
      "epoch 6, step 800 / 900, loss = 0.68 (0.008 sec/batch)\n",
      "epoch 6, step 850 / 900, loss = 0.66 (0.007 sec/batch)\n",
      "epoch 6, step 900 / 900, loss = 0.70 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 76.20\n",
      " avg loss = 0.73\n",
      "\n",
      "Validation error:\n",
      " accuracy = 69.12\n",
      " avg loss = 0.92\n",
      "\n",
      "Epoch time: 9.521225452423096\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 7, step 50 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 7, step 100 / 900, loss = 0.56 (0.007 sec/batch)\n",
      "epoch 7, step 150 / 900, loss = 0.80 (0.009 sec/batch)\n",
      "epoch 7, step 200 / 900, loss = 0.72 (0.007 sec/batch)\n",
      "epoch 7, step 250 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "epoch 7, step 300 / 900, loss = 0.69 (0.009 sec/batch)\n",
      "epoch 7, step 350 / 900, loss = 0.73 (0.018 sec/batch)\n",
      "epoch 7, step 400 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 7, step 450 / 900, loss = 0.49 (0.007 sec/batch)\n",
      "epoch 7, step 500 / 900, loss = 0.99 (0.006 sec/batch)\n",
      "epoch 7, step 550 / 900, loss = 0.69 (0.009 sec/batch)\n",
      "epoch 7, step 600 / 900, loss = 0.58 (0.006 sec/batch)\n",
      "epoch 7, step 650 / 900, loss = 0.72 (0.007 sec/batch)\n",
      "epoch 7, step 700 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 7, step 750 / 900, loss = 1.07 (0.007 sec/batch)\n",
      "epoch 7, step 800 / 900, loss = 0.68 (0.009 sec/batch)\n",
      "epoch 7, step 850 / 900, loss = 0.98 (0.007 sec/batch)\n",
      "epoch 7, step 900 / 900, loss = 1.02 (0.007 sec/batch)\n",
      "Train error:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy = 77.42\n",
      " avg loss = 0.70\n",
      "\n",
      "Validation error:\n",
      " accuracy = 69.34\n",
      " avg loss = 0.92\n",
      "\n",
      "Epoch time: 9.489799499511719\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 8, step 50 / 900, loss = 0.69 (0.007 sec/batch)\n",
      "epoch 8, step 100 / 900, loss = 0.60 (0.008 sec/batch)\n",
      "epoch 8, step 150 / 900, loss = 0.71 (0.008 sec/batch)\n",
      "epoch 8, step 200 / 900, loss = 0.63 (0.009 sec/batch)\n",
      "epoch 8, step 250 / 900, loss = 0.68 (0.009 sec/batch)\n",
      "epoch 8, step 300 / 900, loss = 0.60 (0.008 sec/batch)\n",
      "epoch 8, step 350 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 8, step 400 / 900, loss = 0.69 (0.006 sec/batch)\n",
      "epoch 8, step 450 / 900, loss = 0.63 (0.007 sec/batch)\n",
      "epoch 8, step 500 / 900, loss = 0.82 (0.006 sec/batch)\n",
      "epoch 8, step 550 / 900, loss = 0.75 (0.006 sec/batch)\n",
      "epoch 8, step 600 / 900, loss = 0.54 (0.006 sec/batch)\n",
      "epoch 8, step 650 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "epoch 8, step 700 / 900, loss = 0.88 (0.008 sec/batch)\n",
      "epoch 8, step 750 / 900, loss = 0.73 (0.006 sec/batch)\n",
      "epoch 8, step 800 / 900, loss = 0.54 (0.008 sec/batch)\n",
      "epoch 8, step 850 / 900, loss = 0.97 (0.006 sec/batch)\n",
      "epoch 8, step 900 / 900, loss = 0.63 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 78.80\n",
      " avg loss = 0.66\n",
      "\n",
      "Validation error:\n",
      " accuracy = 69.70\n",
      " avg loss = 0.90\n",
      "\n",
      "Epoch time: 9.450426816940308\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 9, step 50 / 900, loss = 0.49 (0.006 sec/batch)\n",
      "epoch 9, step 100 / 900, loss = 0.65 (0.008 sec/batch)\n",
      "epoch 9, step 150 / 900, loss = 0.76 (0.012 sec/batch)\n",
      "epoch 9, step 200 / 900, loss = 0.71 (0.007 sec/batch)\n",
      "epoch 9, step 250 / 900, loss = 0.68 (0.007 sec/batch)\n",
      "epoch 9, step 300 / 900, loss = 0.62 (0.011 sec/batch)\n",
      "epoch 9, step 350 / 900, loss = 0.62 (0.007 sec/batch)\n",
      "epoch 9, step 400 / 900, loss = 0.61 (0.007 sec/batch)\n",
      "epoch 9, step 450 / 900, loss = 0.61 (0.006 sec/batch)\n",
      "epoch 9, step 500 / 900, loss = 0.70 (0.008 sec/batch)\n",
      "epoch 9, step 550 / 900, loss = 0.66 (0.006 sec/batch)\n",
      "epoch 9, step 600 / 900, loss = 0.66 (0.008 sec/batch)\n",
      "epoch 9, step 650 / 900, loss = 0.79 (0.006 sec/batch)\n",
      "epoch 9, step 700 / 900, loss = 0.68 (0.009 sec/batch)\n",
      "epoch 9, step 750 / 900, loss = 0.58 (0.007 sec/batch)\n",
      "epoch 9, step 800 / 900, loss = 0.61 (0.009 sec/batch)\n",
      "epoch 9, step 850 / 900, loss = 0.55 (0.007 sec/batch)\n",
      "epoch 9, step 900 / 900, loss = 0.72 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 79.78\n",
      " avg loss = 0.64\n",
      "\n",
      "Validation error:\n",
      " accuracy = 70.56\n",
      " avg loss = 0.89\n",
      "\n",
      "Epoch time: 9.400395393371582\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 10, step 50 / 900, loss = 0.58 (0.008 sec/batch)\n",
      "epoch 10, step 100 / 900, loss = 0.69 (0.007 sec/batch)\n",
      "epoch 10, step 150 / 900, loss = 0.42 (0.009 sec/batch)\n",
      "epoch 10, step 200 / 900, loss = 0.42 (0.008 sec/batch)\n",
      "epoch 10, step 250 / 900, loss = 0.52 (0.009 sec/batch)\n",
      "epoch 10, step 300 / 900, loss = 0.75 (0.007 sec/batch)\n",
      "epoch 10, step 350 / 900, loss = 0.69 (0.007 sec/batch)\n",
      "epoch 10, step 400 / 900, loss = 0.64 (0.006 sec/batch)\n",
      "epoch 10, step 450 / 900, loss = 0.60 (0.006 sec/batch)\n",
      "epoch 10, step 500 / 900, loss = 0.77 (0.009 sec/batch)\n",
      "epoch 10, step 550 / 900, loss = 0.58 (0.007 sec/batch)\n",
      "epoch 10, step 600 / 900, loss = 0.43 (0.008 sec/batch)\n",
      "epoch 10, step 650 / 900, loss = 0.61 (0.007 sec/batch)\n",
      "epoch 10, step 700 / 900, loss = 0.58 (0.009 sec/batch)\n",
      "epoch 10, step 750 / 900, loss = 0.83 (0.007 sec/batch)\n",
      "epoch 10, step 800 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "epoch 10, step 850 / 900, loss = 0.68 (0.006 sec/batch)\n",
      "epoch 10, step 900 / 900, loss = 0.64 (0.009 sec/batch)\n",
      "Train error:\n",
      " accuracy = 81.19\n",
      " avg loss = 0.60\n",
      "\n",
      "Validation error:\n",
      " accuracy = 70.86\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.494818925857544\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 11, step 50 / 900, loss = 0.60 (0.010 sec/batch)\n",
      "epoch 11, step 100 / 900, loss = 0.66 (0.013 sec/batch)\n",
      "epoch 11, step 150 / 900, loss = 0.65 (0.007 sec/batch)\n",
      "epoch 11, step 200 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 11, step 250 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 11, step 300 / 900, loss = 0.44 (0.009 sec/batch)\n",
      "epoch 11, step 350 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 11, step 400 / 900, loss = 0.64 (0.008 sec/batch)\n",
      "epoch 11, step 450 / 900, loss = 0.62 (0.006 sec/batch)\n",
      "epoch 11, step 500 / 900, loss = 0.45 (0.008 sec/batch)\n",
      "epoch 11, step 550 / 900, loss = 0.87 (0.007 sec/batch)\n",
      "epoch 11, step 600 / 900, loss = 0.67 (0.007 sec/batch)\n",
      "epoch 11, step 650 / 900, loss = 0.58 (0.009 sec/batch)\n",
      "epoch 11, step 700 / 900, loss = 0.65 (0.007 sec/batch)\n",
      "epoch 11, step 750 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 11, step 800 / 900, loss = 0.63 (0.007 sec/batch)\n",
      "epoch 11, step 850 / 900, loss = 0.54 (0.008 sec/batch)\n",
      "epoch 11, step 900 / 900, loss = 0.65 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 81.22\n",
      " avg loss = 0.59\n",
      "\n",
      "Validation error:\n",
      " accuracy = 70.78\n",
      " avg loss = 0.89\n",
      "\n",
      "Epoch time: 9.557794570922852\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 12, step 50 / 900, loss = 0.58 (0.008 sec/batch)\n",
      "epoch 12, step 100 / 900, loss = 0.63 (0.007 sec/batch)\n",
      "epoch 12, step 150 / 900, loss = 0.47 (0.006 sec/batch)\n",
      "epoch 12, step 200 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 12, step 250 / 900, loss = 0.64 (0.007 sec/batch)\n",
      "epoch 12, step 300 / 900, loss = 0.48 (0.006 sec/batch)\n",
      "epoch 12, step 350 / 900, loss = 0.71 (0.008 sec/batch)\n",
      "epoch 12, step 400 / 900, loss = 0.56 (0.008 sec/batch)\n",
      "epoch 12, step 450 / 900, loss = 0.55 (0.007 sec/batch)\n",
      "epoch 12, step 500 / 900, loss = 0.40 (0.006 sec/batch)\n",
      "epoch 12, step 550 / 900, loss = 0.44 (0.009 sec/batch)\n",
      "epoch 12, step 600 / 900, loss = 0.66 (0.006 sec/batch)\n",
      "epoch 12, step 650 / 900, loss = 0.87 (0.007 sec/batch)\n",
      "epoch 12, step 700 / 900, loss = 0.77 (0.007 sec/batch)\n",
      "epoch 12, step 750 / 900, loss = 0.66 (0.009 sec/batch)\n",
      "epoch 12, step 800 / 900, loss = 0.47 (0.009 sec/batch)\n",
      "epoch 12, step 850 / 900, loss = 0.58 (0.008 sec/batch)\n",
      "epoch 12, step 900 / 900, loss = 0.32 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 82.40\n",
      " avg loss = 0.56\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.50\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.441704750061035\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 13, step 50 / 900, loss = 0.42 (0.008 sec/batch)\n",
      "epoch 13, step 100 / 900, loss = 0.58 (0.006 sec/batch)\n",
      "epoch 13, step 150 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 13, step 200 / 900, loss = 0.95 (0.007 sec/batch)\n",
      "epoch 13, step 250 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 13, step 300 / 900, loss = 0.42 (0.008 sec/batch)\n",
      "epoch 13, step 350 / 900, loss = 0.70 (0.007 sec/batch)\n",
      "epoch 13, step 400 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "epoch 13, step 450 / 900, loss = 0.63 (0.006 sec/batch)\n",
      "epoch 13, step 500 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 13, step 550 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 13, step 600 / 900, loss = 0.56 (0.006 sec/batch)\n",
      "epoch 13, step 650 / 900, loss = 0.57 (0.006 sec/batch)\n",
      "epoch 13, step 700 / 900, loss = 0.48 (0.008 sec/batch)\n",
      "epoch 13, step 750 / 900, loss = 0.67 (0.007 sec/batch)\n",
      "epoch 13, step 800 / 900, loss = 0.49 (0.007 sec/batch)\n",
      "epoch 13, step 850 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 13, step 900 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 83.20\n",
      " avg loss = 0.54\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.72\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.358803749084473\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 14, step 50 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 14, step 100 / 900, loss = 0.43 (0.006 sec/batch)\n",
      "epoch 14, step 150 / 900, loss = 0.43 (0.008 sec/batch)\n",
      "epoch 14, step 200 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 14, step 250 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "epoch 14, step 300 / 900, loss = 0.61 (0.009 sec/batch)\n",
      "epoch 14, step 350 / 900, loss = 0.50 (0.010 sec/batch)\n",
      "epoch 14, step 400 / 900, loss = 0.66 (0.006 sec/batch)\n",
      "epoch 14, step 450 / 900, loss = 0.82 (0.012 sec/batch)\n",
      "epoch 14, step 500 / 900, loss = 0.67 (0.008 sec/batch)\n",
      "epoch 14, step 550 / 900, loss = 0.34 (0.008 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, step 600 / 900, loss = 0.55 (0.006 sec/batch)\n",
      "epoch 14, step 650 / 900, loss = 0.65 (0.008 sec/batch)\n",
      "epoch 14, step 700 / 900, loss = 0.48 (0.010 sec/batch)\n",
      "epoch 14, step 750 / 900, loss = 0.58 (0.007 sec/batch)\n",
      "epoch 14, step 800 / 900, loss = 0.62 (0.006 sec/batch)\n",
      "epoch 14, step 850 / 900, loss = 0.30 (0.007 sec/batch)\n",
      "epoch 14, step 900 / 900, loss = 0.62 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 83.88\n",
      " avg loss = 0.53\n",
      "\n",
      "Validation error:\n",
      " accuracy = 72.06\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.401389122009277\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 15, step 50 / 900, loss = 0.39 (0.007 sec/batch)\n",
      "epoch 15, step 100 / 900, loss = 0.73 (0.006 sec/batch)\n",
      "epoch 15, step 150 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 15, step 200 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "epoch 15, step 250 / 900, loss = 0.61 (0.007 sec/batch)\n",
      "epoch 15, step 300 / 900, loss = 0.27 (0.007 sec/batch)\n",
      "epoch 15, step 350 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 15, step 400 / 900, loss = 0.64 (0.007 sec/batch)\n",
      "epoch 15, step 450 / 900, loss = 0.36 (0.007 sec/batch)\n",
      "epoch 15, step 500 / 900, loss = 0.57 (0.006 sec/batch)\n",
      "epoch 15, step 550 / 900, loss = 0.49 (0.007 sec/batch)\n",
      "epoch 15, step 600 / 900, loss = 0.56 (0.006 sec/batch)\n",
      "epoch 15, step 650 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "epoch 15, step 700 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 15, step 750 / 900, loss = 0.65 (0.007 sec/batch)\n",
      "epoch 15, step 800 / 900, loss = 0.50 (0.009 sec/batch)\n",
      "epoch 15, step 850 / 900, loss = 0.31 (0.006 sec/batch)\n",
      "epoch 15, step 900 / 900, loss = 0.61 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 84.31\n",
      " avg loss = 0.51\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.02\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.377566576004028\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 16, step 50 / 900, loss = 0.67 (0.006 sec/batch)\n",
      "epoch 16, step 100 / 900, loss = 0.65 (0.007 sec/batch)\n",
      "epoch 16, step 150 / 900, loss = 0.59 (0.007 sec/batch)\n",
      "epoch 16, step 200 / 900, loss = 0.34 (0.012 sec/batch)\n",
      "epoch 16, step 250 / 900, loss = 0.54 (0.006 sec/batch)\n",
      "epoch 16, step 300 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 16, step 350 / 900, loss = 0.66 (0.007 sec/batch)\n",
      "epoch 16, step 400 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "epoch 16, step 450 / 900, loss = 0.49 (0.006 sec/batch)\n",
      "epoch 16, step 500 / 900, loss = 0.36 (0.008 sec/batch)\n",
      "epoch 16, step 550 / 900, loss = 0.42 (0.009 sec/batch)\n",
      "epoch 16, step 600 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 16, step 650 / 900, loss = 0.58 (0.007 sec/batch)\n",
      "epoch 16, step 700 / 900, loss = 0.68 (0.007 sec/batch)\n",
      "epoch 16, step 750 / 900, loss = 0.63 (0.007 sec/batch)\n",
      "epoch 16, step 800 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 16, step 850 / 900, loss = 0.55 (0.011 sec/batch)\n",
      "epoch 16, step 900 / 900, loss = 0.73 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 84.79\n",
      " avg loss = 0.50\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.90\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.393240213394165\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 17, step 50 / 900, loss = 0.35 (0.006 sec/batch)\n",
      "epoch 17, step 100 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 17, step 150 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 17, step 200 / 900, loss = 0.61 (0.008 sec/batch)\n",
      "epoch 17, step 250 / 900, loss = 0.73 (0.006 sec/batch)\n",
      "epoch 17, step 300 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 17, step 350 / 900, loss = 0.58 (0.008 sec/batch)\n",
      "epoch 17, step 400 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "epoch 17, step 450 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 17, step 500 / 900, loss = 0.45 (0.008 sec/batch)\n",
      "epoch 17, step 550 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 17, step 600 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 17, step 650 / 900, loss = 0.46 (0.009 sec/batch)\n",
      "epoch 17, step 700 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 17, step 750 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 17, step 800 / 900, loss = 0.45 (0.009 sec/batch)\n",
      "epoch 17, step 850 / 900, loss = 0.33 (0.009 sec/batch)\n",
      "epoch 17, step 900 / 900, loss = 0.42 (0.010 sec/batch)\n",
      "Train error:\n",
      " accuracy = 85.28\n",
      " avg loss = 0.49\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.96\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.535875797271729\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 18, step 50 / 900, loss = 0.55 (0.007 sec/batch)\n",
      "epoch 18, step 100 / 900, loss = 0.72 (0.007 sec/batch)\n",
      "epoch 18, step 150 / 900, loss = 0.58 (0.007 sec/batch)\n",
      "epoch 18, step 200 / 900, loss = 0.33 (0.006 sec/batch)\n",
      "epoch 18, step 250 / 900, loss = 0.57 (0.008 sec/batch)\n",
      "epoch 18, step 300 / 900, loss = 0.57 (0.008 sec/batch)\n",
      "epoch 18, step 350 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 18, step 400 / 900, loss = 0.40 (0.006 sec/batch)\n",
      "epoch 18, step 450 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 18, step 500 / 900, loss = 0.38 (0.007 sec/batch)\n",
      "epoch 18, step 550 / 900, loss = 0.68 (0.007 sec/batch)\n",
      "epoch 18, step 600 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 18, step 650 / 900, loss = 0.57 (0.006 sec/batch)\n",
      "epoch 18, step 700 / 900, loss = 0.47 (0.006 sec/batch)\n",
      "epoch 18, step 750 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 18, step 800 / 900, loss = 0.46 (0.007 sec/batch)\n",
      "epoch 18, step 850 / 900, loss = 0.56 (0.007 sec/batch)\n",
      "epoch 18, step 900 / 900, loss = 0.68 (0.009 sec/batch)\n",
      "Train error:\n",
      " accuracy = 85.48\n",
      " avg loss = 0.48\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.76\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.514918804168701\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 19, step 50 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 19, step 100 / 900, loss = 0.39 (0.007 sec/batch)\n",
      "epoch 19, step 150 / 900, loss = 0.48 (0.009 sec/batch)\n",
      "epoch 19, step 200 / 900, loss = 0.64 (0.009 sec/batch)\n",
      "epoch 19, step 250 / 900, loss = 0.38 (0.006 sec/batch)\n",
      "epoch 19, step 300 / 900, loss = 0.56 (0.009 sec/batch)\n",
      "epoch 19, step 350 / 900, loss = 0.56 (0.007 sec/batch)\n",
      "epoch 19, step 400 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 19, step 450 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 19, step 500 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 19, step 550 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 19, step 600 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 19, step 650 / 900, loss = 0.61 (0.008 sec/batch)\n",
      "epoch 19, step 700 / 900, loss = 0.45 (0.008 sec/batch)\n",
      "epoch 19, step 750 / 900, loss = 0.39 (0.009 sec/batch)\n",
      "epoch 19, step 800 / 900, loss = 0.43 (0.006 sec/batch)\n",
      "epoch 19, step 850 / 900, loss = 0.43 (0.007 sec/batch)\n",
      "epoch 19, step 900 / 900, loss = 0.59 (0.009 sec/batch)\n",
      "Train error:\n",
      " accuracy = 85.98\n",
      " avg loss = 0.48\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.80\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.440505743026733\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 20, step 50 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 20, step 100 / 900, loss = 0.46 (0.008 sec/batch)\n",
      "epoch 20, step 150 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 20, step 200 / 900, loss = 0.58 (0.008 sec/batch)\n",
      "epoch 20, step 250 / 900, loss = 0.39 (0.008 sec/batch)\n",
      "epoch 20, step 300 / 900, loss = 0.46 (0.009 sec/batch)\n",
      "epoch 20, step 350 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 20, step 400 / 900, loss = 0.47 (0.008 sec/batch)\n",
      "epoch 20, step 450 / 900, loss = 0.54 (0.008 sec/batch)\n",
      "epoch 20, step 500 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 20, step 550 / 900, loss = 0.35 (0.007 sec/batch)\n",
      "epoch 20, step 600 / 900, loss = 0.72 (0.007 sec/batch)\n",
      "epoch 20, step 650 / 900, loss = 0.43 (0.008 sec/batch)\n",
      "epoch 20, step 700 / 900, loss = 0.49 (0.006 sec/batch)\n",
      "epoch 20, step 750 / 900, loss = 0.47 (0.008 sec/batch)\n",
      "epoch 20, step 800 / 900, loss = 0.56 (0.007 sec/batch)\n",
      "epoch 20, step 850 / 900, loss = 0.55 (0.008 sec/batch)\n",
      "epoch 20, step 900 / 900, loss = 0.54 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.20\n",
      " avg loss = 0.47\n",
      "\n",
      "Validation error:\n",
      " accuracy = 72.06\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.406922578811646\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 21, step 50 / 900, loss = 0.61 (0.008 sec/batch)\n",
      "epoch 21, step 100 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 21, step 150 / 900, loss = 0.51 (0.008 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, step 200 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "epoch 21, step 250 / 900, loss = 0.55 (0.011 sec/batch)\n",
      "epoch 21, step 300 / 900, loss = 0.32 (0.006 sec/batch)\n",
      "epoch 21, step 350 / 900, loss = 0.34 (0.006 sec/batch)\n",
      "epoch 21, step 400 / 900, loss = 0.60 (0.008 sec/batch)\n",
      "epoch 21, step 450 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 21, step 500 / 900, loss = 0.53 (0.008 sec/batch)\n",
      "epoch 21, step 550 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "epoch 21, step 600 / 900, loss = 0.46 (0.007 sec/batch)\n",
      "epoch 21, step 650 / 900, loss = 0.47 (0.008 sec/batch)\n",
      "epoch 21, step 700 / 900, loss = 0.57 (0.008 sec/batch)\n",
      "epoch 21, step 750 / 900, loss = 0.33 (0.006 sec/batch)\n",
      "epoch 21, step 800 / 900, loss = 0.39 (0.007 sec/batch)\n",
      "epoch 21, step 850 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 21, step 900 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.26\n",
      " avg loss = 0.46\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.64\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.465367555618286\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 22, step 50 / 900, loss = 0.41 (0.008 sec/batch)\n",
      "epoch 22, step 100 / 900, loss = 0.39 (0.007 sec/batch)\n",
      "epoch 22, step 150 / 900, loss = 0.49 (0.006 sec/batch)\n",
      "epoch 22, step 200 / 900, loss = 0.45 (0.013 sec/batch)\n",
      "epoch 22, step 250 / 900, loss = 0.24 (0.009 sec/batch)\n",
      "epoch 22, step 300 / 900, loss = 0.26 (0.008 sec/batch)\n",
      "epoch 22, step 350 / 900, loss = 0.56 (0.008 sec/batch)\n",
      "epoch 22, step 400 / 900, loss = 0.42 (0.009 sec/batch)\n",
      "epoch 22, step 450 / 900, loss = 0.49 (0.006 sec/batch)\n",
      "epoch 22, step 500 / 900, loss = 0.61 (0.007 sec/batch)\n",
      "epoch 22, step 550 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 22, step 600 / 900, loss = 0.38 (0.008 sec/batch)\n",
      "epoch 22, step 650 / 900, loss = 0.84 (0.008 sec/batch)\n",
      "epoch 22, step 700 / 900, loss = 0.50 (0.009 sec/batch)\n",
      "epoch 22, step 750 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 22, step 800 / 900, loss = 0.54 (0.009 sec/batch)\n",
      "epoch 22, step 850 / 900, loss = 0.33 (0.007 sec/batch)\n",
      "epoch 22, step 900 / 900, loss = 0.49 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 86.79\n",
      " avg loss = 0.46\n",
      "\n",
      "Validation error:\n",
      " accuracy = 72.00\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.41845154762268\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 23, step 50 / 900, loss = 0.35 (0.007 sec/batch)\n",
      "epoch 23, step 100 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 23, step 150 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 23, step 200 / 900, loss = 0.71 (0.006 sec/batch)\n",
      "epoch 23, step 250 / 900, loss = 0.53 (0.009 sec/batch)\n",
      "epoch 23, step 300 / 900, loss = 0.49 (0.009 sec/batch)\n",
      "epoch 23, step 350 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 23, step 400 / 900, loss = 0.38 (0.006 sec/batch)\n",
      "epoch 23, step 450 / 900, loss = 0.36 (0.009 sec/batch)\n",
      "epoch 23, step 500 / 900, loss = 0.45 (0.008 sec/batch)\n",
      "epoch 23, step 550 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 23, step 600 / 900, loss = 0.34 (0.006 sec/batch)\n",
      "epoch 23, step 650 / 900, loss = 0.33 (0.006 sec/batch)\n",
      "epoch 23, step 700 / 900, loss = 0.34 (0.008 sec/batch)\n",
      "epoch 23, step 750 / 900, loss = 0.35 (0.008 sec/batch)\n",
      "epoch 23, step 800 / 900, loss = 0.49 (0.006 sec/batch)\n",
      "epoch 23, step 850 / 900, loss = 0.72 (0.006 sec/batch)\n",
      "epoch 23, step 900 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.03\n",
      " avg loss = 0.45\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.96\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.460394144058228\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 24, step 50 / 900, loss = 0.56 (0.006 sec/batch)\n",
      "epoch 24, step 100 / 900, loss = 0.46 (0.008 sec/batch)\n",
      "epoch 24, step 150 / 900, loss = 0.38 (0.010 sec/batch)\n",
      "epoch 24, step 200 / 900, loss = 0.67 (0.007 sec/batch)\n",
      "epoch 24, step 250 / 900, loss = 0.30 (0.008 sec/batch)\n",
      "epoch 24, step 300 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 24, step 350 / 900, loss = 0.64 (0.007 sec/batch)\n",
      "epoch 24, step 400 / 900, loss = 0.49 (0.007 sec/batch)\n",
      "epoch 24, step 450 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "epoch 24, step 500 / 900, loss = 0.48 (0.009 sec/batch)\n",
      "epoch 24, step 550 / 900, loss = 0.32 (0.009 sec/batch)\n",
      "epoch 24, step 600 / 900, loss = 0.34 (0.010 sec/batch)\n",
      "epoch 24, step 650 / 900, loss = 0.46 (0.007 sec/batch)\n",
      "epoch 24, step 700 / 900, loss = 0.51 (0.008 sec/batch)\n",
      "epoch 24, step 750 / 900, loss = 0.36 (0.007 sec/batch)\n",
      "epoch 24, step 800 / 900, loss = 0.46 (0.007 sec/batch)\n",
      "epoch 24, step 850 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 24, step 900 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.07\n",
      " avg loss = 0.45\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.60\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.38111138343811\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 25, step 50 / 900, loss = 0.39 (0.006 sec/batch)\n",
      "epoch 25, step 100 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "epoch 25, step 150 / 900, loss = 0.39 (0.006 sec/batch)\n",
      "epoch 25, step 200 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 25, step 250 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 25, step 300 / 900, loss = 0.34 (0.006 sec/batch)\n",
      "epoch 25, step 350 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 25, step 400 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 25, step 450 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 25, step 500 / 900, loss = 0.56 (0.008 sec/batch)\n",
      "epoch 25, step 550 / 900, loss = 0.68 (0.013 sec/batch)\n",
      "epoch 25, step 600 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "epoch 25, step 650 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "epoch 25, step 700 / 900, loss = 0.29 (0.006 sec/batch)\n",
      "epoch 25, step 750 / 900, loss = 0.28 (0.007 sec/batch)\n",
      "epoch 25, step 800 / 900, loss = 0.57 (0.008 sec/batch)\n",
      "epoch 25, step 850 / 900, loss = 0.48 (0.008 sec/batch)\n",
      "epoch 25, step 900 / 900, loss = 0.57 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.28\n",
      " avg loss = 0.44\n",
      "\n",
      "Validation error:\n",
      " accuracy = 72.14\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.35793662071228\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 26, step 50 / 900, loss = 0.62 (0.007 sec/batch)\n",
      "epoch 26, step 100 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 26, step 150 / 900, loss = 0.44 (0.009 sec/batch)\n",
      "epoch 26, step 200 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 26, step 250 / 900, loss = 0.34 (0.006 sec/batch)\n",
      "epoch 26, step 300 / 900, loss = 0.49 (0.007 sec/batch)\n",
      "epoch 26, step 350 / 900, loss = 0.62 (0.010 sec/batch)\n",
      "epoch 26, step 400 / 900, loss = 0.41 (0.009 sec/batch)\n",
      "epoch 26, step 450 / 900, loss = 0.35 (0.012 sec/batch)\n",
      "epoch 26, step 500 / 900, loss = 0.36 (0.006 sec/batch)\n",
      "epoch 26, step 550 / 900, loss = 0.64 (0.006 sec/batch)\n",
      "epoch 26, step 600 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 26, step 650 / 900, loss = 0.49 (0.008 sec/batch)\n",
      "epoch 26, step 700 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "epoch 26, step 750 / 900, loss = 0.55 (0.007 sec/batch)\n",
      "epoch 26, step 800 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "epoch 26, step 850 / 900, loss = 0.40 (0.009 sec/batch)\n",
      "epoch 26, step 900 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.38\n",
      " avg loss = 0.44\n",
      "\n",
      "Validation error:\n",
      " accuracy = 72.04\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.382044315338135\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 27, step 50 / 900, loss = 0.43 (0.008 sec/batch)\n",
      "epoch 27, step 100 / 900, loss = 0.46 (0.008 sec/batch)\n",
      "epoch 27, step 150 / 900, loss = 0.47 (0.009 sec/batch)\n",
      "epoch 27, step 200 / 900, loss = 0.43 (0.007 sec/batch)\n",
      "epoch 27, step 250 / 900, loss = 0.52 (0.008 sec/batch)\n",
      "epoch 27, step 300 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "epoch 27, step 350 / 900, loss = 0.35 (0.007 sec/batch)\n",
      "epoch 27, step 400 / 900, loss = 0.53 (0.009 sec/batch)\n",
      "epoch 27, step 450 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 27, step 500 / 900, loss = 0.31 (0.008 sec/batch)\n",
      "epoch 27, step 550 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 27, step 600 / 900, loss = 0.38 (0.006 sec/batch)\n",
      "epoch 27, step 650 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 27, step 700 / 900, loss = 0.28 (0.006 sec/batch)\n",
      "epoch 27, step 750 / 900, loss = 0.58 (0.006 sec/batch)\n",
      "epoch 27, step 800 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 27, step 850 / 900, loss = 0.32 (0.007 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, step 900 / 900, loss = 0.53 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.43\n",
      " avg loss = 0.44\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.98\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.328996181488037\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 28, step 50 / 900, loss = 0.60 (0.010 sec/batch)\n",
      "epoch 28, step 100 / 900, loss = 0.50 (0.009 sec/batch)\n",
      "epoch 28, step 150 / 900, loss = 0.28 (0.006 sec/batch)\n",
      "epoch 28, step 200 / 900, loss = 0.49 (0.008 sec/batch)\n",
      "epoch 28, step 250 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 28, step 300 / 900, loss = 0.44 (0.013 sec/batch)\n",
      "epoch 28, step 350 / 900, loss = 0.39 (0.007 sec/batch)\n",
      "epoch 28, step 400 / 900, loss = 0.57 (0.008 sec/batch)\n",
      "epoch 28, step 450 / 900, loss = 0.56 (0.007 sec/batch)\n",
      "epoch 28, step 500 / 900, loss = 0.53 (0.008 sec/batch)\n",
      "epoch 28, step 550 / 900, loss = 0.45 (0.008 sec/batch)\n",
      "epoch 28, step 600 / 900, loss = 0.33 (0.008 sec/batch)\n",
      "epoch 28, step 650 / 900, loss = 0.42 (0.006 sec/batch)\n",
      "epoch 28, step 700 / 900, loss = 0.40 (0.008 sec/batch)\n",
      "epoch 28, step 750 / 900, loss = 0.51 (0.007 sec/batch)\n",
      "epoch 28, step 800 / 900, loss = 0.42 (0.009 sec/batch)\n",
      "epoch 28, step 850 / 900, loss = 0.49 (0.009 sec/batch)\n",
      "epoch 28, step 900 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.48\n",
      " avg loss = 0.44\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.98\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.358166217803955\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 29, step 50 / 900, loss = 0.36 (0.009 sec/batch)\n",
      "epoch 29, step 100 / 900, loss = 0.58 (0.006 sec/batch)\n",
      "epoch 29, step 150 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 29, step 200 / 900, loss = 0.50 (0.006 sec/batch)\n",
      "epoch 29, step 250 / 900, loss = 0.55 (0.007 sec/batch)\n",
      "epoch 29, step 300 / 900, loss = 0.38 (0.006 sec/batch)\n",
      "epoch 29, step 350 / 900, loss = 0.50 (0.009 sec/batch)\n",
      "epoch 29, step 400 / 900, loss = 0.38 (0.006 sec/batch)\n",
      "epoch 29, step 450 / 900, loss = 0.55 (0.009 sec/batch)\n",
      "epoch 29, step 500 / 900, loss = 0.32 (0.006 sec/batch)\n",
      "epoch 29, step 550 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 29, step 600 / 900, loss = 0.36 (0.007 sec/batch)\n",
      "epoch 29, step 650 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 29, step 700 / 900, loss = 0.32 (0.007 sec/batch)\n",
      "epoch 29, step 750 / 900, loss = 0.43 (0.007 sec/batch)\n",
      "epoch 29, step 800 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 29, step 850 / 900, loss = 0.28 (0.007 sec/batch)\n",
      "epoch 29, step 900 / 900, loss = 0.38 (0.012 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.64\n",
      " avg loss = 0.43\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.86\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.328883171081543\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 30, step 50 / 900, loss = 0.51 (0.010 sec/batch)\n",
      "epoch 30, step 100 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 30, step 150 / 900, loss = 0.36 (0.008 sec/batch)\n",
      "epoch 30, step 200 / 900, loss = 0.55 (0.007 sec/batch)\n",
      "epoch 30, step 250 / 900, loss = 0.25 (0.008 sec/batch)\n",
      "epoch 30, step 300 / 900, loss = 0.35 (0.007 sec/batch)\n",
      "epoch 30, step 350 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "epoch 30, step 400 / 900, loss = 0.35 (0.006 sec/batch)\n",
      "epoch 30, step 450 / 900, loss = 0.30 (0.010 sec/batch)\n",
      "epoch 30, step 500 / 900, loss = 0.37 (0.008 sec/batch)\n",
      "epoch 30, step 550 / 900, loss = 0.51 (0.009 sec/batch)\n",
      "epoch 30, step 600 / 900, loss = 0.54 (0.008 sec/batch)\n",
      "epoch 30, step 650 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 30, step 700 / 900, loss = 0.39 (0.009 sec/batch)\n",
      "epoch 30, step 750 / 900, loss = 0.35 (0.008 sec/batch)\n",
      "epoch 30, step 800 / 900, loss = 0.43 (0.008 sec/batch)\n",
      "epoch 30, step 850 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 30, step 900 / 900, loss = 0.27 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.70\n",
      " avg loss = 0.43\n",
      "\n",
      "Validation error:\n",
      " accuracy = 72.08\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.411394357681274\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 31, step 50 / 900, loss = 0.29 (0.012 sec/batch)\n",
      "epoch 31, step 100 / 900, loss = 0.38 (0.006 sec/batch)\n",
      "epoch 31, step 150 / 900, loss = 0.48 (0.006 sec/batch)\n",
      "epoch 31, step 200 / 900, loss = 0.32 (0.006 sec/batch)\n",
      "epoch 31, step 250 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 31, step 300 / 900, loss = 0.31 (0.008 sec/batch)\n",
      "epoch 31, step 350 / 900, loss = 0.29 (0.009 sec/batch)\n",
      "epoch 31, step 400 / 900, loss = 0.47 (0.011 sec/batch)\n",
      "epoch 31, step 450 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 31, step 500 / 900, loss = 0.46 (0.009 sec/batch)\n",
      "epoch 31, step 550 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 31, step 600 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 31, step 650 / 900, loss = 0.31 (0.007 sec/batch)\n",
      "epoch 31, step 700 / 900, loss = 0.44 (0.006 sec/batch)\n",
      "epoch 31, step 750 / 900, loss = 0.45 (0.008 sec/batch)\n",
      "epoch 31, step 800 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 31, step 850 / 900, loss = 0.32 (0.013 sec/batch)\n",
      "epoch 31, step 900 / 900, loss = 0.62 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.72\n",
      " avg loss = 0.43\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.86\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.363265037536621\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 32, step 50 / 900, loss = 0.39 (0.008 sec/batch)\n",
      "epoch 32, step 100 / 900, loss = 0.48 (0.006 sec/batch)\n",
      "epoch 32, step 150 / 900, loss = 0.49 (0.007 sec/batch)\n",
      "epoch 32, step 200 / 900, loss = 0.46 (0.008 sec/batch)\n",
      "epoch 32, step 250 / 900, loss = 0.41 (0.008 sec/batch)\n",
      "epoch 32, step 300 / 900, loss = 0.39 (0.006 sec/batch)\n",
      "epoch 32, step 350 / 900, loss = 0.29 (0.008 sec/batch)\n",
      "epoch 32, step 400 / 900, loss = 0.46 (0.011 sec/batch)\n",
      "epoch 32, step 450 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "epoch 32, step 500 / 900, loss = 0.32 (0.007 sec/batch)\n",
      "epoch 32, step 550 / 900, loss = 0.27 (0.009 sec/batch)\n",
      "epoch 32, step 600 / 900, loss = 0.39 (0.012 sec/batch)\n",
      "epoch 32, step 650 / 900, loss = 0.46 (0.008 sec/batch)\n",
      "epoch 32, step 700 / 900, loss = 0.25 (0.006 sec/batch)\n",
      "epoch 32, step 750 / 900, loss = 0.36 (0.006 sec/batch)\n",
      "epoch 32, step 800 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 32, step 850 / 900, loss = 0.35 (0.010 sec/batch)\n",
      "epoch 32, step 900 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.86\n",
      " avg loss = 0.43\n",
      "\n",
      "Validation error:\n",
      " accuracy = 72.12\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.34594464302063\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 33, step 50 / 900, loss = 0.36 (0.008 sec/batch)\n",
      "epoch 33, step 100 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 33, step 150 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 33, step 200 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 33, step 250 / 900, loss = 0.44 (0.009 sec/batch)\n",
      "epoch 33, step 300 / 900, loss = 0.55 (0.008 sec/batch)\n",
      "epoch 33, step 350 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 33, step 400 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 33, step 450 / 900, loss = 0.36 (0.006 sec/batch)\n",
      "epoch 33, step 500 / 900, loss = 0.60 (0.006 sec/batch)\n",
      "epoch 33, step 550 / 900, loss = 0.41 (0.009 sec/batch)\n",
      "epoch 33, step 600 / 900, loss = 0.33 (0.007 sec/batch)\n",
      "epoch 33, step 650 / 900, loss = 0.47 (0.008 sec/batch)\n",
      "epoch 33, step 700 / 900, loss = 0.27 (0.008 sec/batch)\n",
      "epoch 33, step 750 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "epoch 33, step 800 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 33, step 850 / 900, loss = 0.33 (0.008 sec/batch)\n",
      "epoch 33, step 900 / 900, loss = 0.43 (0.009 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.83\n",
      " avg loss = 0.43\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.96\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.381444692611694\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 34, step 50 / 900, loss = 0.29 (0.008 sec/batch)\n",
      "epoch 34, step 100 / 900, loss = 0.51 (0.009 sec/batch)\n",
      "epoch 34, step 150 / 900, loss = 0.46 (0.006 sec/batch)\n",
      "epoch 34, step 200 / 900, loss = 0.38 (0.009 sec/batch)\n",
      "epoch 34, step 250 / 900, loss = 0.62 (0.006 sec/batch)\n",
      "epoch 34, step 300 / 900, loss = 0.34 (0.008 sec/batch)\n",
      "epoch 34, step 350 / 900, loss = 0.34 (0.008 sec/batch)\n",
      "epoch 34, step 400 / 900, loss = 0.55 (0.007 sec/batch)\n",
      "epoch 34, step 450 / 900, loss = 0.41 (0.007 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, step 500 / 900, loss = 0.28 (0.008 sec/batch)\n",
      "epoch 34, step 550 / 900, loss = 0.40 (0.009 sec/batch)\n",
      "epoch 34, step 600 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 34, step 650 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 34, step 700 / 900, loss = 0.44 (0.008 sec/batch)\n",
      "epoch 34, step 750 / 900, loss = 0.49 (0.008 sec/batch)\n",
      "epoch 34, step 800 / 900, loss = 0.28 (0.007 sec/batch)\n",
      "epoch 34, step 850 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 34, step 900 / 900, loss = 0.47 (0.009 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.95\n",
      " avg loss = 0.43\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.94\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.360340595245361\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 35, step 50 / 900, loss = 0.26 (0.008 sec/batch)\n",
      "epoch 35, step 100 / 900, loss = 0.36 (0.006 sec/batch)\n",
      "epoch 35, step 150 / 900, loss = 0.32 (0.008 sec/batch)\n",
      "epoch 35, step 200 / 900, loss = 0.49 (0.007 sec/batch)\n",
      "epoch 35, step 250 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 35, step 300 / 900, loss = 0.33 (0.007 sec/batch)\n",
      "epoch 35, step 350 / 900, loss = 0.36 (0.006 sec/batch)\n",
      "epoch 35, step 400 / 900, loss = 0.34 (0.007 sec/batch)\n",
      "epoch 35, step 450 / 900, loss = 0.47 (0.007 sec/batch)\n",
      "epoch 35, step 500 / 900, loss = 0.43 (0.008 sec/batch)\n",
      "epoch 35, step 550 / 900, loss = 0.40 (0.006 sec/batch)\n",
      "epoch 35, step 600 / 900, loss = 0.40 (0.008 sec/batch)\n",
      "epoch 35, step 650 / 900, loss = 0.36 (0.007 sec/batch)\n",
      "epoch 35, step 700 / 900, loss = 0.44 (0.008 sec/batch)\n",
      "epoch 35, step 750 / 900, loss = 0.31 (0.007 sec/batch)\n",
      "epoch 35, step 800 / 900, loss = 0.43 (0.007 sec/batch)\n",
      "epoch 35, step 850 / 900, loss = 0.37 (0.007 sec/batch)\n",
      "epoch 35, step 900 / 900, loss = 0.33 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.91\n",
      " avg loss = 0.43\n",
      "\n",
      "Validation error:\n",
      " accuracy = 72.10\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.32069182395935\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 36, step 50 / 900, loss = 0.33 (0.007 sec/batch)\n",
      "epoch 36, step 100 / 900, loss = 0.32 (0.007 sec/batch)\n",
      "epoch 36, step 150 / 900, loss = 0.57 (0.008 sec/batch)\n",
      "epoch 36, step 200 / 900, loss = 0.40 (0.008 sec/batch)\n",
      "epoch 36, step 250 / 900, loss = 0.54 (0.006 sec/batch)\n",
      "epoch 36, step 300 / 900, loss = 0.39 (0.012 sec/batch)\n",
      "epoch 36, step 350 / 900, loss = 0.35 (0.006 sec/batch)\n",
      "epoch 36, step 400 / 900, loss = 0.36 (0.006 sec/batch)\n",
      "epoch 36, step 450 / 900, loss = 0.33 (0.009 sec/batch)\n",
      "epoch 36, step 500 / 900, loss = 0.49 (0.007 sec/batch)\n",
      "epoch 36, step 550 / 900, loss = 0.39 (0.009 sec/batch)\n",
      "epoch 36, step 600 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 36, step 650 / 900, loss = 0.27 (0.006 sec/batch)\n",
      "epoch 36, step 700 / 900, loss = 0.31 (0.008 sec/batch)\n",
      "epoch 36, step 750 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "epoch 36, step 800 / 900, loss = 0.28 (0.007 sec/batch)\n",
      "epoch 36, step 850 / 900, loss = 0.51 (0.006 sec/batch)\n",
      "epoch 36, step 900 / 900, loss = 0.34 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.92\n",
      " avg loss = 0.42\n",
      "\n",
      "Validation error:\n",
      " accuracy = 72.00\n",
      " avg loss = 0.88\n",
      "\n",
      "Epoch time: 9.439465045928955\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 37, step 50 / 900, loss = 0.44 (0.010 sec/batch)\n",
      "epoch 37, step 100 / 900, loss = 0.27 (0.007 sec/batch)\n",
      "epoch 37, step 150 / 900, loss = 0.41 (0.007 sec/batch)\n",
      "epoch 37, step 200 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 37, step 250 / 900, loss = 0.72 (0.007 sec/batch)\n",
      "epoch 37, step 300 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 37, step 350 / 900, loss = 0.41 (0.011 sec/batch)\n",
      "epoch 37, step 400 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 37, step 450 / 900, loss = 0.35 (0.006 sec/batch)\n",
      "epoch 37, step 500 / 900, loss = 0.41 (0.006 sec/batch)\n",
      "epoch 37, step 550 / 900, loss = 0.53 (0.007 sec/batch)\n",
      "epoch 37, step 600 / 900, loss = 0.52 (0.007 sec/batch)\n",
      "epoch 37, step 650 / 900, loss = 0.38 (0.007 sec/batch)\n",
      "epoch 37, step 700 / 900, loss = 0.60 (0.008 sec/batch)\n",
      "epoch 37, step 750 / 900, loss = 0.44 (0.012 sec/batch)\n",
      "epoch 37, step 800 / 900, loss = 0.26 (0.009 sec/batch)\n",
      "epoch 37, step 850 / 900, loss = 0.34 (0.007 sec/batch)\n",
      "epoch 37, step 900 / 900, loss = 0.58 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 87.96\n",
      " avg loss = 0.42\n",
      "\n",
      "Validation error:\n",
      " accuracy = 71.98\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.62856650352478\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 38, step 50 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 38, step 100 / 900, loss = 0.66 (0.009 sec/batch)\n",
      "epoch 38, step 150 / 900, loss = 0.54 (0.007 sec/batch)\n",
      "epoch 38, step 200 / 900, loss = 0.33 (0.006 sec/batch)\n",
      "epoch 38, step 250 / 900, loss = 0.40 (0.006 sec/batch)\n",
      "epoch 38, step 300 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 38, step 350 / 900, loss = 0.63 (0.006 sec/batch)\n",
      "epoch 38, step 400 / 900, loss = 0.54 (0.008 sec/batch)\n",
      "epoch 38, step 450 / 900, loss = 0.48 (0.007 sec/batch)\n",
      "epoch 38, step 500 / 900, loss = 0.53 (0.006 sec/batch)\n",
      "epoch 38, step 550 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 38, step 600 / 900, loss = 0.39 (0.007 sec/batch)\n",
      "epoch 38, step 650 / 900, loss = 0.47 (0.006 sec/batch)\n",
      "epoch 38, step 700 / 900, loss = 0.49 (0.013 sec/batch)\n",
      "epoch 38, step 750 / 900, loss = 0.60 (0.007 sec/batch)\n",
      "epoch 38, step 800 / 900, loss = 0.45 (0.006 sec/batch)\n",
      "epoch 38, step 850 / 900, loss = 0.40 (0.007 sec/batch)\n",
      "epoch 38, step 900 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "Train error:\n",
      " accuracy = 88.02\n",
      " avg loss = 0.42\n",
      "\n",
      "Validation error:\n",
      " accuracy = 72.20\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.33177638053894\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 39, step 50 / 900, loss = 0.47 (0.006 sec/batch)\n",
      "epoch 39, step 100 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 39, step 150 / 900, loss = 0.34 (0.006 sec/batch)\n",
      "epoch 39, step 200 / 900, loss = 0.34 (0.007 sec/batch)\n",
      "epoch 39, step 250 / 900, loss = 0.42 (0.008 sec/batch)\n",
      "epoch 39, step 300 / 900, loss = 0.35 (0.006 sec/batch)\n",
      "epoch 39, step 350 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 39, step 400 / 900, loss = 0.34 (0.007 sec/batch)\n",
      "epoch 39, step 450 / 900, loss = 0.47 (0.008 sec/batch)\n",
      "epoch 39, step 500 / 900, loss = 0.49 (0.008 sec/batch)\n",
      "epoch 39, step 550 / 900, loss = 0.50 (0.007 sec/batch)\n",
      "epoch 39, step 600 / 900, loss = 0.49 (0.007 sec/batch)\n",
      "epoch 39, step 650 / 900, loss = 0.48 (0.010 sec/batch)\n",
      "epoch 39, step 700 / 900, loss = 0.52 (0.006 sec/batch)\n",
      "epoch 39, step 750 / 900, loss = 0.42 (0.006 sec/batch)\n",
      "epoch 39, step 800 / 900, loss = 0.47 (0.006 sec/batch)\n",
      "epoch 39, step 850 / 900, loss = 0.55 (0.006 sec/batch)\n",
      "epoch 39, step 900 / 900, loss = 0.34 (0.008 sec/batch)\n",
      "Train error:\n",
      " accuracy = 88.07\n",
      " avg loss = 0.42\n",
      "\n",
      "Validation error:\n",
      " accuracy = 72.12\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.416100263595581\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "epoch 40, step 50 / 900, loss = 0.54 (0.006 sec/batch)\n",
      "epoch 40, step 100 / 900, loss = 0.45 (0.007 sec/batch)\n",
      "epoch 40, step 150 / 900, loss = 0.49 (0.008 sec/batch)\n",
      "epoch 40, step 200 / 900, loss = 0.37 (0.006 sec/batch)\n",
      "epoch 40, step 250 / 900, loss = 0.30 (0.008 sec/batch)\n",
      "epoch 40, step 300 / 900, loss = 0.27 (0.006 sec/batch)\n",
      "epoch 40, step 350 / 900, loss = 0.38 (0.007 sec/batch)\n",
      "epoch 40, step 400 / 900, loss = 0.36 (0.007 sec/batch)\n",
      "epoch 40, step 450 / 900, loss = 0.49 (0.007 sec/batch)\n",
      "epoch 40, step 500 / 900, loss = 0.44 (0.007 sec/batch)\n",
      "epoch 40, step 550 / 900, loss = 0.42 (0.007 sec/batch)\n",
      "epoch 40, step 600 / 900, loss = 0.31 (0.006 sec/batch)\n",
      "epoch 40, step 650 / 900, loss = 0.36 (0.007 sec/batch)\n",
      "epoch 40, step 700 / 900, loss = 0.43 (0.013 sec/batch)\n",
      "epoch 40, step 750 / 900, loss = 0.37 (0.009 sec/batch)\n",
      "epoch 40, step 800 / 900, loss = 0.30 (0.007 sec/batch)\n",
      "epoch 40, step 850 / 900, loss = 0.28 (0.009 sec/batch)\n",
      "epoch 40, step 900 / 900, loss = 0.58 (0.006 sec/batch)\n",
      "Train error:\n",
      " accuracy = 88.02\n",
      " avg loss = 0.42\n",
      "\n",
      "Validation error:\n",
      " accuracy = 72.10\n",
      " avg loss = 0.87\n",
      "\n",
      "Epoch time: 9.320418119430542\n",
      "Plotting in:  C:\\Users\\Korisnik\\Desktop\\du_lab2\\Deep-Learning\\2_lab\\zad4_images\\training_plot.pdf\n",
      "Total train time: 391.99248576164246\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "train_start = time.time()\n",
    "\n",
    "plot_data={}\n",
    "train_cifar(session, train_x, train_y, valid_x, valid_y, config, plot_data)\n",
    "\n",
    "print(\"Total train time:\", time.time() - train_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAHiCAYAAADcelBQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJUl37/204AEO4mlpBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8a2b44a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_progress(plot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSSjYiEgSCjYikoSCjYgkoWAjIkn8f+e0E0lbrqeIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8cce9860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: cat\n",
      "Predictions: ['frog' 'bird' 'dog'] [  9.99975562e-01   1.84183336e-05   2.21035884e-06]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIJhsiCgIJhsiCoLJhoiCYLIhoiD+D6WU8QAqI1uLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8c865320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: truck\n",
      "Predictions: ['dog' 'cat' 'bird'] [ 0.4655984   0.23260756  0.18337156]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8a0d1cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: automobile\n",
      "Predictions: ['truck' 'horse' 'cat'] [  9.99833584e-01   1.34933565e-04   1.82403510e-05]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8c7caa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: truck\n",
      "Predictions: ['bird' 'frog' 'airplane'] [  9.95070934e-01   3.39995022e-03   5.27196738e-04]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyleZHJTLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8bbb1ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: ship\n",
      "Predictions: ['dog' 'horse' 'cat'] [ 0.89723867  0.07807672  0.01602577]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8cd0ca20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: ship\n",
      "Predictions: ['automobile' 'truck' 'airplane'] [  9.75293100e-01   2.37451978e-02   9.44912841e-04]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8bbb8710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: automobile\n",
      "Predictions: ['dog' 'cat' 'horse'] [ 0.7094292   0.23683818  0.04895716]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZKFgIyJZ/B8WoyFjLyYD2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8bea9e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: ship\n",
      "Predictions: ['airplane' 'bird' 'dog'] [ 0.9796896   0.0096837   0.00739191]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8bcbc550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: ship\n",
      "Predictions: ['airplane' 'truck' 'automobile'] [ 0.98922658  0.00726318  0.00324466]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8cd14a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: cat\n",
      "Predictions: ['airplane' 'ship' 'bird'] [ 0.6248529   0.37288868  0.00127298]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8c460668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: bird\n",
      "Predictions: ['dog' 'frog' 'ship'] [ 0.95125693  0.0277505   0.01826219]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSBL/H3/xCcSgYNFJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8bb31eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: ship\n",
      "Predictions: ['horse' 'dog' 'cat'] [ 0.60634363  0.15830515  0.10272072]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8bd11a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: dog\n",
      "Predictions: ['horse' 'deer' 'automobile'] [  8.12025547e-01   1.87293738e-01   3.79140489e-04]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+d3PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17e887b9da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: deer\n",
      "Predictions: ['automobile' 'horse' 'truck'] [  9.98405993e-01   1.11370184e-03   2.27105586e-04]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17e88616438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: deer\n",
      "Predictions: ['dog' 'cat' 'frog'] [ 0.98430204  0.00717602  0.00645544]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17e886fb438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: airplane\n",
      "Predictions: ['frog' 'cat' 'bird'] [ 0.84072846  0.07509656  0.03518334]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8a1cf748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: airplane\n",
      "Predictions: ['truck' 'automobile' 'airplane'] [  9.83287334e-01   1.65471770e-02   8.93738033e-05]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJRsRSeL/AWBqbT38o7GQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17e888e47f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: deer\n",
      "Predictions: ['bird' 'frog' 'airplane'] [ 0.70057923  0.29675242  0.0011694 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f8c226b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: airplane\n",
      "Predictions: ['horse' 'cat' 'deer'] [ 0.96933293  0.02222641  0.00417694]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmGyIKAgmGyIKgsmGiIJgsiGiIP4/aN56M6AIyJ4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17ee9f14128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct class: horse\n",
      "Predictions: ['cat' 'ship' 'bird'] [ 0.66969067  0.23040417  0.09729752]\n"
     ]
    }
   ],
   "source": [
    "worst = worst_samples(session, test_x, test_y, config)\n",
    "\n",
    "for sample_id, l, predicted in worst:\n",
    "    show_image(test_x[sample_id], data_mean, data_std)\n",
    "    probas = session.run(tf.nn.softmax(logits), feed_dict={X: np.array([test_x[sample_id]])})\n",
    "    probas = probas[0]\n",
    "    predictions  = np.argsort(-probas)\n",
    "\n",
    "    print(\"Correct class:\", class_names[test_y[sample_id]])\n",
    "    print(\"Predictions:\", class_names[predictions[:3]], probas[predictions[:3]])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
